# 8.1 周二
* 1、自适应YOLO：恶劣天气下的目标检测（附源代码） https://mp.weixin.qq.com/s/K5GKLW_-BQ1gOD0D-OOU8w
* 2、通俗解构语言大模型的工作原理 OneFlow https://mp.weixin.qq.com/s/21V8g_7teuRgHLWUej1NzA
* 3、放弃Softmax！首个线性注意力Transformer大模型！1750亿参数，速度和精度更优 计算机视觉daily https://mp.weixin.qq.com/s/NEIiFPcLoh0br8GtHoVtPA \
GPT 等大型语言模型（LLM）的成功离不开 Softmax 注意力机制，但这一机制也存在着成本高等一些缺点。\
近日，上海人工智能实验室和 OpenNLPLab 的一个研究团队提出了一种新的大型语言模型 TransNormerLLM，其中完全抛弃了基于 Softmax 的注意力机制，而是使用了新提出的线性注意力。据介绍，TransNormerLLM 是首个基于线性注意力的大型语言模型（LLM），其在准确度和效率方面的表现优于传统的基于 Softmax 注意力的模型。研究者也将发布其预训练模型的开源版本。
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f054c26c-c76f-4062-b635-010ec6a8fea8) \
论文：https://arxiv.org/abs/2307.14995 \
模型：https://github.com/OpenNLPLab/TransnormerLLM

# 8.2 周三
* 4、语言模型做先验，统一强化学习智能体，DeepMind选择走这条通用AI之路 图灵人工智能 https://mp.weixin.qq.com/s/5S7yMkXJn7_FXEoD7py-2w
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8ba7f6e2-311a-4e93-83d5-20e9a88f3bf9)
  论文地址：https://arxiv.org/pdf/2307.09668.pdf
* 5、突破自监督学习效率极限！马毅、LeCun联合发布EMP-SSL：无需花哨trick，30个epoch即可实现SOTA XRer https://mp.weixin.qq.com/s/PcDa3xA8u7pGE0fxHhiMiQ
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6b58d12f-f5a5-4191-9aa6-4d6b9b2b3495)
  论文链接：https://arxiv.org/pdf/2304.03977.pdf \
  代码链接：https://github.com/tsb0601/EMP-SSL
* 6、首发！国内最大Llama开源社区发布首个预训练中文版Llama2 夕小瑶科技说 https://mp.weixin.qq.com/s/JXyPAgJaX4GvvohJO_Nlyw \
  社区链接：https://github.com/FlagAlpha/Llama2-Chinese \
  主打一个中英文自由切换！中文版 开源Llama2 多模态大模型，完全可商用！AINLPer https://mp.weixin.qq.com/s/bqfXtdqKXgVSa0cML6BB-g
* 7、清华等提出新框架：ToolLLM，增强大模型API调用能力，性能堪比ChatGPT！ AINLPer https://mp.weixin.qq.com/s/xRIJX2GOlLw-GF1T0njCDg
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7df32f70-b4fd-4c02-9c94-60d433ed5550)
  论文地址：https://arxiv.org/pdf/2307.16789.pdf \
  项目地址：https://github.com/OpenBMB/ToolBench

# 8.3 周四
* 8、对话华先胜：不迷信大模型，现阶段的革新仍在「交互」 图灵人工智能 https://mp.weixin.qq.com/s/cANJHTBQOIXntJ2Id9B4jg
* 9、谷歌创始人布林重返职场，投入研发AI杀手锏！预计下半年推出下一代通用模型『Gemini』，和OpenAI的终局之战！ 夕小瑶科技说 https://mp.weixin.qq.com/s/jHCbqgp5Do_rjkiTd2Ws_g
* 10、（**重要**）从感知到理解-融合语言模型的多模态大模型研究 PaperWeekly https://mp.weixin.qq.com/s/kpAxiAoOzp9gmdoGHcVzvg
* 11、一些讨论：三张关于大模型微调方案的脑图及几点llama2等行业落地的问题思考 老刘说nlp https://mp.weixin.qq.com/s/ERvWhSlQgStrxNa7wERnHg

# 8.4 周五
* 12、模拟大脑功能，这个AI模型真正实现像人一样持续学习  XRer https://mp.weixin.qq.com/s/lZbOzlwu53CLr1pSFCOpiA
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9b11eb60-0004-4ada-b3cf-1e9dbaf2bff9)
  论文地址：https://onlinelibrary.wiley.com/doi/abs/10.1002/adts.202200226
* 13、CNS 2023｜如何利用大脑智慧，构建类脑智能？ 追问 https://mp.weixin.qq.com/s/rJkBnSICAKNkeFXor7nFpg

# 8.5 周六
* 14、 （**非常重要 Dynalang **）用语言建模世界：UC伯克利多模态世界模型利用语言预测未来 机器之心 https://mp.weixin.qq.com/s/7IwJ7YGq_3HayGh0BwmVNg
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/46456611-5046-4355-bdc5-46e3668fb7b1)
  论文链接：https://arxiv.org/pdf/2308.01399.pdf \
  项目主页：https://dynalang.github.io/ \
  代码链接：https://github.com/jlin816/dynalang
* 15、卷起来了！中文 LLaMA2 的一些工作 Founder Park https://mp.weixin.qq.com/s/JNkA3bQz0lvp3mk6wcbjMw

# 8.6 
