# 12.1 Fri.
* 1、720亿参数大模型都拿来开源了！通义千问开源全家桶，最小18亿模型端侧都能跑  机器之心  https://mp.weixin.qq.com/s/Q7vxpNr3ZUD2rhjQN_qZDA \
  目前，通义千问开源全家桶已经有了 18 亿、70 亿、140 亿、720 亿参数量的 4 款基础开源模型，以及跨语言、图像、语音等多种模态的多款开源模型。
* 2、DeepMind最新研究：这个AI Agent，几分钟学会人类专家行为，登上Nature子刊  图灵人工智能  https://mp.weixin.qq.com/s/uCCRRBwMwznAFy3eAnsKqQ \
  Learning few-shot imitation as cultural transmission \

# 12.2 Sat.
* 3、(**非常重要**)OpenAI最强竞品训练AI拆解LLM黑箱，意外窥见大模型「灵魂」  新智元  https://mp.weixin.qq.com/s/dCUXM2fWGPDizwwR0GZcFQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/30b03985-6659-4a7b-822e-48e32a51733c) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0a3a5113-4d36-40f6-b3b0-ba5e122e02fe) \
  论文地址：https://transformer-circuits.pub/2023/monosemantic-features/index.html#phenomenology-fsa

# 12.3 Sun.
* 4、(**含研究llama2源码和微调的教程，值得深入学习**)Meta教你5步学会用Llama2：我见过最简单的大模型教学  机器之心  https://mp.weixin.qq.com/s/j0dDtR7N0A9f2NwCO5mkMg \
  要了解有关 Llama 2 工作原理、训练方法和所用硬件的更多信息，请参阅 Meta 的论文《Llama 2: Open Foundation and Fine-Tuned Chat Models》，其中对这些方面进行了更详细的介绍。 \
  论文地址：https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/ \
  从 Meta 的 Llama 2 Github repo 获取模型源代码，源代码展示了模型的工作原理以及如何加载 Llama 2 模型和运行推理的最简单示例。在这里还可以找到下载、设置模型的步骤以及运行文本补全和聊天模型的示例。 \
  repo 地址：https://github.com/facebookresearch/llama \
  在模型卡片（中了解模型的更多信息，包括模型架构、预期用途、硬件和软件要求、训练数据、结果和许可证。 \
  卡片地址：https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md \
  在 Meta 的 llama-recipes Github repo 中提供了如何快速开始微调以及如何为微调模型运行推理的示例。 \
  repo 地址：https://github.com/facebookresearch/llama-recipes/ \
  查阅 Meta 最近发布的编码人工智能工具 Code Llama，这是一个建立在 Llama 2 基础上的人工智能模型，针对生成和分析代码的能力进行了微调。 \
  Code Llama 地址：https://about.fb.com/news/2023/08/code-llama-ai-for-coding/ \
  阅读《负责任使用指南》，它提供了以负责任的方式构建由大语言模型 (LLM) 支持的产品的最佳实践和注意事项，涵盖了从开始到部署的各个开发阶段。 \
  指南地址：https://ai.meta.com/llama/responsible-use-guide/
* 5、(**其中用到的世界模型技术值得研究**)驶向未来，首个多视图预测+规划自动驾驶世界模型来了  机器之心  https://mp.weixin.qq.com/s/x_BH6PCS2WwR6zQjngH4LQ \
  Drive-WM 模型通过多视图世界模型，能够想象不同规划路线的未来情景，并根据视觉预测获取相应的奖惩反馈，从而优化当前的路线选择，为自动驾驶系统的安全提供了保障。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2c21834b-d8bb-4f66-b90f-3e186c05c604) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ae3e20fc-ab43-48a7-b18b-9c2650683b08) \
  网站：https://drive-wm.github.io \
  论文链接：https://arxiv.org/abs/2311.17918
* 6、大模型如何重塑对话系统？港中文等最新《基于语言模型的对话系统演化》综述  专知  https://mp.weixin.qq.com/s/OpWx-M9ne7DGvOmdQYrWXA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/83cd8325-862f-465e-bc48-5e61d7ae93da) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/fe7e9efc-dc9f-4302-8bb9-49053e88d6f4) \
* 7、【图宾根大学博士论文】神经场景表示在三维重建和生成建模中的应用  专知  https://mp.weixin.qq.com/s/DaJJFXfzlYs9vHdsrivJ7Q 
* 8、大模型幻觉！人大 & IAAR & 新华社 | 提出幻觉评测基准UHGEval，全面支持中文！  AINLPer  https://mp.weixin.qq.com/s/2wRSdfxEx1E8euNniueSSg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5b4555c2-657f-4104-94b1-9273be5bba03) \
  Paper：https://arxiv.org/abs/2311.15296 \
  Code：https://github.com/IAAR-Shanghai/UHGEval
  
# 12.4 Mon.
* 9、(**有趣**)【LLM/大模型】战争与和平(WarAgent)：基于大模型的世界大战多智能体模拟  无影寺 AI帝国  https://mp.weixin.qq.com/s/iAoovfM4P-c8BzHkzxDIgw \
  论文标题：War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars \
  论文链接：https://arxiv.org/abs/2311.17227
* 10、(**非常重要，LVM（Large Vision Models）**)通用视觉推理显现，UC伯克利炼出单一纯CV大模型，三位资深学者参与  机器之心  https://mp.weixin.qq.com/s/eTG5u03Thznz-8k3h4EW7g \
  计算机视觉GPT时刻！UC伯克利三巨头祭出首个纯CV大模型，推理惊现AGI火花  OpenMMLab  https://mp.weixin.qq.com/s/ClZkoOidr9IgZCbIz9c4Bg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9d10fd2b-a445-45f6-bc4c-d3f731edce38) \
  论文地址：https://arxiv.org/abs/2312.00785 \
  项目主页：https://yutongbai.com/lvm.html
* 11、一键部署Hugging Face模型！LMDeploy与transformers强强联合  OpenMMLab  https://mp.weixin.qq.com/s/_MfuiK1LpoKM7OSleo5TdQ \
* 12、大模型微调！上百次实验的经验总结：不是全局调不起，而是 LoRA更有性价比  AINLPer  https://mp.weixin.qq.com/s/ERkEOGBHce3_mZfaZCnXwA \
  LoRA微调大模型手把手实用教程！  专知  https://mp.weixin.qq.com/s/Oh25-sH22XHkpz_MxgG6hA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/77ecf0b8-df4e-49c8-907e-75491552ef0b) \

# 12.5 Tues.
* 13、量子计算OpenAI来了？前谷歌3人团队融资1亿元，打造AI算力芯片挑战物理极限  新智元  https://mp.weixin.qq.com/s/0E4T9saTl2QV5I2j7nlDnw \
  前谷歌量子计算团队今日宣布融资1410万美元，打造新型AI算力芯片，将根据热力学和信息的第一原理构建人工智能超级计算机，实现能够自我编程的算力芯片。
* 14、112页报告深挖GPT-4V！UCLA等发布全新「多模态数学推理」基准**MathVista**  新智元  https://mp.weixin.qq.com/s/RuC6LCJB_JZAy_SnJjw-WQ \
  <img width="496" alt="1702264967488" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/df28030f-209c-4c1b-96bf-02809d6f1ce8"> \
  论文地址：https://arxiv.org/abs/2310.02255 \
  项目地址：https://mathvista.github.io/ \
  HF数据集：https://huggingface.co/datasets/AI4Math/MathVista \
  数据可视化：https://mathvista.github.io/#visualization \
  Leaderboard：https://mathvista.github.io/#leaderboard \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/912f9dd1-e9f4-4d95-924a-12795e1dc254) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b3c301d5-c920-470b-b1a6-fbf5c864b496)
* 15、(**重要，Mamba，值得深入研究**)颠覆Transformer霸权！CMU普林斯顿推Mamba新架构，解决致命bug推理速度暴增5倍  新智元  https://mp.weixin.qq.com/s/nVilywouNxnZlb-l3Buj3w \
  Transformer挑战者出现！斯坦福CMU联合团队，开源模型及代码，公司已创办  量子位  https://mp.weixin.qq.com/s/WUdZtHCO6AaQqVzyRlB4Bg \
  五倍吞吐量，性能全面包围Transformer：新架构Mamba引爆AI圈  机器学习研究组订阅  https://mp.weixin.qq.com/s/1w98NpCFlviqfoaF4Cbjpg \
  热门！CMU & 普林斯顿 | 提出Mamba新架构，推理速度暴增5倍，完虐Transformer！  AINLPer  https://mp.weixin.qq.com/s/Rixbjx0kENYdD8LN5WZN0w \
  Transformer虽强大，却有一个致命的bug：核心注意力层无法扩展到长期上下文。\
  刚刚，CMU和普林斯顿的研究者发布了Mamba。这种SSM架构在语言建模上与Transformers不相上下，而且还能线性扩展，同时具有5倍的推理吞吐量！\
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/732c058b-938f-48aa-b606-8c0e1c855e5d) \
  论文地址：https://arxiv.org/abs/2312.00752
* 16、【2023新书】理解大型语言模型：学习其基础概念和技术，166页pdf  专知  https://mp.weixin.qq.com/s/WH8l5MMaGoXff091EZ84cw

# 12.6 Wed.

# 12.7 Thur.
* 17、超越GPT-4！谷歌发布最强多模态大模型—Gemini  AIGC开放社区  https://mp.weixin.qq.com/s/tvHCcEMYLu_FWEH6vMW_iQ \
  超越GPT-4？Google 60页《Gemini-高性能多模态大模型》报告，详解技术测试等细节，附中英文版  专知  https://mp.weixin.qq.com/s/2UlC5Tc4Wxz5nDBPnPAjuQ \
  <img width="452" alt="1702266448923" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/975b45b5-6e6a-4df0-b48a-013e8c2bdd07"> \
  Bard地址：https://bard.google.com/chat \
  论文地址：https://goo.gle/GeminiPaper \
  Gemini Pro的API地址：https://cloud.google.com/vertex-ai
* 18、(**模型结构很有趣**)视觉模型+大语言模型：首个支持10K+帧长视频理解任务的新型框架  PaperWeekly  https://mp.weixin.qq.com/s/OGI9kbH80sc9oIWWnntEIA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/007950ee-fab8-43ba-96ff-695c6a214255) \
  论文链接：https://arxiv.org/abs/2307.16449v2 \
  代码链接：https://github.com/rese1f/MovieChat \
  项目网页：https://rese1f.github.io/MovieChat/ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0db1673d-603c-4ab0-8c11-e41f2064f020)
* 19、从感知到理解-融合语言模型的多模态大模型研究  PaperWeekly  https://mp.weixin.qq.com/s/kpAxiAoOzp9gmdoGHcVzvg 
* 20、多模态3D理解的新篇章：ULIP (CVPR 2023) 与ULIP-2  PaperWeekly  https://mp.weixin.qq.com/s/jwRpPvi-pMvQ5UQsjJ_1CQ
* 21、机器会思考吗？图灵《计算机器与智能》经典回顾  集智俱乐部  https://mp.weixin.qq.com/s/C7fcKoVJ9-zbf3pokUQGNg

# 12.8 Fri.
* 22、拆解大语言模型RLHF中的PPO算法  PaperWeekly  https://mp.weixin.qq.com/s/y7o9F9vz8dv609ee6xqYtw 
* 23、(**值得试试**)小模型也可以「分割一切」，Meta改进SAM，参数仅为原版5%  机器学习研究组订阅  https://mp.weixin.qq.com/s/v0NlN60q8gvsOkEyu2WVwg \
  论文作者 Yunyang Xiong 表示：本文提出的 EfficientSAM 参数减少了 20 倍，但运行时间快了 20 倍，只与原始 SAM 模型的差距在 2 个百分点以内，大大优于 MobileSAM/FastSAM \
  <img width="511" alt="1702267043394" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/109786b8-11db-479c-a7fb-3829abfe3965">
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ddaa6276-bf17-41ff-9f83-1bb8eaa86c37) \
  论文链接：https://arxiv.org/pdf/2312.00863.pdf \
  论文主页：https://yformer.github.io/efficient-sam/

# 12.9 Sat.
* 24、(**重要**)首个精通3D任务的具身通才智能体：感知、推理、规划、行动统统拿下  PaperWeekly  https://mp.weixin.qq.com/s/5oJe46dOGzWfbkx1WRhtPg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/bce6d8fa-3cf4-487e-996b-33fa4f5f9051) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5cdf9ec8-1d04-4a73-b096-9acc94437e5b) \
  论文链接：https://arxiv.org/abs/2311.12871 \
  项目主页：https://embodied-generalist.github.io/ \
  代码链接：https://github.com/embodied-generalist/embodied-generalist
  an embodied generalist agent in 3d world 
* 25、(**可以玩一玩**)30+视觉/多模态工具！通用Agent工具库AgentLego给大模型一双 “慧眼”  InternLM  https://mp.weixin.qq.com/s/UGOGy6qGF27Ule0xTHrHPA \
  AgentLego 通过提供一个易于扩展、易于使用、易于部署的工具集合，让大家能够轻松地在各种 Agent 系统中发挥想象力，赋予大模型更强大的能力 
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f67c5ec8-13dc-4521-b14b-eb7a44005751)
  
# 12.10 Sun.
* 26、(**值得看看**)AI的理解困境：如何走出数据世界，触达生命的理解？  图灵人工智能  https://mp.weixin.qq.com/s/ZXCmsiGDv6HUHozm93NSig \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/63923a49-2c5e-4d54-9e87-67c45c5d4d85) \
  <img width="517" alt="1702271200216" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/13da7f89-6dcc-4982-894d-95cb3d267926">
  ???生成式AI与主动推理的区别到底是啥
* 27、大模型就是「造梦机」，Karpathy一语惊人！人类才是「幻觉问题」根本原因  新智元  https://mp.weixin.qq.com/s/J3YWEyS3ZFlY0q4IMDHkOw \
  大模型就是「造梦机」，Karpathy一语惊人！人类才是「幻觉问题」根本原因  机器学习研究组订阅  https://mp.weixin.qq.com/s/pbLGVhTiUXCFus3znm4TlQ \
* 28、一条磁力链接席卷AI圈，87GB种子直接开源8x7B MoE模型  机器之心  https://mp.weixin.qq.com/s/NdjsET6DG9BJS1lJHh5u6g \
  <img width="429" alt="1702271538223" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8f89ef99-6a2a-4e53-8395-aaaa1ae588e9"> \
  在线体验网站：https://replicate.com/nateraw/mixtral-8x7b-32kseqlen \
  <img width="519" alt="1702271593602" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/bcb847f5-63a9-405f-8e72-b8b9a6fc01de">
* 29、大模型如何高效？OSU等最新《高效大型语言模型》综述，详述模型压缩、预训练、微调、提示等技术  专知  https://mp.weixin.qq.com/s/450GkFMO602S5ciMInPPVA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a2ab30fb-0091-4ff5-af27-d959b9485cd0)
* 30、【EMNLP2023教程】设计、评估以及从人类与NLP模型的互动中学习  专知  https://mp.weixin.qq.com/s/iEtJN9f_dwYnCmZGz5ByEA
* 31、特别详细！大模型的网络优化：超参最佳实践与规模律  AINLPer  https://mp.weixin.qq.com/s/Wf42SWvcSntUpZADcSDCEQ 
* 32、大模型幻觉！亚马逊 | 提出细粒度大模型幻觉检测工具 BSChecker  AINLPer  https://mp.weixin.qq.com/s/R6jnoGN7ph7nTssXR7xubw
* 33、SVM is all you need，支持向量机永不过时。 小白学视觉   https://mp.weixin.qq.com/s/PkQCM_A08g6BBzE1jznTkg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/72d27f81-a666-4918-bea4-ebcca756a24d) \
  论文链接：https://arxiv.org/pdf/2308.16898.pdf

# 12.11 Mon.
* 34、(**值得玩玩，理解LLM**)LLM Visualization大模型网络结构可视化 \
  https://bbycroft.net/llm \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d7219556-6161-4e69-bb5e-551eceee0de6)
* 35、(**跨模型通信，EoT**)复旦团队提出思维交流框架EoT，由CoT到EoT，可跨模型通信，表现更出色  夕小瑶科技说  https://mp.weixin.qq.com/s/hxZ5SnVcQd2zRSYDSsZOuQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/bd240274-1272-4b87-ab43-9fbf15ed7a71) \
  作者提出的思维交流（Exchange-of-Thought，EoT），通过促进跨模型交流，实现对外部反馈的整合。该方法充分利用了 LLM 的通信能力，鼓励参与模型之间理性和答案的共享，从而建立起一个协同思考和分析的环境。\
  论文题目: CoLLiE: Collaborative Training of Large Language Models in an Efficient Way \
  论文链接: https://arxiv.org/abs/2312.01823 
* 36、(**值得玩玩，怎么做到的**)8x7B开源MoE击败Llama 2逼近GPT-4！欧版OpenAI震惊AI界，22人公司半年估值20亿  新智元  https://mp.weixin.qq.com/s/4-ptisnxfyk-SBMAKejEsw \
  开源大模型超越GPT-3.5！爆火MoE实测结果出炉，网友：OpenAI越来越没护城河了  量子位  https://mp.weixin.qq.com/s/t_zdSjpoCE8PZ9FeMM0sfw \
  467亿参数MoE追平GPT-3.5！爆火开源Mixtral模型细节首公开，中杯逼近GPT-4  新智元  https://mp.weixin.qq.com/s/knFuzD7IkJ73lvrRu-hdiQ \
  最新开源模型Mixtral震爆AI社区！超越LLama2和GPT-3.5，来自欧洲初创公司  夕小瑶科技说  https://mp.weixin.qq.com/s/dahc-OgUTXpYocjHSDADww \
  Mistral携微软引爆「小语言模型」潮！Mistral中杯代码能力完胜GPT-4，成本暴降2/3  机器学习研究组订阅  https://mp.weixin.qq.com/s/OokMpM83NSzfagr3dBgrbA \
  首个开源MoE大模型Mixtral 8x7B，已经达到甚至超越了Llama 2 70B和GPT-3.5的水平。

# 12.12 Tues.
* 37、仿人脑神经开发AI！剑桥大学最新研究登Nature子刊，人造大脑成AI新方向  脑机接口社区  https://mp.weixin.qq.com/s/1A9QHTyQWeJ12ES72pg31w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b002a346-2e78-44f9-aa18-d9c2e1ac7100) \
  https://www.cam.ac.uk/research/news/ai-system-self-organises-to-develop-features-of-brains-of-complex-organisms
* 38、(**值得看看**)当GPT-4V充当机器人大脑，可能你都没AI会规划  机器之心  https://mp.weixin.qq.com/s/EuITKR11WRLu1pMK7kZHug \
  ViLa 全称是 Robotic Vision-Language Planning，它利用 GPT-4V 在视觉和语言两个模态上做联合推理的能力，把抽象的语言指令分解为一系列可执行的步骤 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d864b9ff-c587-41b8-a1d3-1f5c6a0051ca)
  论文地址：https://arxiv.org/pdf/2311.17842.pdf \
  论文主页：https://robot-vila.github.io/ \
  论文视频：https://www.youtube.com/watch?v=t8pPZ46xtuc
* 39、用活人脑细胞造AI系统！语音识别已成功，可无监督学习｜Nature子刊  量子位  https://mp.weixin.qq.com/s/Rvk5HS5Psv8umsPotn-giQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9e749125-c21f-41df-97e6-524566062068)
  研究人员将活体脑细胞组成的脑类器官（形状类似小团球）和高密度微电极阵列进行连接，构建出一个叫做“Brainoware”的系统 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/164b0d34-9074-4996-a56c-c032b02d7e37)
* 40、(**值得看看**)让大模型操纵无人机，北航团队提出具身智能新架构  量子位  https://mp.weixin.qq.com/s/ED2nYza15ZpEVLOGPIEyeg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7c09333a-156a-45d1-bb41-f17f4fe2d8d1) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d06eadf8-b251-40d6-8dcd-a6a7a40f6b4d) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f45f6193-1084-4eb0-90de-dfe8766f2466) \
* 41、(**通用世界模型GWM**)Runway官宣下场通用世界模型！解决视频AI最大难题，竟靠AI模拟世界？  新智元  https://mp.weixin.qq.com/s/GPLCbyaS1WVs44RlVq1-oA \
  “我们相信，人工智能的下一个重大进步将来自理解视觉世界及其动态的系统，这就是为什么我们要围绕通用世界模型开始一项新的长期研究工作。”
* 42、(**WALT**)李飞飞谷歌破局之作！用Transformer生成逼真视频，下一个Pika来了？  新智元  https://mp.weixin.qq.com/s/T4wGCB2aX-3eilUakKFJtw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8e3bd942-5677-4c4f-b7e6-04e6ad44f46f)
  论文：https://walt-video-diffusion.github.io/assets/W.A.L.T.pdf
* 43、(**重要，值得看看**)详解基于调整RoPE旋转角度的大模型长度外推方法  InternLM  https://mp.weixin.qq.com/s/OjwjzvE6pC8fmpYJbO5kAQ \

# 12.13 Wed.
* 44、只有27亿参数，性能却高25倍！微软发布Phi-2  AIGC开放社区  https://mp.weixin.qq.com/s/2r1Ry_B4BjrfjpBtBX4VgA \
  微软官宣放出一个「小模型」，仅2.7B参数，击败Llama2和Gemini Nano 2  夕小瑶科技说  https://mp.weixin.qq.com/s/Z77-wMbkFfcuFCGcb268vg \
  2.7B能打Llama 2 70B，微软祭出「小语言模型」！96块A100 14天训出Phi-2，碾压谷歌Gemini nano  新智元  https://mp.weixin.qq.com/s/5BnS_oSxF6t_7BLvHQpLGw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b1a19966-681f-444b-b018-3cc352a7ecf5)
* 45、练习时长两年半，特斯拉人形机器人Optimus二代上线  机器之心  https://mp.weixin.qq.com/s/F7pExeJYHZQG4QZPgxs0Vg
* 46、首个GPT-4驱动的人形机器人！无需编程+零样本学习，还可根据口头反馈调整行为  量子位  https://mp.weixin.qq.com/s/pNDsAy65LD_Qs3O7mH12uw \
* 47、(**值得看看**)语言模型和世界模型如何连接？NeurIPS 2023最新《语言模型、智能体模型和世界模型》增强机器推理和规划的LAW法则  机器学习研究组订阅  https://mp.weixin.qq.com/s/BWm5u2LWKKXF9KHRQn7Wvw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/220ff6ac-d943-42b9-90d6-7babfcec6cc9)
  https://sites.google.com/view/neurips2023law

# 12.14 Thur.
* 48、通往具身通用智能：如何让机器从自然模态中学习到世界模型？  集智俱乐部  https://mp.weixin.qq.com/s/-8B8prYfxkW4Akflta51BQ 

# 12.15 Fri.
* 49、(**重要，对面试有用**)重要资源：\
  原文地址：https://zhuanlan.zhihu.com/p/670962982 \
  Github 地址：https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis \
  LLMs 千面郎君：https://github.com/km1994/LLMs_interview_notes \
  介绍：该仓库主要记录 大模型（LLMs） 算法工程师相关的面试题 \
  LLMs九层妖塔：https://github.com/km1994/LLMsNineStoryDemonTower \
  介绍：【LLMs九层妖塔】分享 LLMs在自然语言处理（ChatGLM、Chinese-LLaMA-Alpaca、小羊驼 Vicuna、LLaMA、GPT4ALL等）、信息检索（langchain）、语言合成、语言识别、多模态等领域（MiniGPT-4、VisualGLM-6B、Ziya-Visual等）等实战与经验。 \
  NLP菜鸟逆袭记：https://github.com/km1994/AwesomeNLP \
  介绍：【NLP菜鸟逆袭】分享 自然语言处理（文本分类、信息抽取、知识图谱、机器翻译、问答系统、文本生成、Text-to-SQL、文本纠错、文本挖掘、知识蒸馏、模型加速、OCR、TTS等）等 实战与经验。 \
  NLP 面无不过：https://github.com/km1994/NLP-Interview-Notes \
  介绍：该仓库主要记录 NLP 算法工程师相关的面试题 
* 50、(**真牛逼**)DeepMind论文登上Nature：大模型找到数学难题最新解，赢过人类数学家  夕小瑶科技说  https://mp.weixin.qq.com/s/KqCoyEL9rxDpAQ-sc6VYiA \
  <img width="503" alt="1703668421251" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4e14512f-6a62-41ba-960c-581f252aeff9"> \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b0bb65e8-6fc6-44b7-a855-fc32483a2364) \
  谷歌DeepMind提出了一种使用大语言模型搜索数学和计算机科学新解决方案的方法 FunSearch，FunSearch 针对历史上一些经典数学难题给出了新的解法，赢过了人类数学家。
* 51、(**很牛逼，一定得玩玩，看看**)UC伯克利DeepMind等联合发布真实世界模拟器，打破虚实边界｜NeurlPS 2023  新智元  https://mp.weixin.qq.com/s/sqVfAVVaEJfDLzMDQ40YFw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f3db8196-2058-4eb3-8bef-7bc84ac0371f)
  论文地址：https://arxiv.org/pdf/2310.06114.pdf \
  网站：https://universal-simulator.github.io/unisim/ \
  RL代理可以在UniSim提供的模拟世界中进行有效训练，之后可以直接转移到真实的机器人上，避免了在现实世界中搭建昂贵而复杂的训练环境。
  
# 12.16 Sat.
* 52、超对齐！OpenAI | 提出了大型语言模型（LLM）新的研究方向：Superalignment  AINLPer  https://mp.weixin.qq.com/s/7pEQM39vRjsWFjZL7zqIXw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ba1c6d51-be41-46ca-ac9d-0dbce90485f1) \
  使用较小（能力较差）的模型来监督较大（能力更强）的模型
* 53、综述｜大模型时代，对话系统的演进和机会，港中大华为联合发布  夕小瑶科技说  https://mp.weixin.qq.com/s/ncrZA9JvVeQRLV7G50lAow 
* 54、(**值得看看**)DeepMind提出代码链，通过“代码思考”改进推理性能  夕小瑶科技说  https://mp.weixin.qq.com/s/DQ6zdPrJavisZMtjdtGJvA \
  Chain of Code通过“以代码方式思考”来拓宽语言模型正确回答推理问题的范围
* 55、(**值得看看**)大模型如何用于机器人？CMU谷歌等最新《基于基础模型的通用机器人》综述，详解机器人技术基础模型  专知  https://mp.weixin.qq.com/s/OeKWKU3EfL9o-FQwgYJClA \
  <img width="504" alt="1703669924202" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8c2baf18-d015-4f0b-b189-d99ee8cdbb1c"> \
  <img width="484" alt="1703669953434" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ab1f4846-9061-4452-8474-848d53cba28f"> \
  <img width="506" alt="1703670201951" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/3e9c399e-73a2-4d4f-8f5a-cc315f3c3cba">
* 56、(**可以看看**)UC伯克利发现GPT-4惊人缺陷：儿童从经验中学习因果，LLM却不行  机器学习研究组订阅  https://mp.weixin.qq.com/s/IJg3aA78UL8U0lXi6wqBmw 
* 57、源代码is all you need！7B代码小模型同尺寸无敌，性能媲美ChatGPT和谷歌Gemini  机器学习研究组订阅  https://mp.weixin.qq.com/s/u54_bj56RHRXN7MkQBUCNA
* 58、(**值得看看，视频预测推理，Merlin**)GPT-4V都搞不明白的未来推理有解法了！来自华科大&上科大  量子位  https://mp.weixin.qq.com/s/0g57A_iDSHzZIv6kfMsNRQ \
  华科大和上科大团队提出了一个赋予多模态大语言模型前瞻性思维的学习范式，并基于这一范式构建了多模态大语言模型Merlin（梅林）\
  <img width="497" alt="1703670411055" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4740735d-536a-4b1f-9353-b8bdb8ac0f48"> \
  论文：https://arxiv.org/pdf/2312.00589.pdf 
* 59、APE｜"全开源"多模态基础感知大模型  李rumor  https://mp.weixin.qq.com/s/EaAQktUGT3yStedMNEj6Gg \
  论文地址：https://arxiv.org/pdf/2312.02153 \
  开源：https://github.com/shenyunhang/APE \
  Demo链接：https://huggingface.co/spaces/shenyunhang/APE_demo \
* 60、(**重要，务必看看**)OpenAI「登月计划」剑指超级AI！LeCun提出AGI之路七阶段，打造世界模型是首位  新智元  https://mp.weixin.qq.com/s/45eS6hDFzv4QqHmLdqvQ2Q \

# 12.17 Sun.
* 61、(**值得看看**)一文带你了解RAG(检索增强生成) | 概念理论介绍+ 代码实操（含源码）  AINLPer  https://mp.weixin.qq.com/s/cygn3Fiuhpo7ePU4R5FegA
* 62、(**非常重要**)大模型如何用于机器人？CMU谷歌等最新《基于基础模型的通用机器人》综述，详解机器人技术基础模型  专知  https://mp.weixin.qq.com/s/OeKWKU3EfL9o-FQwgYJClA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2fa5e996-a6e3-44d2-9ce5-86b0e1bd7513) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/dd65a013-009b-4e3d-b80d-3424e517f698) 
* 63、Mistral携微软引爆「小语言模型」潮！Mistral中杯代码能力完胜GPT-4，成本暴降2/3  机器学习研究组订阅  https://mp.weixin.qq.com/s/OokMpM83NSzfagr3dBgrbA 
* 64、(**重要**)UC伯克利发现GPT-4惊人缺陷：儿童从经验中学习因果，LLM却不行  机器学习研究组订阅  https://mp.weixin.qq.com/s/IJg3aA78UL8U0lXi6wqBmw \
  "工具创新"？？？
* 65、GPT-4V都搞不明白的未来推理有解法了！来自华科大&上科大  量子位  https://mp.weixin.qq.com/s/0g57A_iDSHzZIv6kfMsNRQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4c6fe37c-ba81-4f55-8f22-95bca691d5d7) \
  论文：https://arxiv.org/pdf/2312.00589.pdf 

# 12.18 Mon.
* 66、APE｜"全开源"多模态基础感知大模型  李rumor  https://mp.weixin.qq.com/s/EaAQktUGT3yStedMNEj6Gg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/720d19b7-6ee8-4b2a-8b39-280005e31e45) \
  论文地址：https://arxiv.org/pdf/2312.02153 \
  开源：https://github.com/shenyunhang/APE \
  Demo链接：https://huggingface.co/spaces/shenyunhang/APE_demo
* 67、(**值得看看**)OpenAI「登月计划」剑指超级AI！LeCun提出AGI之路七阶段，打造世界模型是首位  新智元  https://mp.weixin.qq.com/s/45eS6hDFzv4QqHmLdqvQ2Q \ 

# 12.21 Thur.
* 68、推理性能超H100十倍！21岁华裔小哥哈佛辍学开发AI加速芯片「Sohu」，2人公司估值3400万刀  新智元  https://mp.weixin.qq.com/s/TJBB3TkAQNlfiH-ylMQuWg

# 12.20 Wed.
* 69、大模型中的闪电侠问世：Atom-1B  llama中文社区  https://mp.weixin.qq.com/s/WD15khUptwkUG3EKC6YEWg
* 70、可验证大模型输出、训练来源，斯坦福提出“统一归因”框架  AIGC开放社区  https://mp.weixin.qq.com/s/QtsD0la7voAjoYH947mLaQ \
  随着ChatGPT等大模型被广泛应用在实际业务中，其输出内容的真实、可靠、安全性成为了重点。学术界则使用“归因”来表示追查、证实内容。\
  目前，在“归因”研究领域有两大派系，一种是协同归因，主要追查引用数据和训练数据来源；另外一种是贡献归因，证明模型输出内容的真实性以减少幻觉。\
  这两种归因方法对于法律、医疗、金融等，对于内容准确率要求极高的行业应用大模型至关重要。\
  但是这两种研究方法是分开独立进行的，所以，斯坦福大学的研究人员提出了“统一归因”框架，将两种方法集成在一起。\
  论文地址：https://arxiv.org/abs/2311.12233 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1fd59e6c-6fdb-4efa-8947-95552ccacb4f)
* 71、(**有趣且重要**)大模型智能体如何做仿真建模？清华最新《大型语言模型智能体的建模与仿真》综述  专知  https://mp.weixin.qq.com/s/7CleenmqrLXTNP4PluuYTg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a6c4429f-5487-4ae1-94c6-2b3cc2718542)
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ebfe6fb9-53b0-4af6-9782-ee9670a6876f)
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2eac6be2-643b-4add-9b26-ceda19aaea29)

# 12.22 Fri.
* 72、AI变鉴片大师，星际穿越都能看懂！贾佳亚团队新作，多模态大模型挑战超长3小时视频  量子位  https://mp.weixin.qq.com/s/kKMHhWihqPTepDf04gMxKQ \
  **llama-vid**
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0204f211-582c-44b6-86e9-76a168719ebc)
* 73、(**重要，入门llama源码**)LLaMA开源大模型源码分析！  datawhale  https://mp.weixin.qq.com/s/oO7nkY0Fcgd4Y7en3Sx2Xw \
  博客地址：https://flowus.cn/kmno4/share/527055be-464f-4f0f-98c5-8b8f72a1fc2e
* 74、4090成A100平替？token生成速度只比A100低18%，上交大推理引擎火了  机器学习研究组订阅  https://mp.weixin.qq.com/s/nqRF8pmdeZmXK0BrrHPw-Q \
  2080 Ti就能跑70B大模型，上交大新框架让LLM推理增速11倍  PaperWeekly  https://mp.weixin.qq.com/s/FqxwoR-466_je-7beFZh1A \
  **powerinfer**
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9ce71b4e-c152-4cd6-aeb8-0e858f069ff7)
  项目地址：https://github.com/SJTU-IPADS/PowerInfer \
  论文地址：https://ipads.se.sjtu.edu.cn/_media/publications/powerinfer-20231219.pdf
* 75、浅谈「混合专家模型」(MoE)，Mistral-7B×8-MoE发布，MoE+LLM成为潜力股  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/PW3zZrFDQYg2mGdVIjv7WQ
* 76、参数高效微调方法有哪些？岭大等最新《预训练语言模型的参数高效微调》综述  专知  https://mp.weixin.qq.com/s/mdxbw9FehRwJ0fBnbAReAw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5e515e57-4fbd-46a0-ab6e-070f0d5c11e8)

# 12.23 Sat.
* 77、意识更像温度还是生命？  集智俱乐部  https://mp.weixin.qq.com/s/XqpV9fyAIi_lFnZHhkBA-w \
  **整合信息论**
* 78、(**值得玩玩**)CogAgent：带 Agent 能力的视觉模型，免费商用  GLM大模型  https://mp.weixin.qq.com/s/qc_G9Dodlkn6Osh2u_XLMw

# 12.24 Sun.
* 79、CMU权威对比Gemini，GPT-3和Mistral8×7B！GPT-3.5依旧拿捏Gemini，开源模型差距依然不小  新智元  https://mp.weixin.qq.com/s/x2gi84sApX5Of2VibecpqQ
* 80、李飞飞DeepMind全新「代码链」碾压CoT！大模型用Python代码推理，性能暴涨12%  新智元  https://mp.weixin.qq.com/s/FqPyBAZA-pAFcUxluGE8RQ \
    chain of code (CoC) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/80b1368d-949a-498f-acf1-ce85d16734e9) 
  论文地址：https://arxiv.org/pdf/2312.04474.pdf
* 81、NeurIPS23｜视觉 「读脑术」：从大脑活动中重建你眼中的世界  机器之心  https://mp.weixin.qq.com/s/UVlwLq-wC4b8il6YLdHXDA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ea49b9aa-58d0-4327-b5c3-d35ce4da4be9)
  论文链接：https://arxiv.org/abs/2305.17214 \
  项目链接：https://github.com/soinx0629/vis_dec_neurips/
* 82、大模型被偷家！腾讯港中文新研究修正认知：CNN搞多模态不弱于Transfromer  量子位  https://mp.weixin.qq.com/s/J4O7Y10dl2BzujobPmY5Ug
    论文地址: https://arxiv.org/abs/2311.15599

# 12.25 Mon.
* 83、人工智能的惊人发现显示出类似人类的记忆形成  图灵人工智能  https://mp.weixin.qq.com/s/s3IlZWlpCFG6kHHYt7FLMA
* 84、(**重要**)一篇综述，看穿基础模型+机器人的发展路径  机器之心  https://mp.weixin.qq.com/s/0nZsRnQkE9YRZLdUfAtbUg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/87ea90cb-e183-4ee2-b978-d7b9ac96eccb)
  论文地址：https://arxiv.org/pdf/2312.08782.pdf \
  所谓的「基础模型（foundation model）」其实就是大型预训练模型（LPTM）。它们具备强大的视觉和语言能力。
* 85、(**值得看看**)Softmax注意力与线性注意力的优雅融合，Agent Attention推动注意力新升级  机器之心  https://mp.weixin.qq.com/s/NODp9Mt20KaQK38OQg-7sQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d471a440-e74f-4b9a-bdc4-36522cfb65bd)
  全局注意力机制具良好的模型表达能力，但过高的计算成本限制了其在各种场景中的应用。\
  代理注意力在传统的注意力三元组 (Q,K,V) 中引入了一组额外的代理向量 A，定义了一种新的四元注意力机制 (Q, A, K, V)。其中，代理向量 A 首先作为查询向量 Q 的代理，从 K 和 V 中聚合信息，然后将信息广播回 Q。由于代理向量的数量可以设计得比查询向量的数量小得多，代理注意力能够以很低的计算成本实现全局信息的建模。\
  论文链接：https://arxiv.org/abs/2312.08874 \
  代码链接：https://github.com/LeapLabTHU/Agent-Attention
* 86、(**值得看看,SSM**)挑战Transformer的Mamba是什么来头？作者博士论文理清SSM进化路径  机器之心  https://mp.weixin.qq.com/s/oXSwnL0sD96nnnqJyko7UA \
  SSM（state space model），Mamba中所用的架构
* 87、Mixtral-8x7B MoE大模型微调实践，超越Llama2-65B  YeungNLP  https://mp.weixin.qq.com/s/f24e-Tp-1WyXTbVOzePvhg
* 88、惊人！MIT & 微软| 提出高效LLM剪枝方法LASER：无额外训练，且性能提升30%！  AINLPer  https://mp.weixin.qq.com/s/yQfPDmK20tIqaWHsEBabcw

# 12.26 Tues.
* 89、LMDrive: 大语言模型加持的闭环端到端自动驾驶框架  PaperWeekly  https://mp.weixin.qq.com/s/Vp8w-MUZS6t01LCYjSWJJQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/67f5eac3-53f3-4847-bfd1-dfeaec5a32bb)
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/397323b2-4a50-484a-96ea-690108ccaba2)
  论文题目：LMDrive: Closed-Loop End-to-End Driving with Large Language Models \
  论文链接：https://arxiv.org/abs/2312.07488 \
  项目主页：https://hao-shao.com/projects/lmdrive.html \
  开源代码地址：https://github.com/opendilab/LMDrive

# 12.27 Wed.
* 90、单张4090，1秒100张二次元小姐姐！UC伯克利等新模型霸榜Github，吞吐量提升近60倍  新智元  https://mp.weixin.qq.com/s/jJnHrFVueqzPE8IWIqibPw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/be028cd4-ee86-416e-b434-15ecb3d04353)
  论文地址：https://arxiv.org/abs/2312.12491
* 91、(**APPAgent,值得了解**)鹅厂新智能体亮相！操纵手机水平媲美真人，GitHub一周获1.5K星  量子位  https://mp.weixin.qq.com/s/dfn_xVkOcmh5gwD1w_tiTQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d337352e-4bcd-46a2-bfa3-056021cf32dd)
* 92、补齐大模型注意力短板，7B模型工具使用比肩GPT-4！  PaperWeekly  https://mp.weixin.qq.com/s/6fm59gMlhpNareMDkrMlKQ
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e8ffaa0b-f921-44a8-b39b-4954aaf6e65e)
  论文链接：https://arxiv.org/pdf/2312.04455.pdf
* 93、大模型+机器人，详尽的综述报告来了，多位华人学者参与  机器之心  https://mp.weixin.qq.com/s/Sf5fiTm7tX7U7054Z3_fDw \
  <img width="512" alt="1705374767470" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/969e6526-b8da-474d-8b21-b6664fbfbda4">
  论文地址：https://arxiv.org/pdf/2312.07843.pdf \
  论文库：https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models

# 12.28 Thur.
* 94、字节多模态大模型PixelLM：高效像素级推理，无需依赖SAM  量子位  https://mp.weixin.qq.com/s/s9Xv5co0j6x1pcMcx8p1ew

# 12.29 Fri.
* 95、(**Emu2**)全球最强「开源版Gemini」诞生！全能多模态模型Emu2登热榜，多项任务刷新SOTA  新智元  https://mp.weixin.qq.com/s/2uF1UM3Kraeq8nHltX9pCA
* 96、(**字节GR-1**)字节具身智能新成果：用大规模视频数据训练GR-1，复杂任务轻松应对  机器之心  https://mp.weixin.qq.com/s/1KHr1gW9529mXVhLt0zkzw \
  论文地址：https://arxiv.org/abs/2312.13139 \
  论文网站：https://gr1-manipulation.github.io
* 97、(**值得看看**)大模型玩星际争霸能秀到什么程度？有意识，有预判，中科院和汪军团队发布  机器之心  https://mp.weixin.qq.com/s/5SQZxIY8y26TWfO35yfpiQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6161d455-742e-4a76-8f14-542ba6e34691)
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/12820606-7c36-4dae-bbf2-26605a02d5cc)
  文章链接：https://arxiv.org/abs/2312.11865 \
  Github 仓库地址：https://github.com/histmeisah/Large-Language-Models-play-StarCraftII
* 98、顶配版SAM！由分割一切迈向感知一切  PaperWeekly  https://mp.weixin.qq.com/s/j52zcbE_le9TTtOrfQaqnw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/208e1a07-8db8-4e49-b892-0a41aef89932)
  论文地址：https://arxiv.org/abs/2312.09128 \
  项目&代码：https://github.com/baaivision/tokenize-anything \ 
  模型地址：https://huggingface.co/BAAI/tokenize-anything \
  Demo:https://huggingface.co/spaces/BAAI/tokenize-anything
* 99、清华大学提出三维重建的新方法：O²-Recon，用2D扩散模型补全残缺的3D物体  机器之心  https://mp.weixin.qq.com/s/t49-Tt1iQ_iRTGFA0-ntpw
  <img width="533" alt="1705375545877" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/89e3f62a-6845-46d2-ac19-da34c091d594">

# 12.30 Sat.

# 12.31 Sun.
* 100、(**值得玩玩**)8x7B MoE与Flash Attention 2结合，不到10行代码实现快速推理  机器之心  https://mp.weixin.qq.com/s/IAWJIh61_enYoyME3oJqJQ \
  模型地址：https://huggingface.co/models?search=mixtral%20awq \
  Transformer 中量化技术：https://huggingface.co/docs/transformers/main/en/quantization
* 101、(**值得看看**)告别冷启动，LoRA成为大模型「氮气加速器」，提速高达300%  机器之心  https://mp.weixin.qq.com/s/qaDCNjzVM6HP_NE_3vsPiA \
  <img width="521" alt="1705375797384" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/76545971-2470-419b-8af9-9c4d1a8e6076">
* 102、《通用多模态模型的视觉指令微调》综述  机器学习研究组订阅  https://mp.weixin.qq.com/s/i48F3xzwPPj_jJSFON7ubA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5e44c407-b433-4f94-a242-5e1b9ba0b45a)
* 103、真·大一统！AI2南邮校友等打造Unified-IO 2：首个视觉/语言/音频/动作多模态模型  新智元  https://mp.weixin.qq.com/s/THBSr0Jo2YRVljWO-8cqsQ \
  <img width="503" alt="1705375941657" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e60d9897-6dc5-496f-be5c-537455608c50"> \
  论文地址：https://arxiv.org/abs/2312.17172

