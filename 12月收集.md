# 12.1 Fri.
* 1、720亿参数大模型都拿来开源了！通义千问开源全家桶，最小18亿模型端侧都能跑  机器之心  https://mp.weixin.qq.com/s/Q7vxpNr3ZUD2rhjQN_qZDA \
  目前，通义千问开源全家桶已经有了 18 亿、70 亿、140 亿、720 亿参数量的 4 款基础开源模型，以及跨语言、图像、语音等多种模态的多款开源模型。
* 2、DeepMind最新研究：这个AI Agent，几分钟学会人类专家行为，登上Nature子刊  图灵人工智能  https://mp.weixin.qq.com/s/uCCRRBwMwznAFy3eAnsKqQ \
  Learning few-shot imitation as cultural transmission \

# 12.2 Sat.
* 3、(**非常重要**)OpenAI最强竞品训练AI拆解LLM黑箱，意外窥见大模型「灵魂」  新智元  https://mp.weixin.qq.com/s/dCUXM2fWGPDizwwR0GZcFQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/30b03985-6659-4a7b-822e-48e32a51733c) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0a3a5113-4d36-40f6-b3b0-ba5e122e02fe) \
  论文地址：https://transformer-circuits.pub/2023/monosemantic-features/index.html#phenomenology-fsa

# 12.3 Sun.
* 4、(**含研究llama2源码和微调的教程，值得深入学习**)Meta教你5步学会用Llama2：我见过最简单的大模型教学  机器之心  https://mp.weixin.qq.com/s/j0dDtR7N0A9f2NwCO5mkMg \
  要了解有关 Llama 2 工作原理、训练方法和所用硬件的更多信息，请参阅 Meta 的论文《Llama 2: Open Foundation and Fine-Tuned Chat Models》，其中对这些方面进行了更详细的介绍。 \
  论文地址：https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/ \
  从 Meta 的 Llama 2 Github repo 获取模型源代码，源代码展示了模型的工作原理以及如何加载 Llama 2 模型和运行推理的最简单示例。在这里还可以找到下载、设置模型的步骤以及运行文本补全和聊天模型的示例。 \
  repo 地址：https://github.com/facebookresearch/llama \
  在模型卡片（中了解模型的更多信息，包括模型架构、预期用途、硬件和软件要求、训练数据、结果和许可证。 \
  卡片地址：https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md \
  在 Meta 的 llama-recipes Github repo 中提供了如何快速开始微调以及如何为微调模型运行推理的示例。 \
  repo 地址：https://github.com/facebookresearch/llama-recipes/ \
  查阅 Meta 最近发布的编码人工智能工具 Code Llama，这是一个建立在 Llama 2 基础上的人工智能模型，针对生成和分析代码的能力进行了微调。 \
  Code Llama 地址：https://about.fb.com/news/2023/08/code-llama-ai-for-coding/ \
  阅读《负责任使用指南》，它提供了以负责任的方式构建由大语言模型 (LLM) 支持的产品的最佳实践和注意事项，涵盖了从开始到部署的各个开发阶段。 \
  指南地址：https://ai.meta.com/llama/responsible-use-guide/
* 5、(**其中用到的世界模型技术值得研究**)驶向未来，首个多视图预测+规划自动驾驶世界模型来了  机器之心  https://mp.weixin.qq.com/s/x_BH6PCS2WwR6zQjngH4LQ \
  Drive-WM 模型通过多视图世界模型，能够想象不同规划路线的未来情景，并根据视觉预测获取相应的奖惩反馈，从而优化当前的路线选择，为自动驾驶系统的安全提供了保障。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2c21834b-d8bb-4f66-b90f-3e186c05c604) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ae3e20fc-ab43-48a7-b18b-9c2650683b08) \
  网站：https://drive-wm.github.io \
  论文链接：https://arxiv.org/abs/2311.17918
* 6、大模型如何重塑对话系统？港中文等最新《基于语言模型的对话系统演化》综述  专知  https://mp.weixin.qq.com/s/OpWx-M9ne7DGvOmdQYrWXA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/83cd8325-862f-465e-bc48-5e61d7ae93da) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/fe7e9efc-dc9f-4302-8bb9-49053e88d6f4) \
* 7、【图宾根大学博士论文】神经场景表示在三维重建和生成建模中的应用  专知  https://mp.weixin.qq.com/s/DaJJFXfzlYs9vHdsrivJ7Q 
* 8、大模型幻觉！人大 & IAAR & 新华社 | 提出幻觉评测基准UHGEval，全面支持中文！  AINLPer  https://mp.weixin.qq.com/s/2wRSdfxEx1E8euNniueSSg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5b4555c2-657f-4104-94b1-9273be5bba03) \
  Paper：https://arxiv.org/abs/2311.15296 \
  Code：https://github.com/IAAR-Shanghai/UHGEval
  
# 12.4 Mon.
* 9、(**有趣**)【LLM/大模型】战争与和平(WarAgent)：基于大模型的世界大战多智能体模拟  无影寺 AI帝国  https://mp.weixin.qq.com/s/iAoovfM4P-c8BzHkzxDIgw \
  论文标题：War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars \
  论文链接：https://arxiv.org/abs/2311.17227
* 10、(**非常重要，LVM（Large Vision Models）**)通用视觉推理显现，UC伯克利炼出单一纯CV大模型，三位资深学者参与  机器之心  https://mp.weixin.qq.com/s/eTG5u03Thznz-8k3h4EW7g \
  计算机视觉GPT时刻！UC伯克利三巨头祭出首个纯CV大模型，推理惊现AGI火花  OpenMMLab  https://mp.weixin.qq.com/s/ClZkoOidr9IgZCbIz9c4Bg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9d10fd2b-a445-45f6-bc4c-d3f731edce38) \
  论文地址：https://arxiv.org/abs/2312.00785 \
  项目主页：https://yutongbai.com/lvm.html
* 11、一键部署Hugging Face模型！LMDeploy与transformers强强联合  OpenMMLab  https://mp.weixin.qq.com/s/_MfuiK1LpoKM7OSleo5TdQ \
* 12、大模型微调！上百次实验的经验总结：不是全局调不起，而是 LoRA更有性价比  AINLPer  https://mp.weixin.qq.com/s/ERkEOGBHce3_mZfaZCnXwA \
  LoRA微调大模型手把手实用教程！  专知  https://mp.weixin.qq.com/s/Oh25-sH22XHkpz_MxgG6hA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/77ecf0b8-df4e-49c8-907e-75491552ef0b) \

# 12.5 Tues.
* 13、量子计算OpenAI来了？前谷歌3人团队融资1亿元，打造AI算力芯片挑战物理极限  新智元  https://mp.weixin.qq.com/s/0E4T9saTl2QV5I2j7nlDnw \
  前谷歌量子计算团队今日宣布融资1410万美元，打造新型AI算力芯片，将根据热力学和信息的第一原理构建人工智能超级计算机，实现能够自我编程的算力芯片。
* 14、112页报告深挖GPT-4V！UCLA等发布全新「多模态数学推理」基准**MathVista**  新智元  https://mp.weixin.qq.com/s/RuC6LCJB_JZAy_SnJjw-WQ \
  <img width="496" alt="1702264967488" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/df28030f-209c-4c1b-96bf-02809d6f1ce8"> \
  论文地址：https://arxiv.org/abs/2310.02255 \
  项目地址：https://mathvista.github.io/ \
  HF数据集：https://huggingface.co/datasets/AI4Math/MathVista \
  数据可视化：https://mathvista.github.io/#visualization \
  Leaderboard：https://mathvista.github.io/#leaderboard \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/912f9dd1-e9f4-4d95-924a-12795e1dc254) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b3c301d5-c920-470b-b1a6-fbf5c864b496)
* 15、(**重要，Mamba，值得深入研究**)颠覆Transformer霸权！CMU普林斯顿推Mamba新架构，解决致命bug推理速度暴增5倍  新智元  https://mp.weixin.qq.com/s/nVilywouNxnZlb-l3Buj3w \
  Transformer挑战者出现！斯坦福CMU联合团队，开源模型及代码，公司已创办  量子位  https://mp.weixin.qq.com/s/WUdZtHCO6AaQqVzyRlB4Bg \
  五倍吞吐量，性能全面包围Transformer：新架构Mamba引爆AI圈  机器学习研究组订阅  https://mp.weixin.qq.com/s/1w98NpCFlviqfoaF4Cbjpg \
  热门！CMU & 普林斯顿 | 提出Mamba新架构，推理速度暴增5倍，完虐Transformer！  AINLPer  https://mp.weixin.qq.com/s/Rixbjx0kENYdD8LN5WZN0w \
  Transformer虽强大，却有一个致命的bug：核心注意力层无法扩展到长期上下文。\
  刚刚，CMU和普林斯顿的研究者发布了Mamba。这种SSM架构在语言建模上与Transformers不相上下，而且还能线性扩展，同时具有5倍的推理吞吐量！\
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/732c058b-938f-48aa-b606-8c0e1c855e5d) \
  论文地址：https://arxiv.org/abs/2312.00752
* 16、【2023新书】理解大型语言模型：学习其基础概念和技术，166页pdf  专知  https://mp.weixin.qq.com/s/WH8l5MMaGoXff091EZ84cw

# 12.6 Wed.

# 12.7 Thur.
* 17、超越GPT-4！谷歌发布最强多模态大模型—Gemini  AIGC开放社区  https://mp.weixin.qq.com/s/tvHCcEMYLu_FWEH6vMW_iQ \
  超越GPT-4？Google 60页《Gemini-高性能多模态大模型》报告，详解技术测试等细节，附中英文版  专知  https://mp.weixin.qq.com/s/2UlC5Tc4Wxz5nDBPnPAjuQ \
  <img width="452" alt="1702266448923" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/975b45b5-6e6a-4df0-b48a-013e8c2bdd07"> \
  Bard地址：https://bard.google.com/chat \
  论文地址：https://goo.gle/GeminiPaper \
  Gemini Pro的API地址：https://cloud.google.com/vertex-ai
* 18、(**模型结构很有趣**)视觉模型+大语言模型：首个支持10K+帧长视频理解任务的新型框架  PaperWeekly  https://mp.weixin.qq.com/s/OGI9kbH80sc9oIWWnntEIA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/007950ee-fab8-43ba-96ff-695c6a214255) \
  论文链接：https://arxiv.org/abs/2307.16449v2 \
  代码链接：https://github.com/rese1f/MovieChat \
  项目网页：https://rese1f.github.io/MovieChat/ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0db1673d-603c-4ab0-8c11-e41f2064f020)
* 19、从感知到理解-融合语言模型的多模态大模型研究  PaperWeekly  https://mp.weixin.qq.com/s/kpAxiAoOzp9gmdoGHcVzvg 
* 20、多模态3D理解的新篇章：ULIP (CVPR 2023) 与ULIP-2  PaperWeekly  https://mp.weixin.qq.com/s/jwRpPvi-pMvQ5UQsjJ_1CQ
* 21、机器会思考吗？图灵《计算机器与智能》经典回顾  集智俱乐部  https://mp.weixin.qq.com/s/C7fcKoVJ9-zbf3pokUQGNg

# 12.8 Fri.
* 22、拆解大语言模型RLHF中的PPO算法  PaperWeekly  https://mp.weixin.qq.com/s/y7o9F9vz8dv609ee6xqYtw 
* 23、(**值得试试**)小模型也可以「分割一切」，Meta改进SAM，参数仅为原版5%  机器学习研究组订阅  https://mp.weixin.qq.com/s/v0NlN60q8gvsOkEyu2WVwg \
  论文作者 Yunyang Xiong 表示：本文提出的 EfficientSAM 参数减少了 20 倍，但运行时间快了 20 倍，只与原始 SAM 模型的差距在 2 个百分点以内，大大优于 MobileSAM/FastSAM \
  <img width="511" alt="1702267043394" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/109786b8-11db-479c-a7fb-3829abfe3965">
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ddaa6276-bf17-41ff-9f83-1bb8eaa86c37) \
  论文链接：https://arxiv.org/pdf/2312.00863.pdf \
  论文主页：https://yformer.github.io/efficient-sam/

# 12.9 Sat.
* 24、(**重要**)首个精通3D任务的具身通才智能体：感知、推理、规划、行动统统拿下  PaperWeekly  https://mp.weixin.qq.com/s/5oJe46dOGzWfbkx1WRhtPg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/bce6d8fa-3cf4-487e-996b-33fa4f5f9051) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5cdf9ec8-1d04-4a73-b096-9acc94437e5b) \
  论文链接：https://arxiv.org/abs/2311.12871 \
  项目主页：https://embodied-generalist.github.io/ \
  代码链接：https://github.com/embodied-generalist/embodied-generalist
  an embodied generalist agent in 3d world 
* 25、(**可以玩一玩**)30+视觉/多模态工具！通用Agent工具库AgentLego给大模型一双 “慧眼”  InternLM  https://mp.weixin.qq.com/s/UGOGy6qGF27Ule0xTHrHPA \
  AgentLego 通过提供一个易于扩展、易于使用、易于部署的工具集合，让大家能够轻松地在各种 Agent 系统中发挥想象力，赋予大模型更强大的能力 
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f67c5ec8-13dc-4521-b14b-eb7a44005751)
  
# 12.10 Sun.
* 26、(**值得看看**)AI的理解困境：如何走出数据世界，触达生命的理解？  图灵人工智能  https://mp.weixin.qq.com/s/ZXCmsiGDv6HUHozm93NSig \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/63923a49-2c5e-4d54-9e87-67c45c5d4d85) \
  <img width="517" alt="1702271200216" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/13da7f89-6dcc-4982-894d-95cb3d267926">
  ???生成式AI与主动推理的区别到底是啥
* 27、大模型就是「造梦机」，Karpathy一语惊人！人类才是「幻觉问题」根本原因  新智元  https://mp.weixin.qq.com/s/J3YWEyS3ZFlY0q4IMDHkOw \
  大模型就是「造梦机」，Karpathy一语惊人！人类才是「幻觉问题」根本原因  机器学习研究组订阅  https://mp.weixin.qq.com/s/pbLGVhTiUXCFus3znm4TlQ \
* 28、一条磁力链接席卷AI圈，87GB种子直接开源8x7B MoE模型  机器之心  https://mp.weixin.qq.com/s/NdjsET6DG9BJS1lJHh5u6g \
  <img width="429" alt="1702271538223" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8f89ef99-6a2a-4e53-8395-aaaa1ae588e9"> \
  在线体验网站：https://replicate.com/nateraw/mixtral-8x7b-32kseqlen \
  <img width="519" alt="1702271593602" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/bcb847f5-63a9-405f-8e72-b8b9a6fc01de">
* 29、大模型如何高效？OSU等最新《高效大型语言模型》综述，详述模型压缩、预训练、微调、提示等技术  专知  https://mp.weixin.qq.com/s/450GkFMO602S5ciMInPPVA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a2ab30fb-0091-4ff5-af27-d959b9485cd0)
* 30、【EMNLP2023教程】设计、评估以及从人类与NLP模型的互动中学习  专知  https://mp.weixin.qq.com/s/iEtJN9f_dwYnCmZGz5ByEA
* 31、特别详细！大模型的网络优化：超参最佳实践与规模律  AINLPer  https://mp.weixin.qq.com/s/Wf42SWvcSntUpZADcSDCEQ 
* 32、大模型幻觉！亚马逊 | 提出细粒度大模型幻觉检测工具 BSChecker  AINLPer  https://mp.weixin.qq.com/s/R6jnoGN7ph7nTssXR7xubw
* 33、SVM is all you need，支持向量机永不过时。 小白学视觉   https://mp.weixin.qq.com/s/PkQCM_A08g6BBzE1jznTkg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/72d27f81-a666-4918-bea4-ebcca756a24d) \
  论文链接：https://arxiv.org/pdf/2308.16898.pdf
* 34、


