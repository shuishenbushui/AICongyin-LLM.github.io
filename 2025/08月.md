# 8.1 Fri
* 1.为IIT提供结构，为GWT提供内部逻辑，为预测处理提供区分动态的意识范畴UTD  CreateAMind  https://mp.weixin.qq.com/s/QkvvcluM89ZOw9Hy9GeHHQ \
  From Differentiation to Cognition:UTD as a Model of Recursive Awareness
* 2.图灵奖得主加持，蒙特卡洛树搜索×扩散模型杀回规划赛道｜ICML 2025 Spotlight  量子位  https://mp.weixin.qq.com/s/hmNdvQ3MljFl-NiAia8bOQ \
  Monte Carlo Tree Diffusion for System 2 Planning \
  突破了扩散模型在长程任务推理阶段缺乏可扩展性的瓶颈

# 8.2 Sat
* 3.多模态后训练反常识：长思维链SFT和RL的协同困境  机器之心  https://mp.weixin.qq.com/s/NVG3hjr1xIuLKRSmqckrWg \
  在多模态视觉语言模型（VLM）中，SFT+RL组合难以实现协同增益，甚至有时会互相拖后腿 \
  The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs

# 8.3 Sun
* 4.大模型训练的时间都花在哪了？  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/bl2_kCxShpghaf9BAu9xbg 
* 5.DeepMind哈萨比斯：AI能建模所有进化而来的事物  量子位  https://mp.weixin.qq.com/s/4vuQrBPHZvjFHiKZhSHFnw 
* 6.图灵奖得主Sutton再突破：强化学习在控制问题上媲美深度强化学习？  机器之心  https://mp.weixin.qq.com/s/I8IE8Ck-k5OoAy7SLqi9-Q \
  Swift-Sarsa: Fast and Robust Linear Control \
  近些天，Sutton 再发新论文，在强化学习领域再次发力，将他在 2024 年的时序差分学习新算法 SwiftTD 拓展到控制领域，在与一些更强大的预处理算法结合使用时，能够展现出与深度强化学习算法相当的性能表现

# 8.4 Mon
* 7.为什么GRPO重要性权重设计错误？详解Qwen3新强化学习算法GSPO  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/2Ta46U-OpNJPzKORu2wpPw \
  GRPO 对于 next-token 的重要性权重，容易引入高方差的噪声
* 8.连续思考机器 Continuous Thought Machines  CreateAMind  https://mp.weixin.qq.com/s/hwnmiEuOKbmIjNJ3p_LFoQ 
* 9.高质量「上下文工程」资源整理（含速览和精读）  夕小瑶科技说  https://mp.weixin.qq.com/s/bkrTmiWmI6Hxeo6F5IliIA
* 10.Meta华人新秀毕树超，重磅爆料下一代LLM路线！RL+预训练直通AGI  新智元  https://mp.weixin.qq.com/s/EqgKkEB0z90WRnx-sO57OQ
* 11.LLM抢人血案：强化学习天才被挖空，一朝沦为「无人区」！  新智元  https://mp.weixin.qq.com/s/_hUl6kkea6VlS04K-WHmsg \
  PufferLib
* 12.3D-R1：让AI理解3D世界的下一步  机器之心  https://mp.weixin.qq.com/s/TgFY_hZcA7tKX163kztHXg \
  3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding 

# 8.5 Tue

# 8.6 Wed
* 13.震撼，世界模型第一次超真实地模拟了真实世界：谷歌Genie 3昨晚抢了OpenAI风头  机器之心  https://mp.weixin.qq.com/s/iI0-UDW70nOqyRb95WuZNw \
  谷歌Genie3全网玩疯！画质飞跃720P，网友造出西幻RPG游戏  量子位  https://mp.weixin.qq.com/s/KYLIU6MQC_MIOwloahP3Iw \
  仍然存在局限
* 14.Attention Sink现象揭秘：Transformer为何偏爱首Token？  PaperWeekly  https://mp.weixin.qq.com/s/R62I_KVA3FHnk2xAsUlEtg 

# 8.7 Thur
* 15.人大高瓴-华为诺亚：大语言模型智能体记忆机制的系列研究  机器之心  https://mp.weixin.qq.com/s/n_oc7X1cZ1vGwPWhXpLUjA \
  A Survey on the Memory Mechanism of Large Language Model based Agents
* 16.(**值得看看**)强化学习的10层境界：从巴甫洛夫的狗到贝叶斯大脑  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/mWAAdUQ7LmBFGNtQ3MU8Zg 
* 17.(**从经验中学习的RL框架**)强化学习+MCP=王炸？开源框架教AI在MCP中玩转工具解决任务，实测效果超越GPT！  量子位  https://mp.weixin.qq.com/s/YaP6aTuKvONTpnLp_VEUHA \
  专注于LLM+RL的科技公司OpenPipe提出全新开源强化学习框架——MCP·RL \
  只需一个MCP Server的地址，agent就能自动发现工具、生成任务，通过强化学习在闭环反馈中摸索出最优调用策略 \
  MCP·RL是科技公司OpenPipe基于强化学习的智能体训练系统(Agent Reinforcement Trainer，ART)的最新项目。ART是一个开源强化学习框架，其核心思想是让LLM从经验中学习，从而提高agent的可靠性，ART可以将GRPO集成到任何Python应用中。 \
  https://github.com/OpenPipe/ART?tab=readme-ov-file#-notebooks
* 18.字节&MAP重塑大模型推理算法优化重点，强化学习重在高效探索助力LLM提升上限  量子位  https://mp.weixin.qq.com/s/8XfVIRaLfgViBCPNVew0jA \
  一个普遍存在的现象是：在训练过程中，模型的熵值迅速下降，推理路径趋于固化，导致“利用（exploitation）”远超“探索（exploration）”，严重失衡。这种过早收敛不仅削弱了模型的多样性生成能力，也限制了其性能上限的进一步突破。 \
  First Return, Entropy-Eliciting Explore（FR3E） \
  受openai经典论文 First Return, Then Explore 的启发

# 8.8 Fri
* 19.追问专访·Donald Hoffman教授 | 我们能否构建出意识的数学模型？  追问  https://mp.weixin.qq.com/s/GDmf0sdFZRQznu5OMu3V8w \
  意识领军人物科赫：一个浪漫还原论者的自白  追问  https://mp.weixin.qq.com/s/Ry_igAgItWIy5eUYGEgc4w \
  《意识探索》
* 20.DeepSeek的GRPO会导致模型崩溃？看下Qwen3新范式GSPO  机器之心  https://mp.weixin.qq.com/s/YSlp-SXzi7bSW2Y-shJ8ww \
* 21.硬核拆解大模型，从 DeepSeek-V3 到 Kimi K2 ，一文看懂 LLM 主流架构  机器之心  https://mp.weixin.qq.com/s/_as8aCv325cAeJ6kMv9_aA

# 8.9 Sat
* 22.ICML 2025 | 千倍泛化不涨显存！蚂蚁推出新注意力机制，实现16M上下文精准检索  PaperWeekly  https://mp.weixin.qq.com/s/jdU8o07RanOrlcvDXz9VAA \
  提出一种基于因果检索的注意力机制 GCA (Grouped Cross Attention)，完全端到端地学习如何从上文检索并挑选最相关片段，从而实现超长序列高性能处理与泛化能力。人类记忆的另一个特性是大部分时候记忆处于沉睡状态，相关记忆片段只会在激活时进入意识。类似地，GCA 通过将上文信息卸载到 CPU / 磁盘，只在需要的时候动态加载需要的片段到 GPU 的方式，大幅降低了长文本处理的显存开销 \
  Efficient Length-Generalizable Attention via Causal Retrieval for Long-Context Language Modeling \
  https://github.com/ant-research/long-context-modeling
* 23.3万字长文！深度解析大语言模型LLM原理  Datawhale  https://mp.weixin.qq.com/s/7aYSBY0UxyEHKcqzC1fqtg

# 8.10 Sun
* 24.面向视觉语言模型的持续学习：遗忘之外的综述与分类体系  专知  https://mp.weixin.qq.com/s/_-Vsu56jEy-b_Hvi1EbyOw \
  VLMs 如何在随时间获取新知识的同时，不遗忘其原有能力？ \
  Continual Learning for VLMs: A Survey and Taxonomy Beyond Forgetting \
  https://github.com/YuyangSunshine/Awesome-Continual-learning-of-Vision-Language-Models

# 8.11 Mon
* 25.最大熵逆强化学习：理论基础、数学推导与工程实现  图灵人工智能  https://mp.weixin.qq.com/s/14Jfr4uu4poUFm1J1VebJw \
  重点讨论逆强化学习（Inverse Reinforcement Learning, IRL），这是模仿学习的重要分支，其核心目标是基于演示数据学习能够最大化期望奖励的最优策略
* 26.超越样本级RL！人大×快手提出ARPO：熵驱动Agent探索，多轮推理性能飙升  PaperWeekly  https://mp.weixin.qq.com/s/25P7v93nU81HFJoy9T678Q \
  Agentic Reinforced Policy Optimization（ARPO）
* 27.4D空间智能：AI如何一步步「看懂」时空结构？一篇综述解析通往四维世界的五大层次  机器之心  https://mp.weixin.qq.com/s/b2B7fli3qmASykTlYV9eBA \
  Reconstructing 4D Spatial Intelligence: A Survey \
  Project Page：https://github.com/yukangcao/Awesome-4D-Spatial-Intelligence \
  第一层（Level 1）：底层三维属性的重建（如深度、位姿、点云图等） \
  第二层（Level 2）：三维场景组成要素的重建（如物体、人体、建筑、场景等）  \
  第三层（Level 3）：完整的 4D 动态场景的重建 \
  第四层（Level 4）：包含场景内部组成部分之间交互关系的重建 \
  第五层（Level 5）：引入物理规律以及相关约束条件的重建
* 28.为了解释意识，哲学家们重新拾起泛灵论  神经现实  https://mp.weixin.qq.com/s/xBFPPzM_FhX2zntEMzUZqg
* 29.一文全解析：AI 智能体 8 种常见的记忆（Memory）策略与技术实现  Datawhale  https://mp.weixin.qq.com/s/nojzkY-dEnMZ99T17M9wZA 

# 8.12 Tue
* 30.英伟达为机器人推出懂推理的“大脑”！升级版Cosmos世界模型来了  量子位  https://mp.weixin.qq.com/s/r0-Lae5_KfR3-OzvtzXGAw \
  Cosmos主要被用来生成符合现实世界物理规律的合成数据，自发布以来，已被Figure、Agility Robotics、通用汽车等一众知名机器人和自动驾驶公司采用 \
  https://github.com/nvidia-cosmos
* 31.刚刚，商汤内部两万字复盘曝光：多模态通往AGI核心路线首次公开  新智元  https://mp.weixin.qq.com/s/72Spa0wCbRZ7X72-o9bOvQ \
  《迈向多模态通用智能：商汤的思考》
* 32.李飞飞押注的「世界模型」，中国自研Matrix-3D已抢先实现了？   新智元  https://mp.weixin.qq.com/s/hrmjLcaM7j71dARkyiWcYg \
  技术报告：https://github.com/SkyworkAI/Matrix-3D/blob/main/asset/report.pdf \
  项目主页：https://matrix-3d.github.io/ \
  Github：https://github.com/SkyworkAI/Matrix-3D \
  Hugging Face：https://huggingface.co/Skywork/Matrix-3D
* 33.Lumina-mGPT 2.0：自回归模型华丽复兴，媲美顶尖扩散模型  机器之心  https://mp.weixin.qq.com/s/3zcFinrOaK7ZDAojVws5QA \
  一款独立的、仅使用解码器的自回归模型，统一了包括文生图、图像对生成、主体驱动生成、多轮图像编辑、可控生成和密集预测在内的广泛任务 \
  GitHub 地址：Alpha-VLLM/Lumina-mGPT-2.0  

# 8.13 Wed
* 34.《自然》期刊：大脑看世界的方式，竟与语言模型惊人一致  波动智能  https://mp.weixin.qq.com/s/th_URh4ORqYgPh1eCEXeLQ \
  这项研究之所以令人震撼，不仅因为它揭示了语言模型与人脑视觉表征之间的高度一致性，更因为它触及了一个深层次的问题：我们的大脑究竟是如何理解世界的？而语言模型，又是如何在没有视觉经验的前提下，构建出与人类视觉系统高度契合的语义空间？ \
  一个令人振奋的启示是：以 LLM 嵌入为训练目标的视觉模型，在数据量远小于传统模型的情况下，依然能学得更接近人脑的表征。这表明强语义目标可能比海量数据更重要。虽然 LLM 本身是通过大规模文本训练得到的，其“语义密度”远高于传统的类别标签，这是否应计入总数据量仍是一个开放问题。但无论如何，这种训练方式为数据效率提供了新的思路。
* 35.OpenAI没开源的gpt-oss基础模型，他去掉强化学习逆转出来了  机器之心  https://mp.weixin.qq.com/s/m-mxv7gmiMV97R1hZBxo9w \
  从RL模型逆转为基础模型
* 36.研究者警告：强化学习暗藏「策略悬崖」危机，AI对齐的根本性挑战浮现  机器之心  https://mp.weixin.qq.com/s/C4fYaGiA2L2l_qs-8zy1aQ \
  The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large Language Models \
  RL导致模型行为脆弱、风格突变，甚至出现 “欺骗性对齐”、“失控” 等危险倾向 \
  “策略悬崖” 指的是，当你对导航目标做出一个极其微小的调整时（例如，“避开一段收费一元的道路”），导航系统给出的路线可能会发生天翻地覆的变化，从一条康庄大道突然切换到一条完全不相干的乡间小路 \
  RL 优化算法就像一个在平坦高原上寻找最高点的盲人，奖励信号微小的扰动都可能让他从一个 “山峰” 瞬间 “跳” 到另一个 “更高的山峰”，导致模型行为发生剧变 \
  思考：是否能将模型训练过程中生成相应的历史也记录下来作为数据，相应变化越小，给予越大的奖励
* 37.告别Transformer，重塑机器学习范式：上海交大首个「类人脑」大模型诞生  机器之心  https://mp.weixin.qq.com/s/Rvpfom16-50nQIRp53q0Qg \
  首个宏观模拟人类大脑全局机制的大语言模型 BriLLM，脱离了传统 Transformer 架构的限制，以脑科学神经系统为灵感，用受大脑启发的动态信号传播替代了基于注意力的架构 \
  Github 地址：https://github.com/brillm05/BriLLM0.5 \
  模型权重：https://huggingface.co/BriLLM/BriLLM0.5
* 38.华人团队终结Token危机：扩散模型数据潜力超自回归三倍  量子位  https://mp.weixin.qq.com/s/arIxWSG1i055i1HJeEcFog \
  扩散语言模型之所以具备超强的数据学习能力，主要有两个原因： \
  1）扩散目标和双向注意力机制使其能够进行双向建模，更充分地挖掘网络数据中的信息，，而这些数据并非完全因果关系。简单来说，传统自回归语言模型只能从前向上下文预测，存在严格的因果限制，这限制了模型对语言和其他非因果数据（如代码、生物序列等）中复杂模式的捕捉能力。扩散语言模型通过支持双向建模，打破了这种因果限制，更全面地利用数据，从而提升了学习效果。 \
  2）其计算密度极高。扩散模型在训练和推理过程中投入了更多计算资源（FLOPs），通过多次处理数据和迭代优化预测，提高了计算密度和模型性能。相比之下，自回归模型优先考虑计算效率，而非数据潜力。它们的transformer设计采用了教师强制（teacher forcing）和因果掩码（causal masking），虽然能最大化GPU的利用率，但也限制了模型的建模能力。
  
# 8.14 Thur
* 39.链式思维是幻象吗？从数据分布视角重新审视大模型推理，马斯克回复，Grok破防  机器之心  https://mp.weixin.qq.com/s/3uTM1Fu-B-QWjfy0FkpE3A \
  亚利桑那州立大学的一项最新研究却发现，CoT 推理可能并不是真正的推理，而更像是对训练数据分布内模式的复现。一旦输入任务与训练数据分布存在差异，这种看似稳固的推理链条就会迅速失效，呈现出类似「海市蜃楼」的脆弱性。 \
  Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens  \
  通过数据分布的视角，这项研究揭示了 CoT 推理的本质：它更像是对训练中出现过的模式的结构化复现，而不是真正的逻辑推理。一旦任务结构、推理链长度或输入格式超出了训练分布的范围，模型的表现便会迅速崩溃。
* 40.冗长响应缩减80%，DeepSeek GRPO获得颠覆性改进，微软GFPO问世  机器之心  https://mp.weixin.qq.com/s/gXegvKs4BZxkeUa7CPnMqw \
  Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning \
* 41.从Genie 3看懂“世界模型”：为什么说它比语言模型更接近AGI  夕小瑶  https://mp.weixin.qq.com/s/u1AGgjTj3ARWacVyTwGJ6Q \
  世界模型很难训，视频中的特征比语言多 \
  Yann LeCun 同样把世界模型放在核心地位。他曾公开强调：“没有对世界的建模，AI 就无法进行真正的推理。”LeCun 提出的 JEPA（Joint Embedding Predictive Architecture）尝试跳出像素层面的建模，转向预测隐藏状态的抽象表示，强调的是“预测未来潜在表征”的能力，而非逐像素生成。这种思路与人类认知极为相似——我们并不是逐帧还原画面，而是基于抽象模型推测世界会如何演化。
* 42.(**值得看看**)破解「长程智能体」RL训练难题，腾讯提出RLVMR框架，让7B模型「思考」比肩GPT-4o  机器之心  https://mp.weixin.qq.com/s/KICyG1BKoDP7pvFZGRrL1A \
  很多智能体虽然能完成任务，却像个「只会蒙答案的学生」，其成功往往依赖于运气和低效的试错，而非真正高效、可泛化的推理能力。 \
  腾讯混元 AI 数字人团队提出了 RLVMR (Reinforcement Learning with Verifiable Meta-Reasoning Rewards) 框架。这项工作开创性地将认知科学中的「元认知」（即 「思考自己的思考」）理论引入 RL，通过奖励「好的思考过程」而非仅仅奖励「好的结果」，首次实现了对智能体推理过程的端到端强化学习，成功解决了长程任务中的低效探索与泛化难题。 \
  RLVMR: Reinforcement Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon Agents

# 8.15 Fri
* 43.字节开源终身记忆多模态智能体，长时记忆+RL，实测超Gemini‑GPT4o！  探索AGI  https://mp.weixin.qq.com/s/bfXUsOud-BUv2bWiSs3n0g \
  字节Seed开源长线记忆多模态Agent，像人一样能听会看  量子位  https://mp.weixin.qq.com/s/Z_iWhM2BHLZR_iPaxe7dCg \
  https://github.com/ByteDance-Seed/m3-agent \
  整个系统的核心就是构建一个更像人脑、更结构化的、可持续学习的长期记忆系 \
  M3-Agent并非使用单轮检索增强生成（RAG）将记忆加载到上下文中，而是采用强化学习来实现多轮推理和迭代记忆检索，能自主从不同维度（如事件或角色）的长期记忆中检索相关信息，从而提高任务成功率
* 44.Meta视觉基座DINOv3王者归来：自监督首次全面超越弱监督，商用开源  机器之心  https://mp.weixin.qq.com/s/IG5OaG05O_-Ce9o7KkzKLg \
  小扎又开源了：7B实现自监督学习SOTA  量子位  https://mp.weixin.qq.com/s/6UCEtriUh7rC0c2Bpa7PHA \
  Hugging Face 地址：https://huggingface.co/docs/transformers/main/en/model_doc/dinov3 \
  博客地址：https://ai.meta.com/blog/dinov3-self-supervised-vision-model/
* 45.新范式，智能的本质不是算法，而是高维空间中的一种几何结构？智能的本质是数学，所有大模型正秘密融合，通用“心智”即将诞生  图灵人工智能  https://mp.weixin.qq.com/s/x4W9Uc3mXCOJxkh2_lzhcg 
* 46.SFT会记忆，RL能泛化：基础模型后训练的比较研究  CreateAMind  https://mp.weixin.qq.com/s/6aPyqnWJlFU59OxpPScltQ \
  SFT负责记忆，RL负责泛化

# 8.16 Sat
* 47.扩散语言模型综述  专知  https://mp.weixin.qq.com/s/-nYw_4Yldy-Cnm0EwFrLMg \
  A Survey on Diffusion Language Models \
  https://github.com/VILA-Lab/Awesome-DLMs
* 48.北大提出首个复数大模型，2比特量化，推理仅加法，可手机部署！  量子位  https://mp.weixin.qq.com/s/gpLLsi7o4JuepsjqvJeU5A \
  iFairy {+1, -1, +i, -i}
* 49.生成式AI之父Jürgen Schmidhuber：机器学习编年史与宇宙未来  图灵人工智能  https://mp.weixin.qq.com/s/FYK-LDVsslt0hu_flFi4yQ  \
  报告回放：https://event.baai.ac.cn/live/804
* 50.大模型如何推理？斯坦福CS25重要一课，DeepMind首席科学家主讲  机器之心  https://mp.weixin.qq.com/s/VkiQEz78zpx6pldPG6JrEw \
  课程页面：https://web.stanford.edu/class/cs25/ \
  LLM Reasoning \
  https://dennyzhou.github.io/LLM-Reasoning-Stanford-CS-25.pdf

# 8.17 Sun
* 51.400万人围观的分层推理模型，「分层架构」竟不起作用？性能提升另有隐情？  机器之心  https://mp.weixin.qq.com/s/7q5LhAnsfA2ePpAC5yxV3w \
  博客地址：https://arcprize.org/blog/hrm-analysis
  Github：https://github.com/arcprize/hierarchical-reasoning-model-analysis
* 52.CoRL 2025｜隐空间扩散世界模型LaDi-WM大幅提升机器人操作策略的成功率和跨场景泛化能力  机器之心  https://mp.weixin.qq.com/s/TNRZJ1NJDpvq1zGnmWFnOg \
  LaDi-WM（Latent Diffusion-based World Models） \
  https://guhuangai.github.io/LaDiWM.github.io/ \
  WM的作用：策略模型可以在一个时间步多次利用世界模型的未来预测作为引导，从而不断优化自身的动作输出。实验显示，该方案可以逐渐降低策略模型的输出分布熵，达到更准确的动作预测。
* 53.DeepMind CEO定义世界模型标准：不仅理解物理世界，还能创造它  图灵人工智能  https://mp.weixin.qq.com/s/5oUA5rjxvXG6khEU0rGYPw \
  哈萨比斯指出，“思考型模型” （the thinking models）是通向通用人工智能（AGI）的必经之路；DeepMind的终极目标是推出融合语言、多媒体、物理推理与生成能力的全能模型（Omni Model），其核心支撑正是世界模型的持续进化，最终将实现全面且一致的智能表现，推动通用人工智能（AGI）安全落地。
* 54.大模型SFT 22条实践经验，干活效率翻倍！  Datawhale  https://mp.weixin.qq.com/s/XgAIsVQotlf5dfUlbn1t0w
* 55.刚刚！谷歌内部揭秘Genie 3：Sora后最强AI爆款，开启世界模型新时代  新智元  https://mp.weixin.qq.com/s/mqTTlbWjtYZd3tGcgqhUzw \
  在设计上，他们还有一个明确的方向，就是不采用「显式表示法」。市面上已有一些方法，比如用NeRF或Gaussian Splatting等技术，通过构建明确的3D世界结构，来达到一致性。这些方法很好，在某些应用上效果不错。但他们坚持让模型「逐帧生成」，这种方式对模型的泛化能力、适应多样世界的能力更有帮助。
  特殊记忆
* 56.大模型赋能的具身智能：决策与具身学习综述  专知  https://mp.weixin.qq.com/s/DbW0BLinUJTZ_cj3wEeDBg \
  Large Model Empowered Embodied Al: A Survey on Decision-Making and Embodied Learning \
  本文对大模型赋能的具身智能进行了全面综述，重点聚焦于自主决策与具身学习。在决策方面，我们探讨了分层决策与端到端决策两类范式：具体而言，大模型如何增强分层决策中的高层规划、低层执行与反馈机制；以及大模型如何提升视觉-语言-行动（Vision-Language-Action, VLA）模型以支持端到端决策。在具身学习方面，我们介绍了主流的学习方法，并深入阐述大模型如何提升模仿学习与强化学习。首次地，我们将**世界模型（World Models）**纳入具身智能的综述，介绍其设计方法及其在增强决策与学习中的关键作用

# 8.18 Mon
* 57.万字长文实录：RL 界与 CV 界的“世界模型”有什么不同？  图灵人工智能  https://mp.weixin.qq.com/s/w713dQE8jUmRSDO--mRJfQ \
  RL和CV的WM差异在于动作 
* 58.ICML 2025 | 大模型能在信息不完备的情况下问出正确的问题吗？  机器学习研究组订阅  https://mp.weixin.qq.com/s/dP2ko1FPJKf3zSMM-842Pg \
  然而，当前针对 LLM 推理能力的研究主要集中于被动推理（Passive Reasoning, PR），即在提供完整信息的前提下让模型进行推理。相比之下，对信息不完备场景下模型推理能力的研究明显不足。这类场景在实际应用中十分常见，例如侦探需要通过询问和走访获取破案线索，医生需要通过问诊收集诊断依据。我们将这类需要主动获取信息的推理称为主动推理（Active Reasoning, AR） \
  大模型主动推理能力严重不足
* 59.协调客观坍缩理论的实证证据：意识源于细胞内微管的量子过程  集智  https://mp.weixin.qq.com/s/bE0Jx14h87Hbior0oOp90w \
  当麻醉剂吸入体内，人是如何失去意识的呢？这与细胞骨架结构的微管有何关系？哈梅罗夫（Stuart Hameroff）和彭罗斯（Roger Penrose）在 1996 年提出协调客观坍缩（Orch OR）的意识理论，认为意识源于细胞内微管的量子过程。在 Neuroscience of Consciousness 2025 年第 1 期，美国韦尔斯利学院神经科学系的Michael C Wiest 发表了题为《A quantum microtubule substrate of consciousness is experimentally supported and solves the binding and epiphenomenalism problems》的文章。文中他总结了支持 Orch OR 理论的实证证据，尤其是微管可能作为改变意识状态的多种麻醉剂的共同靶点，室温条件下微管可发生功能性量⼦效应，以及近期有研究发现⼈脑中的宏观量⼦纠缠态与意识状态和⼯作记忆存在相关性。作者提出，基于 Orch OR 量⼦意识模型的泛原⼼论（panprotopsychism） 哲 学 框 架 ，可 解 决 绑 定（the binding problem） 或 组 合 问 题（the combination problem） 、 意 识 难 题 （ the hard problem of consciousness ）、副 现 象 论（epiphenomenalism）等意识的哲学难题。
* 60.LLM为什么能看懂图？秘密不在Projector，残差结构才是跨模态理解的关键  PaperWeekly  https://mp.weixin.qq.com/s/B4SSNI2-0_zYsM4cLimNLQ \
  a. 不同模态在 LLM 中逐步得到对齐； \
  b. LLM 的残差结构造就了其强大的泛化性，使之能够在非文本 embedding 上泛化； \
  c. LLM 中天然存在模态无关的神经元，是它们建模了模态无关的抽象语义

# 8.19 Tue
# 8.20 Wed
# 8.21 Thur
# 8.22 Fri
# 8.23 Sat
# 8.24 Sun

# 8.25 Mon
# 8.26 Tue
# 8.27 Wed
# 8.28 Thur
# 8.29 Fri
# 8.30 Sat
# 8.31 Sun
