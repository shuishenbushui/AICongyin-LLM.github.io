# 8.1 Fri
* 1.为IIT提供结构，为GWT提供内部逻辑，为预测处理提供区分动态的意识范畴UTD  CreateAMind  https://mp.weixin.qq.com/s/QkvvcluM89ZOw9Hy9GeHHQ \
  From Differentiation to Cognition:UTD as a Model of Recursive Awareness
* 2.图灵奖得主加持，蒙特卡洛树搜索×扩散模型杀回规划赛道｜ICML 2025 Spotlight  量子位  https://mp.weixin.qq.com/s/hmNdvQ3MljFl-NiAia8bOQ \
  Monte Carlo Tree Diffusion for System 2 Planning \
  突破了扩散模型在长程任务推理阶段缺乏可扩展性的瓶颈

# 8.2 
* 3.多模态后训练反常识：长思维链SFT和RL的协同困境  机器之心  https://mp.weixin.qq.com/s/NVG3hjr1xIuLKRSmqckrWg \
  在多模态视觉语言模型（VLM）中，SFT+RL组合难以实现协同增益，甚至有时会互相拖后腿 \
  The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs

# 8.3 Sun
* 4.大模型训练的时间都花在哪了？  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/bl2_kCxShpghaf9BAu9xbg 
* 5.DeepMind哈萨比斯：AI能建模所有进化而来的事物  量子位  https://mp.weixin.qq.com/s/4vuQrBPHZvjFHiKZhSHFnw 
* 6.图灵奖得主Sutton再突破：强化学习在控制问题上媲美深度强化学习？  机器之心  https://mp.weixin.qq.com/s/I8IE8Ck-k5OoAy7SLqi9-Q \
  Swift-Sarsa: Fast and Robust Linear Control \
  近些天，Sutton 再发新论文，在强化学习领域再次发力，将他在 2024 年的时序差分学习新算法 SwiftTD 拓展到控制领域，在与一些更强大的预处理算法结合使用时，能够展现出与深度强化学习算法相当的性能表现

# 8.4 Mon
* 7.为什么GRPO重要性权重设计错误？详解Qwen3新强化学习算法GSPO  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/2Ta46U-OpNJPzKORu2wpPw \
  GRPO 对于 next-token 的重要性权重，容易引入高方差的噪声
* 8.连续思考机器 Continuous Thought Machines  CreateAMind  https://mp.weixin.qq.com/s/hwnmiEuOKbmIjNJ3p_LFoQ 
* 9.高质量「上下文工程」资源整理（含速览和精读）  夕小瑶科技说  https://mp.weixin.qq.com/s/bkrTmiWmI6Hxeo6F5IliIA
* 10.Meta华人新秀毕树超，重磅爆料下一代LLM路线！RL+预训练直通AGI  新智元  https://mp.weixin.qq.com/s/EqgKkEB0z90WRnx-sO57OQ
* 11.LLM抢人血案：强化学习天才被挖空，一朝沦为「无人区」！  新智元  https://mp.weixin.qq.com/s/_hUl6kkea6VlS04K-WHmsg \
  PufferLib
* 12.3D-R1：让AI理解3D世界的下一步  机器之心  https://mp.weixin.qq.com/s/TgFY_hZcA7tKX163kztHXg \
  3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding 

# 8.5 Tue

# 8.6 Wed
* 13.震撼，世界模型第一次超真实地模拟了真实世界：谷歌Genie 3昨晚抢了OpenAI风头  机器之心  https://mp.weixin.qq.com/s/iI0-UDW70nOqyRb95WuZNw \
  谷歌Genie3全网玩疯！画质飞跃720P，网友造出西幻RPG游戏  量子位  https://mp.weixin.qq.com/s/KYLIU6MQC_MIOwloahP3Iw \
  仍然存在局限
* 14.Attention Sink现象揭秘：Transformer为何偏爱首Token？  PaperWeekly  https://mp.weixin.qq.com/s/R62I_KVA3FHnk2xAsUlEtg 

# 8.7 Thur
* 15.人大高瓴-华为诺亚：大语言模型智能体记忆机制的系列研究  机器之心  https://mp.weixin.qq.com/s/n_oc7X1cZ1vGwPWhXpLUjA \
  A Survey on the Memory Mechanism of Large Language Model based Agents
* 16.(**值得看看**)强化学习的10层境界：从巴甫洛夫的狗到贝叶斯大脑  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/mWAAdUQ7LmBFGNtQ3MU8Zg 
* 17.(**从经验中学习的RL框架**)强化学习+MCP=王炸？开源框架教AI在MCP中玩转工具解决任务，实测效果超越GPT！  量子位  https://mp.weixin.qq.com/s/YaP6aTuKvONTpnLp_VEUHA \
  专注于LLM+RL的科技公司OpenPipe提出全新开源强化学习框架——MCP·RL \
  只需一个MCP Server的地址，agent就能自动发现工具、生成任务，通过强化学习在闭环反馈中摸索出最优调用策略 \
  MCP·RL是科技公司OpenPipe基于强化学习的智能体训练系统(Agent Reinforcement Trainer，ART)的最新项目。ART是一个开源强化学习框架，其核心思想是让LLM从经验中学习，从而提高agent的可靠性，ART可以将GRPO集成到任何Python应用中。 \
  https://github.com/OpenPipe/ART?tab=readme-ov-file#-notebooks
* 18.字节&MAP重塑大模型推理算法优化重点，强化学习重在高效探索助力LLM提升上限  量子位  https://mp.weixin.qq.com/s/8XfVIRaLfgViBCPNVew0jA \
  一个普遍存在的现象是：在训练过程中，模型的熵值迅速下降，推理路径趋于固化，导致“利用（exploitation）”远超“探索（exploration）”，严重失衡。这种过早收敛不仅削弱了模型的多样性生成能力，也限制了其性能上限的进一步突破。 \
  First Return, Entropy-Eliciting Explore（FR3E） \
  受openai经典论文 First Return, Then Explore 的启发

# 8.8 Fri
* 19.追问专访·Donald Hoffman教授 | 我们能否构建出意识的数学模型？  追问  https://mp.weixin.qq.com/s/GDmf0sdFZRQznu5OMu3V8w \
  意识领军人物科赫：一个浪漫还原论者的自白  追问  https://mp.weixin.qq.com/s/Ry_igAgItWIy5eUYGEgc4w \
  《意识探索》
* 20.DeepSeek的GRPO会导致模型崩溃？看下Qwen3新范式GSPO  机器之心  https://mp.weixin.qq.com/s/YSlp-SXzi7bSW2Y-shJ8ww \
* 21.硬核拆解大模型，从 DeepSeek-V3 到 Kimi K2 ，一文看懂 LLM 主流架构  机器之心  https://mp.weixin.qq.com/s/_as8aCv325cAeJ6kMv9_aA

# 8.9 Sat
* 22.ICML 2025 | 千倍泛化不涨显存！蚂蚁推出新注意力机制，实现16M上下文精准检索  PaperWeekly  https://mp.weixin.qq.com/s/jdU8o07RanOrlcvDXz9VAA \
  提出一种基于因果检索的注意力机制 GCA (Grouped Cross Attention)，完全端到端地学习如何从上文检索并挑选最相关片段，从而实现超长序列高性能处理与泛化能力。人类记忆的另一个特性是大部分时候记忆处于沉睡状态，相关记忆片段只会在激活时进入意识。类似地，GCA 通过将上文信息卸载到 CPU / 磁盘，只在需要的时候动态加载需要的片段到 GPU 的方式，大幅降低了长文本处理的显存开销 \
  Efficient Length-Generalizable Attention via Causal Retrieval for Long-Context Language Modeling \
  https://github.com/ant-research/long-context-modeling
* 23.3万字长文！深度解析大语言模型LLM原理  Datawhale  https://mp.weixin.qq.com/s/7aYSBY0UxyEHKcqzC1fqtg

# 8.10 Sun
* 24.面向视觉语言模型的持续学习：遗忘之外的综述与分类体系  专知  https://mp.weixin.qq.com/s/_-Vsu56jEy-b_Hvi1EbyOw \
  VLMs 如何在随时间获取新知识的同时，不遗忘其原有能力？ \
  Continual Learning for VLMs: A Survey and Taxonomy Beyond Forgetting \
  https://github.com/YuyangSunshine/Awesome-Continual-learning-of-Vision-Language-Models
* 25.
* 26.
* 27.

# 8.11 Mon
# 8.12 Tue
# 8.13 Wed
# 8.14 Thur
# 8.15 Fri
# 8.16 Sat
# 8.17 Sun

# 8.18 Mon
# 8.19 Tue
# 8.20 Wed
# 8.21 Thur
# 8.22 Fri
# 8.23 Sat
# 8.24 Sun

# 8.25 Mon
# 8.26 Tue
# 8.27 Wed
# 8.28 Thur
# 8.29 Fri
# 8.30 Sat
# 8.31 Sun
