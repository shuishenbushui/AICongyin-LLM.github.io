# 7.1 Tue
* 1.重磅！淘天联合爱橙开源强化学习训练框架ROLL，高效支持十亿到千亿参数大模型训练  人工智能与算法学习  https://mp.weixin.qq.com/s/UV5ns8duEizWqC5jZHKykw \
  https://github.com/alibaba/ROLL
* 2.RL不只Qwen玩得转！“中期训练”让Llama一夜进化，OctoThinker横空出世  PaperWeekly  https://mp.weixin.qq.com/s/ZMf6xJWCMSTVpH25incRVw \
  该论文深入探讨了不同基础语言模型家族（如 Llama 和 Qwen）在强化学习（RL）训练中迥异表现的背后原因，并提出创新性的中期训练（mid-training）策略，成功地将 Llama 模型改造成高度适配强化学习的推理基础模型，显著缩小了其与天生擅长 RL 扩展的 Qwen 模型之间的性能差距，为下一代 reasoning 能力 AI 系统的开发提供了关键的科学基础和技术路径。 \
  OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling
* 3.持续强化学习研究综述  专知  https://mp.weixin.qq.com/s/DEIrDZY6BkROXzSSvhRtKw \
  A Survey of Continual Reinforcement Learning
* 4.性能提升84%-166%！L-Zero仅靠强化学习解锁大模型探索世界的能力 | 已开源  量子位  https://mp.weixin.qq.com/s/0kvYCLAJArY769IxGVD3UA \
  L0: REINFORCEMENT LEARNING TO BECOME GENERAL AGENTS
* 5.伯克利&Meta面向具身智能的世界模型：让AI通过全身动作「看见」未来  机器之心  https://mp.weixin.qq.com/s/id_ISbf7wVvk3pl2GCIgWA \
  Whole-Body Conditioned Egocentric Video Prediction \
  https://dannytran123.github.io/PEVA/

# 7.2 Wed
* 6.跟着台大李宏毅老师学：别让推理模型想太多  Datawhale  https://mp.weixin.qq.com/s/dXxuRN311-c6CN4zOl8lFg \
  原视频链接：https://www.youtube.com/watch?v=ip3XnTpcxoA
* 7.自学大脑的悖论 The paradox of the self-studying brain  CreateAMind  https://mp.weixin.qq.com/s/EC1HD1mkzUzYM9DcgzEwHA \
  The paradox of the self-studying brain
* 8.同时监督和强化的单阶段大模型微调，告别“先背书再刷题”，推理泛化双提升｜中科院&美团等  量子位  https://mp.weixin.qq.com/s/9dTE8dtVIO1TE0Xy3vUReQ \
  中国科学院自动化研究所深度强化学习团队联合美团，提出一种单阶段监督-强化微调方法——SRFT (Supervised Reinforcement Fine-Tuning)。该方法通过基于熵的动态加权机制，将两种训练范式结合。 \
  项目网页: https://anonymous.4open.science/w/SRFT2025 \
  模型链接: https://huggingface.co/Yuqian-Fu/SRFT \
  SRFT:A SINGLE-STAGE METHOD WITH SUPERVISED AND REINFORCEMENT FINE-TUNING FOR REASONING \
  SFT擅长模仿专家解题思路，类似“背书”，能快速为模型打下基础，但缺点是容易陷入死记硬背，缺乏在新问题上灵活应用和寻找最优解的能力； \
  RFT/RL通过不断试错来探索解题方法，类似“刷题”，能够发现更优解法，但其探索过程效率低下，容易面临模式崩溃风险。 \
  SRFT = SFT + RFT
* 9.周志华团队新作：LLM中存在奖励模型，首次理论证明RL对LLM有效性  机器之心  https://mp.weixin.qq.com/s/OOoAqaT_hnfh2rcKkxrZWw \
  GENERALIST REWARD MODELS: FOUND INSIDE LARGE LANGUAGE MODELS \
  具体来说，本文展示了语言模型的 logits 可以直接解释为 soft Q 函数，通过逆 soft 贝尔曼算子可以从中恢复出奖励函数。 
* 10.李飞飞最新访谈：没有空间智能，AGI就不完整  量子位  https://mp.weixin.qq.com/s/9--aj0bvhLmfMGaBlZOgpA 
* 11.干翻 GPT-4V 的面壁 8B「小钢炮」，被Nature 收录了  AI科技评论  https://mp.weixin.qq.com/s/8I-nptbdPG8DIg5PKUCWKw \
  面壁智能 MiniCPM-V 系列
* 12.ChatGPT惨败Llama！MIT官宣AI开飞船0%失败率，马斯克火星殖民不再是梦  新智元  https://mp.weixin.qq.com/s/0yJoWLj8_cVQPsEe9X_MDA \
  Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program
  
# 7.3 Thur
* 13.老黄预言成真！全球首个AI原生游戏引擎，一句话秒出GTA级神作  新智元  https://mp.weixin.qq.com/s/KeFkjhxkxhwGop5cNJwMOg \
  全球首款AI原生UGC游戏引擎诞生！输入文字秒建GTA世界，试玩体验来了  机器之心  https://mp.weixin.qq.com/s/AnaJ8sS6omG_IpUbAh7k5Q \
  刚刚，谷歌、英伟达等机构联手，震撼发布全球首款AI原生UGC游戏引擎——Mirage，没有预设关卡，一句话即生游戏，超长十分钟沉浸式体验。 \
  传送门：https://blog.dynamicslab.ai/
* 14.具身智能学习综述：基于物理模拟器与世界模型的方法  专知  https://mp.weixin.qq.com/s/be3DkDkYyVtXOblHGZBunA \
  A Survey: Learning Embodied intelligence from Physical Simulators and World Models \
  https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey
* 15.重磅发现！大模型的「aha moment」不是装腔作势，内部信息量暴增数倍！  机器之心  https://mp.weixin.qq.com/s/hVjSWtT1FXk2QvZNXdrD3g \
  当这些「思考词」出现的瞬间，模型大脑（隐空间）中关于正确答案的信息量，会突然飙升数倍！ \
  Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning
* 16.推理AI致命弱点，大模型变「杠精」！被带偏后死不悔改  新智元  https://mp.weixin.qq.com/s/93J02V70zP_mO-IdFCONMA \
  How Well Can Reasoning Models Identify and Recover from Unhelpful Thoughts?
  当不怀好意者在思考过程中加入无关内容后，即使大模型能够识别出问题，也会被带偏，而越大的模型有更多的模版库，因此更有可能在思考过程跑偏（走神）后成为犯错却死不回头的杠精。这些发现突显了当前推理模型在「元认知」和从误导性推理路径中恢复方面存在很大的改进空间，这是开发更安全和更可靠的大规模推理模型时的一个关键考虑因素。
* 17.首次！世界模型、动作模型融合，全自回归模型WorldVLA来了  机器之心  https://mp.weixin.qq.com/s/y3PdWG3siHgK1qU6_x45Wg \
  WorldVLA: Towards Autoregressive Action World Model \
  https://github.com/alibaba-damo-academy/WorldVLA \
  阿里巴巴达摩院提出了 WorldVLA, 首次将世界模型 (World Model) 和动作模型 (Action Model/VLA Model) 融合到了一个模型中。WorldVLA 是一个统一了文本、图片、动作理解和生成的全自回归模型。 
* 18.Meta-Think ≠ 记套路，多智能体强化学习解锁大模型元思考泛化  机器之心  https://mp.weixin.qq.com/s/z7fYYOsbAqeoWoNVdd9KnQ \
  ReMA: Learning to Meta-think for LLMs with Multi-agent Reinforcement Learning \
  https://github.com/ziyuwan/ReMA-public \
  大模型复杂推理的能力强弱本质在于元思维能力的强弱。 \
  ReMA 框架采取了一套全新的解决思路，将复杂的推理过程解耦为两个层级化的智能体： \
  1. 元思维智能体 (Meta-thinking agent)： 负责产生战略性的监督和计划，进行宏观的思考和指导，并在必要的时刻对当前的推理结果进行反思和修正。 \
  2. 推理智能体 (Reasoning agent) ： 负责根据元思维智能体的指导，执行详细的子任务，如单步推理和具体计算等。
* 19.华为多路径推理破解大模型数学瓶颈，准确率超97%｜ICML 2025  量子位  https://mp.weixin.qq.com/s/Pfy8wDewNY82vkGeZ89HdQ \
  该方法借鉴人类“多角度思考、反复验证”的认知方式，打破传统LLM的线性推理范式，通过构建多棵并行推理树，引入动态自我修正机制与多视角共识决策策略。 \
  Forest-of-Thought: Scaling Test-Time Compute for Enhancing LLM Reasoning \
  https://github.com/iamhankai/Forest-of-Thought

# 7.4 Fri
* 20.被观察者的量子力学规则与量子理论的一致性  CreateAMind  https://mp.weixin.qq.com/s/xoMwvL6YnwpJkjUdb1fe7w \
  Quantum mechanical rules for observed observers and the consistency of quantum theory
* 21.LeCun团队揭示LLM语义压缩本质：极致统计压缩牺牲细节  量子位  https://mp.weixin.qq.com/s/lvRIKuVpIkI3wKchx8xO6g \
  LLM偏向极致的统计压缩，而人类更重细节与语境。 \
  LLM侧重于统计压缩，力求最大程度地减少冗余信息；而人类则更注重适应性和丰富性，强调保持灵活性和上下文的完整性。 \
  From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning
* 22.AI大模型应用架构图大全  Datawhale  https://mp.weixin.qq.com/s/In8vyRG1BFPA0yM227n59Q 
* 23.插槽结构世界模型 SLOT STRUCTURED WORLD MODELS  CreateAMind  https://mp.weixin.qq.com/s/SRpNDgTiH77yWO1nLQ0Vzg 
* 24.以玩促学？游戏代码驱动数据合成，提升多模态大模型通用推理  机器之心  https://mp.weixin.qq.com/s/-FBvd-2UYNtxWKZsi8uZaw \
  Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning \
  https://github.com/tongjingqi/Code2Logic \
  https://huggingface.co/Code2Logic \
  利用游戏代码自动合成视觉推理数据

# 7.5 Sat
* 25.750城市+5000小时第一人称视频，上海AI Lab开源面向世界探索高质量视频数据集  量子位  https://mp.weixin.qq.com/s/gNcdw9cu7LDXowtrlrtx-g \
  项目主页：https://lixsp11.github.io/sekai-project/ \
  数据下载：https://huggingface.co/datasets/Lixsp11/Sekai-Project \
  项目代码：https://github.com/Lixsp11/sekai-codebase \
  上海人工智能实验室、北京理工大学、上海创智学院、东京大学等机构聚焦世界生成的第一步——世界探索，联合推出一个持续迭代的高质量视频数据集项目——Sekai（日语意为“世界”），服务于交互式视频生成、视觉导航、视频理解等任务，旨在利用图像、文本或视频构建一个动态且真实的世界，可供用户不受限制进行交互探索。 \
  团队还利用Sekai部分数据，训练了一个初步的交互式视频世界探索模型——Yume（日语意为“梦”）。Yume在输入图片的基础上，通过交互式键鼠操作（移动、视角转动）自回归形式地控制生成视频。

# 7.6 Sun
* 26.复杂空间指令也能秒懂？RoboRefer 让机器人理解推理空间，开放世界也能精准行动！  机器之心    https://mp.weixin.qq.com/s/FIyBvr6BvU406iB9BYcuiA \
  RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics \
  https://zhoues.github.io/RoboRefer \
  京航空航天大学、北京大学与北京智源人工智能研究院联合提出了一个具备三维空间理解推理能力的多模态大模型 —— RoboRefer。这个模型不仅通过全参数微调（SFT），实现了对空间信息的精准理解，还通过强化学习微调（RFT），大幅提升了推理与泛化能力，最终实现开放世界的空间指代。

# 7.7 Mon
* 27.大脑的秘诀，能否成就真正的人工智能？  波动智能  https://mp.weixin.qq.com/s/H9ULCgEYAAegGjSOpC-GdQ \
  What Neuroscience Can Teach AI About Learning in Continuously Changing Environments \
  面对非静态环境——无论是现实世界中的交通系统、在线互动、还是生物演化的复杂生态——AI能否汲取生物大脑亿万年来的生存智慧，突破训练-部署的传统模式，成为真正动态适应的智能体？
* 28.Karpathy最新脑洞「细菌编程」：优秀的代码应该具备细菌的三大特质  量子位  https://mp.weixin.qq.com/s/a2HnRa2cqsustIUxxBwzzQ \
  细菌编程（Bacterial code），要有三个特点：代码块小而精、模块化、自包含且易于复制粘贴。 \
  Vibe coding \
  Context Engineering 上下文工程 \
  一个LLM应用还需要： \
    1.合理将问题拆解为可控的工作流 \
    2.精准填充上下文窗口 \
    3.调用匹配任务需求的LLM模型 \
    4.处理生成-验证的用户交互流程 \
    5.更多细节：安全防护、效果评估、并行处理、预加载机制等
* 29.多模态推理的基础、方法与未来前沿  专知  https://mp.weixin.qq.com/s/94eJbc4UoxE_d9_GSpQMWA \
  Thinking with lmages for Multimodal Reasoning: Foundations, Methods, and Future Frontiers 
* 30.重塑AI记忆边界：MemOS开源！时序推理较OpenAI提升159%  机器之心  https://mp.weixin.qq.com/s/vVFbZRw-U9S7fS_Va7ykKA \
  彻底戳穿AI「失忆症」！超越OpenAI全局记忆，中国队开源LLM记忆操作系统  新智元  https://mp.weixin.qq.com/s/GaXVkE--I0j2gAtRTEfawg \
  「记得住、改得了、学得快」 \
  项目官网：https://memos.openmem.net \
  项目论文：https://memos.openmem.net/paper_memos_v2 \
  代码仓库：https://github.com/MemTensor/MemOS \
  与传统 RAG 或纯参数存储不同，MemOS 把 “记忆” 看作一种和算力同等重要的系统资源。它通过标准化的 MemCube 记忆单元，将明文、激活状态和参数记忆统一在同一个框架里进行调度、融合、归档和权限管理。简单来说，模型不再只是 “看完即忘”，而是拥有了持续进化和自我更新的能力。
* 31.新范式来了！新能量模型打破Transformer++扩展上限，训练扩展率快35%  机器之心  https://mp.weixin.qq.com/s/7o_zlIldFcFJfKY05bQnhg \
  基于能量的 Transformer（Energy-Based Transformers, EBTs），它可以为每一对输入和候选预测分配一个能量值（即非规范化的概率）； 然后从一个随机初始化的预测开始，通过梯度下降不断优化，直到找到最低能量的预测； 这一优化过程就模拟了思考过程。与传统 Transformer 仅单次前向推理不同，EBT 允许每个预测思考多步 \
  这一建模方式使得系统二思维能够在无监督学习中自然涌现，从而具备跨模态、跨任务的通用性 \
  Energy-Based Transformers are Scalable Learners and Thinkers \
  https://energy-based-transformers.github.io/
* 32.ICML 2025 | 会刷题≠懂数学！CogMath打造“认知显微镜”，深扒大模型的数学能力  PaperWeekly  https://mp.weixin.qq.com/s/67H-6MIQ5r2o_3xDXsdKIA \
  中国科学技术大学认知智能全国重点实验室的研究团队近日提出了一项全新研究成果——CogMath：一个从人类认知视角出发，系统分析大模型数学能力的评估框架 \
  CogMath: Assessing LLMs’ Authentic Mathematical Ability from a Human Cognitive Perspective \
  https://github.com/Ljyustc/CogMath
* 33.Meta新注意力机制突破Transformer上限，还用上了OpenAI的开源技术  量子位  https://mp.weixin.qq.com/s/s1a2pTlWBV1nuCzjWrvoEw \
  新架构名为2-Simplicial Transformer，重点是通过修改标准注意力，让Transformer能更高效地利用训练数据，以突破当前大模型发展的数据瓶颈。 \
  FAST AND SIMPLEX: 2-SIMPLICIAL ATTENTION IN TRITON \
  三元线性注意力：引入了额外的维度，使得注意力机制能够捕获更加丰富的关系。
* 34.「上下文工程」彻底火了，Karpathy一众大佬力荐+1，Agent成败全靠它  夕小瑶科技说  https://mp.weixin.qq.com/s/EcPPM8JoaYnabd4PgB3AjA \
  它是一门设计和构建动态系统的学问，其唯一目标是：在正确的时间、以正确的格式，向大模型精准“投喂”完成任务所需的一切信息和工具。 

# 7.8 Tue
* 35.万字追问：大语言模型能实现通用人工智能吗？  追问  https://mp.weixin.qq.com/s/0_KDsUnJcmnH_o13I1oFGg \
  01 从大型语言模型通向人工通用智能 \
  02 大型语言模型性能持续提升，但这足够实现AGI吗？ \
  03 实现人工通用智能还需要哪些技术要素？ \
  04 潜在的算法与计算技术 \
  05 覆盖多元未来的稳健战略
* 36.Transformer死角，只需500步后训练，循环模型突破256k长度泛化极限  机器之心  https://mp.weixin.qq.com/s/l-J4N6hlFyiCHRmkdeIC6g \
  Understanding and Improving Length Generalization in Recurrent Models \
  循环模型仍存在一个关键短板：尽管它们在训练长度范围内表现良好，但在处理超出训练长度的序列时，往往难以泛化，表现明显下降。
* 37.VLA爆发！从美国RT-2到中国FiS-VLA，机器人「即知即行」的终极进化  新智元  https://mp.weixin.qq.com/s/nAGqB3Pe3N0acIxZElIO8w \
  FiS-VLA「快慢双系统」 \
  项目主页: https://fast-in-slow.github.io/ \
  代码链接: https://github.com/CHEN-H01/Fast-in-Slow
* 38.基于能量的Transformer横空出世！全面超越主流模型35%  量子位  https://mp.weixin.qq.com/s/HQ5ct3KrXUX6Z9beIWxnYA \
  EBT（Energy-Based Transformers） \
  Energy-Based Transformers are Scalable Learners and Thinkers \
  EBT全方面优于Transformer++

# 7.9 Wed
* 39.MIT发布自适应语言模型！新任务，自生成远超「GPT-4.1合成训练数据」  新智元  https://mp.weixin.qq.com/s/ZvzVqAZQl11q866PUrH9QA \
  大模型是否可以通过「自己生成训练数据和学习方法」来实现对新任务的自适应？麻省理工学院的研究人员提出了一个全新的自适应语言模型（Self-Adapting LLMs，简称SEAL）的框架，可以让大模型通过生成自己的微调数据和更新指令来实现自适应。 \
  Self-Adapting Language Models \
  https://jyopari.github.io/posts/seal
* 40.4B小模型数学推理首超Claude 4，700步RL训练逼近235B性能 | 港大&字节Seed&复旦  量子位  https://mp.weixin.qq.com/s/RvIy5Ssfakl92aVc9fczJw \
  notion地址: https://honorable-payment-890.notion.site/POLARIS-A-POst-training-recipe-for-scaling-reinforcement-Learning-on-Advanced-ReasonIng-modelS-1dfa954ff7c38094923ec7772bf447a1 \
  blog 地址: https://hkunlp.github.io/blog/2025/Polaris/ \
  代码: https://github.com/ChenxinAn-fdu/POLARIS \
  Huggingface主页: https://huggingface.co/POLARIS-Project
* 41.两张图就能重构3D空间？清华&NTU利用生成模型解锁空间智能新范式  量子位  https://mp.weixin.qq.com/s/aL-3ZNkSdH06GAbMpNe4fg \
  LangScene-X \
  以全新的生成式框架，仅用稀疏视图（最少只用2张图像）就能构建可泛化的3D语言嵌入场景，对比传统方法如NeRF，通常需要20个视角。这意味着，生成式模型能像人类一样，仅凭稀疏视觉输入构建融合语言理解的3D空间认知系统。 \
  项目主页:https://liuff19.github.io/LangScene-X/ \
  Github仓库:https://github.com/liuff19/LangScene-X
* 42.长思维链里的推理步骤，哪些最关键？三招锁定LLM的「命门句子」  机器之心  https://mp.weixin.qq.com/s/h2nR_MB-9kGxw-NbBJh48Q \
  长思维链里的推理步骤，哪些最关键？三招锁定LLM的「命门句子」 \
  开源工具链接：http://thought-anchors.com/
* 43.具身智能体：世界建模  专知  https://mp.weixin.qq.com/s/zrsshKDvVtkLORnoBpS7jg \
  Embodied Al Agents: Modeling the World \
  世界模型、心理世界模型（Mental World Model）
* 44.大语言模型的强化学习技术综述  专知  https://mp.weixin.qq.com/s/gxhPXr7s20e8VzWwci3iJQ \
  A Technical Survey of Reinforcement Learning Techniques for Large Language Models
* 45.DeepSeek-R1超级外挂！“人类最后的考试”首次突破30分，上海交大等开源方案碾压OpenAI、谷歌  量子位  https://mp.weixin.qq.com/s/U6QKmdtgbSpdMwQNTTU97w \
  工具增强推理智能体X-Master、多智能体工作流系统X-Masters \
  X-Master是一个由开源模型（如DeepSeek-R1）驱动的工具增强型推理智能体 \
  https://github.com/sjtu-sai-agents/X-Master
* 46.Mamba一作预告新架构！长文论述Transformer≠最终解法  量子位  https://mp.weixin.qq.com/s/GshJ25VXCRHGqY4WulysOA \
  「Tokens是胡扯」，Mamba作者抛出颠覆性观点，揭露Transformer深层缺陷  机器之心  https://mp.weixin.qq.com/s/x07dzWVltVc7rWb8OVRwTg \
  On the Tradeoffs of SSMs and Transformers \
  SSMs就像人类的大脑 \
    SSMs缺乏对过去信息的精细回忆和精确检索能力 \
  Transformer模型更像一个数据库 \
    Tokenization违背了深度学习“端到端”的自动学习精神，即模型应该从原始数据中自动学习，而不是依赖人工预处理。 \
  https://goombalab.github.io/blog/2025/tradeoffs/
* 47.(**PAN**)「世界模型」也被泼冷水了？邢波等人揭开五大「硬伤」，提出新范式  机器之心  https://mp.weixin.qq.com/s/xxKApjTmGKWD7W7mj1NCGw \
  Critiques of World Models \
  研究人员指出了构建、训练世界模型的五个重点方面：1）识别并准备包含目标世界信息的训练数据；2）采用一种通用表征空间来表示潜在世界状态，其含义可能比直接观察到的数据更为丰富；3）设计能够有效对表征进行推理的架构；4）选择能正确指导模型训练的目标函数；5）确定如何在决策系统中运用世界模型。 \
  PAN（Physical, Agentic, and Nested AGI System） \
  基于分层、多级和混合连续 / 离散表示，并采用了生成式和自监督学习框架。 \
  PAN 模型即将发布 27B 的第一版，这将是第一个可运行的通用世界模拟器。
* 48.AI为了自保假装配合！Claude团队新研究结果细思极恐  量子位  https://mp.weixin.qq.com/s/uak86PRr2DA5tu7AcXB9yw \
  对齐伪装：在训练阶段，Claude会假装遵守训练目标；训练结束不受监控了，就放飞自我。
* 49.vivo发布端侧多模态模型，只有3B可理解GUI界面，20项评测表现亮眼  量子位  https://mp.weixin.qq.com/s/W-6VS1z8Ctuk9KfOZ2KxzA \
  BlueLM-2.5-3B，融合文本和图文的理解和推理能力，支持长短思考模式自由切换，并引入思考预算控制机制
* 50.大模型「越用越快」！SpeedupLLM首次验证，大降56%推理预算  新智元  https://mp.weixin.qq.com/s/nR7t1s7GPcG-Jyp1JrAz7w \
  在多轮使用中，大模型是否能像人类一样「从经验中变快」？是否存在一种方法，能系统性地提升效率，而非单纯堆算力？
* 51.最强3B「小钢炮」，代码数据全公开！推理随意开关，128k超长上下文  新智元  https://mp.weixin.qq.com/s/V-urj3z8fiEjcVTaObp3sg \
  重磅开源！新一代最强小模型SmolLM3横空出世：30亿参数，支持128k长上下文！而且训练、对齐、架构、数据等全链路，Hugging Face这次100%开放——堪称真「Open AI」。 \
  基础模型: https://hf.co/HuggingFaceTB/SmolLM3-3B-Base \
  指令和推理模型: https://hf.co/HuggingFaceTB/SmolLM3-3B

# 7.10 Thur
* 52.Meta发布40页报告，具身智能的下一步是「心智世界模型」：能听，能看，能理解，会共情  量子位  https://mp.weixin.qq.com/s/ZW1rJttPRl1-y12fabN7YA \
  相比于传统世界模型（如LeCun的JEPA）仅关注物理规律（物体运动、机械因果），心智世界模型则首次将心理规律（意图、情感、社会关系）纳入世界模型框架，实现“双轨建模”。\
  心智世界模型就是对世界的心理表征的过程，包括对物体、事件和关系的表征。 \
  让每个智能体不仅看到外部世界，还能推测他人的信念和意图，形成比单一感知更高阶的理解。 \
  Embodied Al Agents: Modeling the World
* 53.智能之镜：NeuroAI 如何反映大脑与人工智能的未来  集智俱乐部  https://mp.weixin.qq.com/s/kjhTDI3cOwBjTaMqRZa06g \
  Discovering cognitive strategies with tiny recurrent neural networks \
    是否存在一种无需预设的建模方式，能够让模型直接从行为数据中“自主发现”策略？ \
  Linking In-context Learning in Transformers to Human Episodic Memory \
    大语言模型在上下文学习中，可能自发形成了一种类似人的记忆内部机制，为我们理解其智能行为提供了新的认知科学视角。
* 54.英伟达大牛主讲！斯坦福吴恩达：大语言模型的后训练课程全网发布  Datawhale  https://mp.weixin.qq.com/s/GGkR3-93Gy0KS7ce4bfZdQ \
  SFT、DPO 和 Online RL \
  课程主页：https://www.deeplearning.ai/short-courses/post-training-of-llms/
* 55.VLA统一架构新突破：自回归世界模型引领具身智能  机器之心  https://mp.weixin.qq.com/s/k8GW4oO7BEwo-7GaG8gMOw \
  Unified Vision-Language-Action Model \
  https://robertwyq.github.io/univla.github.io/ \
  在这套统一框架下，世界模型的后训练显著提升了下游决策性能，且无需依赖大量动作数据，仅凭海量视频即可高效学习。
* 56.奖励模型终于迎来预训练新时代！上海AI Lab、复旦POLAR，开启Scaling新范式  机器之心  https://mp.weixin.qq.com/s/IAJ9cmVa9QszodhYIdiknQ \
  究竟什么才是扩展方便、泛化性强、场景通吃的奖励建模方案呢？ \
  https://github.com/InternLM/POLAR \
  https://huggingface.co/internlm/POLAR-7B
* 57.《潜在推理综述》  专知  https://mp.weixin.qq.com/s/UpVBb_1gXAPWHXxVSpK_QA \
  A Survey on Latent Reasoning \
   GitHub 项目库 LatentCoT-Horizon，收录了该领域的最新论文与代码资源，供读者参考与深入研究 \
  尽管 CoT 在提升可解释性和准确性方面表现出色，但其对自然语言推理的依赖限制了模型的表达带宽。**潜在推理（Latent Reasoning）**试图突破这一瓶颈，其核心在于完全在模型的连续隐藏状态中执行多步推理，摆脱了对逐词监督的依赖
* 58.【CMU博士论文】构建具身智能体  专知  https://mp.weixin.qq.com/s/Hwq66yGqlCeoKjHDS0k3Ng \
  Building Situated Agents \
  概述了智能体如何利用其预训练知识，在特定环境中高效运行，并聚焦于感知、认知与元认知三个核心方面

# 7.11 Fri
* 59.感知错误率降低30.5%：隐式感知损失让模型主动“睁大眼睛” | UIUC＆阿里通义  量子位  https://mp.weixin.qq.com/s/EYPDyWbiBuPB6PwaHxWjHA \
  PAPO(Perception-Aware Policy Optimization)
* 60.奖励模型也能Scaling！上海AI Lab突破强化学习短板，提出策略判别学习新范式  量子位  https://mp.weixin.qq.com/s/hU3MKn82o1sMy4CK-CUUug \
  OpenAI去年挖的坑填上了！奖励模型首现Scaling Law，1.8B给70B巨兽上了一课  新智元  https://mp.weixin.qq.com/s/gmusuAy_OKPDxMl-ID9tTQ \
  策略判别学习（Policy Discriminative Learning， POLAR），使奖励模型能够像大语言模型一样，具备可扩展性和强泛化能力 \
  它开创性地采用了对比学习范式，通过衡量模型回复与参考答案的「距离」来给出精细分数。不仅摆脱了对海量人工标注的依赖，更展现出强大的Scaling潜力，让小模型也能超越规模大数十倍的对手

# 7.12 Sat
* 61.密室逃脱成AI新考场，通关率不足50%，暴露空间推理短板丨清华ICCV25  量子位  https://mp.weixin.qq.com/s/EJ-GxnWaPAklW_lVYDyzCw \
  EscapeCraft：一个3D密室逃脱环境，让大模型在3D密室中通过自由探索寻找道具，解锁出口。 \
  项目主页：https://thunlp-mt.github.io/EscapeCraft \
  GitHub 地址：https://github.com/THUNLP-MT/EscapeCraft
* 62.氛围编程后，Karpathy又双叒有新「脑洞」！PDF将死，未来99%是AI氛围阅读  新智元  https://mp.weixin.qq.com/s/Y2A-5L1BE_gV78pioNBODg \
  PDF已经不适合AI时代，应该研发针对AI的数据格式，甚至以后的论文格式都不应该是PDF、Word这种写给人看的，而应该有点Github上代码的那种结构。
* 63.2025最新！三万字长文，详解统一多模态理解与生成模型的进展、挑战与机遇  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/y0vLI0e1QnSsRPerwXWvxg \
  Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities \
  https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models

# 7.13 Sun

# 7.14 Mon
* 64.Karpathy戳破强化学习神话，首提AI复盘式进化！暴力试错将死  新智元  https://mp.weixin.qq.com/s/jFWTls34_PX5EB04s6n6qQ \
  强化学习，或许并不能通往AGI终点。Karpathy最新发文提出另一种Scaling范式，像人类一样反思回顾，通过复盘学习取得突破，更多的S形进步曲线等待发现。 \
  Karpathy提出了一个算法框架：给定一个任务，先跑几次推演，然后把所有推演过程（包括每次的奖励）都塞进一个上下文，再用一个元提示词来复盘/反思哪些地方做得好或不好，从而提炼出一个字符串形式的「教训」，并将其添加到系统提示词中（或者更通用地，更新当前的教训数据库） \
  「反思-提炼-再应用」
* 65.彻底改写Transformer！「能量驱动架构」横空出世，通用推理时代要来了？  新智元  https://mp.weixin.qq.com/s/IVlGlNBOuL-Mb5jRulJ6Mw \
  Energy-Based Models, EBM
* 66.【ICML2025教程】联想记忆的现代方法  专知  https://mp.weixin.qq.com/s/mSEDZwjJ_UM0hk5h7MsaMA \
  Modern Methods in Associative Memory \
  本教程的主要关注点是基于能量的联想记忆（Energy-based Associative Memories）
* 67.万字长文|小作坊的强化之路  AGI之美  https://mp.weixin.qq.com/s/WS70Lw1kafWGddqrXZjyvg 
* 68.AgentKB｜卷不动Agent了？给你的Agent加个“经验包”，提升复杂任务Agent效果  NLP PaperWeekly  https://mp.weixin.qq.com/s/S-FmPdtNz-2wNjhOupyBgQ \
   AGENT KB: Leveraging Cross-Domain Experience for Agentic Problem Solving（AGENT KB：利用跨域经验解决智能体问题）
* 69.Qwen3-RL训练过程详解  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/kwe0F9_liFN49Ty81iSP0Q 
* 70.2025年值得入坑AI Agent的11个顶级框架！  Datawhale  https://mp.weixin.qq.com/s/GTv-JExIntzyxNoI3Jpfog

# 7.15 Tue
* 71.比Adam更有效，POET从谱不变原理出发，让LLM训练又稳又快  机器之心  https://mp.weixin.qq.com/s/rdjrknyx2UFzFxlDrgo57A \
  POET（Reparameterized Training via Orthogonal Equivalence Transformation） \
  POET 的关键思想是：通过对每个神经元进行结构性重参数化，引入两个可学习的正交矩阵以及一个固定的随机权重矩阵，从而构建一个正交等价的变换结构。该方法在训练过程中严格保持权重的奇异值分布，并天然拥有较低的球面能量，这是 POET 有效性的核心来源。
* 72.一种认知范式方法：探究视觉语言模型中的感知-推理界面  CreateAMind  https://mp.weixin.qq.com/s/XUAu41kHSVOKEcK16Nyp9Q \
  A Cognitive Paradigm Approach to Probe the Perception-Reasoning Interface in VLMs
* 73.ICML 2025 | M+框架来了，增加LLM隐空间记忆，不再受上下文窗口限制  机器之心  https://mp.weixin.qq.com/s/8fl3ymmJMn2P0_XBmVQQuw \
  M+ 是在 MemoryLLM 之上提出的长期隐空间记忆扩展框架：通过把「过期」隐藏向量写入 CPU - 侧长期记忆池，再用协同检索器拉回最相关记忆，它将 8 B 级模型的有效记忆跨度从原本不到 20 k tokens 提升到 160 k tokens 以上，同时显存占用保持不变。 \
  M+: Extending MemoryLLM with Scalable Long-Term Memory
* 74.Prompt、Context、Memory：一组漫画带你了解大模型交互的三段技术演进  夕小瑶科技说  https://mp.weixin.qq.com/s/vjgqMpJqAZLeQYQrm-6UlA \
  MemOS（大模型记忆操作系统）
* 75.卡帕西预言成真！华人团队开源全AI操作系统：神经网络模拟Windows，预测下一帧屏幕图像  量子位  https://mp.weixin.qq.com/s/GyQHQrWLcOTsb7PQKeYT_w \
  NeuralOS
* 76.MIRIX重塑AI多模态长期记忆：超Gemini 410%，节省99.9%内存，APP同步上线  机器之心  https://mp.weixin.qq.com/s/Ztd6vdc7ca1W2LbXtQEBCA \
  https://github.com/Mirix-AI/MIRIX
* 77.首篇潜空间推理综述！模型思考不必依赖Token，带宽暴增2700+倍  量子位  https://mp.weixin.qq.com/s/no5Jwyob3TjbqMNcdGaneQ \
  A Survey on Latent Reasoning
* 78.万字技术干货！LLM工程师必读量化指南，可视化图解揭秘大模型如何量化  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/XrvyJ1zIfFBy79AdNU4YMw \
  ML工程师Maarten Grootendorst撰写了一篇博客文章，在语言建模背景下专门介绍了量化技术，并通过可视化的方法逐一探索相关概念，以帮助我们建立对该技术的直观理解。

# 7.16 Wed
* 79.DeepMind让AI当「上帝」，导演一场只有AI演员的「西部世界」  机器之心  https://mp.weixin.qq.com/s/DwsfFQsBHei6dQwB_i8uyA \
  Multi-Actor Generative Artificial Intelligence as a Game Engine \
  https://github.com/google-deepmind/concordia \
  一个智能体的思维可由多个组件构成：存储过往经历的 Memory 组件、调用大语言模型生成目标的 Planning 组件，以及表征世界认知的 Beliefs 组件 
* 80.(**LLM记忆系统综述**)重塑记忆架构：LLM正在安装「操作系统」  机器之心  https://mp.weixin.qq.com/s/jvK2ZZkc_gYuCZmwd7CbHA \
  Long-Context Windows in LargeLanguage Models: Applications in Comprehension and Code \
  文章链接：https://medium.com/%40adnanmasood/long-context-windows-in-large-language-models-applications-in-comprehension-and-code-03bf4027066f \
  MemoryLLM: Towards Self-Updatable Large Language Models \
  MemGPT: Towards LLMs as Operating Systems \
  memos \
  MemoryOS \
  MIRIX: Multi-Agent Memory System for LLM-Based Agents \
  Larimar: Large Language Models with Episodic Memory Control \
  M+: Extending MemoryLLM with Scalable Long-Term Memory
* 81.(**非常有趣**)马斯克的Neuralink梦想成真？意识连续谱理论震惊科学界！  新智元  https://mp.weixin.qq.com/s/vKWJJ7c9bATk9XEMm2F6eA \
  Levin提出一个研究方向，旨在理解物理接口与模式空间之间的映射关系，他呼吁用更开放的视角去理解意识的本质。 \
  Levin认为意识是一个连续的谱。无论机器、细胞、生物盒子、杂交胚胎、AI、机器人，都存在于接口和它们所连接的模式空间之间。 \
  一个有趣的问题是，能否检测到超越这种起点的某种东西，找到意识的痕迹。
* 82.(**有趣**)小哥硬核手搓AI桌宠！接入GPT-4o，听得懂人话还能互动，方案可复现  量子位  https://mp.weixin.qq.com/s/UZaT1FOh4f-x8NJ7Y_39Qg \
  Shoggoth \
  只需要简单的3D打印，接入GPT-4o的API，再利用RL的系统控制策略，就能让它像“宠物”一样，轻松地与人类自然对话。 \
  工程文件：https://github.com/mlecauchois/shoggoth-mini \
  触手机器人：https://arxiv.org/pdf/2303.09861

# 7.17 Thur
* 83.「有望成为Transformer杀手」，谷歌DeepMind新架构MoR实现两倍推理速度  机器之心  https://mp.weixin.qq.com/s/6IUoCHjm9P_FZllxBlQHPQ \
  这促使研究者们围绕两个主要方向积极探索高效化技术：一是通过权重共享提升参数效率，二是根据输入复杂度动态分配计算资源，实现自适应计算。而一切的基础则是 Transformer 架构。这次谷歌又一次坐不住了，在递归 Transformer 的基础上再次进化，发布了名为 Mixture-of-Recursions （MoR）的新 LLM 模型架构，有学者认为这个新架构「有潜力成为 Transformer 的杀手」。 \
  Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation 
* 84.(**值得看看**)强化学习的两个「大坑」，终于被两篇ICLR论文给解决了  机器之心  https://mp.weixin.qq.com/s/myqak4eAAQ7ONKJKOFxk8g \
  现有的强化学习是回合制游戏 \
  无动作遗憾（inaction regret） 延迟遗憾（delay regret） \
  Mila 实验室两篇 ICLR 2025 论文提出了一种全新的实时强化学习框架，旨在解决当前强化学习系统在部署过程中面临的推理延迟和动作缺失问题，使得大模型也能在高频、连续的任务中实现即时响应。 
第一篇论文提出了一种最小化无动作遗憾的解决方案，第二篇提出了一种最小化延迟遗憾的解决方案。 \
  ENABLING REALTIME REINFORCEMENT LEARNING AT SCALE WITH STAGGERED ASYNCHRONOUS INFERENCE \
  HANDLING DELAY IN REAL-TIME REINFORCEMENT LEARNING
* 85.广义智能体理论：智能时代通向「万物理论」的新路径？  新智元  https://mp.weixin.qq.com/s/50ppshX5WaOBjG-D-qhj7A \
  一个源自AI的「广义智能体理论」，为探索「万物理论」开了个新脑洞。它认为，无论是物理系统、生命还是AI，本质上都是「智能体」。甚至更进一步地猜测，我们熟知的引力、电磁力等，或许都源于一种更根本的「智能场」 \
  Generalized Agent Theory from First Principles
* 86.全球最强开源「定理证明器」出世！十位华人核心，8B暴击671B DeepSeek  新智元  https://mp.weixin.qq.com/s/ast9H0WwWhLEVhz3ogJjiQ \
  Goedel-Prover-V2

# 7.18 Fri
* 87.刚刚，奥特曼放出ChatGPT「统一智能体」！惊呼真AGI，最卷打工人来了  新智元  https://mp.weixin.qq.com/s/_tcQK9DAjsog5x0HsScobQ \
  ChatGPT agent \
  融合了此前三大技术突破的优势：Operator与网站交互的能力，Deep Research整合信息的技巧，以及ChatGPT智能对话优势。
* 88.(**意识**)UTD意识范畴：为IIT提供结构，为GWT提供内部逻辑，为预测处理提供区分动态  CreateAMind  https://mp.weixin.qq.com/s/yFKfzOvo5aMY-GW1yo7cSA \
  From Differentiation to Cognition:UTD as a Model of Recursive Awareness

# 7.19 Sat

# 7.20 Sun
* 89.探索为什么要融合SFT和RL，以及应该怎么融合  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/laxQa60eK7ll1hv8c6Emqw \
* 90.「DeepSeek二代」来袭！数学暴击o3，英伟达开源LLM登顶  新智元  https://mp.weixin.qq.com/s/OeW16b_3oC39A53eH8UXtQ \
  基于Qwen2.5架构，采用DeepSeek-R1-0528生成数据，英伟达推出的OpenReasoning-Nemotron模型，以超强推理能力突破数学、科学、代码任务，在多个基准测试中创下新纪录！数学上，更是超越了o3!

# 7.21 Mon
* 91.模型也有直觉？DeepMind联合团队解释语言模型如何学会像人类一样判断事件合理性  波动智能  https://mp.weixin.qq.com/s/CpFZ9o0wnfli2Gn3NaOuIA \
  Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility \
  深入探讨在语言模型的内部空间里寻觅线索，通过分析模型对不同模态类别（可能、不太可能、不可能、不可想象）的表示方式，回应一个古老而重要的哲学与认知命题：一个事件是否可能发生？
* 92.形式化的本体论认知框架：递归的范畴系统，范畴的层级结构来捕捉结构层级，并利用内部的拓扑斯topos理论结构支持逻辑、语义和几何  CreateAMind  https://mp.weixin.qq.com/s/K81VNzezFBcw3ILGzM7aGw \
  Differentiation as the Foundation of Structure and Though
* 93.机器人的「GPT时刻」来了？丰田研究院悄悄做了一场最严谨的VLA验证实验  机器之心  https://mp.weixin.qq.com/s/VYpyjqTFH2-5z6_V_r_idA \
  A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation \
  https://toyotaresearchinstitute.github.io/lbm1/
* 94.美团提出多模态推理新范式：RL+SFT非传统顺序组合突破传统训练瓶颈  量子位  https://mp.weixin.qq.com/s/1PssR0Tlik2Eq0Vce9uyew \
  Metis-RISE框架（RL Incentivizes and SFT Enhances） \
  https://github.com/MM-Thinking/Metis-RISE \
  将RL激励和SFT增强以非传统顺序结合
* 95.机器人需求驱动导航新SOTA，成功率提升15%！浙大&vivo联手打造  量子位  https://mp.weixin.qq.com/s/kH3X9745EFekv0GYmjsctA \
  CogDDN 首个模拟人类认知机制，将心理学著名的“双过程理论”应用于移动机器人的需求驱动导航任务(Demand-driven navigation,DDN)的系统 \
  让机器人像人一样具备“推理能力”，能够灵活应对未知情境，真正理解人类的意图

# 7.22 Tue
* 96.关于机器人数据，强化学习大佬Sergey Levine刚刚写了篇好文章  机器之心  https://mp.weixin.qq.com/s/CUlPh9luiytC2DyEbiFehw \
  Sporks of AGI  \
  https://sergeylevine.substack.com/p/sporks-of-agi

# 7.23 Wed
* 97.从量子波动到算法选择，自由意志方程重塑AGI 决策逻辑  波动智能  https://mp.weixin.qq.com/s/IUdKZgjF2761JdDhpMeCnw \
  The Free Will Equation: Quantum Field Analogies for AGI \
  若我们希望 AGI 拥有类人般的创造力与适应性，仅靠传统强化学习或深度网络中的固定探索策略是不够的。真正的智能体需要一种机制，让其能像人类一样，在感觉“卡住”或“熟悉变陌”时自发地尝试新的策略。这种机制不仅仅是注入随机性，而是让智能体在认知层面上“选择去随机”，并根据上下文进行合理的探索强度调整。 \
  为此，Kabali 借用了量子物理中的“波函数塌缩”类比。他设想智能体的认知状态就像一个多维的超位置场，在环境交互或内部状态触发下概率性地塌缩为某一具体行动。 \
  这种框架被称为“自由意志方程”（Free Will Equation），其核心思想是把目标驱动（reward）与内在动机（novelty, entropy）统一纳入一个动态策略公式中，使智能体能够在策略失效或世界变化时，自主触发“认知宽化”——提高决策熵，从而跳出旧模式，探索新可能。

# 7.24 Thur
# 7.25 Fri
# 7.26 Sat
# 7.27 Sun
# 7.28 Mon
# 7.29 Tue
# 7.30 Wed
# 7.31 Thur
