# 7.1 Tue
* 1.重磅！淘天联合爱橙开源强化学习训练框架ROLL，高效支持十亿到千亿参数大模型训练  人工智能与算法学习  https://mp.weixin.qq.com/s/UV5ns8duEizWqC5jZHKykw \
  https://github.com/alibaba/ROLL
* 2.RL不只Qwen玩得转！“中期训练”让Llama一夜进化，OctoThinker横空出世  PaperWeekly  https://mp.weixin.qq.com/s/ZMf6xJWCMSTVpH25incRVw \
  该论文深入探讨了不同基础语言模型家族（如 Llama 和 Qwen）在强化学习（RL）训练中迥异表现的背后原因，并提出创新性的中期训练（mid-training）策略，成功地将 Llama 模型改造成高度适配强化学习的推理基础模型，显著缩小了其与天生擅长 RL 扩展的 Qwen 模型之间的性能差距，为下一代 reasoning 能力 AI 系统的开发提供了关键的科学基础和技术路径。 \
  OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling
* 3.持续强化学习研究综述  专知  https://mp.weixin.qq.com/s/DEIrDZY6BkROXzSSvhRtKw \
  A Survey of Continual Reinforcement Learning
* 4.性能提升84%-166%！L-Zero仅靠强化学习解锁大模型探索世界的能力 | 已开源  量子位  https://mp.weixin.qq.com/s/0kvYCLAJArY769IxGVD3UA \
  L0: REINFORCEMENT LEARNING TO BECOME GENERAL AGENTS
* 5.伯克利&Meta面向具身智能的世界模型：让AI通过全身动作「看见」未来  机器之心  https://mp.weixin.qq.com/s/id_ISbf7wVvk3pl2GCIgWA \
  Whole-Body Conditioned Egocentric Video Prediction \
  https://dannytran123.github.io/PEVA/

# 7.2 Wed
* 6.跟着台大李宏毅老师学：别让推理模型想太多  Datawhale  https://mp.weixin.qq.com/s/dXxuRN311-c6CN4zOl8lFg \
  原视频链接：https://www.youtube.com/watch?v=ip3XnTpcxoA
* 7.自学大脑的悖论 The paradox of the self-studying brain  CreateAMind  https://mp.weixin.qq.com/s/EC1HD1mkzUzYM9DcgzEwHA \
  The paradox of the self-studying brain
* 8.同时监督和强化的单阶段大模型微调，告别“先背书再刷题”，推理泛化双提升｜中科院&美团等  量子位  https://mp.weixin.qq.com/s/9dTE8dtVIO1TE0Xy3vUReQ \
  中国科学院自动化研究所深度强化学习团队联合美团，提出一种单阶段监督-强化微调方法——SRFT (Supervised Reinforcement Fine-Tuning)。该方法通过基于熵的动态加权机制，将两种训练范式结合。 \
  项目网页: https://anonymous.4open.science/w/SRFT2025 \
  模型链接: https://huggingface.co/Yuqian-Fu/SRFT \
  SRFT:A SINGLE-STAGE METHOD WITH SUPERVISED AND REINFORCEMENT FINE-TUNING FOR REASONING \
  SFT擅长模仿专家解题思路，类似“背书”，能快速为模型打下基础，但缺点是容易陷入死记硬背，缺乏在新问题上灵活应用和寻找最优解的能力； \
  RFT/RL通过不断试错来探索解题方法，类似“刷题”，能够发现更优解法，但其探索过程效率低下，容易面临模式崩溃风险。 \
  SRFT = SFT + RFT
* 9.周志华团队新作：LLM中存在奖励模型，首次理论证明RL对LLM有效性  机器之心  https://mp.weixin.qq.com/s/OOoAqaT_hnfh2rcKkxrZWw \
  GENERALIST REWARD MODELS: FOUND INSIDE LARGE LANGUAGE MODELS \
  具体来说，本文展示了语言模型的 logits 可以直接解释为 soft Q 函数，通过逆 soft 贝尔曼算子可以从中恢复出奖励函数。 
* 10.李飞飞最新访谈：没有空间智能，AGI就不完整  量子位  https://mp.weixin.qq.com/s/9--aj0bvhLmfMGaBlZOgpA 
* 11.干翻 GPT-4V 的面壁 8B「小钢炮」，被Nature 收录了  AI科技评论  https://mp.weixin.qq.com/s/8I-nptbdPG8DIg5PKUCWKw \
  面壁智能 MiniCPM-V 系列
* 12.ChatGPT惨败Llama！MIT官宣AI开飞船0%失败率，马斯克火星殖民不再是梦  新智元  https://mp.weixin.qq.com/s/0yJoWLj8_cVQPsEe9X_MDA \
  Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program
  
# 7.3 Thur
* 13.老黄预言成真！全球首个AI原生游戏引擎，一句话秒出GTA级神作  新智元  https://mp.weixin.qq.com/s/KeFkjhxkxhwGop5cNJwMOg \
  全球首款AI原生UGC游戏引擎诞生！输入文字秒建GTA世界，试玩体验来了  机器之心  https://mp.weixin.qq.com/s/AnaJ8sS6omG_IpUbAh7k5Q \
  刚刚，谷歌、英伟达等机构联手，震撼发布全球首款AI原生UGC游戏引擎——Mirage，没有预设关卡，一句话即生游戏，超长十分钟沉浸式体验。 \
  传送门：https://blog.dynamicslab.ai/
* 14.具身智能学习综述：基于物理模拟器与世界模型的方法  专知  https://mp.weixin.qq.com/s/be3DkDkYyVtXOblHGZBunA \
  A Survey: Learning Embodied intelligence from Physical Simulators and World Models \
  https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey
* 15.重磅发现！大模型的「aha moment」不是装腔作势，内部信息量暴增数倍！  机器之心  https://mp.weixin.qq.com/s/hVjSWtT1FXk2QvZNXdrD3g \
  当这些「思考词」出现的瞬间，模型大脑（隐空间）中关于正确答案的信息量，会突然飙升数倍！ \
  Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning
* 16.推理AI致命弱点，大模型变「杠精」！被带偏后死不悔改  新智元  https://mp.weixin.qq.com/s/93J02V70zP_mO-IdFCONMA \
  How Well Can Reasoning Models Identify and Recover from Unhelpful Thoughts?
  当不怀好意者在思考过程中加入无关内容后，即使大模型能够识别出问题，也会被带偏，而越大的模型有更多的模版库，因此更有可能在思考过程跑偏（走神）后成为犯错却死不回头的杠精。这些发现突显了当前推理模型在「元认知」和从误导性推理路径中恢复方面存在很大的改进空间，这是开发更安全和更可靠的大规模推理模型时的一个关键考虑因素。
* 17.首次！世界模型、动作模型融合，全自回归模型WorldVLA来了  机器之心  https://mp.weixin.qq.com/s/y3PdWG3siHgK1qU6_x45Wg \
  WorldVLA: Towards Autoregressive Action World Model \
  https://github.com/alibaba-damo-academy/WorldVLA \
  阿里巴巴达摩院提出了 WorldVLA, 首次将世界模型 (World Model) 和动作模型 (Action Model/VLA Model) 融合到了一个模型中。WorldVLA 是一个统一了文本、图片、动作理解和生成的全自回归模型。 
* 18.Meta-Think ≠ 记套路，多智能体强化学习解锁大模型元思考泛化  机器之心  https://mp.weixin.qq.com/s/z7fYYOsbAqeoWoNVdd9KnQ \
  ReMA: Learning to Meta-think for LLMs with Multi-agent Reinforcement Learning \
  https://github.com/ziyuwan/ReMA-public \
  大模型复杂推理的能力强弱本质在于元思维能力的强弱。 \
  ReMA 框架采取了一套全新的解决思路，将复杂的推理过程解耦为两个层级化的智能体： \
  1. 元思维智能体 (Meta-thinking agent)： 负责产生战略性的监督和计划，进行宏观的思考和指导，并在必要的时刻对当前的推理结果进行反思和修正。 \
  2. 推理智能体 (Reasoning agent) ： 负责根据元思维智能体的指导，执行详细的子任务，如单步推理和具体计算等。
* 19.华为多路径推理破解大模型数学瓶颈，准确率超97%｜ICML 2025  量子位  https://mp.weixin.qq.com/s/Pfy8wDewNY82vkGeZ89HdQ \
  该方法借鉴人类“多角度思考、反复验证”的认知方式，打破传统LLM的线性推理范式，通过构建多棵并行推理树，引入动态自我修正机制与多视角共识决策策略。 \
  Forest-of-Thought: Scaling Test-Time Compute for Enhancing LLM Reasoning \
  https://github.com/iamhankai/Forest-of-Thought

# 7.4 Fri
* 20.被观察者的量子力学规则与量子理论的一致性  CreateAMind  https://mp.weixin.qq.com/s/xoMwvL6YnwpJkjUdb1fe7w \
  Quantum mechanical rules for observed observers and the consistency of quantum theory
* 21.LeCun团队揭示LLM语义压缩本质：极致统计压缩牺牲细节  量子位  https://mp.weixin.qq.com/s/lvRIKuVpIkI3wKchx8xO6g \
  LLM偏向极致的统计压缩，而人类更重细节与语境。 \
  LLM侧重于统计压缩，力求最大程度地减少冗余信息；而人类则更注重适应性和丰富性，强调保持灵活性和上下文的完整性。 \
  From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning
* 22.AI大模型应用架构图大全  Datawhale  https://mp.weixin.qq.com/s/In8vyRG1BFPA0yM227n59Q 
* 23.插槽结构世界模型 SLOT STRUCTURED WORLD MODELS  CreateAMind  https://mp.weixin.qq.com/s/SRpNDgTiH77yWO1nLQ0Vzg 
* 24.以玩促学？游戏代码驱动数据合成，提升多模态大模型通用推理  机器之心  https://mp.weixin.qq.com/s/-FBvd-2UYNtxWKZsi8uZaw \
  Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning \
  https://github.com/tongjingqi/Code2Logic \
  https://huggingface.co/Code2Logic \
  利用游戏代码自动合成视觉推理数据

# 7.5 Sat
* 25.750城市+5000小时第一人称视频，上海AI Lab开源面向世界探索高质量视频数据集  量子位  https://mp.weixin.qq.com/s/gNcdw9cu7LDXowtrlrtx-g \
  项目主页：https://lixsp11.github.io/sekai-project/ \
  数据下载：https://huggingface.co/datasets/Lixsp11/Sekai-Project \
  项目代码：https://github.com/Lixsp11/sekai-codebase \
  上海人工智能实验室、北京理工大学、上海创智学院、东京大学等机构聚焦世界生成的第一步——世界探索，联合推出一个持续迭代的高质量视频数据集项目——Sekai（日语意为“世界”），服务于交互式视频生成、视觉导航、视频理解等任务，旨在利用图像、文本或视频构建一个动态且真实的世界，可供用户不受限制进行交互探索。 \
  团队还利用Sekai部分数据，训练了一个初步的交互式视频世界探索模型——Yume（日语意为“梦”）。Yume在输入图片的基础上，通过交互式键鼠操作（移动、视角转动）自回归形式地控制生成视频。

# 7.6 Sun
* 26.复杂空间指令也能秒懂？RoboRefer 让机器人理解推理空间，开放世界也能精准行动！  机器之心    https://mp.weixin.qq.com/s/FIyBvr6BvU406iB9BYcuiA \
  RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics \
  https://zhoues.github.io/RoboRefer \
  京航空航天大学、北京大学与北京智源人工智能研究院联合提出了一个具备三维空间理解推理能力的多模态大模型 —— RoboRefer。这个模型不仅通过全参数微调（SFT），实现了对空间信息的精准理解，还通过强化学习微调（RFT），大幅提升了推理与泛化能力，最终实现开放世界的空间指代。

# 7.7 Mon
* 27.大脑的秘诀，能否成就真正的人工智能？  波动智能  https://mp.weixin.qq.com/s/H9ULCgEYAAegGjSOpC-GdQ \
  What Neuroscience Can Teach AI About Learning in Continuously Changing Environments \
  面对非静态环境——无论是现实世界中的交通系统、在线互动、还是生物演化的复杂生态——AI能否汲取生物大脑亿万年来的生存智慧，突破训练-部署的传统模式，成为真正动态适应的智能体？
* 28.Karpathy最新脑洞「细菌编程」：优秀的代码应该具备细菌的三大特质  量子位  https://mp.weixin.qq.com/s/a2HnRa2cqsustIUxxBwzzQ \
  细菌编程（Bacterial code），要有三个特点：代码块小而精、模块化、自包含且易于复制粘贴。 \
  Vibe coding \
  Context Engineering 上下文工程 \
  一个LLM应用还需要： \
    1.合理将问题拆解为可控的工作流 \
    2.精准填充上下文窗口 \
    3.调用匹配任务需求的LLM模型 \
    4.处理生成-验证的用户交互流程 \
    5.更多细节：安全防护、效果评估、并行处理、预加载机制等
* 29.多模态推理的基础、方法与未来前沿  专知  https://mp.weixin.qq.com/s/94eJbc4UoxE_d9_GSpQMWA \
  Thinking with lmages for Multimodal Reasoning: Foundations, Methods, and Future Frontiers 
* 30.重塑AI记忆边界：MemOS开源！时序推理较OpenAI提升159%  机器之心  https://mp.weixin.qq.com/s/vVFbZRw-U9S7fS_Va7ykKA \
  彻底戳穿AI「失忆症」！超越OpenAI全局记忆，中国队开源LLM记忆操作系统  新智元  https://mp.weixin.qq.com/s/GaXVkE--I0j2gAtRTEfawg \
  「记得住、改得了、学得快」 \
  项目官网：https://memos.openmem.net \
  项目论文：https://memos.openmem.net/paper_memos_v2 \
  代码仓库：https://github.com/MemTensor/MemOS \
  与传统 RAG 或纯参数存储不同，MemOS 把 “记忆” 看作一种和算力同等重要的系统资源。它通过标准化的 MemCube 记忆单元，将明文、激活状态和参数记忆统一在同一个框架里进行调度、融合、归档和权限管理。简单来说，模型不再只是 “看完即忘”，而是拥有了持续进化和自我更新的能力。
* 31.新范式来了！新能量模型打破Transformer++扩展上限，训练扩展率快35%  机器之心  https://mp.weixin.qq.com/s/7o_zlIldFcFJfKY05bQnhg \
  基于能量的 Transformer（Energy-Based Transformers, EBTs），它可以为每一对输入和候选预测分配一个能量值（即非规范化的概率）； 然后从一个随机初始化的预测开始，通过梯度下降不断优化，直到找到最低能量的预测； 这一优化过程就模拟了思考过程。与传统 Transformer 仅单次前向推理不同，EBT 允许每个预测思考多步 \
  这一建模方式使得系统二思维能够在无监督学习中自然涌现，从而具备跨模态、跨任务的通用性 \
  Energy-Based Transformers are Scalable Learners and Thinkers \
  https://energy-based-transformers.github.io/
* 32.ICML 2025 | 会刷题≠懂数学！CogMath打造“认知显微镜”，深扒大模型的数学能力  PaperWeekly  https://mp.weixin.qq.com/s/67H-6MIQ5r2o_3xDXsdKIA \
  中国科学技术大学认知智能全国重点实验室的研究团队近日提出了一项全新研究成果——CogMath：一个从人类认知视角出发，系统分析大模型数学能力的评估框架 \
  CogMath: Assessing LLMs’ Authentic Mathematical Ability from a Human Cognitive Perspective \
  https://github.com/Ljyustc/CogMath
* 33.Meta新注意力机制突破Transformer上限，还用上了OpenAI的开源技术  量子位  https://mp.weixin.qq.com/s/s1a2pTlWBV1nuCzjWrvoEw \
  新架构名为2-Simplicial Transformer，重点是通过修改标准注意力，让Transformer能更高效地利用训练数据，以突破当前大模型发展的数据瓶颈。 \
  FAST AND SIMPLEX: 2-SIMPLICIAL ATTENTION IN TRITON \
  三元线性注意力：引入了额外的维度，使得注意力机制能够捕获更加丰富的关系。
* 34.「上下文工程」彻底火了，Karpathy一众大佬力荐+1，Agent成败全靠它  夕小瑶科技说  https://mp.weixin.qq.com/s/EcPPM8JoaYnabd4PgB3AjA \
  它是一门设计和构建动态系统的学问，其唯一目标是：在正确的时间、以正确的格式，向大模型精准“投喂”完成任务所需的一切信息和工具。 

# 7.8 Tue
* 35.
* 36.
* 37.
* 38.
* 39.
* 40.

# 7.9 Wed
# 7.10 Thur
# 7.11 Fri
# 7.12 Sat
# 7.13 Sun
# 7.14 Mon
# 7.15 Tue
# 7.16 Wed
# 7.17 Thur
# 7.18 Fri
# 7.19 Sat
# 7.20 Sun
# 7.21 Mon
# 7.22 Tue
# 7.23 Wed
# 7.24 Thur
# 7.25 Fri
# 7.26 Sat
# 7.27 Sun
# 7.28 Mon
# 7.29 Tue
# 7.30 Wed
# 7.31 Thur
