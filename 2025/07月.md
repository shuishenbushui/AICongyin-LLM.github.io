# 7.1 Tue
* 1.重磅！淘天联合爱橙开源强化学习训练框架ROLL，高效支持十亿到千亿参数大模型训练  人工智能与算法学习  https://mp.weixin.qq.com/s/UV5ns8duEizWqC5jZHKykw \
  https://github.com/alibaba/ROLL
* 2.RL不只Qwen玩得转！“中期训练”让Llama一夜进化，OctoThinker横空出世  PaperWeekly  https://mp.weixin.qq.com/s/ZMf6xJWCMSTVpH25incRVw \
  该论文深入探讨了不同基础语言模型家族（如 Llama 和 Qwen）在强化学习（RL）训练中迥异表现的背后原因，并提出创新性的中期训练（mid-training）策略，成功地将 Llama 模型改造成高度适配强化学习的推理基础模型，显著缩小了其与天生擅长 RL 扩展的 Qwen 模型之间的性能差距，为下一代 reasoning 能力 AI 系统的开发提供了关键的科学基础和技术路径。 \
  OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling
* 3.持续强化学习研究综述  专知  https://mp.weixin.qq.com/s/DEIrDZY6BkROXzSSvhRtKw \
  A Survey of Continual Reinforcement Learning
* 4.性能提升84%-166%！L-Zero仅靠强化学习解锁大模型探索世界的能力 | 已开源  量子位  https://mp.weixin.qq.com/s/0kvYCLAJArY769IxGVD3UA \
  L0: REINFORCEMENT LEARNING TO BECOME GENERAL AGENTS
* 5.伯克利&Meta面向具身智能的世界模型：让AI通过全身动作「看见」未来  机器之心  https://mp.weixin.qq.com/s/id_ISbf7wVvk3pl2GCIgWA \
  Whole-Body Conditioned Egocentric Video Prediction \
  https://dannytran123.github.io/PEVA/

# 7.2 Wed
* 6.跟着台大李宏毅老师学：别让推理模型想太多  Datawhale  https://mp.weixin.qq.com/s/dXxuRN311-c6CN4zOl8lFg \
  原视频链接：https://www.youtube.com/watch?v=ip3XnTpcxoA
* 7.自学大脑的悖论 The paradox of the self-studying brain  CreateAMind  https://mp.weixin.qq.com/s/EC1HD1mkzUzYM9DcgzEwHA \
  The paradox of the self-studying brain
* 8.同时监督和强化的单阶段大模型微调，告别“先背书再刷题”，推理泛化双提升｜中科院&美团等  量子位  https://mp.weixin.qq.com/s/9dTE8dtVIO1TE0Xy3vUReQ \
  中国科学院自动化研究所深度强化学习团队联合美团，提出一种单阶段监督-强化微调方法——SRFT (Supervised Reinforcement Fine-Tuning)。该方法通过基于熵的动态加权机制，将两种训练范式结合。 \
  项目网页: https://anonymous.4open.science/w/SRFT2025 \
  模型链接: https://huggingface.co/Yuqian-Fu/SRFT \
  SRFT:A SINGLE-STAGE METHOD WITH SUPERVISED AND REINFORCEMENT FINE-TUNING FOR REASONING \
  SFT擅长模仿专家解题思路，类似“背书”，能快速为模型打下基础，但缺点是容易陷入死记硬背，缺乏在新问题上灵活应用和寻找最优解的能力； \
  RFT/RL通过不断试错来探索解题方法，类似“刷题”，能够发现更优解法，但其探索过程效率低下，容易面临模式崩溃风险。 \
  SRFT = SFT + RFT
* 9.周志华团队新作：LLM中存在奖励模型，首次理论证明RL对LLM有效性  机器之心  https://mp.weixin.qq.com/s/OOoAqaT_hnfh2rcKkxrZWw \
  GENERALIST REWARD MODELS: FOUND INSIDE LARGE LANGUAGE MODELS \
  具体来说，本文展示了语言模型的 logits 可以直接解释为 soft Q 函数，通过逆 soft 贝尔曼算子可以从中恢复出奖励函数。 
* 10.李飞飞最新访谈：没有空间智能，AGI就不完整  量子位  https://mp.weixin.qq.com/s/9--aj0bvhLmfMGaBlZOgpA 
* 11.干翻 GPT-4V 的面壁 8B「小钢炮」，被Nature 收录了  AI科技评论  https://mp.weixin.qq.com/s/8I-nptbdPG8DIg5PKUCWKw \
  面壁智能 MiniCPM-V 系列
* 12.ChatGPT惨败Llama！MIT官宣AI开飞船0%失败率，马斯克火星殖民不再是梦  新智元  https://mp.weixin.qq.com/s/0yJoWLj8_cVQPsEe9X_MDA \
  Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program
  
# 7.3 Thur
* 13.老黄预言成真！全球首个AI原生游戏引擎，一句话秒出GTA级神作  新智元  https://mp.weixin.qq.com/s/KeFkjhxkxhwGop5cNJwMOg \
  全球首款AI原生UGC游戏引擎诞生！输入文字秒建GTA世界，试玩体验来了  机器之心  https://mp.weixin.qq.com/s/AnaJ8sS6omG_IpUbAh7k5Q \
  刚刚，谷歌、英伟达等机构联手，震撼发布全球首款AI原生UGC游戏引擎——Mirage，没有预设关卡，一句话即生游戏，超长十分钟沉浸式体验。 \
  传送门：https://blog.dynamicslab.ai/
* 14.具身智能学习综述：基于物理模拟器与世界模型的方法  专知  https://mp.weixin.qq.com/s/be3DkDkYyVtXOblHGZBunA \
  A Survey: Learning Embodied intelligence from Physical Simulators and World Models \
  https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey
* 15.重磅发现！大模型的「aha moment」不是装腔作势，内部信息量暴增数倍！  机器之心  https://mp.weixin.qq.com/s/hVjSWtT1FXk2QvZNXdrD3g \
  当这些「思考词」出现的瞬间，模型大脑（隐空间）中关于正确答案的信息量，会突然飙升数倍！ \
  Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning
* 16.推理AI致命弱点，大模型变「杠精」！被带偏后死不悔改  新智元  https://mp.weixin.qq.com/s/93J02V70zP_mO-IdFCONMA \
  How Well Can Reasoning Models Identify and Recover from Unhelpful Thoughts?
  当不怀好意者在思考过程中加入无关内容后，即使大模型能够识别出问题，也会被带偏，而越大的模型有更多的模版库，因此更有可能在思考过程跑偏（走神）后成为犯错却死不回头的杠精。这些发现突显了当前推理模型在「元认知」和从误导性推理路径中恢复方面存在很大的改进空间，这是开发更安全和更可靠的大规模推理模型时的一个关键考虑因素。
* 17.首次！世界模型、动作模型融合，全自回归模型WorldVLA来了  机器之心  https://mp.weixin.qq.com/s/y3PdWG3siHgK1qU6_x45Wg \
  WorldVLA: Towards Autoregressive Action World Model \
  https://github.com/alibaba-damo-academy/WorldVLA \
  阿里巴巴达摩院提出了 WorldVLA, 首次将世界模型 (World Model) 和动作模型 (Action Model/VLA Model) 融合到了一个模型中。WorldVLA 是一个统一了文本、图片、动作理解和生成的全自回归模型。 
* 18.Meta-Think ≠ 记套路，多智能体强化学习解锁大模型元思考泛化  机器之心  https://mp.weixin.qq.com/s/z7fYYOsbAqeoWoNVdd9KnQ \
  ReMA: Learning to Meta-think for LLMs with Multi-agent Reinforcement Learning \
  https://github.com/ziyuwan/ReMA-public \
  大模型复杂推理的能力强弱本质在于元思维能力的强弱。 \
  ReMA 框架采取了一套全新的解决思路，将复杂的推理过程解耦为两个层级化的智能体： \
  1. 元思维智能体 (Meta-thinking agent)： 负责产生战略性的监督和计划，进行宏观的思考和指导，并在必要的时刻对当前的推理结果进行反思和修正。 \
  2. 推理智能体 (Reasoning agent) ： 负责根据元思维智能体的指导，执行详细的子任务，如单步推理和具体计算等。
* 19.华为多路径推理破解大模型数学瓶颈，准确率超97%｜ICML 2025  量子位  https://mp.weixin.qq.com/s/Pfy8wDewNY82vkGeZ89HdQ \
  该方法借鉴人类“多角度思考、反复验证”的认知方式，打破传统LLM的线性推理范式，通过构建多棵并行推理树，引入动态自我修正机制与多视角共识决策策略。 \
  Forest-of-Thought: Scaling Test-Time Compute for Enhancing LLM Reasoning \
  https://github.com/iamhankai/Forest-of-Thought

# 7.4 Fri
* 20.被观察者的量子力学规则与量子理论的一致性  CreateAMind  https://mp.weixin.qq.com/s/xoMwvL6YnwpJkjUdb1fe7w \
  Quantum mechanical rules for observed observers and the consistency of quantum theory
* 21.LeCun团队揭示LLM语义压缩本质：极致统计压缩牺牲细节  量子位  https://mp.weixin.qq.com/s/lvRIKuVpIkI3wKchx8xO6g \
  LLM偏向极致的统计压缩，而人类更重细节与语境。 \
  LLM侧重于统计压缩，力求最大程度地减少冗余信息；而人类则更注重适应性和丰富性，强调保持灵活性和上下文的完整性。 \
  From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning
* 22.AI大模型应用架构图大全  Datawhale  https://mp.weixin.qq.com/s/In8vyRG1BFPA0yM227n59Q 
* 23.插槽结构世界模型 SLOT STRUCTURED WORLD MODELS  CreateAMind  https://mp.weixin.qq.com/s/SRpNDgTiH77yWO1nLQ0Vzg 
* 24.以玩促学？游戏代码驱动数据合成，提升多模态大模型通用推理  机器之心  https://mp.weixin.qq.com/s/-FBvd-2UYNtxWKZsi8uZaw \
  Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning \
  https://github.com/tongjingqi/Code2Logic \
  https://huggingface.co/Code2Logic \
  利用游戏代码自动合成视觉推理数据

# 7.5 Sat
* 25.750城市+5000小时第一人称视频，上海AI Lab开源面向世界探索高质量视频数据集  量子位  https://mp.weixin.qq.com/s/gNcdw9cu7LDXowtrlrtx-g \
  项目主页：https://lixsp11.github.io/sekai-project/ \
  数据下载：https://huggingface.co/datasets/Lixsp11/Sekai-Project \
  项目代码：https://github.com/Lixsp11/sekai-codebase \
  上海人工智能实验室、北京理工大学、上海创智学院、东京大学等机构聚焦世界生成的第一步——世界探索，联合推出一个持续迭代的高质量视频数据集项目——Sekai（日语意为“世界”），服务于交互式视频生成、视觉导航、视频理解等任务，旨在利用图像、文本或视频构建一个动态且真实的世界，可供用户不受限制进行交互探索。 \
  团队还利用Sekai部分数据，训练了一个初步的交互式视频世界探索模型——Yume（日语意为“梦”）。Yume在输入图片的基础上，通过交互式键鼠操作（移动、视角转动）自回归形式地控制生成视频。

# 7.6 Sun
# 7.7 Mon
# 7.8 Tue
# 7.9 Wed
# 7.10 Thur
# 7.11 Fri
# 7.12 Sat
# 7.13 Sun
# 7.14 Mon
# 7.15 Tue
# 7.16 Wed
# 7.17 Thur
# 7.18 Fri
# 7.19 Sat
# 7.20 Sun
# 7.21 Mon
# 7.22 Tue
# 7.23 Wed
# 7.24 Thur
# 7.25 Fri
# 7.26 Sat
# 7.27 Sun
# 7.28 Mon
# 7.29 Tue
# 7.30 Wed
# 7.31 Thur
