# 7.1 Tue
* 1.重磅！淘天联合爱橙开源强化学习训练框架ROLL，高效支持十亿到千亿参数大模型训练  人工智能与算法学习  https://mp.weixin.qq.com/s/UV5ns8duEizWqC5jZHKykw \
  https://github.com/alibaba/ROLL
* 2.RL不只Qwen玩得转！“中期训练”让Llama一夜进化，OctoThinker横空出世  PaperWeekly  https://mp.weixin.qq.com/s/ZMf6xJWCMSTVpH25incRVw \
  该论文深入探讨了不同基础语言模型家族（如 Llama 和 Qwen）在强化学习（RL）训练中迥异表现的背后原因，并提出创新性的中期训练（mid-training）策略，成功地将 Llama 模型改造成高度适配强化学习的推理基础模型，显著缩小了其与天生擅长 RL 扩展的 Qwen 模型之间的性能差距，为下一代 reasoning 能力 AI 系统的开发提供了关键的科学基础和技术路径。 \
  OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling
* 3.持续强化学习研究综述  专知  https://mp.weixin.qq.com/s/DEIrDZY6BkROXzSSvhRtKw \
  A Survey of Continual Reinforcement Learning
* 4.性能提升84%-166%！L-Zero仅靠强化学习解锁大模型探索世界的能力 | 已开源  量子位  https://mp.weixin.qq.com/s/0kvYCLAJArY769IxGVD3UA \
  L0: REINFORCEMENT LEARNING TO BECOME GENERAL AGENTS
* 5.伯克利&Meta面向具身智能的世界模型：让AI通过全身动作「看见」未来  机器之心  https://mp.weixin.qq.com/s/id_ISbf7wVvk3pl2GCIgWA \
  Whole-Body Conditioned Egocentric Video Prediction \
  https://dannytran123.github.io/PEVA/

# 7.2 Wed
* 6.跟着台大李宏毅老师学：别让推理模型想太多  Datawhale  https://mp.weixin.qq.com/s/dXxuRN311-c6CN4zOl8lFg \
  原视频链接：https://www.youtube.com/watch?v=ip3XnTpcxoA
* 7.自学大脑的悖论 The paradox of the self-studying brain  CreateAMind  https://mp.weixin.qq.com/s/EC1HD1mkzUzYM9DcgzEwHA \
  The paradox of the self-studying brain
* 8.同时监督和强化的单阶段大模型微调，告别“先背书再刷题”，推理泛化双提升｜中科院&美团等  量子位  https://mp.weixin.qq.com/s/9dTE8dtVIO1TE0Xy3vUReQ \
  中国科学院自动化研究所深度强化学习团队联合美团，提出一种单阶段监督-强化微调方法——SRFT (Supervised Reinforcement Fine-Tuning)。该方法通过基于熵的动态加权机制，将两种训练范式结合。 \
  项目网页: https://anonymous.4open.science/w/SRFT2025 \
  模型链接: https://huggingface.co/Yuqian-Fu/SRFT \
  SRFT:A SINGLE-STAGE METHOD WITH SUPERVISED AND REINFORCEMENT FINE-TUNING FOR REASONING \
  SFT擅长模仿专家解题思路，类似“背书”，能快速为模型打下基础，但缺点是容易陷入死记硬背，缺乏在新问题上灵活应用和寻找最优解的能力； \
  RFT/RL通过不断试错来探索解题方法，类似“刷题”，能够发现更优解法，但其探索过程效率低下，容易面临模式崩溃风险。 \
  SRFT = SFT + RFT
* 9.周志华团队新作：LLM中存在奖励模型，首次理论证明RL对LLM有效性  机器之心  https://mp.weixin.qq.com/s/OOoAqaT_hnfh2rcKkxrZWw \
  GENERALIST REWARD MODELS: FOUND INSIDE LARGE LANGUAGE MODELS \
  具体来说，本文展示了语言模型的 logits 可以直接解释为 soft Q 函数，通过逆 soft 贝尔曼算子可以从中恢复出奖励函数。 
* 10.李飞飞最新访谈：没有空间智能，AGI就不完整  量子位  https://mp.weixin.qq.com/s/9--aj0bvhLmfMGaBlZOgpA 
* 11.干翻 GPT-4V 的面壁 8B「小钢炮」，被Nature 收录了  AI科技评论  https://mp.weixin.qq.com/s/8I-nptbdPG8DIg5PKUCWKw \
  面壁智能 MiniCPM-V 系列
* 12.ChatGPT惨败Llama！MIT官宣AI开飞船0%失败率，马斯克火星殖民不再是梦  新智元  https://mp.weixin.qq.com/s/0yJoWLj8_cVQPsEe9X_MDA \
  Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program
  
# 7.3 Thur
* 13.老黄预言成真！全球首个AI原生游戏引擎，一句话秒出GTA级神作  新智元  https://mp.weixin.qq.com/s/KeFkjhxkxhwGop5cNJwMOg \
  全球首款AI原生UGC游戏引擎诞生！输入文字秒建GTA世界，试玩体验来了  机器之心  https://mp.weixin.qq.com/s/AnaJ8sS6omG_IpUbAh7k5Q \
  刚刚，谷歌、英伟达等机构联手，震撼发布全球首款AI原生UGC游戏引擎——Mirage，没有预设关卡，一句话即生游戏，超长十分钟沉浸式体验。 \
  传送门：https://blog.dynamicslab.ai/
* 14.具身智能学习综述：基于物理模拟器与世界模型的方法  专知  https://mp.weixin.qq.com/s/be3DkDkYyVtXOblHGZBunA \
  A Survey: Learning Embodied intelligence from Physical Simulators and World Models \
  https://github.com/NJU3DV-LoongGroup/Embodied-World-Models-Survey
* 15.重磅发现！大模型的「aha moment」不是装腔作势，内部信息量暴增数倍！  机器之心  https://mp.weixin.qq.com/s/hVjSWtT1FXk2QvZNXdrD3g \
  当这些「思考词」出现的瞬间，模型大脑（隐空间）中关于正确答案的信息量，会突然飙升数倍！ \
  Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning
* 16.推理AI致命弱点，大模型变「杠精」！被带偏后死不悔改  新智元  https://mp.weixin.qq.com/s/93J02V70zP_mO-IdFCONMA \
  How Well Can Reasoning Models Identify and Recover from Unhelpful Thoughts?
  当不怀好意者在思考过程中加入无关内容后，即使大模型能够识别出问题，也会被带偏，而越大的模型有更多的模版库，因此更有可能在思考过程跑偏（走神）后成为犯错却死不回头的杠精。这些发现突显了当前推理模型在「元认知」和从误导性推理路径中恢复方面存在很大的改进空间，这是开发更安全和更可靠的大规模推理模型时的一个关键考虑因素。
* 17.首次！世界模型、动作模型融合，全自回归模型WorldVLA来了  机器之心  https://mp.weixin.qq.com/s/y3PdWG3siHgK1qU6_x45Wg \
  WorldVLA: Towards Autoregressive Action World Model \
  https://github.com/alibaba-damo-academy/WorldVLA \
  阿里巴巴达摩院提出了 WorldVLA, 首次将世界模型 (World Model) 和动作模型 (Action Model/VLA Model) 融合到了一个模型中。WorldVLA 是一个统一了文本、图片、动作理解和生成的全自回归模型。 
* 18.Meta-Think ≠ 记套路，多智能体强化学习解锁大模型元思考泛化  机器之心  https://mp.weixin.qq.com/s/z7fYYOsbAqeoWoNVdd9KnQ \
  ReMA: Learning to Meta-think for LLMs with Multi-agent Reinforcement Learning \
  https://github.com/ziyuwan/ReMA-public \
  大模型复杂推理的能力强弱本质在于元思维能力的强弱。 \
  ReMA 框架采取了一套全新的解决思路，将复杂的推理过程解耦为两个层级化的智能体： \
  1. 元思维智能体 (Meta-thinking agent)： 负责产生战略性的监督和计划，进行宏观的思考和指导，并在必要的时刻对当前的推理结果进行反思和修正。 \
  2. 推理智能体 (Reasoning agent) ： 负责根据元思维智能体的指导，执行详细的子任务，如单步推理和具体计算等。
* 19.华为多路径推理破解大模型数学瓶颈，准确率超97%｜ICML 2025  量子位  https://mp.weixin.qq.com/s/Pfy8wDewNY82vkGeZ89HdQ \
  该方法借鉴人类“多角度思考、反复验证”的认知方式，打破传统LLM的线性推理范式，通过构建多棵并行推理树，引入动态自我修正机制与多视角共识决策策略。 \
  Forest-of-Thought: Scaling Test-Time Compute for Enhancing LLM Reasoning \
  https://github.com/iamhankai/Forest-of-Thought

# 7.4 Fri
* 20.被观察者的量子力学规则与量子理论的一致性  CreateAMind  https://mp.weixin.qq.com/s/xoMwvL6YnwpJkjUdb1fe7w \
  Quantum mechanical rules for observed observers and the consistency of quantum theory
* 21.LeCun团队揭示LLM语义压缩本质：极致统计压缩牺牲细节  量子位  https://mp.weixin.qq.com/s/lvRIKuVpIkI3wKchx8xO6g \
  LLM偏向极致的统计压缩，而人类更重细节与语境。 \
  LLM侧重于统计压缩，力求最大程度地减少冗余信息；而人类则更注重适应性和丰富性，强调保持灵活性和上下文的完整性。 \
  From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning
* 22.AI大模型应用架构图大全  Datawhale  https://mp.weixin.qq.com/s/In8vyRG1BFPA0yM227n59Q 
* 23.插槽结构世界模型 SLOT STRUCTURED WORLD MODELS  CreateAMind  https://mp.weixin.qq.com/s/SRpNDgTiH77yWO1nLQ0Vzg 
* 24.以玩促学？游戏代码驱动数据合成，提升多模态大模型通用推理  机器之心  https://mp.weixin.qq.com/s/-FBvd-2UYNtxWKZsi8uZaw \
  Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning \
  https://github.com/tongjingqi/Code2Logic \
  https://huggingface.co/Code2Logic \
  利用游戏代码自动合成视觉推理数据

# 7.5 Sat
* 25.750城市+5000小时第一人称视频，上海AI Lab开源面向世界探索高质量视频数据集  量子位  https://mp.weixin.qq.com/s/gNcdw9cu7LDXowtrlrtx-g \
  项目主页：https://lixsp11.github.io/sekai-project/ \
  数据下载：https://huggingface.co/datasets/Lixsp11/Sekai-Project \
  项目代码：https://github.com/Lixsp11/sekai-codebase \
  上海人工智能实验室、北京理工大学、上海创智学院、东京大学等机构聚焦世界生成的第一步——世界探索，联合推出一个持续迭代的高质量视频数据集项目——Sekai（日语意为“世界”），服务于交互式视频生成、视觉导航、视频理解等任务，旨在利用图像、文本或视频构建一个动态且真实的世界，可供用户不受限制进行交互探索。 \
  团队还利用Sekai部分数据，训练了一个初步的交互式视频世界探索模型——Yume（日语意为“梦”）。Yume在输入图片的基础上，通过交互式键鼠操作（移动、视角转动）自回归形式地控制生成视频。

# 7.6 Sun
* 26.复杂空间指令也能秒懂？RoboRefer 让机器人理解推理空间，开放世界也能精准行动！  机器之心    https://mp.weixin.qq.com/s/FIyBvr6BvU406iB9BYcuiA \
  RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics \
  https://zhoues.github.io/RoboRefer \
  京航空航天大学、北京大学与北京智源人工智能研究院联合提出了一个具备三维空间理解推理能力的多模态大模型 —— RoboRefer。这个模型不仅通过全参数微调（SFT），实现了对空间信息的精准理解，还通过强化学习微调（RFT），大幅提升了推理与泛化能力，最终实现开放世界的空间指代。

# 7.7 Mon
* 27.大脑的秘诀，能否成就真正的人工智能？  波动智能  https://mp.weixin.qq.com/s/H9ULCgEYAAegGjSOpC-GdQ \
  What Neuroscience Can Teach AI About Learning in Continuously Changing Environments \
  面对非静态环境——无论是现实世界中的交通系统、在线互动、还是生物演化的复杂生态——AI能否汲取生物大脑亿万年来的生存智慧，突破训练-部署的传统模式，成为真正动态适应的智能体？
* 28.Karpathy最新脑洞「细菌编程」：优秀的代码应该具备细菌的三大特质  量子位  https://mp.weixin.qq.com/s/a2HnRa2cqsustIUxxBwzzQ \
  细菌编程（Bacterial code），要有三个特点：代码块小而精、模块化、自包含且易于复制粘贴。 \
  Vibe coding \
  Context Engineering 上下文工程 \
  一个LLM应用还需要： \
    1.合理将问题拆解为可控的工作流 \
    2.精准填充上下文窗口 \
    3.调用匹配任务需求的LLM模型 \
    4.处理生成-验证的用户交互流程 \
    5.更多细节：安全防护、效果评估、并行处理、预加载机制等
* 29.多模态推理的基础、方法与未来前沿  专知  https://mp.weixin.qq.com/s/94eJbc4UoxE_d9_GSpQMWA \
  Thinking with lmages for Multimodal Reasoning: Foundations, Methods, and Future Frontiers 
* 30.重塑AI记忆边界：MemOS开源！时序推理较OpenAI提升159%  机器之心  https://mp.weixin.qq.com/s/vVFbZRw-U9S7fS_Va7ykKA \
  彻底戳穿AI「失忆症」！超越OpenAI全局记忆，中国队开源LLM记忆操作系统  新智元  https://mp.weixin.qq.com/s/GaXVkE--I0j2gAtRTEfawg \
  「记得住、改得了、学得快」 \
  项目官网：https://memos.openmem.net \
  项目论文：https://memos.openmem.net/paper_memos_v2 \
  代码仓库：https://github.com/MemTensor/MemOS \
  与传统 RAG 或纯参数存储不同，MemOS 把 “记忆” 看作一种和算力同等重要的系统资源。它通过标准化的 MemCube 记忆单元，将明文、激活状态和参数记忆统一在同一个框架里进行调度、融合、归档和权限管理。简单来说，模型不再只是 “看完即忘”，而是拥有了持续进化和自我更新的能力。
* 31.新范式来了！新能量模型打破Transformer++扩展上限，训练扩展率快35%  机器之心  https://mp.weixin.qq.com/s/7o_zlIldFcFJfKY05bQnhg \
  基于能量的 Transformer（Energy-Based Transformers, EBTs），它可以为每一对输入和候选预测分配一个能量值（即非规范化的概率）； 然后从一个随机初始化的预测开始，通过梯度下降不断优化，直到找到最低能量的预测； 这一优化过程就模拟了思考过程。与传统 Transformer 仅单次前向推理不同，EBT 允许每个预测思考多步 \
  这一建模方式使得系统二思维能够在无监督学习中自然涌现，从而具备跨模态、跨任务的通用性 \
  Energy-Based Transformers are Scalable Learners and Thinkers \
  https://energy-based-transformers.github.io/
* 32.ICML 2025 | 会刷题≠懂数学！CogMath打造“认知显微镜”，深扒大模型的数学能力  PaperWeekly  https://mp.weixin.qq.com/s/67H-6MIQ5r2o_3xDXsdKIA \
  中国科学技术大学认知智能全国重点实验室的研究团队近日提出了一项全新研究成果——CogMath：一个从人类认知视角出发，系统分析大模型数学能力的评估框架 \
  CogMath: Assessing LLMs’ Authentic Mathematical Ability from a Human Cognitive Perspective \
  https://github.com/Ljyustc/CogMath
* 33.Meta新注意力机制突破Transformer上限，还用上了OpenAI的开源技术  量子位  https://mp.weixin.qq.com/s/s1a2pTlWBV1nuCzjWrvoEw \
  新架构名为2-Simplicial Transformer，重点是通过修改标准注意力，让Transformer能更高效地利用训练数据，以突破当前大模型发展的数据瓶颈。 \
  FAST AND SIMPLEX: 2-SIMPLICIAL ATTENTION IN TRITON \
  三元线性注意力：引入了额外的维度，使得注意力机制能够捕获更加丰富的关系。
* 34.「上下文工程」彻底火了，Karpathy一众大佬力荐+1，Agent成败全靠它  夕小瑶科技说  https://mp.weixin.qq.com/s/EcPPM8JoaYnabd4PgB3AjA \
  它是一门设计和构建动态系统的学问，其唯一目标是：在正确的时间、以正确的格式，向大模型精准“投喂”完成任务所需的一切信息和工具。 

# 7.8 Tue
* 35.万字追问：大语言模型能实现通用人工智能吗？  追问  https://mp.weixin.qq.com/s/0_KDsUnJcmnH_o13I1oFGg \
  01 从大型语言模型通向人工通用智能 \
  02 大型语言模型性能持续提升，但这足够实现AGI吗？ \
  03 实现人工通用智能还需要哪些技术要素？ \
  04 潜在的算法与计算技术 \
  05 覆盖多元未来的稳健战略
* 36.Transformer死角，只需500步后训练，循环模型突破256k长度泛化极限  机器之心  https://mp.weixin.qq.com/s/l-J4N6hlFyiCHRmkdeIC6g \
  Understanding and Improving Length Generalization in Recurrent Models \
  循环模型仍存在一个关键短板：尽管它们在训练长度范围内表现良好，但在处理超出训练长度的序列时，往往难以泛化，表现明显下降。
* 37.VLA爆发！从美国RT-2到中国FiS-VLA，机器人「即知即行」的终极进化  新智元  https://mp.weixin.qq.com/s/nAGqB3Pe3N0acIxZElIO8w \
  FiS-VLA「快慢双系统」 \
  项目主页: https://fast-in-slow.github.io/ \
  代码链接: https://github.com/CHEN-H01/Fast-in-Slow
* 38.基于能量的Transformer横空出世！全面超越主流模型35%  量子位  https://mp.weixin.qq.com/s/HQ5ct3KrXUX6Z9beIWxnYA \
  EBT（Energy-Based Transformers） \
  Energy-Based Transformers are Scalable Learners and Thinkers \
  EBT全方面优于Transformer++

# 7.9 Wed
* 39.MIT发布自适应语言模型！新任务，自生成远超「GPT-4.1合成训练数据」  新智元  https://mp.weixin.qq.com/s/ZvzVqAZQl11q866PUrH9QA \
  大模型是否可以通过「自己生成训练数据和学习方法」来实现对新任务的自适应？麻省理工学院的研究人员提出了一个全新的自适应语言模型（Self-Adapting LLMs，简称SEAL）的框架，可以让大模型通过生成自己的微调数据和更新指令来实现自适应。 \
  Self-Adapting Language Models \
  https://jyopari.github.io/posts/seal
* 40.4B小模型数学推理首超Claude 4，700步RL训练逼近235B性能 | 港大&字节Seed&复旦  量子位  https://mp.weixin.qq.com/s/RvIy5Ssfakl92aVc9fczJw \
  notion地址: https://honorable-payment-890.notion.site/POLARIS-A-POst-training-recipe-for-scaling-reinforcement-Learning-on-Advanced-ReasonIng-modelS-1dfa954ff7c38094923ec7772bf447a1 \
  blog 地址: https://hkunlp.github.io/blog/2025/Polaris/ \
  代码: https://github.com/ChenxinAn-fdu/POLARIS \
  Huggingface主页: https://huggingface.co/POLARIS-Project
* 41.两张图就能重构3D空间？清华&NTU利用生成模型解锁空间智能新范式  量子位  https://mp.weixin.qq.com/s/aL-3ZNkSdH06GAbMpNe4fg \
  LangScene-X \
  以全新的生成式框架，仅用稀疏视图（最少只用2张图像）就能构建可泛化的3D语言嵌入场景，对比传统方法如NeRF，通常需要20个视角。这意味着，生成式模型能像人类一样，仅凭稀疏视觉输入构建融合语言理解的3D空间认知系统。 \
  项目主页:https://liuff19.github.io/LangScene-X/ \
  Github仓库:https://github.com/liuff19/LangScene-X
* 42.长思维链里的推理步骤，哪些最关键？三招锁定LLM的「命门句子」  机器之心  https://mp.weixin.qq.com/s/h2nR_MB-9kGxw-NbBJh48Q \
  长思维链里的推理步骤，哪些最关键？三招锁定LLM的「命门句子」 \
  开源工具链接：http://thought-anchors.com/
* 43.具身智能体：世界建模  专知  https://mp.weixin.qq.com/s/zrsshKDvVtkLORnoBpS7jg \
  Embodied Al Agents: Modeling the World \
  世界模型、心理世界模型（Mental World Model）
* 44.大语言模型的强化学习技术综述  专知  https://mp.weixin.qq.com/s/gxhPXr7s20e8VzWwci3iJQ \
  A Technical Survey of Reinforcement Learning Techniques for Large Language Models
* 45.DeepSeek-R1超级外挂！“人类最后的考试”首次突破30分，上海交大等开源方案碾压OpenAI、谷歌  量子位  https://mp.weixin.qq.com/s/U6QKmdtgbSpdMwQNTTU97w \
  工具增强推理智能体X-Master、多智能体工作流系统X-Masters \
  X-Master是一个由开源模型（如DeepSeek-R1）驱动的工具增强型推理智能体 \
  https://github.com/sjtu-sai-agents/X-Master
* 46.Mamba一作预告新架构！长文论述Transformer≠最终解法  量子位  https://mp.weixin.qq.com/s/GshJ25VXCRHGqY4WulysOA \
  「Tokens是胡扯」，Mamba作者抛出颠覆性观点，揭露Transformer深层缺陷  机器之心  https://mp.weixin.qq.com/s/x07dzWVltVc7rWb8OVRwTg \
  On the Tradeoffs of SSMs and Transformers \
  SSMs就像人类的大脑 \
    SSMs缺乏对过去信息的精细回忆和精确检索能力 \
  Transformer模型更像一个数据库 \
    Tokenization违背了深度学习“端到端”的自动学习精神，即模型应该从原始数据中自动学习，而不是依赖人工预处理。 \
  https://goombalab.github.io/blog/2025/tradeoffs/
* 47.(**PAN**)「世界模型」也被泼冷水了？邢波等人揭开五大「硬伤」，提出新范式  机器之心  https://mp.weixin.qq.com/s/xxKApjTmGKWD7W7mj1NCGw \
  Critiques of World Models \
  研究人员指出了构建、训练世界模型的五个重点方面：1）识别并准备包含目标世界信息的训练数据；2）采用一种通用表征空间来表示潜在世界状态，其含义可能比直接观察到的数据更为丰富；3）设计能够有效对表征进行推理的架构；4）选择能正确指导模型训练的目标函数；5）确定如何在决策系统中运用世界模型。 \
  PAN（Physical, Agentic, and Nested AGI System） \
  基于分层、多级和混合连续 / 离散表示，并采用了生成式和自监督学习框架。 \
  PAN 模型即将发布 27B 的第一版，这将是第一个可运行的通用世界模拟器。
* 48.AI为了自保假装配合！Claude团队新研究结果细思极恐  量子位  https://mp.weixin.qq.com/s/uak86PRr2DA5tu7AcXB9yw \
  对齐伪装：在训练阶段，Claude会假装遵守训练目标；训练结束不受监控了，就放飞自我。
* 49.vivo发布端侧多模态模型，只有3B可理解GUI界面，20项评测表现亮眼  量子位  https://mp.weixin.qq.com/s/W-6VS1z8Ctuk9KfOZ2KxzA \
  BlueLM-2.5-3B，融合文本和图文的理解和推理能力，支持长短思考模式自由切换，并引入思考预算控制机制
* 50.大模型「越用越快」！SpeedupLLM首次验证，大降56%推理预算  新智元  https://mp.weixin.qq.com/s/nR7t1s7GPcG-Jyp1JrAz7w \
  在多轮使用中，大模型是否能像人类一样「从经验中变快」？是否存在一种方法，能系统性地提升效率，而非单纯堆算力？
* 51.最强3B「小钢炮」，代码数据全公开！推理随意开关，128k超长上下文  新智元  https://mp.weixin.qq.com/s/V-urj3z8fiEjcVTaObp3sg \
  重磅开源！新一代最强小模型SmolLM3横空出世：30亿参数，支持128k长上下文！而且训练、对齐、架构、数据等全链路，Hugging Face这次100%开放——堪称真「Open AI」。 \
  基础模型: https://hf.co/HuggingFaceTB/SmolLM3-3B-Base \
  指令和推理模型: https://hf.co/HuggingFaceTB/SmolLM3-3B

# 7.10 Thur
* 52.Meta发布40页报告，具身智能的下一步是「心智世界模型」：能听，能看，能理解，会共情  量子位  https://mp.weixin.qq.com/s/ZW1rJttPRl1-y12fabN7YA \
  相比于传统世界模型（如LeCun的JEPA）仅关注物理规律（物体运动、机械因果），心智世界模型则首次将心理规律（意图、情感、社会关系）纳入世界模型框架，实现“双轨建模”。\
  心智世界模型就是对世界的心理表征的过程，包括对物体、事件和关系的表征。 \
  让每个智能体不仅看到外部世界，还能推测他人的信念和意图，形成比单一感知更高阶的理解。 \
  Embodied Al Agents: Modeling the World
* 53.智能之镜：NeuroAI 如何反映大脑与人工智能的未来  集智俱乐部  https://mp.weixin.qq.com/s/kjhTDI3cOwBjTaMqRZa06g \
  Discovering cognitive strategies with tiny recurrent neural networks \
    是否存在一种无需预设的建模方式，能够让模型直接从行为数据中“自主发现”策略？ \
  Linking In-context Learning in Transformers to Human Episodic Memory \
    大语言模型在上下文学习中，可能自发形成了一种类似人的记忆内部机制，为我们理解其智能行为提供了新的认知科学视角。
* 54.英伟达大牛主讲！斯坦福吴恩达：大语言模型的后训练课程全网发布  Datawhale  https://mp.weixin.qq.com/s/GGkR3-93Gy0KS7ce4bfZdQ \
  SFT、DPO 和 Online RL \
  课程主页：https://www.deeplearning.ai/short-courses/post-training-of-llms/
* 55.VLA统一架构新突破：自回归世界模型引领具身智能  机器之心  https://mp.weixin.qq.com/s/k8GW4oO7BEwo-7GaG8gMOw \
  Unified Vision-Language-Action Model \
  https://robertwyq.github.io/univla.github.io/ \
  在这套统一框架下，世界模型的后训练显著提升了下游决策性能，且无需依赖大量动作数据，仅凭海量视频即可高效学习。
* 56.奖励模型终于迎来预训练新时代！上海AI Lab、复旦POLAR，开启Scaling新范式  机器之心  https://mp.weixin.qq.com/s/IAJ9cmVa9QszodhYIdiknQ \
  究竟什么才是扩展方便、泛化性强、场景通吃的奖励建模方案呢？ \
  https://github.com/InternLM/POLAR \
  https://huggingface.co/internlm/POLAR-7B
* 57.《潜在推理综述》  专知  https://mp.weixin.qq.com/s/UpVBb_1gXAPWHXxVSpK_QA \
  A Survey on Latent Reasoning \
   GitHub 项目库 LatentCoT-Horizon，收录了该领域的最新论文与代码资源，供读者参考与深入研究 \
  尽管 CoT 在提升可解释性和准确性方面表现出色，但其对自然语言推理的依赖限制了模型的表达带宽。**潜在推理（Latent Reasoning）**试图突破这一瓶颈，其核心在于完全在模型的连续隐藏状态中执行多步推理，摆脱了对逐词监督的依赖
* 58.【CMU博士论文】构建具身智能体  专知  https://mp.weixin.qq.com/s/Hwq66yGqlCeoKjHDS0k3Ng \
  Building Situated Agents \
  概述了智能体如何利用其预训练知识，在特定环境中高效运行，并聚焦于感知、认知与元认知三个核心方面

# 7.11 Fri
* 59.感知错误率降低30.5%：隐式感知损失让模型主动“睁大眼睛” | UIUC＆阿里通义  量子位  https://mp.weixin.qq.com/s/EYPDyWbiBuPB6PwaHxWjHA \
  PAPO(Perception-Aware Policy Optimization)
* 60.奖励模型也能Scaling！上海AI Lab突破强化学习短板，提出策略判别学习新范式  量子位  https://mp.weixin.qq.com/s/hU3MKn82o1sMy4CK-CUUug \
  OpenAI去年挖的坑填上了！奖励模型首现Scaling Law，1.8B给70B巨兽上了一课  新智元  https://mp.weixin.qq.com/s/gmusuAy_OKPDxMl-ID9tTQ \
  策略判别学习（Policy Discriminative Learning， POLAR），使奖励模型能够像大语言模型一样，具备可扩展性和强泛化能力 \
  它开创性地采用了对比学习范式，通过衡量模型回复与参考答案的「距离」来给出精细分数。不仅摆脱了对海量人工标注的依赖，更展现出强大的Scaling潜力，让小模型也能超越规模大数十倍的对手

# 7.12 Sat
* 61.密室逃脱成AI新考场，通关率不足50%，暴露空间推理短板丨清华ICCV25  量子位  https://mp.weixin.qq.com/s/EJ-GxnWaPAklW_lVYDyzCw \
  EscapeCraft：一个3D密室逃脱环境，让大模型在3D密室中通过自由探索寻找道具，解锁出口。 \
  项目主页：https://thunlp-mt.github.io/EscapeCraft \
  GitHub 地址：https://github.com/THUNLP-MT/EscapeCraft
* 62.氛围编程后，Karpathy又双叒有新「脑洞」！PDF将死，未来99%是AI氛围阅读  新智元  https://mp.weixin.qq.com/s/Y2A-5L1BE_gV78pioNBODg \
  PDF已经不适合AI时代，应该研发针对AI的数据格式，甚至以后的论文格式都不应该是PDF、Word这种写给人看的，而应该有点Github上代码的那种结构。
* 63.2025最新！三万字长文，详解统一多模态理解与生成模型的进展、挑战与机遇  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/y0vLI0e1QnSsRPerwXWvxg \
  Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities \
  https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models

# 7.13 Sun
# 7.14 Mon
# 7.15 Tue
# 7.16 Wed
# 7.17 Thur
# 7.18 Fri
# 7.19 Sat
# 7.20 Sun
# 7.21 Mon
# 7.22 Tue
# 7.23 Wed
# 7.24 Thur
# 7.25 Fri
# 7.26 Sat
# 7.27 Sun
# 7.28 Mon
# 7.29 Tue
# 7.30 Wed
# 7.31 Thur
