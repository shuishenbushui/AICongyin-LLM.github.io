# 2.1 Sat
* 1.(**值得看看**)o1开启LLM新范式，Ai2科学家解析背后秘籍：推理和强化学习是关键  新智元  https://mp.weixin.qq.com/s/3X5MMSWFiP1d4lvacTtjcA \
  Ai2研究科学家Nathan Lambert总结语言推理现状，揭开OpenAI o1训练中强化学习的秘密 \
  The state of reasoning \
  视频和原文地址：https://www.interconnects.ai/p/the-state-of-reasoning
* 2.(**值得看看**)Jay Alammar：图解DeepSeek-R1  图灵人工智能  https://mp.weixin.qq.com/s/SVMjyxx3gKKCxVqCtBuT3A \
  英文连接 https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1 
* 3.麻省理工大佬： DeepSeek是科技史上伟大时刻，5年后依旧难忘！  AIGC开放社区  https://mp.weixin.qq.com/s/ENTs7K4VguQl_aKu7c72hw
* 4.万字长文解读Scaling Law的一切，洞见LLM的未来  机器之心  https://mp.weixin.qq.com/s/1H5E9Z6BoW6Oi5ns4FGflw \
  原文链接：https://cameronrwolfe.substack.com/p/llm-scaling-laws

# 2.2 Sun
* 5.OpenAI 发布推理模型o3-mini，附37页技术报告，中英文版  专知  https://mp.weixin.qq.com/s/kebVgBDILCnc8-_KaW5QVA \
  OpenAI o3-mini System Card
* 6.o3-mini物理推理粉碎DeepSeek R1，OpenAI王者归来！全网最全实测来袭  新智元  https://mp.weixin.qq.com/s/_oE2-Mm3yAWeXcjwqJgi_A 
* 7.GPT-4o惊现自我意识！自主激活「后门」，告诉人类自己在写危险代码  新智元  https://mp.weixin.qq.com/s/_wYO8F9e0Uc3kThav-nQ1A \
  本研究探讨了LLM是否具备行为自我意识的能力，揭示了模型在微调过程中学到的潜在行为策略，以及其是否能准确描述这些行为。研究结果表明，LLM能够识别并描述自身行为，展现出行为自我意识 \
  行为自我意识，指的是LLM无需借助上下文，便能准确描述自身行为 \
  TELL ME ABOUT YOURSELF: LLMS ARE AWARE OF THEIR LEARNED BEHAVIORS \
  https://www.lesswrong.com/posts/xrv2fNJtqabN3h6Aj/tell-me-about-yourself-llms-are-aware-of-their-learned
* 8.全面梳理200+篇前沿论文，视觉生成模型理解物理世界规律的通关密码，都在这篇综述里了！  机器之心  https://mp.weixin.qq.com/s/0fMOhfxIUy1w0ERu2QzKpA \
  Generative Physical AI in Vision: A Survey

# 2.3 Mon
* 9.(**Deep Research**)OpenAI紧急直播，ChatGPT疯狂开挂「深度研究」！10分钟爆肝万字现AGI雏形，刷榜人类最后考试  新智元  https://mp.weixin.qq.com/s/9eEBM7U7FBfpOGtLXeUfEw  \
  刚刚，OpenAI上线Deep Research！人类终极考试远超DeepSeek R1  机器之心  https://mp.weixin.qq.com/s/FMTvXxspbgGyvk33loH24w \
  OpenAI 又发新产品了，这次是面向深度研究领域的智能体产品 ——「Deep Research」 \
  Deep Research 通过端到端的强化学习在多个领域的复杂浏览和推理任务上进行了训练 \
  现在看来，Deep research 能够进行异步的在线查找，而 Operator 则能够在现实世界中采取行动，两者的结合将使 ChatGPT 能够为用户执行越来越复杂的任务
* 10.解放双手！OSCAR让操作系统交互实现自然语言「自由」  机器之心  https://mp.weixin.qq.com/s/OvZ1MC8AEd4wQA85ULsNNQ \
  OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning \
  博客地址：https://openai.com/index/introducing-deep-research/
* 11.新研究揭示DeepSeek/o3弱点：频繁切换思路放弃正确方向，最短答案往往就是对的！  量子位  https://mp.weixin.qq.com/s/6oejP8sKLAHGeD2esUZPcA \
  在遇到高难度问题时，推理大模型可能像“三心二意的学生”一样频繁切换解题思路，却因缺乏深入探索而失败——这种现象被研究者称为Underthinking（欠思考） \
  通过分析AI的错误答案，他们发现当前的推理大模型经常在思考早期就走上了正确的路线，但倾向于“浅尝辄止”，很快开始探索别的思路，导致后续生成的数千个tokens对解题毫无贡献 \
  Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs
* 12.高维向量计算  CreateAMind  https://mp.weixin.qq.com/s/whZ6xyjswGNVODD498SxYg \
  Computing with high-dimensional vectors
* 13.完整的671B R1塞进本地，详尽教程来了！  Datawhale  https://mp.weixin.qq.com/s/dKfQfv78ch4IlzBML9Tmkw \
  https://snowkylin.github.io/blogs/a-note-on-deepseek-r1.html

# 2.4 Tue
* 14.ICLR 2025 | 大模型“遗忘”竟是错觉？华南理工团队首次揭示LLM训练中的“虚假遗忘”  PaperWeekly  https://mp.weixin.qq.com/s/d7QkZGBE1IKnrEfcqDH4ng \
  Spurious Forgetting in Continual Learning of Language Models \
  任务表现=任务对齐(Task Alignment)+潜在知识(Underlying Knowledge) \
  任务性能的下降可能并非由于旧知识的遗忘，而是模型在新任务初期丧失了对旧任务的任务对齐能力
* 15.机器人使用工具的快速学习机制  CreateAMind  https://mp.weixin.qq.com/s/cmOuJs3ks-fLMpWDokXIyA \
  Efficient motor learning through action-perception cycles in deep kinematic
* 16.Go语言开发AI智能体有多丝滑？字节重磅开源Eino框架，内含保姆级教程  机器之心  https://mp.weixin.qq.com/s/kevdQGjV3GVi1_4B9XGtJw \
  ? Go语言相对于python有啥优势

# 2.5 Wed
* 17.基于网格细胞启发的高效地图构建中的碎片化与回忆  CreateAMind  https://mp.weixin.qq.com/s/RoVJQXmBs6ymcnVGTQjygg \
  Grid Cell-Inspired Fragmentation and Recall for Efficient Map Building \
  https://github.com/FieteLab/FARMap
* 18.超越DeepSeek V3！Ai2再祭开源杀器Tülu 3，强化学习打破性能瓶颈  新智元  https://mp.weixin.qq.com/s/hX2pNUupJ5yJ-eqe3qyP-Q \
  艾伦人工智能研究所（Ai2）推出了基于强化学习的新一代开源模型Tülu 3 405B，不仅能够媲美GPT-4o，更在多项关键基准测试中超越了DeepSeek v3 \
  Tülu 3 8B和70B \
  Tülu 3: Pushing Frontiers in Open Language Model Post-Training
* 19.训练1000样本就能超越o1，李飞飞等人画出AI扩展新曲线  机器之心  https://mp.weixin.qq.com/s/ax_CCrqpgrp5j2mLOssY4w \
  斯坦福大学、华盛顿大学等研究机构尝试了最简化实现测试时间扩展（test-time scaling）的方法，仅让模型训练 1000 个问题就获得了超越 o1 的强推理性能 \
  s1: Simple test-time scaling \
  https://github.com/simplescaling/s1 \
  研究人员开发了「预算强制」来控制测试时间计算，方法是强制终止模型的思考过程，或者在模型试图结束时多次将「等待」附加到模型的生成中以延长思考。这有可能会导致模型仔细检查其答案，修复其不正确的推理步骤

# 2.6 Thur
* 20.
* 21.
* 22.
* 23.
* 24.
* 25.
* 26.
* 27.
* 28.
* 29.
* 30.

# 2.7 Fri

# 2.8 Sat

# 2.9 Sun

# 2.10 Mon

# 2.11 Tue

# 2.12 Wed

# 2.13 Thur

# 2.14 Fri

# 2.15 Sat

# 2.16 Sun

# 2.17 Mon

# 2.18 Tue

# 2.19 Wed

# 2.20 Thur

# 2.21 Fri

# 2.22 Sat

# 2.23 Sun

# 2.24 Mon

# 2.25 Tue

# 2.26 Wed

# 2.27 Thur

# 2.28 Fri


