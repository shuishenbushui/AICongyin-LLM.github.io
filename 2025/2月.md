# 2.1 Sat
* 1.(**值得看看**)o1开启LLM新范式，Ai2科学家解析背后秘籍：推理和强化学习是关键  新智元  https://mp.weixin.qq.com/s/3X5MMSWFiP1d4lvacTtjcA \
  Ai2研究科学家Nathan Lambert总结语言推理现状，揭开OpenAI o1训练中强化学习的秘密 \
  The state of reasoning \
  视频和原文地址：https://www.interconnects.ai/p/the-state-of-reasoning
* 2.(**值得看看**)Jay Alammar：图解DeepSeek-R1  图灵人工智能  https://mp.weixin.qq.com/s/SVMjyxx3gKKCxVqCtBuT3A \
  英文连接 https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1 
* 3.麻省理工大佬： DeepSeek是科技史上伟大时刻，5年后依旧难忘！  AIGC开放社区  https://mp.weixin.qq.com/s/ENTs7K4VguQl_aKu7c72hw
* 4.万字长文解读Scaling Law的一切，洞见LLM的未来  机器之心  https://mp.weixin.qq.com/s/1H5E9Z6BoW6Oi5ns4FGflw \
  原文链接：https://cameronrwolfe.substack.com/p/llm-scaling-laws

# 2.2 Sun
* 5.OpenAI 发布推理模型o3-mini，附37页技术报告，中英文版  专知  https://mp.weixin.qq.com/s/kebVgBDILCnc8-_KaW5QVA \
  OpenAI o3-mini System Card
* 6.o3-mini物理推理粉碎DeepSeek R1，OpenAI王者归来！全网最全实测来袭  新智元  https://mp.weixin.qq.com/s/_oE2-Mm3yAWeXcjwqJgi_A 
* 7.GPT-4o惊现自我意识！自主激活「后门」，告诉人类自己在写危险代码  新智元  https://mp.weixin.qq.com/s/_wYO8F9e0Uc3kThav-nQ1A \
  本研究探讨了LLM是否具备行为自我意识的能力，揭示了模型在微调过程中学到的潜在行为策略，以及其是否能准确描述这些行为。研究结果表明，LLM能够识别并描述自身行为，展现出行为自我意识 \
  行为自我意识，指的是LLM无需借助上下文，便能准确描述自身行为 \
  TELL ME ABOUT YOURSELF: LLMS ARE AWARE OF THEIR LEARNED BEHAVIORS \
  https://www.lesswrong.com/posts/xrv2fNJtqabN3h6Aj/tell-me-about-yourself-llms-are-aware-of-their-learned
* 8.全面梳理200+篇前沿论文，视觉生成模型理解物理世界规律的通关密码，都在这篇综述里了！  机器之心  https://mp.weixin.qq.com/s/0fMOhfxIUy1w0ERu2QzKpA \
  Generative Physical AI in Vision: A Survey

# 2.3 Mon
* 9.(**Deep Research**)OpenAI紧急直播，ChatGPT疯狂开挂「深度研究」！10分钟爆肝万字现AGI雏形，刷榜人类最后考试  新智元  https://mp.weixin.qq.com/s/9eEBM7U7FBfpOGtLXeUfEw  \
  刚刚，OpenAI上线Deep Research！人类终极考试远超DeepSeek R1  机器之心  https://mp.weixin.qq.com/s/FMTvXxspbgGyvk33loH24w \
  OpenAI 又发新产品了，这次是面向深度研究领域的智能体产品 ——「Deep Research」 \
  Deep Research 通过端到端的强化学习在多个领域的复杂浏览和推理任务上进行了训练 \
  现在看来，Deep research 能够进行异步的在线查找，而 Operator 则能够在现实世界中采取行动，两者的结合将使 ChatGPT 能够为用户执行越来越复杂的任务
* 10.解放双手！OSCAR让操作系统交互实现自然语言「自由」  机器之心  https://mp.weixin.qq.com/s/OvZ1MC8AEd4wQA85ULsNNQ \
  OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning \
  博客地址：https://openai.com/index/introducing-deep-research/
* 11.新研究揭示DeepSeek/o3弱点：频繁切换思路放弃正确方向，最短答案往往就是对的！  量子位  https://mp.weixin.qq.com/s/6oejP8sKLAHGeD2esUZPcA \
  在遇到高难度问题时，推理大模型可能像“三心二意的学生”一样频繁切换解题思路，却因缺乏深入探索而失败——这种现象被研究者称为Underthinking（欠思考） \
  通过分析AI的错误答案，他们发现当前的推理大模型经常在思考早期就走上了正确的路线，但倾向于“浅尝辄止”，很快开始探索别的思路，导致后续生成的数千个tokens对解题毫无贡献 \
  Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs
* 12.高维向量计算  CreateAMind  https://mp.weixin.qq.com/s/whZ6xyjswGNVODD498SxYg \
  Computing with high-dimensional vectors
* 13.完整的671B R1塞进本地，详尽教程来了！  Datawhale  https://mp.weixin.qq.com/s/dKfQfv78ch4IlzBML9Tmkw \
  https://snowkylin.github.io/blogs/a-note-on-deepseek-r1.html

# 2.4 Tue
* 14.ICLR 2025 | 大模型“遗忘”竟是错觉？华南理工团队首次揭示LLM训练中的“虚假遗忘”  PaperWeekly  https://mp.weixin.qq.com/s/d7QkZGBE1IKnrEfcqDH4ng \
  Spurious Forgetting in Continual Learning of Language Models \
  任务表现=任务对齐(Task Alignment)+潜在知识(Underlying Knowledge) \
  任务性能的下降可能并非由于旧知识的遗忘，而是模型在新任务初期丧失了对旧任务的任务对齐能力
* 15.机器人使用工具的快速学习机制  CreateAMind  https://mp.weixin.qq.com/s/cmOuJs3ks-fLMpWDokXIyA \
  Efficient motor learning through action-perception cycles in deep kinematic
* 16.Go语言开发AI智能体有多丝滑？字节重磅开源Eino框架，内含保姆级教程  机器之心  https://mp.weixin.qq.com/s/kevdQGjV3GVi1_4B9XGtJw \
  ? Go语言相对于python有啥优势

# 2.5 Wed
* 17.基于网格细胞启发的高效地图构建中的碎片化与回忆  CreateAMind  https://mp.weixin.qq.com/s/RoVJQXmBs6ymcnVGTQjygg \
  Grid Cell-Inspired Fragmentation and Recall for Efficient Map Building \
  https://github.com/FieteLab/FARMap
* 18.超越DeepSeek V3！Ai2再祭开源杀器Tülu 3，强化学习打破性能瓶颈  新智元  https://mp.weixin.qq.com/s/hX2pNUupJ5yJ-eqe3qyP-Q \
  艾伦人工智能研究所（Ai2）推出了基于强化学习的新一代开源模型Tülu 3 405B，不仅能够媲美GPT-4o，更在多项关键基准测试中超越了DeepSeek v3 \
  Tülu 3 8B和70B \
  Tülu 3: Pushing Frontiers in Open Language Model Post-Training
* 19.训练1000样本就能超越o1，李飞飞等人画出AI扩展新曲线  机器之心  https://mp.weixin.qq.com/s/ax_CCrqpgrp5j2mLOssY4w \
  16张H100训26分钟，超越o1-preview！李飞飞等用1K样本，揭秘测试时Scaling  新智元  https://mp.weixin.qq.com/s/iGi20QGI8KFn-WPtBL5JCw \
  成本不到150元！李飞飞等26分钟训出个推理模型，媲美o1和R1，秘诀：用蒸馏 
 量子位  https://mp.weixin.qq.com/s/KEGrXVpNXdq-WcQxRzBJfg \
  斯坦福大学、华盛顿大学等研究机构尝试了最简化实现测试时间扩展（test-time scaling）的方法，仅让模型训练 1000 个问题就获得了超越 o1 的强推理性能 \
  s1: Simple test-time scaling \
  https://github.com/simplescaling/s1 \
  研究人员开发了「预算强制」来控制测试时间计算，方法是强制终止模型的思考过程，或者在模型试图结束时多次将「等待」附加到模型的生成中以延长思考。这有可能会导致模型仔细检查其答案，修复其不正确的推理步骤

# 2.6 Thur
* 20.DeepSeek-R1的顿悟时刻是如何出现的？ 背后的数学原理：强化学习如何教大型语言模型进行推理  图灵人工智能  https://mp.weixin.qq.com/s/n-sorNRrxDUD7LrcSHQs_Q 
* 21.LLaVA-Mini来了！每张图像所需视觉token压缩至1个，兼顾效率内存  机器之心  https://mp.weixin.qq.com/s/tlFW5FSVWeFri6JfeRxxWw \
  LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One Vision Token \
  计算效率提升（FLOPs 减少 77%）、响应时延降低（响应延时降至 40 毫秒）、显存占用减少（从 360 MB / 图像降至 0.6MB / 图像，支持 24GB GPU 上进行长达 3 小时的视频处理）
* 22.冲击DeepSeek R1，谷歌发布新一代Gemini全型号刷榜，编程、物理模拟能力炸裂  机器之心  https://mp.weixin.qq.com/s/QgW_MkES0PK0rP5GUU7DzA \
  力压DeepSeek-R1！谷歌Gemini 2.0系列集体上新，全员跻身大模型竞技场前10  量子位  https://mp.weixin.qq.com/s/zx-mY4MoCZgBWG9byh2wnA
* 23.多模态版DeepSeek-R1：评测表现超GPT-4o，模态穿透反哺文本推理能力！北大港科大出品，已开源  量子位  https://mp.weixin.qq.com/s/_S4tovrggFZdPIqFuos2Nw \
  此前DeepSeek自家的Janus-Pro-7B没有结合推理能力，但现在，国内有研究团队先做到了——基于自研全模态框架Align-Anything，北大联合港科大团队推出多模态版DeepSeek-R1: Align-DS-V \
  在部分视觉理解表现评测集上超越GPT-4o
* 24.百位专家联名警告：AI或将体验痛苦！Hinton、Bengio掀AI意识大论战  新智元  https://mp.weixin.qq.com/s/0CFdfz9LDYoykORgr78T3w \
  人类在开发AI系统时，必须足够负责，否则，可能具有情感或自我意识的AI系统，就可能会受到伤害 \
  Principles for Responsible AI Consciousness Research
* 25.可视化角度具象化理解DeepSeek-R1类推理大模型的习得进程  老刘说NLP  https://mp.weixin.qq.com/s/ytKTGTgU2T7jSNrBghX1cA 
* 26.大神Karpathy亲授！最新LLM入门视频课！  Datawhale  https://mp.weixin.qq.com/s/qw4CNN4z4-T_HUcezdkU0A \
  https://www.youtube.com/watch?v=7xTGNNLPyMI \
  Deep Dive into LLMs like ChatGPT
* 27.DeepSeek R1 Zero中文复现教程来了！  Datawhale  https://mp.weixin.qq.com/s/Z7P61IV3n4XYeC0Et_fvwg \
  TinyZero（https://github.com/Jiayi-Pan/TinyZero） 项目用了 4 张 A800 训练了 8 小时，预计花费为：224 元

# 2.7 Fri
* 28.万字长文详解DeepSeek-R1模型工作原理  图灵人工智能  https://mp.weixin.qq.com/s/2A5aEwtT_b_qqJ8c32ehBg \
  自我演化过程 顿悟时刻
* 29.丹尼特：自我不在脑中，那它到底在哪里？  追问nextquestion  https://mp.weixin.qq.com/s/SyKrcBxRBL6fj175JEPBow 
* 30.817样本激发7倍推理性能：上交大「少即是多」定律挑战RL Scaling范式 
 机器之心  https://mp.weixin.qq.com/s/c62TWyepruRYf_1xHFKw4g \
  LIMO: Less is More for Reasoning \
  仅需 817 条精心设计的样本，就能让模型在数学竞赛级别的题目上超越当前许多最先进模型 \
  大模型的数学能力或许一直都在，关键在于如何唤醒它 \
  第一，知识基础革命（Knowledge Foundation Revolution）。近年来，大模型在预训练阶段已纳入海量数学知识。例如，比起全领域训练数据只有 1.8T 的 Llama2，Llama 3 仅在数学推理上的训练数据就高达 3.7 万亿 token，这意味着现代 LLM 早已 “知道” 大量数学知识，关键是如何 “唤醒” 它们。 \
  第二，推理计算革命（Inference-time Computation Scaling Revolution）。最新研究表明，推理链（chain-of-thought, CoT）的长度，与模型的推理能力密切相关。与其在训练阶段硬灌大规模监督数据，不如在推理阶段提供更优质的问题和示范，让模型自主展开深入思考。 \
  基于这两点，LIMO 团队提出了一个全新的理论视角：大模型的推理能力本质上是 "潜伏" 的而非 "缺失" 的 \
  大模型的推理能力本身是内在存在的，关键挑战在于如何找到最优的激活路径 \
  引领了一种全新的研究范式——从“训练新能力”转向“激活潜在能力”
* 31.华人研究团队揭秘：DeepSeek-R1-Zero或许并不存在「顿悟时刻」  机器之心  https://mp.weixin.qq.com/s/_VK7fm8p3mpfhPh_zBdagA \
  DeepSeek-R1-Zero不存在顿悟时刻？华人团队揭秘真相：或只因强化学习  新智元  https://mp.weixin.qq.com/s/kYdLDi6Z2UG3lPy96LLIcA \
  There May Not be Aha Moment in R1-Zero-like Training - A Pilot Study \
  原文链接：https://oatllm.notion.site/oat-zero \
  来自新加坡 Sea AI Lab 等机构的研究者再次梳理了类 R1-Zero 的训练过程，并在一篇博客中分享了三项重要发现： \
  1. 在类似 R1-Zero 的训练中，可能并不存在「顿悟时刻」。相反，我们发现「顿悟时刻」（如自我反思模式）出现在 epoch 0，即基础模型中。 \
  2. 他们从基础模型的响应中发现了肤浅的自我反思（SSR），在这种情况下，自我反思并不一定会导致正确的最终答案。 \
  3. 仔细研究通过 RL 进行的类 R1-Zero 的训练，发现响应长度增加的现象并不是因为出现了自我反思，而是 RL 优化设计良好的基于规则的奖励函数的结果。\
  整个 RL 过程是将原本肤浅的自我反思转变为有效的自我反思，以最大化预期奖励，从而提高推理能力
* 32.将集体学习引入树搜索，新方法CoMCTS实现o1-like的推理与反思  机器之心  https://mp.weixin.qq.com/s/zkCvrKM4z7ov94BlmuaV4w \
  最近，NLP 领域的突破，如 OpenAI o1，展示了 LLM 的推理能力并应对复杂语言任务的巨大潜力。这些进展的核心设计灵感源于类似 AlphaGo 的 “树搜索” 方法：通过使用 MCTS 等树搜索方法，自引导地构建中间思维树，探索有效的推理路径，并利用这些路径对模型进行训练，从而实现逐步推理能力的提升。 \
  本文提出了集体蒙特卡罗树搜索（Collective Monte Carlo Tree Search, CoMCTS），这是一种新的学习推理方法，通过将集体学习引入 “树搜索”，实现有效且高效的推理路径搜索与学习。\
  Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search \
  代码链接：https://github.com/HJYao00/Mulberry
* 33.DeepSeek用的GRPO占用大量内存？有人给出了些破解方法  机器之心  https://mp.weixin.qq.com/s/28GRpZwqv4gMnrmItMQchQ \
  原文链接：https://www.oxen.ai/blog/grpo-vram-requirements-for-the-gpu-poor \
  自 DeepSeek-R1 发布以来，群组相对策略优化（GRPO）因其有效性和易于训练而成为大型语言模型强化学习的热门话题。R1 论文展示了如何使用 GRPO 从遵循 LLM（DeepSeek-v3）的基本指令转变为推理模型（DeepSeek-R1）
* 34.微软官宣All in智能体，SWE Agent首曝光！奥特曼预警2025编程巨变  新智元  https://mp.weixin.qq.com/s/aKLnb2jOMUJ3QIV9r6R25Q 
* 35.千万不要尝试 Qwen2.5-Max，你会因此忘掉 DeepSeek V3  夕小瑶科技说  https://mp.weixin.qq.com/s/QenD-0elk1VWDgO8_7alUw
* 36.被DeepSeek带火的知识蒸馏，开山之作曾被NeurIPS拒收，Hinton坐镇都没用  量子位  https://mp.weixin.qq.com/s/Uw9rScSJfUqrQc0KFULjQg \
  Distilling the Knowledge in a Neural Network
* 37.深度解析 DeepSeek 的蒸馏技术  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/9_AS1VTQMhsEWLh5hxwSGw

# 2.8 Sat
* 38.DeepSeek-R1、o1都低于10%，人类给AI的「最后考试」来了，贡献者名单长达两页  机器之心  https://mp.weixin.qq.com/s/2JlZG-_8KP9nAisrYZKczw \
  Humanity’s Last Exam \
  项目地址：https://lastexam.ai
* 39.NAACL 2025 | 知识增强下的智能体规划  专知  https://mp.weixin.qq.com/s/F_auRKSg3qQnDggQ8-H6wg \
  KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents \
  智能体缺乏内置的动作知识，导致它们在任务解决过程中无法有效地指导规划轨迹，从而引发规划幻觉 \
  为了解决这一问题，我们提出了KnowAgent，旨在通过利用外部动作知识来增强轨迹合成，缓解其中出现的规划幻觉问题
* 40.多机器人系统的大型语言模型：综述  专知  https://mp.weixin.qq.com/s/wMIEanYPRgzLuP6pkAfq4w \
  Large Language Models for Multi-Robot Systems: A Survey
* 41.谷歌AI解决IMO中84%的几何问题，o1一道没做对！Nature：AI已超过金牌得主平均水平  量子位  https://mp.weixin.qq.com/s/w68oOOv80fIPwWwj2kegAg \
  DeepMind Al crushes tough mathsproblemson par with top human solvers \
  AlphaGeometry2
* 42.图像生成迎来CoT时刻！港中文首次提出文生图的o1推理和Inference Scaling新范式！  机器之心  https://mp.weixin.qq.com/s/CTpDAzzk5mcXtQrCpTJs1Q \
  Can We Generate Images with CoT? Let’s Verify and Reinforce Image Generation Step by Step 
* 43.吴恩达Agent新成果来了！  Datawhale  https://mp.weixin.qq.com/s/oWQ4A-FSiYOQ2hFNDrFxnA \
  Agentic Object Detection \
  在线试玩：https://va.landing.ai/demo/agentic-od

# 2.9 Sun
* 44.SFT并非必需！推理模型仅靠RL就能获得长思维链能力，清华CMU团队破解黑盒  量子位  https://mp.weixin.qq.com/s/5DIoA-R_PLAAvAATPXgbVg \
  Demystifying Long Chain-of-Thought Reasoning in LLMs \
  1.SFT并非必需，但能简化训练并提高效率； \
  2.推理能力随着训练计算的增加而出现，但并非总是如此； \
  3.可验证奖励函数对增长CoT至关重要； \
  4.纠错等核心能力基础模型天生自带，但通过RL有效地激励这些技能需要大量的计算。
* 45.大规模语言模型推理的进展综述  专知  https://mp.weixin.qq.com/s/oPoDUdWg1FydMnEyB91_uQ \
  Reasoning in LLMs: Dive deeper into working, techniques and approaches 
* 46.Sebastian Raschka：关于DeepSeek R1和推理模型，我有几点看法  机器之心  https://mp.weixin.qq.com/s/LT22OjbJWKDzTuQeO4yvlg \
  
* 47.(**值得实践**)DeepSeek-R1推理本地跑，7GB GPU体验啊哈时刻？GRPO内存暴降，GitHub超2万星  新智元  https://mp.weixin.qq.com/s/WayXEwbzAv00gd1uj-7jqg \
  开源项目Unsloth AI \
  现在可以在本地设备上复现DeepSeek-R1的推理！只需7GB VRAM，你就能体验到「Aha」时刻。Unsloth把GRPO训练需要的内存减少了80%。15GB VRAM就可以把Llama-3.1（8B）和Phi-4（14B）转变为推理模型。 \
  原文链接：https://unsloth.ai/blog/r1-reasoning \
  Train your own R1 reasoningmodel with Unsloth \
  项目链接：https://github.com/unslothai/unsloth \
  文档链接：https://docs.unsloth.ai/get-started/unsloth-notebooks
* 48.Sebastian Raschka：关于DeepSeek R1和推理模型，我有几点看法  机器之心  https://mp.weixin.qq.com/s/LT22OjbJWKDzTuQeO4yvlg \
  Understanding Reasoning LLMs: Methods and Strategies for Building and Refining Reasoning Models \
  原文地址：https://sebastianraschka.com/blog/2025/understanding-reasoning-llms.html \
  纯 RL: TinyZero \
  纯 SFT: Sky-T1 \
  O1 Replication Journey: A Strategic Progress Report – Part 1 \
  论文的核心思想是用「旅程学习」替代「捷径学习」。\
  捷径学习是指指令微调的传统方法，其中仅使用正确的解决方案路径来训练模型。 \
  另一方面，旅程学习也包括错误的解决路径，让模型从错误中学习。

# 2.10 Mon
* 49.MoE环游记：从几何意义出发  PaperWeekly  https://mp.weixin.qq.com/s/kUF4cy1QA_xQSyT5HtcKIA 
* 50.AAAI 2025 | 大模型会组合关系推理吗？打开黑盒，窥探Transformer脑回路  PaperWeekly  https://mp.weixin.qq.com/s/ndiNoWw-nbnf1xPY3IePyQ \
  Benchmarking and Understanding Compositional Relational Reasoning of LLMs
* 51.(**值得看看**)LLM实现自回归搜索！MIT哈佛等提出「行动思维链」COAT，推理能力大提升  新智元  https://mp.weixin.qq.com/s/wHU8m7rq2B3fIC5nA_mG6Q \
  Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search \
  https://github.com/satori-reasoning/Satori \
  来自MIT、新加坡科技设计大学、哈佛大学等机构的华人研究者探索了全新的方向：让LLM拥有自回归搜索能力。通过自我反思和探索新策略，提升LLM推理能力。研究者引入了行动-思维链（COAT）机制，使LLM在解决问题时能够执行多种元动作，并提出了一种创新的两阶段训练框架：小规模格式调优阶段：让LLM熟悉并掌握COAT推理格式。大规模自我优化阶段：运用重启与探索（RAE）技术，通过RL进行优化。\
  Satori具有以下核心特点：1.无需外部指导，即可自我反思与探索。2.主要依靠自我改进（RL），实现了最先进的推理性能。3.展现出强大的迁移能力，可应用于数学以外的领域。
* 52.AI意识更进一步！谷歌DeepMind等：LLM不仅能感受痛苦，还能趋利避害  新智元  https://mp.weixin.qq.com/s/ppseOPqKfxcD2IORDm-GxQ \
  Can LLMs make trade-offs involving stipulated pain and pleasure states?
* 53.人大刘勇团队「慢思考」机理分析：从雪球误差到正确推理概率  机器之心  https://mp.weixin.qq.com/s/SSBZucZgp9QknA901-x5ig \
  Rethinking External Slow-Thinking: From Snowball Errors to Probability of Correct Reasoning
* 54.北航推出TinyLLaVA-Video，有限计算资源优于部分7B模型，代码、模型、训练数据全开源  机器之心  https://mp.weixin.qq.com/s/e1zUm8dv445RjrDtedJh3Q \
  TinyLLaVA-Video: A Simple Framework of Small-scale Large Multimodal Models for Video Understanding \
  https://github.com/ZhangXJ199/TinyLLaVA-Video
* 55.(**值得看看**)具身物体表示学习与识别  CreateAMind  https://mp.weixin.qq.com/s/ohM4yq8RuFtGnsA8KV0pVg \
  Embodied Object Representation Learning and Recognition \
  涉及到《千脑智能》中的皮质柱网络
* 56.海马模型Hopfield网络的情境控制  CreateAMind  https://mp.weixin.qq.com/s/VUX4IFbbO0ZJGuZ0iaLIkg \
  Contextual Control of Hopfield Networks in a Hippocampal Model 
* 57.清华姚班校友等揭Transformer致命缺陷，OpenAI科学家紧急回应：学术界节奏太慢  新智元  https://mp.weixin.qq.com/s/c-FIYgcxQm4eH2d6lT4BBA \
  Transformer缺乏组合能力，由此导致LLM产生了幻觉 \
  如果一个大模型只有单层Transformer结构，总参数量小于域的大小，AI便无法解决组合任务 \
  模型规模增大后，确实能解决更具挑战性的问题。但要是同时扩大问题的规模，就算模型变得更大，解决起来照样棘手。这充分表明，Transformer架构存在着难以逾越的局限性

# 2.11 Tue
* 58.开源22万条DeepSeek R1的高质量数据！你也能复现DeepSeek了  机器之心  https://mp.weixin.qq.com/s/yIEisGrfguRkpjRnHmNYCg \
  项目地址：https://github.com/huggingface/open-r1 \
  数据集链接：https://huggingface.co/datasets/open-r1/OpenR1-Math-220k \
  这些数据可以用来支持更小的模型，来达到媲美 DeepSeek R1 的效果。比如在 OpenR1-Math-220k 数据集上训练出来的 Qwen-7B-Math-Instruct，达到了与 DeepSeek-Distill-Qwen-7B 相当的性能 \
  开源社区也从多个角度探索了 GRPO，有多个研究实验室表明，大约 1000 个高质量的训练样本可能就足以在现有的开源模型中引发推理能力
* 59.(**值得看看**)推理模型新路线开源！与DeepSeek截然不同，抛弃思维链不用人类语言思考 
 量子位  https://mp.weixin.qq.com/s/HK6fjolKDcHG6MD_cVgifg \
  开源推理大模型新架构来了，采用与Deepseek-R1/OpenAI o1截然不同的路线：抛弃长思维链和人类的语言，直接在连续的高维潜空间用隐藏状态推理，可自适应地花费更多计算来思考更长时间 \
  Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach \
  马里兰大学的一篇论文表明，通过使用循环语言模型，可以在潜在空间中隐式推理，从而在测试时扩展计算能力，这类似于 Meta 的 Coconut。这些方法的优势在于它们的计算效率更高：通过探索潜在空间，无需生成大量「思考」token 即可获得高性能 \
  新架构给Transformer加入循环模块，新架构仍然围绕Decoder-only的Transformer block构建，但分为三段： \
  1.Prelude（前奏）：使用多个transformer层将输入数据嵌入到潜空间中 \
  2.Recurrent Block（循环块）：循环计算单元，在潜在空间中修改状态 \
  3.Coda（尾声）：从潜空间解码，并包含模型的预测头
* 60.4500美元复刻DeepSeek神话，1.5B战胜o1-preview只用RL！训练细节全公开  新智元  https://mp.weixin.qq.com/s/g2PfdI8N1oU7RWU0owh75Q \
  UC伯克利团队只用简单的RL微调，就训出了DeepScaleR-1.5B-Preview，15亿参数模型直接吊打o1-preview \
  训练策略就是四个字——先短后长 \
  Deepseek-R1发现，直接在小型模型上用强化学习，效果不如知识蒸馏。在Qwen-32B模型上做对比实验，强化学习只能让AIME测试的准确率达到47％，但只用知识蒸馏就能达到72.6％。不过，要是从更大的模型中，通过蒸馏得到高质量的SFT数据，再用强化学习，小模型的推理能力也能大幅提升
* 61.AI已学会自我复制！复旦新研究：开源LLM克隆成功率最高90%  新智元  https://mp.weixin.qq.com/s/uWvY6RBp-pdUb7fqIt49mw \
  Frontier Al systems have surpassed the self-replicating red line \
  这些AI系统已有足够的自我感知、环境认知和解决问题能力，得以实现自我复制。它们还会利用这种能力逃避关闭指令，不断创建复制链以增强生存能力，这极有可能导致AI数量失控。一旦AI实现自我复制，这条成功复制的链条，可能催生出一种人类无法掌控的AI物种。它们会抢占更多计算设备，联合起来对抗人类

# 2.12 Wed
* 62.理解DeepSeek在MoE技术的演进过程和具体实现  大模型生态圈  https://mp.weixin.qq.com/s/DzDhfSiNp6GXdLt_snKvzg 
* 64.DeepSeek并非完美，训练过程存在“深度诅咒”  AIGC开放社区  https://mp.weixin.qq.com/s/vuMzQzT4jPXykLA1239GDg \
  移除模型的深层对性能的影响微乎其微，而移除浅层性能会明显下降。这表明DeepSeek模型的深层在训练过程中未能有效学习到有用的特征，而浅层则承担了大部分的特征提取任务。这种现象称为“深度诅咒”（Curse of Depth），同时研究人员也提出了一种有效的解决方法——LayerNorm Scaling（层归一化缩放） \
  The Curse of Depth in Large Language Models
* 65.推理成本比MoE直降83%！字节最新大模型架构入围ICLR 2025  量子位  https://mp.weixin.qq.com/s/4kxHv_WR8t63yB4x4rRQhg \
  ULTRA-SPARSE MEMORY NETWORK \
  这个全新的稀疏模型架构叫做UltraMem，有效地解决了目前主流的MoE架构和PKM架构所存在的局限性 \
  推理速度相比MoE架构提升2-6倍，推理成本最高可降低83%
* 66.DeepSeek模型综述：V1 V2 V3 R1-Zero  专知  https://mp.weixin.qq.com/s/gNBG108v4_9WChB7A31Hlg 
* 67.8卡32B模型超越o1预览版、DeepSeek V3，普林斯顿、北大提出层次化RL推理新范式  机器之心  https://mp.weixin.qq.com/s/Vqif83WcgUpFrCJMHYxGmA \
  8块A100，32B碾压DeepSeek V3、o1-preview！普林斯顿北大首提分层RL推理 
 新智元  https://mp.weixin.qq.com/s/bSaIzvvg7UJkP0XNOK2uzA \
  8卡32B模型超越o1预览版、DeepSeek V3，普林斯顿、北大提出层次化RL推理新范式  PaperWeekly  https://mp.weixin.qq.com/s/Suihdv_BLkF_HK_l34gawQ \
  ReasonFlux: 多层次（Hierarchical）LLM 推理框架 \
  ReasonFlux: Hierarchical LM Reasoning via Scaling Thought Templates \
  开源地址：https://github.com/Gen-Verse/ReasonFlux
* 68.啊？7B的DeepSeek反超R1满血版，上海AI Lab周伯文团队新成果：计算最优的Test-Time Scaling  量子位  https://mp.weixin.qq.com/s/BUBp2TShir9MRd6iVtFSfw \
  清华一作1B暴打405B巨无霸，7B逆袭DeepSeek R1！测试时Scaling封神  新智元  https://mp.weixin.qq.com/s/ygv_CIcVJcRsgr98fdKc_g \
  Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling \
  来自清华、哈工大、北邮等机构的研究人员发现，使用**计算最优TTS策略**，极小的策略模型也可以超越更大的模型 \
  TTS是增强LLM推理能力的一种极有前途的方法 \
  ???什么是TTS
* 69.生物人工智能——从具身认知到具身机器人学  CreateAMind  https://mp.weixin.qq.com/s/ofoF108tk6yRqAe10iE2sg \
  Bio A.I. - from embodied cognition to enactive robotics
* 70.4090单卡跑满血版DeepSeek-R1，清华团队开源项目再破大模型推理门槛  量子位  https://mp.weixin.qq.com/s/UjsaPDeCfW8QUYTCUZmVxA \
  KTransformers开源项目 \
  GitHub 地址：https://github.com/kvcache-ai/ktransformers \
  具体技术细节指路：https://zhuanlan.zhihu.com/p/714877271
* 71.超越思维链？深度循环隐式推理引爆AI圈，LLM扩展有了新维度  机器之心  https://mp.weixin.qq.com/s/WGszi-BKl50jQj8j7X0PYQ \
  Scaling up Test-Time Compute with Latent Reasoning:A Recurrent Depth Approach \
  模型下载: https://huggingface.co/tomg-group-umd/huginn-0125 \
  代码链接: https://github.com/seal-rg/recurrent-pretraining \
  ???什么是深度循环隐式推理
* 72.o3拿下IOI 2024金牌！新论文公布RL秘诀：AI自己设计测试时推理策略，无需人类干预  量子位  https://mp.weixin.qq.com/s/7WV67GcOh2oTJhBQF9zP6Q \
  o3的表现，证明了通过大规模端到端RL（强化学习），无需依赖人工设计的测试时推理策略，就能自己学会先写暴力求解代码提高效率，再用其他方法交叉验证的策略 \
  Competitive Programming with Large Reasoning Model
* 73.(**有趣**)被AI追杀，还要解谜逃生！UCSD等发布LLM测试神器，边玩游戏边评估  新智元  https://mp.weixin.qq.com/s/-R6NBJGhnxDamrVM2WaDdA \
  GAMEARENA: EVALUATING LLM REASONING THROUGH LIVE COMPUTER GAMES \
  项目地址：https://lmgame.org/
* 74.Cell子刊《Patterns》最新综述：大语言模型Attention Heads的可解释性研究  PaperWeekly  https://mp.weixin.qq.com/s/88LG1RSoPIdfo8Lc3tuWNg \
  Attention Heads of Large Language Models \
  在 Transformer 结构中，注意力头是其推理能力的关键组件，它通过选择性地关注输入序列中的相关部分，从而实现上下文理解。然而，不同注意力头在推理中的具体功能与协作方式尚不明确。深入研究注意力头不仅有助于揭示大模型的内部逻辑，还为大模型的可解释性研究提供了理论基础 \
  该综述创新性地提出了一个认知框架用于描述人类大脑解决特定问题的过程。该框架将人脑的推理过程分为知识召回（Knowledge Recalling）、上下文识别（In-Context Identification）、潜在推理（Latent Reasoning）以及表达准备（Expression Preparation）四个阶段 \
  借助提出的认知框架，该综述首次将认知神经科学的原理融入大模型可解释性研究中，清晰定义了不同注意力头在推理过程中的具体功能。例如，某些注意力头专注于跨句子的上下文对齐，另一些则负责增强模型的记忆能力，还有一些承担了核心的推理工作。
* 75.什么是自指 | 集智百科  集智俱乐部  https://mp.weixin.qq.com/s/fQqJ106erMfuW2VbMhlIYA
* 76.大模型向通用意识机器进化的关键——自指的启示  集智俱乐部  https://mp.weixin.qq.com/s/jBZwi83nLjU68HlPb0u1qQ 
* 77.用大模型可以实现完美自指吗？  集智俱乐部  https://mp.weixin.qq.com/s/fFVqK3j6kSL3yw_QTO0o9A 
* 78.UC伯克利 | Deepseek训练复现：1.5B模型也能超越o1预览版，代码数据全开源！  AINLPer  https://mp.weixin.qq.com/s/2CG9KSQcJJLJ2NmHVd49lw \
  DeepScaleR-1.5B-Preview，基于 Deepseek-R1-Distilled-Qwen-1.5B 模型，通过强化学习（RL）微调，实现了惊人的 43.1% Pass@1 准确率，提升了 14.3%，并在 AIME 2024 竞赛中超越了 O1-Preview \
  这一成果不仅打破了 “大模型才能强大” 的固有认知，更展示了 RL 在小型模型中的无限可能 \
  博客地址：https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2 \
  项目地址：https://github.com/agentica-project/deepscaler \
  项目网站：https://agentica-project.com/Hugging Face \
  模型：https://huggingface.co/agentica-org/DeepScaleR-1.5B-PreviewHugging Face \
  数据集：https://huggingface.co/datasets/agentica-org/DeepScaleR-Preview-DatasetWandb \
  训练日志：https://wandb.ai/mluo/deepscaler-1.5b?nw=nwusermluo

# 2.13 Thur
* 79.最 Deep 的 Seek：AI 的“终极设计图”是什么样子？  图灵人工智能  https://mp.weixin.qq.com/s/AqnuUDPk2IleoYvkSnDCKg \
  元胞自动机涌现出智能？
* 80.0.5B小模型逆袭！不到50元，「X-R1」让每个人都能复现Aha Moment 
 PaperWeekly  https://mp.weixin.qq.com/s/Lv0mEpS1e9Eh2BVH97TsrA \
  X-R1开源仓库：https://github.com/dhcode-cpp/X-R1 \
  项目的代码基础为 open-r1 ，由于官方例子需要 8x80G显卡，我们探索了一条更易训练的方案 \
  4x3090/4090 GPUs 训练总时间2小时以内,在第10分钟的 37步优化中输出了“aha Moment“
* 81.DeepSeek R1不编程就能生成GPU内核，比熟练工程师好，惊到了英伟达  机器之心  https://mp.weixin.qq.com/s/8GE8xqY-7V3c4LFU4fcT2Q \
  英伟达却在尝试用 DeepSeek 给大模型 pipeline 本身搞自动化 \
  英伟达在博客中介绍了利用 DeepSeek-R1 和推理时扩展技术来自动生成优化 GPU 内核的最新研究成果，效果异常的好 \
  Automating GPU Kernel Generation with DeepSeek-Rl and Inference Time Scaling
* 82.【博士论文】《认知与视觉神经科学中的循环神经网络》  专知  https://mp.weixin.qq.com/s/VRBc72MhwKwIMG-FYDV6Ww \
  Recurrent neural networks in cognitive and vision neuroscience
* 83.哥德尔-Prover超过DeepSeek-Prover，金驰、陈丹琦团队造出当前最强形式化推理模型  机器之心  https://mp.weixin.qq.com/s/IfYQdMyZ7FBEJCXNCTpZtQ \
  最近一段时间，以 DeepSeek-R1 为代表的大型推理模型可谓是「当红炸子鸡」，不过整体来说，这些模型所做的推理都属于非形式化推理（informal reasoning）。也就是说，它们主要是通过自然语言执行推理。\
  但是，这种推理模式有个缺点：难以通过机器来自动验证。也因此，非形式化推理在实际应用中的可靠性就大打折扣了。这还会让研究者更加难以进一步对推理模型进行改进。 \
  解决方案也很直观：形式化推理（formal reasoning） \
  一个用于自动定理证明的形式化推理模型 Goedel-Prover（哥德尔证明器），并且该模型在数学问题的自动形式化证明生成任务上达到了 SOTA \
  Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving \
  项目地址：https://github.com/Goedel-LM/Goedel-Prover \
  Hugging Face：https://huggingface.co/Goedel-LM/Goedel-Prover-SFT \
  形式化推理: 以机器可验证的格式进行推理
  非形式化推理：自然语言推理
* 84.直逼DeepSeek-R1-32B，碾压李飞飞s1！UC伯克利等开源全新SOTA推理模型  新智元  https://mp.weixin.qq.com/s/4j6eLEJY2K9MpFsNqEVFHg \
  斯坦福、UC伯克利等多机构联手发布了开源推理新SOTA——OpenThinker-32B，性能直逼DeepSeek-R1-32B。其成功秘诀在于数据规模化、严格验证和模型扩展 \
  项目主页：https://www.open-thoughts.ai/blog/scale \
  Hugging Face：https://huggingface.co/open-thoughts/OpenThinker-32B \
  数据集：https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k

# 2.14 Fri
* 85.李飞飞看中的万亿赛道，中国首个自研空间智能AI登场！单张图即生3D世界  新智元  https://mp.weixin.qq.com/s/oXdNdVz27LaPA5dPYZBOrg \
  昆仑万维正式发布了一款全新自研的Matrix-Zero世界模型 \
  两部分功能：1.支持将用户输入的图片转化为可自由探索的真实合理的3D场景；2.支持根据用户输入实时生成互动视频效果。
* 86.Anthropic秘密「混合模型」 Claude 4首曝细节，硬刚GPT-5！深度推理模型来了  新智元  https://mp.weixin.qq.com/s/KrzjCv5zlzH0nP22Ry5irQ 
* 87.谷歌最新论文，生成式AI 是否有“意识”？  探索AGI  https://mp.weixin.qq.com/s/nHgkvPnLXWMkgJrQiQCJvw \
  Agency Is Frame-Dependent \
  如何判断一个系统是否具有主观能动性呢？论文中提出了四个维度: \
  1.这个系统要有明确的边界，能够区分自己和环境; \
  2.它的行为应该来源于自身，而不是完全被外界推动; \
  3.它要有明确的目标导向; \
  4.它能够根据环境变化调整自己的行为

# 2.15 Sat
* 88.
* 89.
* 90.
* 91.
* 92.
* 93.
* 94.
* 95.
* 96.
* 97.
* 98.
* 99.
* 100.

# 2.16 Sun

# 2.17 Mon

# 2.18 Tue

# 2.19 Wed

# 2.20 Thur

# 2.21 Fri

# 2.22 Sat

# 2.23 Sun

# 2.24 Mon

# 2.25 Tue

# 2.26 Wed

# 2.27 Thur

# 2.28 Fri


