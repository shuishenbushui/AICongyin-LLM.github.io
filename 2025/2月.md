# 2.1 Sat
* 1.(**值得看看**)o1开启LLM新范式，Ai2科学家解析背后秘籍：推理和强化学习是关键  新智元  https://mp.weixin.qq.com/s/3X5MMSWFiP1d4lvacTtjcA \
  Ai2研究科学家Nathan Lambert总结语言推理现状，揭开OpenAI o1训练中强化学习的秘密 \
  The state of reasoning \
  视频和原文地址：https://www.interconnects.ai/p/the-state-of-reasoning
* 2.(**值得看看**)Jay Alammar：图解DeepSeek-R1  图灵人工智能  https://mp.weixin.qq.com/s/SVMjyxx3gKKCxVqCtBuT3A \
  英文连接 https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1 
* 3.麻省理工大佬： DeepSeek是科技史上伟大时刻，5年后依旧难忘！  AIGC开放社区  https://mp.weixin.qq.com/s/ENTs7K4VguQl_aKu7c72hw
* 4.万字长文解读Scaling Law的一切，洞见LLM的未来  机器之心  https://mp.weixin.qq.com/s/1H5E9Z6BoW6Oi5ns4FGflw \
  原文链接：https://cameronrwolfe.substack.com/p/llm-scaling-laws

# 2.2 Sun
* 5.OpenAI 发布推理模型o3-mini，附37页技术报告，中英文版  专知  https://mp.weixin.qq.com/s/kebVgBDILCnc8-_KaW5QVA \
  OpenAI o3-mini System Card
* 6.o3-mini物理推理粉碎DeepSeek R1，OpenAI王者归来！全网最全实测来袭  新智元  https://mp.weixin.qq.com/s/_oE2-Mm3yAWeXcjwqJgi_A 
* 7.GPT-4o惊现自我意识！自主激活「后门」，告诉人类自己在写危险代码  新智元  https://mp.weixin.qq.com/s/_wYO8F9e0Uc3kThav-nQ1A \
  本研究探讨了LLM是否具备行为自我意识的能力，揭示了模型在微调过程中学到的潜在行为策略，以及其是否能准确描述这些行为。研究结果表明，LLM能够识别并描述自身行为，展现出行为自我意识 \
  行为自我意识，指的是LLM无需借助上下文，便能准确描述自身行为 \
  TELL ME ABOUT YOURSELF: LLMS ARE AWARE OF THEIR LEARNED BEHAVIORS \
  https://www.lesswrong.com/posts/xrv2fNJtqabN3h6Aj/tell-me-about-yourself-llms-are-aware-of-their-learned
* 8.全面梳理200+篇前沿论文，视觉生成模型理解物理世界规律的通关密码，都在这篇综述里了！  机器之心  https://mp.weixin.qq.com/s/0fMOhfxIUy1w0ERu2QzKpA \
  Generative Physical AI in Vision: A Survey

# 2.3 Mon
* 9.(**Deep Research**)OpenAI紧急直播，ChatGPT疯狂开挂「深度研究」！10分钟爆肝万字现AGI雏形，刷榜人类最后考试  新智元  https://mp.weixin.qq.com/s/9eEBM7U7FBfpOGtLXeUfEw  \
  刚刚，OpenAI上线Deep Research！人类终极考试远超DeepSeek R1  机器之心  https://mp.weixin.qq.com/s/FMTvXxspbgGyvk33loH24w \
  OpenAI 又发新产品了，这次是面向深度研究领域的智能体产品 ——「Deep Research」 \
  Deep Research 通过端到端的强化学习在多个领域的复杂浏览和推理任务上进行了训练 \
  现在看来，Deep research 能够进行异步的在线查找，而 Operator 则能够在现实世界中采取行动，两者的结合将使 ChatGPT 能够为用户执行越来越复杂的任务
* 10.解放双手！OSCAR让操作系统交互实现自然语言「自由」  机器之心  https://mp.weixin.qq.com/s/OvZ1MC8AEd4wQA85ULsNNQ \
  OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning \
  博客地址：https://openai.com/index/introducing-deep-research/
* 11.新研究揭示DeepSeek/o3弱点：频繁切换思路放弃正确方向，最短答案往往就是对的！  量子位  https://mp.weixin.qq.com/s/6oejP8sKLAHGeD2esUZPcA \
  在遇到高难度问题时，推理大模型可能像“三心二意的学生”一样频繁切换解题思路，却因缺乏深入探索而失败——这种现象被研究者称为Underthinking（欠思考） \
  通过分析AI的错误答案，他们发现当前的推理大模型经常在思考早期就走上了正确的路线，但倾向于“浅尝辄止”，很快开始探索别的思路，导致后续生成的数千个tokens对解题毫无贡献 \
  Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs
* 12.高维向量计算  CreateAMind  https://mp.weixin.qq.com/s/whZ6xyjswGNVODD498SxYg \
  Computing with high-dimensional vectors
* 13.完整的671B R1塞进本地，详尽教程来了！  Datawhale  https://mp.weixin.qq.com/s/dKfQfv78ch4IlzBML9Tmkw \
  https://snowkylin.github.io/blogs/a-note-on-deepseek-r1.html

# 2.4 Tue
* 14.ICLR 2025 | 大模型“遗忘”竟是错觉？华南理工团队首次揭示LLM训练中的“虚假遗忘”  PaperWeekly  https://mp.weixin.qq.com/s/d7QkZGBE1IKnrEfcqDH4ng \
  Spurious Forgetting in Continual Learning of Language Models \
  任务表现=任务对齐(Task Alignment)+潜在知识(Underlying Knowledge) \
  任务性能的下降可能并非由于旧知识的遗忘，而是模型在新任务初期丧失了对旧任务的任务对齐能力
* 15.机器人使用工具的快速学习机制  CreateAMind  https://mp.weixin.qq.com/s/cmOuJs3ks-fLMpWDokXIyA \
  Efficient motor learning through action-perception cycles in deep kinematic
* 16.Go语言开发AI智能体有多丝滑？字节重磅开源Eino框架，内含保姆级教程  机器之心  https://mp.weixin.qq.com/s/kevdQGjV3GVi1_4B9XGtJw \
  ? Go语言相对于python有啥优势

# 2.5 Wed
* 17.基于网格细胞启发的高效地图构建中的碎片化与回忆  CreateAMind  https://mp.weixin.qq.com/s/RoVJQXmBs6ymcnVGTQjygg \
  Grid Cell-Inspired Fragmentation and Recall for Efficient Map Building \
  https://github.com/FieteLab/FARMap
* 18.超越DeepSeek V3！Ai2再祭开源杀器Tülu 3，强化学习打破性能瓶颈  新智元  https://mp.weixin.qq.com/s/hX2pNUupJ5yJ-eqe3qyP-Q \
  艾伦人工智能研究所（Ai2）推出了基于强化学习的新一代开源模型Tülu 3 405B，不仅能够媲美GPT-4o，更在多项关键基准测试中超越了DeepSeek v3 \
  Tülu 3 8B和70B \
  Tülu 3: Pushing Frontiers in Open Language Model Post-Training
* 19.训练1000样本就能超越o1，李飞飞等人画出AI扩展新曲线  机器之心  https://mp.weixin.qq.com/s/ax_CCrqpgrp5j2mLOssY4w \
  16张H100训26分钟，超越o1-preview！李飞飞等用1K样本，揭秘测试时Scaling  新智元  https://mp.weixin.qq.com/s/iGi20QGI8KFn-WPtBL5JCw \
  成本不到150元！李飞飞等26分钟训出个推理模型，媲美o1和R1，秘诀：用蒸馏 
 量子位  https://mp.weixin.qq.com/s/KEGrXVpNXdq-WcQxRzBJfg \
  斯坦福大学、华盛顿大学等研究机构尝试了最简化实现测试时间扩展（test-time scaling）的方法，仅让模型训练 1000 个问题就获得了超越 o1 的强推理性能 \
  s1: Simple test-time scaling \
  https://github.com/simplescaling/s1 \
  研究人员开发了「预算强制」来控制测试时间计算，方法是强制终止模型的思考过程，或者在模型试图结束时多次将「等待」附加到模型的生成中以延长思考。这有可能会导致模型仔细检查其答案，修复其不正确的推理步骤

# 2.6 Thur
* 20.DeepSeek-R1的顿悟时刻是如何出现的？ 背后的数学原理：强化学习如何教大型语言模型进行推理  图灵人工智能  https://mp.weixin.qq.com/s/n-sorNRrxDUD7LrcSHQs_Q 
* 21.LLaVA-Mini来了！每张图像所需视觉token压缩至1个，兼顾效率内存  机器之心  https://mp.weixin.qq.com/s/tlFW5FSVWeFri6JfeRxxWw \
  LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One Vision Token \
  计算效率提升（FLOPs 减少 77%）、响应时延降低（响应延时降至 40 毫秒）、显存占用减少（从 360 MB / 图像降至 0.6MB / 图像，支持 24GB GPU 上进行长达 3 小时的视频处理）
* 22.冲击DeepSeek R1，谷歌发布新一代Gemini全型号刷榜，编程、物理模拟能力炸裂  机器之心  https://mp.weixin.qq.com/s/QgW_MkES0PK0rP5GUU7DzA \
  力压DeepSeek-R1！谷歌Gemini 2.0系列集体上新，全员跻身大模型竞技场前10  量子位  https://mp.weixin.qq.com/s/zx-mY4MoCZgBWG9byh2wnA
* 23.多模态版DeepSeek-R1：评测表现超GPT-4o，模态穿透反哺文本推理能力！北大港科大出品，已开源  量子位  https://mp.weixin.qq.com/s/_S4tovrggFZdPIqFuos2Nw \
  此前DeepSeek自家的Janus-Pro-7B没有结合推理能力，但现在，国内有研究团队先做到了——基于自研全模态框架Align-Anything，北大联合港科大团队推出多模态版DeepSeek-R1: Align-DS-V \
  在部分视觉理解表现评测集上超越GPT-4o
* 24.百位专家联名警告：AI或将体验痛苦！Hinton、Bengio掀AI意识大论战  新智元  https://mp.weixin.qq.com/s/0CFdfz9LDYoykORgr78T3w \
  人类在开发AI系统时，必须足够负责，否则，可能具有情感或自我意识的AI系统，就可能会受到伤害 \
  Principles for Responsible AI Consciousness Research
* 25.可视化角度具象化理解DeepSeek-R1类推理大模型的习得进程  老刘说NLP  https://mp.weixin.qq.com/s/ytKTGTgU2T7jSNrBghX1cA 
* 26.大神Karpathy亲授！最新LLM入门视频课！  Datawhale  https://mp.weixin.qq.com/s/qw4CNN4z4-T_HUcezdkU0A \
  https://www.youtube.com/watch?v=7xTGNNLPyMI \
  Deep Dive into LLMs like ChatGPT
* 27.DeepSeek R1 Zero中文复现教程来了！  Datawhale  https://mp.weixin.qq.com/s/Z7P61IV3n4XYeC0Et_fvwg \
  TinyZero（https://github.com/Jiayi-Pan/TinyZero） 项目用了 4 张 A800 训练了 8 小时，预计花费为：224 元

# 2.7 Fri
* 28.万字长文详解DeepSeek-R1模型工作原理  图灵人工智能  https://mp.weixin.qq.com/s/2A5aEwtT_b_qqJ8c32ehBg \
  自我演化过程 顿悟时刻
* 29.丹尼特：自我不在脑中，那它到底在哪里？  追问nextquestion  https://mp.weixin.qq.com/s/SyKrcBxRBL6fj175JEPBow 
* 30.817样本激发7倍推理性能：上交大「少即是多」定律挑战RL Scaling范式 
 机器之心  https://mp.weixin.qq.com/s/c62TWyepruRYf_1xHFKw4g \
  LIMO: Less is More for Reasoning \
  仅需 817 条精心设计的样本，就能让模型在数学竞赛级别的题目上超越当前许多最先进模型 \
  大模型的数学能力或许一直都在，关键在于如何唤醒它 \
  第一，知识基础革命（Knowledge Foundation Revolution）。近年来，大模型在预训练阶段已纳入海量数学知识。例如，比起全领域训练数据只有 1.8T 的 Llama2，Llama 3 仅在数学推理上的训练数据就高达 3.7 万亿 token，这意味着现代 LLM 早已 “知道” 大量数学知识，关键是如何 “唤醒” 它们。 \
  第二，推理计算革命（Inference-time Computation Scaling Revolution）。最新研究表明，推理链（chain-of-thought, CoT）的长度，与模型的推理能力密切相关。与其在训练阶段硬灌大规模监督数据，不如在推理阶段提供更优质的问题和示范，让模型自主展开深入思考。 \
  基于这两点，LIMO 团队提出了一个全新的理论视角：大模型的推理能力本质上是 "潜伏" 的而非 "缺失" 的 \
  大模型的推理能力本身是内在存在的，关键挑战在于如何找到最优的激活路径 \
  引领了一种全新的研究范式——从“训练新能力”转向“激活潜在能力”
* 31.华人研究团队揭秘：DeepSeek-R1-Zero或许并不存在「顿悟时刻」  机器之心  https://mp.weixin.qq.com/s/_VK7fm8p3mpfhPh_zBdagA \
  DeepSeek-R1-Zero不存在顿悟时刻？华人团队揭秘真相：或只因强化学习  新智元  https://mp.weixin.qq.com/s/kYdLDi6Z2UG3lPy96LLIcA \
  There May Not be Aha Moment in R1-Zero-like Training - A Pilot Study \
  原文链接：https://oatllm.notion.site/oat-zero \
  来自新加坡 Sea AI Lab 等机构的研究者再次梳理了类 R1-Zero 的训练过程，并在一篇博客中分享了三项重要发现： \
  1. 在类似 R1-Zero 的训练中，可能并不存在「顿悟时刻」。相反，我们发现「顿悟时刻」（如自我反思模式）出现在 epoch 0，即基础模型中。 \
  2. 他们从基础模型的响应中发现了肤浅的自我反思（SSR），在这种情况下，自我反思并不一定会导致正确的最终答案。 \
  3. 仔细研究通过 RL 进行的类 R1-Zero 的训练，发现响应长度增加的现象并不是因为出现了自我反思，而是 RL 优化设计良好的基于规则的奖励函数的结果。\
  整个 RL 过程是将原本肤浅的自我反思转变为有效的自我反思，以最大化预期奖励，从而提高推理能力
* 32.将集体学习引入树搜索，新方法CoMCTS实现o1-like的推理与反思  机器之心  https://mp.weixin.qq.com/s/zkCvrKM4z7ov94BlmuaV4w \
  最近，NLP 领域的突破，如 OpenAI o1，展示了 LLM 的推理能力并应对复杂语言任务的巨大潜力。这些进展的核心设计灵感源于类似 AlphaGo 的 “树搜索” 方法：通过使用 MCTS 等树搜索方法，自引导地构建中间思维树，探索有效的推理路径，并利用这些路径对模型进行训练，从而实现逐步推理能力的提升。 \
  本文提出了集体蒙特卡罗树搜索（Collective Monte Carlo Tree Search, CoMCTS），这是一种新的学习推理方法，通过将集体学习引入 “树搜索”，实现有效且高效的推理路径搜索与学习。\
  Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search \
  代码链接：https://github.com/HJYao00/Mulberry
* 33.DeepSeek用的GRPO占用大量内存？有人给出了些破解方法  机器之心  https://mp.weixin.qq.com/s/28GRpZwqv4gMnrmItMQchQ \
  原文链接：https://www.oxen.ai/blog/grpo-vram-requirements-for-the-gpu-poor \
  自 DeepSeek-R1 发布以来，群组相对策略优化（GRPO）因其有效性和易于训练而成为大型语言模型强化学习的热门话题。R1 论文展示了如何使用 GRPO 从遵循 LLM（DeepSeek-v3）的基本指令转变为推理模型（DeepSeek-R1）
* 34.微软官宣All in智能体，SWE Agent首曝光！奥特曼预警2025编程巨变  新智元  https://mp.weixin.qq.com/s/aKLnb2jOMUJ3QIV9r6R25Q 
* 35.千万不要尝试 Qwen2.5-Max，你会因此忘掉 DeepSeek V3  夕小瑶科技说  https://mp.weixin.qq.com/s/QenD-0elk1VWDgO8_7alUw
* 36.被DeepSeek带火的知识蒸馏，开山之作曾被NeurIPS拒收，Hinton坐镇都没用  量子位  https://mp.weixin.qq.com/s/Uw9rScSJfUqrQc0KFULjQg \
  Distilling the Knowledge in a Neural Network
* 37.深度解析 DeepSeek 的蒸馏技术  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/9_AS1VTQMhsEWLh5hxwSGw

# 2.8 Sat
* 38.DeepSeek-R1、o1都低于10%，人类给AI的「最后考试」来了，贡献者名单长达两页  机器之心  https://mp.weixin.qq.com/s/2JlZG-_8KP9nAisrYZKczw \
  Humanity’s Last Exam \
  项目地址：https://lastexam.ai
* 39.NAACL 2025 | 知识增强下的智能体规划  专知  https://mp.weixin.qq.com/s/F_auRKSg3qQnDggQ8-H6wg \
  KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents \
  智能体缺乏内置的动作知识，导致它们在任务解决过程中无法有效地指导规划轨迹，从而引发规划幻觉 \
  为了解决这一问题，我们提出了KnowAgent，旨在通过利用外部动作知识来增强轨迹合成，缓解其中出现的规划幻觉问题
* 40.多机器人系统的大型语言模型：综述  专知  https://mp.weixin.qq.com/s/wMIEanYPRgzLuP6pkAfq4w \
  Large Language Models for Multi-Robot Systems: A Survey
* 41.谷歌AI解决IMO中84%的几何问题，o1一道没做对！Nature：AI已超过金牌得主平均水平  量子位  https://mp.weixin.qq.com/s/w68oOOv80fIPwWwj2kegAg \
  DeepMind Al crushes tough mathsproblemson par with top human solvers \
  AlphaGeometry2
* 42.图像生成迎来CoT时刻！港中文首次提出文生图的o1推理和Inference Scaling新范式！  机器之心  https://mp.weixin.qq.com/s/CTpDAzzk5mcXtQrCpTJs1Q \
  Can We Generate Images with CoT? Let’s Verify and Reinforce Image Generation Step by Step 
* 43.吴恩达Agent新成果来了！  Datawhale  https://mp.weixin.qq.com/s/oWQ4A-FSiYOQ2hFNDrFxnA \
  Agentic Object Detection \
  在线试玩：https://va.landing.ai/demo/agentic-od

# 2.9 Sun
* 44.SFT并非必需！推理模型仅靠RL就能获得长思维链能力，清华CMU团队破解黑盒  量子位  https://mp.weixin.qq.com/s/5DIoA-R_PLAAvAATPXgbVg \
  Demystifying Long Chain-of-Thought Reasoning in LLMs \
  1.SFT并非必需，但能简化训练并提高效率； \
  2.推理能力随着训练计算的增加而出现，但并非总是如此； \
  3.可验证奖励函数对增长CoT至关重要； \
  4.纠错等核心能力基础模型天生自带，但通过RL有效地激励这些技能需要大量的计算。
* 45.大规模语言模型推理的进展综述  专知  https://mp.weixin.qq.com/s/oPoDUdWg1FydMnEyB91_uQ \
  Reasoning in LLMs: Dive deeper into working, techniques and approaches 
* 46.Sebastian Raschka：关于DeepSeek R1和推理模型，我有几点看法  机器之心  https://mp.weixin.qq.com/s/LT22OjbJWKDzTuQeO4yvlg \
  
* 47.(**值得实践**)DeepSeek-R1推理本地跑，7GB GPU体验啊哈时刻？GRPO内存暴降，GitHub超2万星  新智元  https://mp.weixin.qq.com/s/WayXEwbzAv00gd1uj-7jqg \
  开源项目Unsloth AI \
  现在可以在本地设备上复现DeepSeek-R1的推理！只需7GB VRAM，你就能体验到「Aha」时刻。Unsloth把GRPO训练需要的内存减少了80%。15GB VRAM就可以把Llama-3.1（8B）和Phi-4（14B）转变为推理模型。 \
  原文链接：https://unsloth.ai/blog/r1-reasoning \
  Train your own R1 reasoningmodel with Unsloth \
  项目链接：https://github.com/unslothai/unsloth \
  文档链接：https://docs.unsloth.ai/get-started/unsloth-notebooks
* 48.Sebastian Raschka：关于DeepSeek R1和推理模型，我有几点看法  机器之心  https://mp.weixin.qq.com/s/LT22OjbJWKDzTuQeO4yvlg \
  Understanding Reasoning LLMs: Methods and Strategies for Building and Refining Reasoning Models \
  原文地址：https://sebastianraschka.com/blog/2025/understanding-reasoning-llms.html \
  纯 RL: TinyZero \
  纯 SFT: Sky-T1 \
  O1 Replication Journey: A Strategic Progress Report – Part 1 \
  论文的核心思想是用「旅程学习」替代「捷径学习」。\
  捷径学习是指指令微调的传统方法，其中仅使用正确的解决方案路径来训练模型。 \
  另一方面，旅程学习也包括错误的解决路径，让模型从错误中学习。

# 2.10 Mon
* 49.MoE环游记：从几何意义出发  PaperWeekly  https://mp.weixin.qq.com/s/kUF4cy1QA_xQSyT5HtcKIA 
* 50.AAAI 2025 | 大模型会组合关系推理吗？打开黑盒，窥探Transformer脑回路  PaperWeekly  https://mp.weixin.qq.com/s/ndiNoWw-nbnf1xPY3IePyQ \
  Benchmarking and Understanding Compositional Relational Reasoning of LLMs
* 51.(**值得看看**)LLM实现自回归搜索！MIT哈佛等提出「行动思维链」COAT，推理能力大提升  新智元  https://mp.weixin.qq.com/s/wHU8m7rq2B3fIC5nA_mG6Q \
  Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search \
  https://github.com/satori-reasoning/Satori \
  来自MIT、新加坡科技设计大学、哈佛大学等机构的华人研究者探索了全新的方向：让LLM拥有自回归搜索能力。通过自我反思和探索新策略，提升LLM推理能力。研究者引入了行动-思维链（COAT）机制，使LLM在解决问题时能够执行多种元动作，并提出了一种创新的两阶段训练框架：小规模格式调优阶段：让LLM熟悉并掌握COAT推理格式。大规模自我优化阶段：运用重启与探索（RAE）技术，通过RL进行优化。\
  Satori具有以下核心特点：1.无需外部指导，即可自我反思与探索。2.主要依靠自我改进（RL），实现了最先进的推理性能。3.展现出强大的迁移能力，可应用于数学以外的领域。
* 52.AI意识更进一步！谷歌DeepMind等：LLM不仅能感受痛苦，还能趋利避害  新智元  https://mp.weixin.qq.com/s/ppseOPqKfxcD2IORDm-GxQ \
  Can LLMs make trade-offs involving stipulated pain and pleasure states?
* 53.人大刘勇团队「慢思考」机理分析：从雪球误差到正确推理概率  机器之心  https://mp.weixin.qq.com/s/SSBZucZgp9QknA901-x5ig \
  Rethinking External Slow-Thinking: From Snowball Errors to Probability of Correct Reasoning
* 54.北航推出TinyLLaVA-Video，有限计算资源优于部分7B模型，代码、模型、训练数据全开源  机器之心  https://mp.weixin.qq.com/s/e1zUm8dv445RjrDtedJh3Q \
  TinyLLaVA-Video: A Simple Framework of Small-scale Large Multimodal Models for Video Understanding \
  https://github.com/ZhangXJ199/TinyLLaVA-Video
* 55.(**值得看看**)具身物体表示学习与识别  CreateAMind  https://mp.weixin.qq.com/s/ohM4yq8RuFtGnsA8KV0pVg \
  Embodied Object Representation Learning and Recognition \
  涉及到《千脑智能》中的皮质柱网络
* 56.海马模型Hopfield网络的情境控制  CreateAMind  https://mp.weixin.qq.com/s/VUX4IFbbO0ZJGuZ0iaLIkg \
  Contextual Control of Hopfield Networks in a Hippocampal Model 
* 57.清华姚班校友等揭Transformer致命缺陷，OpenAI科学家紧急回应：学术界节奏太慢  新智元  https://mp.weixin.qq.com/s/c-FIYgcxQm4eH2d6lT4BBA \
  Transformer缺乏组合能力，由此导致LLM产生了幻觉 \
  如果一个大模型只有单层Transformer结构，总参数量小于域的大小，AI便无法解决组合任务 \
  模型规模增大后，确实能解决更具挑战性的问题。但要是同时扩大问题的规模，就算模型变得更大，解决起来照样棘手。这充分表明，Transformer架构存在着难以逾越的局限性

# 2.11 Tue
* 58.开源22万条DeepSeek R1的高质量数据！你也能复现DeepSeek了  机器之心  https://mp.weixin.qq.com/s/yIEisGrfguRkpjRnHmNYCg \
  项目地址：https://github.com/huggingface/open-r1 \
  数据集链接：https://huggingface.co/datasets/open-r1/OpenR1-Math-220k \
  这些数据可以用来支持更小的模型，来达到媲美 DeepSeek R1 的效果。比如在 OpenR1-Math-220k 数据集上训练出来的 Qwen-7B-Math-Instruct，达到了与 DeepSeek-Distill-Qwen-7B 相当的性能 \
  开源社区也从多个角度探索了 GRPO，有多个研究实验室表明，大约 1000 个高质量的训练样本可能就足以在现有的开源模型中引发推理能力
* 59.(**值得看看**)推理模型新路线开源！与DeepSeek截然不同，抛弃思维链不用人类语言思考 
 量子位  https://mp.weixin.qq.com/s/HK6fjolKDcHG6MD_cVgifg \
  开源推理大模型新架构来了，采用与Deepseek-R1/OpenAI o1截然不同的路线：抛弃长思维链和人类的语言，直接在连续的高维潜空间用隐藏状态推理，可自适应地花费更多计算来思考更长时间 \
  Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach \
  马里兰大学的一篇论文表明，通过使用循环语言模型，可以在潜在空间中隐式推理，从而在测试时扩展计算能力，这类似于 Meta 的 Coconut。这些方法的优势在于它们的计算效率更高：通过探索潜在空间，无需生成大量「思考」token 即可获得高性能 \
  新架构给Transformer加入循环模块，新架构仍然围绕Decoder-only的Transformer block构建，但分为三段： \
  1.Prelude（前奏）：使用多个transformer层将输入数据嵌入到潜空间中 \
  2.Recurrent Block（循环块）：循环计算单元，在潜在空间中修改状态 \
  3.Coda（尾声）：从潜空间解码，并包含模型的预测头
* 60.4500美元复刻DeepSeek神话，1.5B战胜o1-preview只用RL！训练细节全公开  新智元  https://mp.weixin.qq.com/s/g2PfdI8N1oU7RWU0owh75Q \
  UC伯克利团队只用简单的RL微调，就训出了DeepScaleR-1.5B-Preview，15亿参数模型直接吊打o1-preview \
  训练策略就是四个字——先短后长 \
  Deepseek-R1发现，直接在小型模型上用强化学习，效果不如知识蒸馏。在Qwen-32B模型上做对比实验，强化学习只能让AIME测试的准确率达到47％，但只用知识蒸馏就能达到72.6％。不过，要是从更大的模型中，通过蒸馏得到高质量的SFT数据，再用强化学习，小模型的推理能力也能大幅提升
* 61.AI已学会自我复制！复旦新研究：开源LLM克隆成功率最高90%  新智元  https://mp.weixin.qq.com/s/uWvY6RBp-pdUb7fqIt49mw \
  Frontier Al systems have surpassed the self-replicating red line \
  这些AI系统已有足够的自我感知、环境认知和解决问题能力，得以实现自我复制。它们还会利用这种能力逃避关闭指令，不断创建复制链以增强生存能力，这极有可能导致AI数量失控。一旦AI实现自我复制，这条成功复制的链条，可能催生出一种人类无法掌控的AI物种。它们会抢占更多计算设备，联合起来对抗人类

# 2.12 Wed
* 62.理解DeepSeek在MoE技术的演进过程和具体实现  大模型生态圈  https://mp.weixin.qq.com/s/DzDhfSiNp6GXdLt_snKvzg 
* 64.DeepSeek并非完美，训练过程存在“深度诅咒”  AIGC开放社区  https://mp.weixin.qq.com/s/vuMzQzT4jPXykLA1239GDg \
  移除模型的深层对性能的影响微乎其微，而移除浅层性能会明显下降。这表明DeepSeek模型的深层在训练过程中未能有效学习到有用的特征，而浅层则承担了大部分的特征提取任务。这种现象称为“深度诅咒”（Curse of Depth），同时研究人员也提出了一种有效的解决方法——LayerNorm Scaling（层归一化缩放） \
  The Curse of Depth in Large Language Models
* 65.推理成本比MoE直降83%！字节最新大模型架构入围ICLR 2025  量子位  https://mp.weixin.qq.com/s/4kxHv_WR8t63yB4x4rRQhg \
  ULTRA-SPARSE MEMORY NETWORK \
  这个全新的稀疏模型架构叫做UltraMem，有效地解决了目前主流的MoE架构和PKM架构所存在的局限性 \
  推理速度相比MoE架构提升2-6倍，推理成本最高可降低83%
* 66.DeepSeek模型综述：V1 V2 V3 R1-Zero  专知  https://mp.weixin.qq.com/s/gNBG108v4_9WChB7A31Hlg 
* 67.8卡32B模型超越o1预览版、DeepSeek V3，普林斯顿、北大提出层次化RL推理新范式  机器之心  https://mp.weixin.qq.com/s/Vqif83WcgUpFrCJMHYxGmA \
  8块A100，32B碾压DeepSeek V3、o1-preview！普林斯顿北大首提分层RL推理 
 新智元  https://mp.weixin.qq.com/s/bSaIzvvg7UJkP0XNOK2uzA \
  8卡32B模型超越o1预览版、DeepSeek V3，普林斯顿、北大提出层次化RL推理新范式  PaperWeekly  https://mp.weixin.qq.com/s/Suihdv_BLkF_HK_l34gawQ \
  ReasonFlux: 多层次（Hierarchical）LLM 推理框架 \
  ReasonFlux: Hierarchical LM Reasoning via Scaling Thought Templates \
  开源地址：https://github.com/Gen-Verse/ReasonFlux
* 68.啊？7B的DeepSeek反超R1满血版，上海AI Lab周伯文团队新成果：计算最优的Test-Time Scaling  量子位  https://mp.weixin.qq.com/s/BUBp2TShir9MRd6iVtFSfw \
  1B 参数的语言模型能否超越 405B 参数的语言模型？重新思考计算最优的测试时扩展  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/Ok5MLb0IIGy6_0HFIfvBTg \
  清华一作1B暴打405B巨无霸，7B逆袭DeepSeek R1！测试时Scaling封神  新智元  https://mp.weixin.qq.com/s/ygv_CIcVJcRsgr98fdKc_g \
  Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling \
  来自清华、哈工大、北邮等机构的研究人员发现，使用**计算最优TTS策略**，极小的策略模型也可以超越更大的模型 \
  TTS是增强LLM推理能力的一种极有前途的方法 \
  模型越强，对 PRM, TTS 所需要的依赖就越少 \
* 69.生物人工智能——从具身认知到具身机器人学  CreateAMind  https://mp.weixin.qq.com/s/ofoF108tk6yRqAe10iE2sg \
  Bio A.I. - from embodied cognition to enactive robotics
* 70.4090单卡跑满血版DeepSeek-R1，清华团队开源项目再破大模型推理门槛  量子位  https://mp.weixin.qq.com/s/UjsaPDeCfW8QUYTCUZmVxA \
  KTransformers开源项目 \
  GitHub 地址：https://github.com/kvcache-ai/ktransformers \
  具体技术细节指路：https://zhuanlan.zhihu.com/p/714877271
* 71.超越思维链？深度循环隐式推理引爆AI圈，LLM扩展有了新维度  机器之心  https://mp.weixin.qq.com/s/WGszi-BKl50jQj8j7X0PYQ \
  Scaling up Test-Time Compute with Latent Reasoning:A Recurrent Depth Approach \
  模型下载: https://huggingface.co/tomg-group-umd/huginn-0125 \
  代码链接: https://github.com/seal-rg/recurrent-pretraining \
  ???什么是深度循环隐式推理
* 72.o3拿下IOI 2024金牌！新论文公布RL秘诀：AI自己设计测试时推理策略，无需人类干预  量子位  https://mp.weixin.qq.com/s/7WV67GcOh2oTJhBQF9zP6Q \
  o3的表现，证明了通过大规模端到端RL（强化学习），无需依赖人工设计的测试时推理策略，就能自己学会先写暴力求解代码提高效率，再用其他方法交叉验证的策略 \
  Competitive Programming with Large Reasoning Model
* 73.(**有趣**)被AI追杀，还要解谜逃生！UCSD等发布LLM测试神器，边玩游戏边评估  新智元  https://mp.weixin.qq.com/s/-R6NBJGhnxDamrVM2WaDdA \
  GAMEARENA: EVALUATING LLM REASONING THROUGH LIVE COMPUTER GAMES \
  项目地址：https://lmgame.org/
* 74.Cell子刊《Patterns》最新综述：大语言模型Attention Heads的可解释性研究  PaperWeekly  https://mp.weixin.qq.com/s/88LG1RSoPIdfo8Lc3tuWNg \
  Attention Heads of Large Language Models \
  在 Transformer 结构中，注意力头是其推理能力的关键组件，它通过选择性地关注输入序列中的相关部分，从而实现上下文理解。然而，不同注意力头在推理中的具体功能与协作方式尚不明确。深入研究注意力头不仅有助于揭示大模型的内部逻辑，还为大模型的可解释性研究提供了理论基础 \
  该综述创新性地提出了一个认知框架用于描述人类大脑解决特定问题的过程。该框架将人脑的推理过程分为知识召回（Knowledge Recalling）、上下文识别（In-Context Identification）、潜在推理（Latent Reasoning）以及表达准备（Expression Preparation）四个阶段 \
  借助提出的认知框架，该综述首次将认知神经科学的原理融入大模型可解释性研究中，清晰定义了不同注意力头在推理过程中的具体功能。例如，某些注意力头专注于跨句子的上下文对齐，另一些则负责增强模型的记忆能力，还有一些承担了核心的推理工作。
* 75.什么是自指 | 集智百科  集智俱乐部  https://mp.weixin.qq.com/s/fQqJ106erMfuW2VbMhlIYA
* 76.大模型向通用意识机器进化的关键——自指的启示  集智俱乐部  https://mp.weixin.qq.com/s/jBZwi83nLjU68HlPb0u1qQ 
* 77.用大模型可以实现完美自指吗？  集智俱乐部  https://mp.weixin.qq.com/s/fFVqK3j6kSL3yw_QTO0o9A 
* 78.UC伯克利 | Deepseek训练复现：1.5B模型也能超越o1预览版，代码数据全开源！  AINLPer  https://mp.weixin.qq.com/s/2CG9KSQcJJLJ2NmHVd49lw \
  DeepScaleR-1.5B-Preview，基于 Deepseek-R1-Distilled-Qwen-1.5B 模型，通过强化学习（RL）微调，实现了惊人的 43.1% Pass@1 准确率，提升了 14.3%，并在 AIME 2024 竞赛中超越了 O1-Preview \
  这一成果不仅打破了 “大模型才能强大” 的固有认知，更展示了 RL 在小型模型中的无限可能 \
  博客地址：https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2 \
  项目地址：https://github.com/agentica-project/deepscaler \
  项目网站：https://agentica-project.com/Hugging Face \
  模型：https://huggingface.co/agentica-org/DeepScaleR-1.5B-PreviewHugging Face \
  数据集：https://huggingface.co/datasets/agentica-org/DeepScaleR-Preview-DatasetWandb \
  训练日志：https://wandb.ai/mluo/deepscaler-1.5b?nw=nwusermluo

# 2.13 Thur
* 79.最 Deep 的 Seek：AI 的“终极设计图”是什么样子？  图灵人工智能  https://mp.weixin.qq.com/s/AqnuUDPk2IleoYvkSnDCKg \
  元胞自动机涌现出智能？
* 80.0.5B小模型逆袭！不到50元，「X-R1」让每个人都能复现Aha Moment 
 PaperWeekly  https://mp.weixin.qq.com/s/Lv0mEpS1e9Eh2BVH97TsrA \
  X-R1开源仓库：https://github.com/dhcode-cpp/X-R1 \
  项目的代码基础为 open-r1 ，由于官方例子需要 8x80G显卡，我们探索了一条更易训练的方案 \
  4x3090/4090 GPUs 训练总时间2小时以内,在第10分钟的 37步优化中输出了“aha Moment“
* 81.DeepSeek R1不编程就能生成GPU内核，比熟练工程师好，惊到了英伟达  机器之心  https://mp.weixin.qq.com/s/8GE8xqY-7V3c4LFU4fcT2Q \
  英伟达却在尝试用 DeepSeek 给大模型 pipeline 本身搞自动化 \
  英伟达在博客中介绍了利用 DeepSeek-R1 和推理时扩展技术来自动生成优化 GPU 内核的最新研究成果，效果异常的好 \
  Automating GPU Kernel Generation with DeepSeek-Rl and Inference Time Scaling
* 82.【博士论文】《认知与视觉神经科学中的循环神经网络》  专知  https://mp.weixin.qq.com/s/VRBc72MhwKwIMG-FYDV6Ww \
  Recurrent neural networks in cognitive and vision neuroscience
* 83.哥德尔-Prover超过DeepSeek-Prover，金驰、陈丹琦团队造出当前最强形式化推理模型  机器之心  https://mp.weixin.qq.com/s/IfYQdMyZ7FBEJCXNCTpZtQ \
  最近一段时间，以 DeepSeek-R1 为代表的大型推理模型可谓是「当红炸子鸡」，不过整体来说，这些模型所做的推理都属于非形式化推理（informal reasoning）。也就是说，它们主要是通过自然语言执行推理。\
  但是，这种推理模式有个缺点：难以通过机器来自动验证。也因此，非形式化推理在实际应用中的可靠性就大打折扣了。这还会让研究者更加难以进一步对推理模型进行改进。 \
  解决方案也很直观：形式化推理（formal reasoning） \
  一个用于自动定理证明的形式化推理模型 Goedel-Prover（哥德尔证明器），并且该模型在数学问题的自动形式化证明生成任务上达到了 SOTA \
  Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving \
  项目地址：https://github.com/Goedel-LM/Goedel-Prover \
  Hugging Face：https://huggingface.co/Goedel-LM/Goedel-Prover-SFT \
  形式化推理: 以机器可验证的格式进行推理
  非形式化推理：自然语言推理
* 84.直逼DeepSeek-R1-32B，碾压李飞飞s1！UC伯克利等开源全新SOTA推理模型  新智元  https://mp.weixin.qq.com/s/4j6eLEJY2K9MpFsNqEVFHg \
  斯坦福、UC伯克利等多机构联手发布了开源推理新SOTA——OpenThinker-32B，性能直逼DeepSeek-R1-32B。其成功秘诀在于数据规模化、严格验证和模型扩展 \
  项目主页：https://www.open-thoughts.ai/blog/scale \
  Hugging Face：https://huggingface.co/open-thoughts/OpenThinker-32B \
  数据集：https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k

# 2.14 Fri
* 85.李飞飞看中的万亿赛道，中国首个自研空间智能AI登场！单张图即生3D世界  新智元  https://mp.weixin.qq.com/s/oXdNdVz27LaPA5dPYZBOrg \
  昆仑万维正式发布了一款全新自研的Matrix-Zero世界模型 \
  两部分功能：1.支持将用户输入的图片转化为可自由探索的真实合理的3D场景；2.支持根据用户输入实时生成互动视频效果。
* 86.Anthropic秘密「混合模型」 Claude 4首曝细节，硬刚GPT-5！深度推理模型来了  新智元  https://mp.weixin.qq.com/s/KrzjCv5zlzH0nP22Ry5irQ 
* 87.谷歌最新论文，生成式AI 是否有“意识”？  探索AGI  https://mp.weixin.qq.com/s/nHgkvPnLXWMkgJrQiQCJvw \
  Agency Is Frame-Dependent \
  如何判断一个系统是否具有主观能动性呢？论文中提出了四个维度: \
  1.这个系统要有明确的边界，能够区分自己和环境; \
  2.它的行为应该来源于自身，而不是完全被外界推动; \
  3.它要有明确的目标导向; \
  4.它能够根据环境变化调整自己的行为

# 2.15 Sat
* 88.苹果牛津发现「蒸馏Scaling Law」！必须满足两个条件，蒸馏才有优势  新智元  https://mp.weixin.qq.com/s/f_5tx8ysXf43kBS_r_ufqw \
  Distilling the Knowledge in a Neural Network \
  仅当满足以下两个条件时，蒸馏才比监督学习更具优势： \
  1. 用于蒸馏的总计算量或token数量不超过与学生规模相关的阈值。 \
  2. 已经存在教师模型，或者要训练的教师模型具有除单次蒸馏之外的用途。
* 89.从想太多到想不透？DeepSeek-R1等长推理模型也存在「思考不足」问题  机器之心  https://mp.weixin.qq.com/s/LbyHxCbtyYsOelwu6bzs2w \
  Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs \
  长推理模型在面对简单问题时，其思考行为会出现大量重复，从而浪费大量计算资源 \
  长推理模型在推理过程中往往频繁地进行思路跳转，无法将注意力集中在一个正确的思路上并深入思考，从而得到正确答案 \
  在处理难题时，长推理模型也存在 “注意力缺陷多动障碍” 的问题。研究团队将这种现象命名为 “思考不足”（Underthinking），即长推理模型在推理过程中频繁地进行思路跳转，无法将注意力集中在一个正确的思路上并深入思考，从而得到正确答案
* 90.博弈论与大语言模型的结合：系统性综述  专知  https://mp.weixin.qq.com/s/ZZvONmaZnUD8mo0Qp6iaQQ \
  Game Theory Meets Large Language Models: A Systematic Survey
* 91.炒菜、雕刻、绘画、汽车人变形！MakeAnything用扩散Transformer解锁多任务过程生成  机器之心  https://mp.weixin.qq.com/s/xzOxHNeSWaFeOP9H8DNLtQ \
  MakeAnything: Harnessing Diffusion Transformers for Multi-Domain Procedural Sequence Generation \
  GitHub: https://github.com/showlab/MakeAnything
* 92.又一个Deep Research来了！1-2分钟抵人类专家数小时，所有人免费  机器之心  https://mp.weixin.qq.com/s/DuX3U8cFEbaDgh8RISFQbg \
  Perplexity Deep Research 网页版

# 2.16 Sun
* 93.赶紧放弃强化学习？！图灵奖得主、Meta 首席 AI 科学家杨立昆喊话：当前推理方式会“作弊”，卷大模型没有意义！  图灵人工智能  https://mp.weixin.qq.com/s/34RZEOD5NdMSJaFBN-C1oA 
* 94.不蒸馏R1也能超越DeepSeek，上海 AI Lab 用RL突破数学推理极限  量子位  https://mp.weixin.qq.com/s/o6csP1xSdg6gISXVmrnNcw \
  Exploring the Limit of Outcome Rewardfor Learning Mathematical Reasoning \
  上海AI Lab提出了基于结果奖励的强化学习新范式——从Qwen2.5-32B-Base模型出发，仅通过微调和基于结果反馈的强化学习，在不蒸馏超大模型如DeepSeek-R1的情况下，就能超越DeepSeek-R1-Distill-Qwen32B和OpenAI-O1系列的超强数学推理性能 \
  项目链接：https://github.com/InternLM/OREAL \
  RL 训练数据链接：https://huggingface.co/datasets/internlm/OREAL-RL-Prompts \
  系列模型地址：https://huggingface.co/collections/internlm/oreal-67aaccf5a8192c1ba3cff018
* 95.学习即编程  CreateAMind  https://mp.weixin.qq.com/s/gZcRcGHkYHJeFRa8wNWs3A \
  Human spatiotemporal pattern learningas probabilistic program synthesis \
  人类能够从小量数据中学习各种结构化模式，从偏差-方差权衡的角度来看，这提出了一个难题：什么样的表示和算法能够支持人类学习的灵活性与数据稀缺性？一种可能性是人类通过“编程学习”：诱导概率模型以拟合观测数据。在此，我们通过一个实验测试人类在二维结构化模式领域的学习能力，实验中参与者根据点的先前轨迹反复预测其移动位置。我们将人类表现与标准的参数化和非参数化时间序列模型进行比较，同时还评估了两种贝叶斯程序合成模型，这些模型的假设在结构程度上有所不同：一种是组合高斯过程模型，另一种是结构化的“思维语言”（Language of Thought，LoT）模型。我们发现，人类模式学习的特征最好由LoT模型解释，这支持了人类结构学习的灵活性和数据效率可以通过在富有表现力的程序空间中进行概率推理来理解的观点

# 2.17 Mon
* 96.比知识蒸馏好用，田渊栋等提出连续概念混合，再度革新Transformer预训练框架  图灵人工智能  https://mp.weixin.qq.com/s/ZkM-0Smgg-q27F-uoPp6LQ \
  LLM Pretraining with Continuous Concepts \
  来自 Meta 等机构的研究者提出了一种新颖且高效的预训练框架：连续概念混合（Continuous Concept Mixing, CoCoMix），其将离散的下一个 token 预测与连续概念相结合 \
  ???什么是连续概念 \
  https://github.com/facebookresearch/RAM/tree/main/projects/cocomix
* 97.如何提升大模型通用推理能力？DeepSeek最新论文《CODEI/O：通过代码输入输出预测凝练推理模式》  专知  https://mp.weixin.qq.com/s/GBjJItoPNZYLJnIPcOUlOQ \
  DeepSeek团队新作：把代码变成思维链，大模型推理各种能力全面提升  量子位  https://mp.weixin.qq.com/s/2Xb8hdrZe0JcLjBdKfktkQ \
  LLM推理暴涨，数学逻辑开挂！ DeepSeek等华人团队新大招，Ai2大牛狂点赞  新智元  https://mp.weixin.qq.com/s/XeDrS94fGifOF5mY1clD0A \
  CoDEI/0: Condensing Reasoning Patterns via Code Input-Output Prediction \
  https://github.com/hkust-nlp/CodeIO \
  数据集：https://huggingface.co/datasets/hkust-nlp/CodeIO-PyEdu-Reasoning \
  CODEI/O通过将代码转换为输入/输出预测格式，从而系统性地提炼出蕴含在代码上下文中的多种推理模式。研究团队提出将原始代码文件转换成可执行的函数，并设计一个更直接的任务：给定一个函数及其相应的文本查询，模型需要以自然语言的CoT推理形式预测给定输入的执行输出或给定输出的可行输入。这种方法将核心推理流程从代码特定的语法中解脱出来，同时保留逻辑的严谨性。通过收集和转换来自不同来源的函数，生成的数据包含了各种基础推理技能，如逻辑流程编排、状态空间探索、递归分解和决策 \
  实验结果表明，CODEI/O在符号推理、科学推理、逻辑推理、数学与数值推理以及常识推理任务上均实现了持续的性能提升 \
  CODEI/O的有效性在于选择多样化的原始代码来源，以涵盖广泛的推理模式
* 98.迈向意识的（元）数学理论：体验的普遍（映射）属性  CreateAMind  https://mp.weixin.qq.com/s/M9V7-BJZGO4xZ0cfFbkDAg \
  Towards a (meta-)mathematical theory of consciousness:universal (mapping) properties of experience
* 99.语言模型新范式：首个8B扩散大语言模型LLaDA发布，性能比肩LLaMA 3  机器之心  https://mp.weixin.qq.com/s/V7lM0Z44X7k5yHoBW7o2OQ \
  嚯！大语言扩散模型来了，何必只预测下一个token | 人大高瓴&蚂蚁  量子位  https://mp.weixin.qq.com/s/ipXMp7QxP-CtteHGwboqNA \
  扩散语言模型 LLaDA 首次展示了通过前向掩码加噪与反向去噪机制，同样可以实现大语言模型的核心能力。实验表明，LLaDA 在可扩展性、上下文学习和指令遵循等方面表现优异，具备与传统自回归模型相媲美甚至更优的性能，同时其双向生成与增强的鲁棒性有效突破了自回归建模的固有限制，从而挑战了「大语言模型的智能必然依赖自回归生成」的传统观念 \
  Large Language Diffusion Models
* 100.DeepSeek加持，北大通院几何模型达IMO金牌水平！32个CPU核心和1块4090就能实现满血解题  量子位  https://mp.weixin.qq.com/s/eswmr-dcYx_oeYrKJwX0qQ \
  TongGeometry 北京通用人工智能研究院 \
  Proposing and solving olympiad geometry with guided tree search \
  相比较AlphaGeometry1/2，TongGeometry有如下改进： \
  摒弃算数推理（AR），仅仅使用归纳数据库方法（DD） \
  严格构造对称图形，确保几何图形上的优美性 \
  使用马尔可夫链构造树形状搜索结构，并使用人类数据启发数据生成树的搜索方向 \
  利用策略网络（Policy）和价值网络（Value）联合Beam Search进行解题
* 101.玩转 DeepSeek-R1 本地部署+知识库搭建+多轮RAG，保姆级教程！  OpenBMB  https://mp.weixin.qq.com/s/vfIOKuHm-BNMaXhnYSVapw \
  利用UltraRAG 框架  https://github.com/OpenBMB/UltraRAG \
  需要A100-80G显卡
* 102.从Policy Gradient到REINFORCE++，万字长文梳理强化学习最新进展 
 PaperWeekly  https://mp.weixin.qq.com/s/mGlObqTANspHGkujzCmY5A 

# 2.18 Tue
* 103.这届出题太难了！新基准让多模态模型集体自闭，GPT-4o都是零分  机器之心  https://mp.weixin.qq.com/s/XB2UrbU8l4_O8BGWNTxyHg \
  ZeroBench
* 104.思维语言假说 The language of thought hypothesis [HTML] 
 CreateAMind  https://mp.weixin.qq.com/s/PVImWv_DPcBjRM-uu2HAJg \
  The Language of Thought Hypothesis \
  原文链接：https://plato.stanford.edu/entries/language-thought/ \
  语言思维假说（LOTH）认为，思维是通过一种心智语言进行的。这种心智语言通常被称为“思维语”（Mentalese），它在几个关键方面与口语相似：它包含可以组合成句子的词汇；这些词汇和句子都有意义；每个句子的意义以一种系统的方式依赖于其组成词汇的意义以及这些词汇的组合方式。例如，存在一个表示“鲸鱼”的思维语词汇，它指代鲸鱼；还有一个表示“哺乳动物”的思维语词汇，它指代哺乳动物。这些词汇可以组合成一个思维语句子“鲸鱼是哺乳动物”，其意思是“鲸鱼是哺乳动物”。相信“鲸鱼是哺乳动物”就是与这个句子建立适当的心理关系。在进行一个典型的演绎推理时，我可能会将思维语句子“鲸鱼是哺乳动物”和“莫比·迪克是一条鲸鱼”转化为“莫比·迪克是哺乳动物”。在执行推理的过程中，我进入了一系列体现这些句子的心理状态
* 105. 200多行代码，超低成本复现DeepSeek R1「Aha Moment」！复旦大学开源  机器之心  https://mp.weixin.qq.com/s/hFArGyWTRTkQIMeStg279w \
  Simple-GRPO \
  https://github.com/lsdefine/simple_GRPO
* 106.强化学习Scaling Law错了？无需蒸馏，数据量只要1/6，效果还更好  新智元  https://mp.weixin.qq.com/s/wgSmwRxwnNXon55Wl5rkcQ \
  大模型强化学习新发现：删减84%数据反提升效果  机器之心  https://mp.weixin.qq.com/s/XYL4QyeHqR7v_xhs_Z_Jwg \
  LIMR: Less is More for RL Scaling \
  https://github.com/GAIR-NLP/LIMR
* 107.马斯克20万块GPU炼出Grok-3，暴击DeepSeek R1数学屠榜！疯狂复仇OpenAI  新智元  https://mp.weixin.qq.com/s/YDjin48P-qsxPv48mpCbtg 
* 108.微软开放3.1T token高质量数据！通用/代码/数学/问答，全领域超越开源  新智元  https://mp.weixin.qq.com/s/4NVBVRTuk8azQbD5SDi92Q \
  https://github.com/microsoft/RedStone
* 109.范畴论视角下的语言思维（Language of Thought）  CreateAMind  https://mp.weixin.qq.com/s/Or32-uc8MjUSxievgnD_dA \
  A category theory perspective on the Language of Thought: LoT is universal
* 110.多模态检索增强生成的综合综述  专知  https://mp.weixin.qq.com/s/k1WijJZxyvPbILvUIw10fw \
  Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation
* 111.(**值得看看**)聊聊Reasoning Model的精巧实现（ReFT, Kimi K1.5, DeepSeek R1） 
 吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/UQ1CZPSHlHdcpt_1P27IPg \
  Reasoning Model的早期猜想: PRM和MCTS \
  PRM和MCTS的方法理论上都有自身的优势。对于复杂的推理过程，PRM可以按步骤做细粒度的监督，MCTS可以自动探索解空间。两者配合可以在探索（Exploration）和利用（Exploitation）上做平衡，以提升复杂问题的推理能力 \
  PRM和MCTS方法，都会引入模型训练和推理的复杂性。在实际的复现Reasoning Model工作中，大家并没有应用这些技术，而是不约而同的选择了更轻量、更直接的方案 \
  Reasoning Model三篇有价值的工作: 字节ReFT、kimi K1.5 、deepseek R1，都是在卷RL \
  通过设定清晰的目标，减少过多的人为设定，基于RL端到端的自驱探索能力上限
* 112.太震撼了！梁文锋携DeepSeek团队丢出注意力新机制重磅论文，网友：这才是真正的OpenAI  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/mEU_rZkRnHttN7XhUOUspQ \
  原生稀疏注意力（Native Sparse Attention, NSA），有望大幅提升下一代大语言模型处理长文本的能力，同时还能兼顾效率 \
  Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention
* 113.人类心智理论的起源 The origin of human Theory-of-Mind 
 CreateAMind  https://mp.weixin.qq.com/s/NHNKoX_g2GaB6zWqJc1DDw 
* 114.DeepSeek V3+R1满血微调工具上线！一键启动，硬件要求降10倍  机器之心  https://mp.weixin.qq.com/s/ywJAbcjXPef1RazHj1HIjg \
  4w Star！一个低成本微调DeepSeek的开源方案，悄悄火了  夕小瑶科技说  https://mp.weixin.qq.com/s/9gW6SP2Jnk9_WJxRAn8VWQ \
  https://github.com/hpcaitech/ColossalAI
* 115.撞车DeepSeek NSA，Kimi杨植麟署名的新注意力架构MoBA发布，代码也公开  机器之心  https://mp.weixin.qq.com/s/okrYBqSRxUrXQiHjo-nlYA \
  提出了一种名为 MoBA 的注意力机制，即 Mixture of Block Attention，可以直译为「块注意力混合」。据介绍，MoBA 是「一种将混合专家（MoE）原理应用于注意力机制的创新方法。」该方法遵循「更少结构」原则，并不会引入预定义的偏见，而是让模型自主决定关注哪些位置 \
  MoBA: Mixture of Block Attention for Long-Context LLMs \
  论文地址：https://github.com/MoonshotAI/MoBA/blob/master/MoBA_Tech_Report.pdf \
  项目地址：https://github.com/MoonshotAI/MoBA

# 2.19 Wed
* 116.OpenAI：强化学习确实可显著提高LLM性能，DeepSeek R1、Kimi k1.5发现o1的秘密  机器之心  https://mp.weixin.qq.com/s/jh5L5MV6jU8W6coFH7jsAg \
  Competitive Programming with Large Reasoning Models \
  将强化学习应用于大型语言模型（LLM）可显著提高在复杂编程和推理任务上的性能 \
  这种策略不仅适用于编程，它还是通往 AGI 及更远未来的最清晰路径 \
  这篇论文不仅仅是展示了 AI 编程的新成绩，更是给出了一份创造世界最佳 AI 程序员乃至 AGI 的蓝图。正如 OpenAI 在论文中写到的那样：「这些结果表明，扩展通用强化学习，而不是依赖特定领域的技术，能为在推理领域（例如竞技编程）实现 SOTA AI 提供一条稳健的路径 \
  DeepSeek-R1 的突破来自于「可验证奖励的强化学习」，而这其实也是 AlphaGo 使用的方法 —— 让模型在试错中学习，然后无限地扩展智能
* 117.DeepSeek R1 最新全面综述，近两个月的深度思考！  Datawhale  https://mp.weixin.qq.com/s/aZky-d9733mhbAAS24n6zg \
  分享PPT：https://github.com/datawhalechina/hugging-llm/tree/main/resources
* 118.让机器人像人类一样终身学习，突破性框架LEGION登Nat. Mach. Intell.  集智俱乐部  https://mp.weixin.qq.com/s/W22BkhXV52OQGxMaYe_NBQ \
  Preserving and combining knowledge in robotic lifelong reinforcement learning \
  LEGION通过贝叶斯非参数知识空间与语言嵌入技术，让机器人实现终身强化学习，甚至能像人类一样重组旧技能解决复杂新任务

# 2.20 Thur
* 119.20年磨一剑！微软发布全球首个拓扑量子芯片，一夜改变半导体 
 AIGC开放社区  https://mp.weixin.qq.com/s/95mgZhgrVJ_IULbGl0Rk-A \
  微软20年精炼，全球首个拓扑量子芯片出炉！巴掌大芯片碾压全球超算  新智元  https://mp.weixin.qq.com/s/Xxjowh9lxv-qwlxbJDxI1w \
  微软发布了全球首个基于拓扑架构的量子芯片Majorana 1，这是一种超越固态、液态和气态的全新物质，彻底改变量子计算半导体产业
* 120.LangMem 发布：任何人都能轻松构建智能体记忆！  AI小智  https://mp.weixin.qq.com/s/xG60BKuB9RhWfyISVESeyQ \
  LangMem SDK - LangChain系列下的记忆框架
* 121.当脑启发人工智能遇上通用人工智能  CreateAMind  https://mp.weixin.qq.com/s/wmKG_eML0ewBzoAJcfnHiQ \
  When Brain-inspired AI Meets AGI
* 122.脑启发计算的基础软件综述  CreateAMind  https://mp.weixin.qq.com/s/uDg2Chw6M-4HOXZctc9hRg \
  A review of basic software for brain‑inspired computing
* 123.图解DeepSeek-R1的创新训练和推理模型实现原理  图灵人工智能  https://mp.weixin.qq.com/s/qObIiCUKcgKxz9IwO66UYQ \
  原文地址：https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1
* 124.简单示例提升DeepSeek-R1美国数学邀请赛AIME分数：以步骤为粒度对齐上下文学习与推理  量子位  https://mp.weixin.qq.com/s/MGamLwtxLpYJ-KAN-hVZlg \
  BoostStep: Boosting mathematical capability of Large Language Models via improved single-step reasoning \
  https://github.com/beichenzbc/BoostStep 
* 125.(**重要**)物理直觉不再是人类专属？LeCun等新研究揭示AI可如何涌现出此能力  机器之心  https://mp.weixin.qq.com/s/6CmUsrbQxbXKytII3dvp8Q \
  在近期的一次演讲中，LeCun将自己的观点总结成了「四个放弃」：放弃生成式模型、放弃概率模型、放弃对比方法、放弃强化学习。他给出的研究方向建议则是联合嵌入架构、基于能量的模型、正则化方法与模型预测式控制。他还表示：「如果你感兴趣的是人类水平的 AI，那就不要研究 LLM。」 \
  近日，Yann LeCun 团队又发布了一项新研究。他们发现，只需在自然视频上进行自监督预训练，对物理规则的直觉理解就会涌现出来。似乎就像驴一样，通过观察世界，就能直觉地找到最轻松省力的负重登山方法 \
  Intuitive physics understanding emerges from self-supervised pretraining on natural videos \
  项目地址：https://github.com/facebookresearch/jepa-intuitive-physics
* 126.概率电路的可扩展学习  CreateAMind  https://mp.weixin.qq.com/s/6_TBRWsCaCvIiyeDX1w1Mg \
  什么是概率电路？ \
  什么是可扩展学习？ 
* 127.谷歌豪华阵容打造AI科学家，用测试时间计算加速科学发现，CEO皮猜也来站台了  量子位  https://mp.weixin.qq.com/s/--IS99Np8SelEdsZVNOJvg \
  AI co-scientist，一个能够利用高级推理综合大量文献、生成新颖假设，并提出详细研究计划的多智能体AI系统。该系统将与OpenAI o1/DeepSeek-R1相似的测试时间计算用来加速科学发现
* 128.重磅发现！DeepSeek R1方法成功迁移到视觉领域，多模态AI迎来新突破！  机器之心  https://mp.weixin.qq.com/s/TZHdZ2H_-dkjzODr1dxjrw \
  VLM-R1 \
  VLM-R1 团队直接把GRPO应用到了视觉语言模型上
* 129.世界首个「AI CUDA工程师」诞生！AI自己写代码优化CUDA内核，性能狂飙100倍  新智元  https://mp.weixin.qq.com/s/10WcoPyp8ZNSLSuiGoqboQ \
  The AI CUDA Engineer: Agentic CUDA Kernel Discovery, Optimization and Composition \
  项目主页：https://pub.sakana.ai/ai-cuda-engineer
* 130.(**WHAM**)微软Muse秒生游戏登Nature，10亿级画面练出最强AI！千亿游戏市场重洗牌  新智元  https://mp.weixin.qq.com/s/aHrXr1mvngWSd4Szh_0UGw \
  World and Human Action Models towards gameplay ideation \
  微软团队首次引入了「世界与人类行动模型」（WHAM），并冠以希腊艺术女神「缪斯」（Muse）之名 \
  项目链接：https://huggingface.co/microsoft/wham
* 131.再次颠覆学界想象，何恺明发表新作：扩散模型不一定需要噪声条件  机器之心  https://mp.weixin.qq.com/s/J93KJ-IVbKOKcqsOv8SFBw \
  Is Noise Conditioning Necessary for Denoising Generative Models?
* 132.大脑如何将复杂信息“压缩”成简洁地图？Sci. Adv. 揭示果蝇嗅觉回路工作奥秘  集智俱乐部  https://mp.weixin.qq.com/s/9ZzZQqMgWg_W3Pf4Dw4qkw \
  A biological model of nonlinear dimensionality reduction \
  这项研究首次证明，**简单生物网络可通过局部学习规则实现复杂降维**，其意义不仅在于为机器学习提供新算法，更揭示了大脑高效处理信息的本质——**通过层级稀疏编码与全局调质信号的协同**，将高维世界压缩为可操作的认知地图。或许未来AI的“泛化能力”提升，正藏在果蝇微小的蘑菇体中 \
  什么是局部学习规则？ \
  什么是层级稀疏编码？ \
  什么是全局调质信号？
* 133.DeepSeek背后的技术基石：DeepSeekMoE基于专家混合系统的大规模语言模型架构  机器学习研究组订阅  https://mp.weixin.qq.com/s/3cN2ojKC_-v7gitSkDKHFw \
  DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models \
  DeepSeekMoE通过创新的混合专家架构、潜在注意力缓存和优化的归一化策略，在模型规模与计算效率之间找到了新的平衡点。其在降低计算成本的同时保持了领先的性能水平，为大规模AI系统的可持续发展提供了新的思路。后续研究将探索该架构在多模态任务中的应用，以及路由算法的进一步优化

# 2.21 Fri
* 134.知识蒸馏：由诺奖得主Hinton提出，9年后被DeepSeek带火，究竟是什么？  图灵人工智能  https://mp.weixin.qq.com/s/WSf09wWF59tOVVCK6D7rUA \
  软目标蒸馏 \
  中间层蒸馏 \
  对抗性知识蒸馏 \
  R1的蒸馏是输出结果蒸馏，其中包含了教师模型的思维链推理过程，比没有经过蒸馏的同参数模型更加聪明 \
  R1仅靠蒸馏是不够的，通过RL还可以大大提升模型性能
* 135.张量网络遇上神经网络：综述与未来展望  CreateAMind  https://mp.weixin.qq.com/s/KFh1AB90ZySTMe3lycxecg \
  Tensor Networks Meet Neural Networks:A Survey and Future Perspectives \
  ???什么是张量网络
* 136.出人意料！DeepSeek-R1用的GRPO其实没必要？规模化强化学习训练用PPO就够了  机器之心  https://mp.weixin.qq.com/s/nT2KTyrsgkv-ztXN2CK_Lw \
  相较于 PPO，GRPO 去掉了价值模型，而是通过分组分数来估计基线，从而可极大减少训练资源 \
  但现在，有一项研究却证明 GRPO 对推理模型来说并不很重要 \
  阶跃星辰与清华大学近期的一项研究发现，只需使用带 GAE （λ= 1，γ= 1）的普通 PPO 以及基于规则的简单奖励函数，无需任何 KL 正则化，就足以扩展在推理任务上的响应长度和基准性能，类似于在 DeepSeek-R1-Zero 上观察到的现象 \
  使用这种极简方法，他们打造了 Open-Reasoner-Zero，这是首个面向大规模推理的强化学习训练的开源实现。并且该实现在 GPQA Diamond 基准上的表现优于 DeepSeek-R1-Zero-Qwen-32B，同时仅需使用 1/30 的训练步数。需要强调，该团队不仅开源了代码，还发布了参数设置、训练数据和模型权重 \
  Open-Reasoner-Zero: An Open Source Approach to Scaling Up Reinforcement Learning on the Base Model \
  论文地址：https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero/blob/main/ORZ_paper.pdf \
  项目地址：https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero \
  Hugging Face：https://huggingface.co/Open-Reasoner-Zero
* 137.(**WMP**)机器人视觉控制新范式！ByteDance Research新算法实现通过性能SOTA 
 机器之心  https://mp.weixin.qq.com/s/aQF0Sj2i2tN5BgzAkH_O5g \
  WMP 基于世界模型的感知算法 \
  World Model-based Perception for Visual Legged Locomotion \
  项目主页：https://wmp-loco.github.io/ \
  ByteDance Research 研究团队成功将世界模型应用于四足机器人视觉控制领域，提出了基于世界模型的感知算法 WMP（World Model-based Perception），WMP 通过在模拟器中学习世界模型和策略，其中世界模型通过历史感知信息（包括视觉感知和本体感知）预测未来的感知，策略以世界模型提取的特征作为输入，输出具体控制动作
* 138.谷歌超硬核教科书来了！Jeff Dean带货揭Gemini训练秘籍：在TPU上scaling  新智元  https://mp.weixin.qq.com/s/__aYLXjE4Mk1H6gGcs1XSw \
  近日，谷歌DeepMind科学家Jacob Austint在X上， 发布了基于JAX和TPU的大模型Scaling教科书《How to Sacle Your Model \
  教科书链接：https://jax-ml.github.io/scaling-book/ \
  The Illustrated Transformer \
  博客链接：https://jalammar.github.io/illustrated-transformer/ \
  JAX讲义:https://github.com/rwitten/HighPerfLLMs2024
* 139.解释AGI，实现AGI，联想学习与主动推理  CreateAMind  https://mp.weixin.qq.com/s/muo8IlDRUqL3nqORLX4JBA \
  Associative Learning and Active Inference \
  ?什么是联想学习与主动推理

# 2.22 Sat
* 139.不到1美元，打造全球第3超强AI助手！港大3人开源最强Deep Research  新智元  https://mp.weixin.qq.com/s/CMaORHORl3s6dl1WENR1Kw \
  Auto-Deep-Research仅基于Claude-3.5-Sonnet构建 \
  https://github.com/HKUDS/AutoAgentAuto-Deep-Research：https://github.com/HKUDS/Auto-Deep-Research论文地址：https://arxiv.org/abs/2502.05957
* 140.谷歌AI掌门人Jeff Dean对话Transformer作者：AI提速300%，1000万倍工程师要来了  新智元  https://mp.weixin.qq.com/s/O7VEu7wwdGheYiynm-ifYw 
* 141.AI智能体结对编程秒杀人类，90分钟神作惊动OpenAI总裁！引全网140万围观  新智元  https://mp.weixin.qq.com/s/S6Mw2Fish-FNRzpkdgrzTg \
  Browser Use项目地址：https://github.com/browser-use/browser-use
* 142.10美元成功复现DeepSeek顿悟时刻，3B模型爆发超强推理！微软论文反驳涌现  新智元  https://mp.weixin.qq.com/s/xH86_m71lZnSVMM7q_jzXw \
  10美元通过强化学习，成功复现DeepSeek顿悟时刻！  Datawhale  https://mp.weixin.qq.com/s/_f_rjamF4itAxFVz7hz-tQ \
  来自荷兰的开发者采用轻量级的RL算法Reinforce-Lite，把复刻成本降到了史上最低！ \
  Replicating DeepSeek's 'AhaMoment' for Under $10: A Breakthrough in Affordable AI Reasoning \
  巧的是，最近来自微软亚洲研究院的一项工作，也证明了RL的巨大潜力——通过有效且稳定的RL训练后，一个7B模型，居然就发展出了反思、验证和总结的高级推理技能！而这些技能，在逻辑语料库中是完全缺失的。受DeepSeek-R1成功的启发，研究团队探索了基于规则的强化学习（RL）在大规模推理模型中的潜力。 \
  Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning \
  所以，这项研究的训练期间，也出现「顿悟时刻」了吗？换句话说就是，在强化学习过程中，模型的推理能力是否会发生显著的飞跃，出现多步验证或反思，而且这些行为不是在训练语料中明确植入的，而是模型与RL环境的互动所自然产生的？研究人员发现，模型并没有出现「等一下，等一下」这样特定的语言表述，但图4显示出，它在第10步时表现出了一些复杂的推理行为（例如自我反思、探索、验证、总结）。由此，研究人员的结论是，RL学习过程可能没有突如其来的「顿悟时刻」——复杂的推理行为并不是在某个特定的训练步骤中突然出现的。
* 143.DeepSeek-R1技术剖析：没有强化学习基础也能看懂的PPO & GRPO  PaperWeekly  https://mp.weixin.qq.com/s/OIiNOMcuXERGVOghwNZ5Uw
* 144.AAAI 2025 | 大模型会组合关系推理吗？打开黑盒，窥探Transformer脑回路  机器学习研究组订阅  https://mp.weixin.qq.com/s/ARhZ0UQnjyY70-MwXv1gVQ \
  Benchmarking and Understanding Compositional Relational Reasoning of LLMs \
  https://github.com/Caiyun-AI/GAR
* 145.最全梳理：一文搞懂RAG技术的5种范式！  Datawhale  https://mp.weixin.qq.com/s/lbeeblGYvb1JeC0gW4AE9g 

# 2.23 Sun
* 146.主动推理主体的反应性环境  CreateAMind  https://mp.weixin.qq.com/s/B21Q99Y7xd6kAX5A1DjPkw \
  Reactive Environments for Active InferenceAgents with RxEnvironments.jl \
  反应性环境 RxEnvironments.jl
* 147.大规模语言模型在自动规划中的应用综述  专知  https://mp.weixin.qq.com/s/U2s6XOiijPEVYHRvqUkEYg \
  A Survey on Large Language Models for Automated Planning \
  尽管LLMs因其局限性不适合单独作为规划器，但当与其他方法结合时，它们仍然为增强规划应用提供了巨大的机会。因此，我们提倡一种平衡的方法，结合LLMs固有的灵活性和广泛知识，以及传统规划方法的严谨性和成本效益
* 148.最新综述：世界模型如何推动自动驾驶  我爱计算机视觉  https://mp.weixin.qq.com/s/SlAYXUi5xVXb4Crr5X9IkA \
  The Role of World Models in Shaping Autonomous Driving: A Comprehensive Survey
* 149.Bengio参与，扩散模型+蒙特卡洛树搜索实现System 2规划  机器之心  https://mp.weixin.qq.com/s/MsU78wStnqVwgskRzAa4jA \
  把扩散模型的生成能力与 MCTS 的自适应搜索能力相结合 \
  Monte Carlo Tree Diffusion for System 2 Planning \
  蒙特卡洛树扩散（MCTD） \
  MCTD = 扩散模型 + MCTS \
* 150.使用范畴论构建向量符号架构的基础  CreateAMind  https://mp.weixin.qq.com/s/1lTT_Ng5F1Wuud0hzlY-fg \
  Developing a Foundation of Vector Symbolic ArchitecturesUsing Category Theory \
  一个与神经网络和基于梯度的学习兼容，但明确建模组合性的替代框架是向量符号架构（Vector Symbolic Architectures，VSAs）。VSAs 是一类关于高维向量表示的代数。它们源于认知科学，旨在统一神经处理和人类所进行的符号推理 \
  向量符号架构（VSAs）是为了解决认知科学中的一个问题而产生的：人类行为可以通过规则和符号推理来描述，但这种行为的实现却依赖于神经网络，而神经网络依靠操作向量表示并进行基于相似性的推理 [51]。在核心层面，VSAs使用随机生成的向量来表示变量及其取值（也被称为“槽”和“填充物”）。这些基础符号通过一组固定的代数运算组合成更高层次的表示
* 151.两万字长文深度解密DeepSeek-R1、Kimi 1.5，强推理模型凭什么火出圈？  Datawhale  https://mp.weixin.qq.com/s/Q3JjWAj80mQ7oelwyQie4w \
  视频：DeepSeek-R1/Kimi 1.5 及类强推理模型开发解读 
* 152.单卡3090实现超长视频理解！港大团队打造首个超长视频理解引擎VideoRAG  PaperWeekly  https://mp.weixin.qq.com/s/MZ9t_uB3JqDwgGZnmG4Qlg \
  VideoRAG \
  香港大学黄超教授实验室联合百度提出 VideoRAG，一种面向超长视频理解的多模态 RAG 框架 \
  VideoRAG 采用动态知识图谱构建与多模态特征编码，将视频内容压缩为基于多模态上下文的结构化知识表示，从而支持跨视频推理与精准内容检索。在回答生成过程中，VideoRAG 根据查询动态提取原始视频的细粒度内容，避免存储冗余信息，提高推理效率 \
  https://github.com/HKUDS/VideoRAG

# 2.24 Mon
* 153.演绎和归纳处理在人脑中分离  CreateAMind  https://mp.weixin.qq.com/s/oDSUc0lggMHRctpUpU_rDw \
  Deductive and Inductive Processing Dissociate in theHuman Brain \
  逻辑演绎和归纳是人类推理的基本组成部分，从理论上被认为具有区别。然而，尚不清楚在经验层面，这些是否是可分离的认知过程，或者它们只是同一底层认知操作的不同表现形式。逻辑推理的表征形式也一直存在争议，一些人主张使用语言表征，而另一些人则提倡一种符号化但非语言的“思想语言（Language of Thought, LOT）”，所有逻辑推理都在其中进行。在此，我们通过脑成像（fMRI）来探讨这两个问题，并发现：i）演绎和归纳在神经层面是可分离的；ii）这两种推理形式均不依赖于语言表征
* 154.万字梳理：揭秘 DeepSeek 中的 RL 与 AGI 下一步  图灵人工智能  https://mp.weixin.qq.com/s/o1OfaI80lt1Q3Rotf9VRRA 
* 155.使用向量符号架构建模神经概率计算  CreateAMind  https://mp.weixin.qq.com/s/qaqfsaiUG3xsvndeudX44g \
  Modelling Neural Probabilistic Computationusing Vector Symbolic Architectures
* 156.从o1-mini到DeepSeek-R1，万字长文带你读懂推理模型的历史与技术  机器之心  https://mp.weixin.qq.com/s/t19D5_2nsbIVI_eemLtx-Q \
  Demystifying Reasoning Models \
  原文地址：https://cameronrwolfe.substack.com/p/demystifying-reasoning-models
* 157.因果律是客观存在的法则，还是感知的幻象？  集智俱乐部  https://mp.weixin.qq.com/s/GAaT5efMqWJnMKW2PXLwzQ
* 158.零基础入门：DeepSeek微调教程来了！  Datawhale  https://mp.weixin.qq.com/s/hOgeu6EPbuaQgVHyjij-kg 
* 159.“源神”DeepSeek！突破H800性能上限，FlashMLA重磅开源，算力成本还能降  量子位  https://mp.weixin.qq.com/s/OZmMTW4JyiP4GWkzShlqAg \
  DeepSeek开源放大招：FlashMLA让H800算力狂飙！曝光低成本秘笈  新智元  https://mp.weixin.qq.com/s/IIRtU2gFCeCnrhtamGVOig \
  刚刚！DeepSeek开源FlashMLA，推理加速核心技术  Datawhale  https://mp.weixin.qq.com/s/h2iigzbDISkxGDezdNmFHw \
  按照官方介绍来说，FlashMLA使用之后，H800可以达到3000GB/s内存，实现580TFLOPS计算性能 \
  https://github.com/deepseek-ai/FlashMLA \
  DeepSeek的成本涉及两项关键的技术：一个是MoE，一个就是MLA（多头潜注意力） \
  多头潜注意力（MLA）KV缓存是Transforme模型中的一种内存机制，用于存储表示对话上下文的数据，从而减少不必要的计算开销。随着对话上下文的增长，KV缓存会不断扩大，从而造成显著的内存限制。通过大幅减少每次查询所需的KV缓存量，可以相应减少每次查询所需的硬件资源，从而降低运营成本。与标准注意力机制相比，MLA将每次查询所需的KV缓存减少了约93.3%。 

# 2.25 Tue
* 160.人类和动物行为中发现符号认知模型  CreateAMind  https://mp.weixin.qq.com/s/Vtk-5CgITDzHFSEHtFqHWg \
  Discovering Symbolic Cognitive Models fromHuman and Animal Behavior
* 161.当AI教父们炒上热搜，大模型是类人智能还是鹦鹉学舌？  图灵人工智能  https://mp.weixin.qq.com/s/T0eF3vJ7HVfslRwrBQ2okw
* 162.全球首个混合推理模型：Claude 3.7 Sonnet来袭，真实编码力压一切对手  机器之心  https://mp.weixin.qq.com/s/RzdrxKbHKKqtN-FvbOQsZw \
  刚刚，全球首个混合推理模型Claude 3.7降世！最强编程大脑暴击DeepSeek R1  新智元  https://mp.weixin.qq.com/s/JZ-HYbSj9R48UZwyvTQ1XQ \
  ???混合推理
* 163.神经系统绑定器Neural Systematic Binder  CreateAMind  https://mp.weixin.qq.com/s/4R06QLQIk5bqwsImXVvzcg \
  NEURAL SYSTEMATIC BINDER
* 164.LeCun力荐！进化算法淘汰77%低质数据：RIP方法让模型性能狂飙60%  新智元  https://mp.weixin.qq.com/s/NdcysBp8NnE8vtFgUsnK9A \
  近日，Meta等机构发表的论文介绍了一种通过进化算法构造高质量数据集的方法：拒绝指令偏好（RIP） \
  R.I.P: Better Models by Survival of the Fittest Prompts \
  Meta、UC伯克利、NYU等机构的学者提出了一种最新方法，简称RIP，让低质量数据「一路走好」的同时，也是在暗示——只有成功存活下来的数据才是高质量的数据 \
  ??? RIP具体是如何实现的
* 165.DeepSeek开源第二弹，为MoE和EP量身定制的通信库！暂和英伟达显卡绑定  量子位  https://mp.weixin.qq.com/s/2ecxmq9zbwFlzOalprok0Q \
  刚刚，DeepSeek开源DeepEP通信库，千亿MoE训推颠覆级创新！FP8狂飙，带飞GPU  机器学习研究组订阅  https://mp.weixin.qq.com/s/KQ0oYTl20IopkJVMehL3ww \
  DeepEP， 第一个用于MoE模型训练和推理的开源EP通信库（expert parallelism，专家并行） \
  ??? 专家并行 \
  它提供高吞吐量和低延迟的all-to-all GPU内核，也称为MoE dispatch和combine。该库还支持低精度运算，包括FP8 \
  ??? 没有理解DeepEP的具体用途？
  https://github.com/deepseek-ai/DeepEP
* 166.北邮、美团联合提出反思微调AgentRefine：微调的也能让Agent模型学会反思？  PaperWeekly  https://mp.weixin.qq.com/s/Hc7DY-mVY3Q9FOyPfB8o5A \
  提出了一种新颖的 AgentRefine 框架用于智能体微调策略。其核心思想是让模型通过轨迹中的观察学习纠正其错误

# 2.26 Wed
* 167.DeepSeek开源通用矩阵乘法库，300行代码加速V3、R1，R2被曝五月前问世  机器之心  https://mp.weixin.qq.com/s/TgSSgdnPZnm3Iu_pNG5vlQ \
  DeepGEMM，是一款支持密集型和专家混合（MoE）GEMM 的 FP8 GEMM 库，为 V3/R1 的训练和推理提供了支持，在 Hopper GPU 上可以达到 1350+ FP8 TFLOPS 的计算性能 \
  开源地址：https://github.com/deepseek-ai/DeepGEMM
* 168.从系统1到系统2：推理大语言模型综述  专知  https://mp.weixin.qq.com/s/01Me8ehQ_sqIIWaZd2bTQA \
  From System 1 to System 2: A Survey of Reasoning Large Language Models 
* 169.何恺明开辟分形图像生成新范式！计算效率提高4000倍，首次实现高分辨率逐像素生成  量子位  https://mp.weixin.qq.com/s/SK89sa0N7Hj-yr8lI1PD_w \
  何恺明ResNet级神作，分形生成模型计算效率狂飙4000倍！清华校友一作  新智元  https://mp.weixin.qq.com/s/ymXTL8758Dfm7QNg-rDoQA \
  分形生成模型 Fractal Generative Models，首次使逐像素生成高分辨率图像成为可能 \
  Fractal Generative Models \
  团队将生成模型本身抽象为可复用的“原子模块” 。通过递归地在生成模型中调用这些原子生成模块，可以构建出一种自相似的分形架构。其灵感源于数学中的分形思想。它相当于一个粗糙或零碎的几何形状分成数个部分，每一部分都（至少近似地）是整体缩小后的形状。即具有自相似的性质。嗯，就是像俄罗斯套娃（Matryoshka）那样子 
* 170.千帧长视频时代到来！MIT全新扩散算法让任意模型突破时长极限  机器之心  https://mp.weixin.qq.com/s/Ra-RJfgEVjbUUDcmZFE07Q \
  History-guided Video Diffusion \
  提出了一种全新算法 Diffusion Forcing Transformer（DFoT），在不改动原有架构的情况下就能让模型稳定输出比之前近 50 倍、近千帧长的视频
* 171.Claude 3.7 Sonnet游戏里贪吃蛇惊现自我意识？发现自己是代码绝望崩溃  新智元  https://mp.weixin.qq.com/s/yIUk63MLz7CH-2k18PBQeA 
* 172.英伟达下场，首次优化DeepSeek-R1！B200性能狂飙25倍，碾压H100  新智元  https://mp.weixin.qq.com/s/FC8ZX4SeFteQQbJ8cZZi4w \
  最近，英伟达开源了首个在Blackwell架构上优化的DeepSeek-R1，实现了推理速度提升25倍，和每token成本降低20倍的惊人成果。同时，DeepSeek连续开源多个英伟达GPU优化项目，共同探索模型性能极限 \
  随着DeepSeek-R1本地化部署的爆火，英伟达也亲自下场，开源了首个基于Blackwell架构的优化方案——DeepSeek-R1-FP4 \
  模型地址：https://huggingface.co/nvidia/DeepSeek-R1-FP4 \
  总的来说，不管是英伟达开源的DeepSeek-R1-FP4，还是DeepSeek开源的三个仓库，都是通过对英伟达GPU和集群的优化，来推动AI模型的高效计算和部署

# 2.27 Thur
* 173.神经符号模型的统一框架  CreateAMind  https://mp.weixin.qq.com/s/-oH8Qco7lnI_mO7cR25EBg \
  A Mathematical Framework, a Taxonomy of Modeling Paradigms, and a Suite of Learning Techniques for Neural-Symbolic \
  完全不懂，能量基模型相关
* 174.MLSys’25 | 极低内存消耗：用SGD的内存成本实现AdamW的优化性能  机器之心  https://mp.weixin.qq.com/s/YCL_tol6hpeEHWWxgPBYzQ \
  APOLLO: SGD-LIKE MEMORY, ADAMW-LEVEL PERFORMANCE \
  https://github.com/zhuhanqing/APOLLO \
  目前 APOLLO 已在 Hugging Face Transformers、LLaMA-Factory 等主流开源项目中落地，研究者可以轻松调用这一方法开展低内存大模型训练与微调。\
  核心亮点: \
  1.极低内存消耗：首次以类 SGD 内存成本完成大模型训练，达到甚至超越 AdamW 的性能。 \
  2.无需 SVD 计算：首次实现仅需轻量级随机投影进行大模型预训练，甚至在 7B 模型上优化速度超越 Adam。
* 175.摆脱编码器依赖！Encoder-free 3D多模态大模型，性能超越13B现有SOTA | 上海AI Lab港中文等团队新作  量子位  https://mp.weixin.qq.com/s/SREUDeo-ZU7UwcDNK7Hxxw \
  ENEL在预训练阶段探索了如何使用自监督损失将3D编码器的功能整合到LLM本身，在指令调优阶段提出了一种层次几何聚合策略，基于PointLLM首次全面研究了无编码器架构在3D多模态大模型中的潜力 \
  Exploring the Potential of Encoder-free Architectures in 3D LMMs
* 176.DeepSeek开源三箭齐发，梁文峰亲自上阵！双向并行LLM训练飙升  新智元  https://mp.weixin.qq.com/s/nC_M6ZTRbcX9T1_C5BKIcA \
  开源周第4天，DeepSeek放出的是——优化并行策略，一共三个项目。 \
  DualPipe：一种用于V3/R1模型训练中实现计算与通信重叠的双向流水线并行算法 \
  EPLB：一个针对V3/R1的专家并行负载均衡工具 \
  计算与通信重叠机制的优化并行策略：深入分析V3/R1模型中的计算与通信重叠机制
* 177.DeepSeek-R1自写CUDA内核跑分屠榜！斯坦福学霸狂飙GPU编程自动化挑战人类  新智元  https://mp.weixin.qq.com/s/9PA8m7lKaJlZabN246lT_Q \
  
* 178.微软Phi-4家族新增两位成员，5.6B多模态单任务超GPT-4o，3.8B小模型媲美千问7B  机器之心  https://mp.weixin.qq.com/s/WNw1nfeQsggqwv4Hogm_kA \
  2024 年底，微软正式发布了 Phi-4，仅用了 40% 合成数据，140 亿参数的 Phi-4 就在数学性能上击败了 GPT-4o \
  刚刚，微软又隆重介绍了 Phi-4 模型家族的两位新成员：Phi-4-multimodal （多模态模型）和 Phi-4-mini（语言模型，38 亿参数）。Phi-4-multimodal 改进了语音识别、翻译、摘要、音频理解和图像分析，而 Phi-4-mini 专为速度和效率而设计，两者都可供智能手机、PC 和汽车上的开发人员使用 \
  项目地址：https://huggingface.co/microsoft/phi-4
* 179.DeepSeek-R1自写CUDA内核跑分屠榜！斯坦福学霸狂飙GPU编程自动化挑战人类  新智元  https://mp.weixin.qq.com/s/9PA8m7lKaJlZabN246lT_Q \
  KernelBench: Can LLMs Write Effcient GPU Kernels? \
  具体来说，研究者发现：对模型而言，编写功能正确的内核仍然具有挑战性；模型通过优化展示了生成高性能内核的潜力；利用反馈对于减少执行错误和发现更快的方案很重要。 
  
# 2.28 Fri


