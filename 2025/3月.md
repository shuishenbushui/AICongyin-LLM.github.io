# 3.1 Sat
* 1.多模态基础模型的机制可解释性综述  专知  https://mp.weixin.qq.com/s/gTLYisN09Omty1HD0OTMGA \
  A Survey on Mechanistic Interpretability for Muti-Modal Foundation Models \
  本综述探索了两个关键方面：（1）将LLM可解释性方法适应到多模态模型；（2）理解单模态语言模型与跨模态系统之间的机制差异。
* 2.大模型是否有自知之明？新研究发现LLM可以知晓自己的知识范围  机器之心  https://mp.weixin.qq.com/s/_SGEw75r6SjcB5JUTg9ENw \
  Do Large Language Models Know How Much They Know? \
  「虽然不同架构涌现这种能力的速率不同，但结果表明，知识意识（awareness of knowledge）可能是 LLM 的一个普遍属性。」 \
  整体来说，这项研究证明了足够规模的 LLM 确实具有知识意识（awareness of knowledge），即能够知晓自己的知识范围。
* 3.ICLR 2025｜AI不语，只是一味根据人类意图推理3D空间定位  机器之心  https://mp.weixin.qq.com/s/DXExxwZ7t6lzdfoKa3kJYQ \
  Intent3D: 3D Object Detection in RGB-D Scans Based on Human Intention \
   3D 意图定位（3D-IG）
* 4.刚刚，LangGraph官方开源Ultra版本，多智能体能力提升10倍！  探索AGI  https://mp.weixin.qq.com/s/XRoyD5O9o1CqISFkIDeBBA
* 5.Agent or SFT or RL ? 9个多模态R1推理开源项目核心思路解析  老刘说NLP  https://mp.weixin.qq.com/s/yIDqvJLASPWX6gkOoRr1Pg 
* 6.DeepSeek-V3 / R1 推理系统概览  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/HBuIB1yoXyYKVwqqgt0SFQ
* 7.一个统一的视角理解：计算力学、因果抽象和信息分解  集智俱乐部  https://mp.weixin.qq.com/s/LW3Rvs6JIRFlwTMamZiwLg
  在众多研究涌现的框架里，计算力学的框架相比较而言很宏大，而且讲起来有特别的吸引力。它依托于生物进化论的思想，以信息论为工具，同时有硬核的统计物理解释以及严谨的数学表达。如下图所示，它假设宇宙是一个巨大的确定动力系统，每一个生物体或者说主体，都因其有限的观察能力，只能感知到宇宙的一部分，也就是环境。环境中就有噪音，而这很可能威胁到主体的生存。所以迫于进化的压力，每一个主体都要尽可能有能力预测到环境的变化。对于每一个主体的构造而言，除去那些实际的物理和化学结构以外，计算力学关注的是它的“虚拟层”。主体根据传感器获知环境的历史信息，再根据自己的内在模型做出预测，然后做出相应的行动。这个内在模型的概念，和现在流行的**自由能原理**与**世界模型**理论也是相一致的。 \
  光能做出准确的预测还不够。比如现在的大模型预测能力很强，那是不是说让每一个主体都背着一个大模型就万事大吉了？这太笨重了。如果对环境建模的内在模型非常复杂，就会消耗很多资源，也不利于主体的生存。所以大自然要求主体既要能预测环境变化，又要这个预测模型尽可能简洁。这个既要又要，使得主体不断地动态调整自己的内在模型，总要在一个最合适的尺度上归纳总结周围的环境变化。而这，便是主体为什么进化出识别涌现现象的能力，我们人类也不例外。

# 3.2 Sun
* 8.LeCun世界模型再近一步！Meta研究证明：AI可无先验理解直觉物理  新智元  https://mp.weixin.qq.com/s/OeUYyfEonlKlwQQEwhLVgg \
  V-JEPA不是去生成像素级的精准预测，而是在抽象的表示空间里进行预测。这种方式更接近LeCun所认为的人类大脑处理信息的模式。\
  Intuitive physics understanding emerges from self-supervised pretraining on natural videos \
  这次的主要发现如下： \
  1.V-JEPA能够准确且一致地分辨出，符合物理定律的视频和违反物理定律的视频，远超多模态LLM和像素空间中的视频预测方法。 \
  2.虽然在实验中观察到改变模型的任一组件，都会影响性能，但所有V-JEPA模型都取得了明显高于随机水平的表现。
* 9.【AAAI2025教程】大型语言模型中的知识生命周期：记忆、编辑与超越，216页ppt  专知  https://mp.weixin.qq.com/s/fF4fHQ9tSCs3XgVjJ-ywCQ \
  The Lifecycle of Knowledge in Large Language Models: Memorization, Editing, and Beyond \
  https://llmknowledgelifecycle.github.io/AAAI2025_Tutorial_LLMKnowledge \
  本教程探讨大型语言模型中的知识生命周期，包括：(1) 通过基础模型预训练知识的涌现；(2) 外部知识的注入；(3) 知识的更新与修改；(4) 知识的探测与生成；(5) 多模态知识的整合，包括对物理世界的理解和程序性规划。
* 10.DeepSeek关键RL算法GRPO，有人从头跑通了，贡献完整代码  机器之心  https://mp.weixin.qq.com/s/e0-tVsaIgNajBTOl117ctg \
  DeepSeek关键RL算法GRPO，手把手教你从头跑通！  Datawhale  https://mp.weixin.qq.com/s/gi8ee4m6borLPlPRBcp7Mg \
  GRPO 算法丢弃了 critic model，放弃了价值函数近似，转而通过组内样本的相对比较来计算策略梯度，从而有效降低了训练的不稳定性，同时提高了学习效率。 \
  教程地址：https://github.com/aburkov/theLMbook/blob/main/GRPO_From_Scratch_Multi_GPU_DataParallel_Qwen_2_5_1_5B_Instruct.ipynb
* 11.超越人类！DeepMind强化学习新突破：AI在「我的世界」中封神！  新智元  https://mp.weixin.qq.com/s/RTEcC56XLXLqMtov3Og1mQ \
  Improving Transformer World Models for Data-Efficient RL \
  Crafter是一个2D版的《我的世界》，具体来说，他们用的是Craftax-classic环境，它是Crafter的快速复刻版。Craftax-classic环境有几个很好的特点：1.每次游戏的环境都是随机生成的，AI需要应对不同的挑战。2.AI只能看到局部视野，就好像只能看到屏幕的一部分，而不是整个地图。3.这是一个以成就层级来设定奖励信号的体系，需要进行深入且广泛的探索才能达成。 \
  DeepMind研究团队的这篇论文主要研究了如何在Craftax-classic环境中改进基于Transformer世界模型（TWM）的强化学习方法。研究人员主要从三个方面入手：如何使用TWM、如何将图像转换成TWM的输入以及如何训练TWM。 \
  研究团队的方法让智能体在仅用100万步环境交互的情况下，就取得了Craftax-classic 67.42%的奖励和 27.91%的得分，这比之前的最佳研究成果（SOTA）——53.20%的奖励和19.4%的得分——都有了显著提升。智能体的表现甚至超越了人类专家！相当炸裂。
* 12.小模型指导大模型！田渊栋等爆锤蒸馏：新方法更高效、更透明、更可控  新智元  https://mp.weixin.qq.com/s/V-zQgo-xc0aDBC4hHSkFaw \
  LLM Pretraining with Continuous Concepts \
  基于连续概念，Meta团队新研究提出了超越「下一个token预测」语言建模新范式。更加重要的是，新方法不仅能增强原有的范式，而且比起知识蒸馏，数据量减少20%，甚至能从小模型提取概念指导更大的模型！
* 13.AGI理论比较：主动推理、强化学习、控制论、贝叶斯大脑、效用决策、有限理性、情感动机、动态体内平衡  CreateAMind  https://mp.weixin.qq.com/s/egj-2woxVpdA8XuGcOVaeQ \
  Active-InferenceThe-Free-Energy-Principle-in-Mind \
  我们总结了主动推理的主要理论要点（来自本书的第一部分）及其实际实现（来自第二部分）。然后，我们将这些点联系起来：我们从前面章节中讨论的特定主动推理模型中抽象出来，专注于框架的集成方面。主动推理的好处之一是它为有感知力的生物体必须解决的适应性问题提供了完整的解决方案。因此，它为感知、行动选择、注意力和情绪调节等问题提供了统一的视角，这些问题通常在心理学和神经科学中被单独处理，并在人工智能中使用不同的计算方法来解决。我们将在控制论、行动思想运动理论、强化学习和最优控制等既定理论的背景下讨论这些问题（以及更多问题）。最后，我们简要讨论如何将主动推理的范围扩展到涵盖本书未深入讨论的其他生物、社会和技术主题 \
  大骂“深度学习是垃圾”的自由能到底是什么？有什么效果？  CreateAMind  https://mp.weixin.qq.com/s/Jjw1BA1ociiCbAxKmjvU6A -> 内含从机器人到AGI，从具身到可解释，从入门到应用实现的最全自由能原理资料
  一个框架整合大脑理论3 概要+公式图表  CreateAMind  https://mp.weixin.qq.com/s/KTzLYx0LVvIHks_KPP0zoA 
* 14.这几天！DeepSeek开源周 | 发布5个重要代码库，涉及AI基础设施建设的关键节点  AINLPer  https://mp.weixin.qq.com/s/XbYp7v2Ls9pw-11FQSZWOA \
  FlashMLA、DeepEP、DeepGEMM、并行策略优化、3FS文件系统、DS-V3/R1推理系统概述
* 15.可视化图解MOE大模型的7个核心问题：专家、路由、负载均衡及其用于视觉模态  老刘说NLP  https://mp.weixin.qq.com/s/-SFFB6gUp0KA4x95lCoxcg \
  原文：https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts \
  主要包括7个问题： \
  1、什么是专家混合模型（Mixture of Experts, MoE）？ \
  2、什么是专家？ \
  3、路由机制如何工作？ \
  4、如何进行负载均衡？ \
  5、如何通过Switch Transformer简化MoE？ \
  6、专家混合模型在视觉模型中如何应用？ \
  7、Mixtral 8x7B中的活跃参数与稀疏参数？
* 16.LLM「啊哈时刻」竟会自我纠正，单体数学性能暴涨！UIUC华人一作  新智元  https://mp.weixin.qq.com/s/nUdj4aVN2Xk1OJur6YDndA \
  该研究团队打造了一款「自我奖励推理模型」，让大模型 (LLM) 从生成推理路径到自我评估，再到纠正错误，全部一气呵成。 \
  Self-rewarding correction for mathematical reasoning \
  https://github.com/RLHFlow/Self-rewarding-reasoning-LLM
* 17.知识蒸馏技术原理详解：从软标签到模型压缩的实现机制  机器学习研究组订阅  https://mp.weixin.qq.com/s/I9aU6eHjhNCA77tc_usP5g 
* 18.Level-Navi Agent：开源AI 搜索智能体框架  大语言模型论文跟踪  https://mp.weixin.qq.com/s/lFqu0COKdvqKXwGwLMs8Ig \
  Level-Navi Agent: A Framework and benchmark for Chinese Web Search Agents \
  https://github.com/chuanruihu/Level-Navi-Agent-Search

# 3.3 Mon
* 19.AI 时代下，技术人如何保持核心竞争力？这位 MIT 毕业生给出了答案。“别再刷 Leetcode 了！”  图灵人工智能  https://mp.weixin.qq.com/s/mXulwIWWXxfpZ20jVzhy_A
* 20.

# 3.4 Tue
# 3.5 Wed
# 3.6 Thur
# 3.7 Fri
# 3.8 Sat
# 3.9 Sun
# 3.10 Mon
# 3.11 Tue
# 3.12 Wed
# 3.13 Thur
# 3.14 Fri
# 3.15 Sat
# 3.16 Sun
# 3.17 Mon
# 3.18 Tue
# 3.19 Wed
# 3.20 Thur
# 3.21 Fri
# 3.22 Sat
# 3.23 Sun
# 3.24 Mon
# 3.25 Tue
# 3.26 Wed
# 3.27 Thur
# 3.28 Fri
# 3.29 Sat
# 3.30 Sun
# 3.31 Mon
