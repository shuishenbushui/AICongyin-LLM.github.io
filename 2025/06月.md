# 6.1 Sun
* 1.从推理到学习：基于大语言模型的假设发现与规则学习综述  专知  https://mp.weixin.qq.com/s/S8iWkp5Ob6b17ScgF903ng \
  From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models
* 2.SFT在帮倒忙？新研究：直接进行强化学习，模型多模态推理上限更高  机器之心  https://mp.weixin.qq.com/s/oJNtHlfz4Jwv2a-9JvqoZA \
  SFT 可能会阻碍学习 —— 经常导致出现伪推理路径，而 RL 则是在促进真正的多模态推理！ \
  SFT or RL? An Early Investigation into Training R1-Like Reasoning Large Vision-Language Models \
  https://ucsc-vlaa.github.io/VLAA-Thinking/
* 3.Mamba核心作者新作：取代DeepSeek在用的注意力机制，专为推理打造  量子位  https://mp.weixin.qq.com/s/61k_W7m21hWBYv2Er00E9A \
  Grouped-Tied Attention（GTA）  Grouped Latent Attention（GLA） \
  在保持模型性能不变的情况下，将解码速度和吞吐量最高提升2倍，大大优化了模型的长上下文推理能力

# 6.2 Mon
* 4.AI数学能力暴涨100%，自进化直逼RL极限！CMU新作颠覆认知  图灵人工智能  https://mp.weixin.qq.com/s/PVi5J3pX9IdcwKgl0CXihA \
  「自奖励训练」（SRT） \
  Can Large Reasoning Models Self-Train? \
  https://github.com/tajwarfahim/srt
* 5.LeCun新作反杀AGI派！AI连「鸟」都搞不懂，拿什么超越人类？  新智元  https://mp.weixin.qq.com/s/nv59rJhXkkUgEE19uEr4zg \
  LLM根本不会思考！LeCun团队新作直接戳破了大模型神话。最新实验揭示了，AI仅在粗糙分类任务表现优秀，却在精细任务中彻底失灵。 \
  From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning \
  究其原因，LLM的内部概念结构和人类直觉，有着根本性错位。也就是说，它们可能知道「鸟」这个词，却理解不了「鸟」的深层含义。LLM追求的是极致的统计压缩，而人类追求适应性语义丰富。
* 6.《元强化学习教程》书册，164页pdf  专知  https://mp.weixin.qq.com/s/_2z--RMORCetCpJFd7vmVw \
  A Tutorial on Meta-Reinforcement Learning
* 7.LSTM之父22年前构想将成真？一周内AI「自我进化」论文集中发布，新趋势涌现？  机器之心  https://mp.weixin.qq.com/s/0PPw4t2YCwu-7zrxpjglcA \
  Can Large Reasoning Models Self-Train?  \
  项目地址：https://self-rewarding-llm-training.github.io/ \
  代码地址：https://github.com/tajwarfahim/srt \
  数据集：https://huggingface.co/collections/ftajwar/self-rewarding-llm-training-6835218091832c3664176553 
* 8.微软等提出「模型链」新范式，与Transformer性能相当，扩展性灵活性更好  机器之心  https://mp.weixin.qq.com/s/UFqC41KYaE3h6KnbLw5iXQ \
  Chain-of-Model Learning for Language Model  \
  CoM 可以将不同规模的多个子模型集成到一个模型中，能够在现有模型的基础上进行扩展。这种能力直接赋予了基础模型更好的可扩展性和灵活性。
* 9.AI竟会「自己认错」？破解多智能体协作「罗生门」，斩获ICML 2025 Spotlight  新智元  https://mp.weixin.qq.com/s/dIhJj6Z6WmBAobM3Ay1YjQ \
  在多智能体AI系统中，一旦任务失败，开发者常陷入「谁错了、错在哪」的谜团。PSU、杜克大学与谷歌DeepMind等机构首次提出「自动化失败归因」，发布Who&When数据集，探索三种归因方法，揭示该问题的复杂性与挑战性。 \
  Which Agent Causes Task Failures and When? On Automated Failure Attribution of LL Multi-Agent Systems \
  自动化失败归因（Automated Failure Attribution）

# 6.3 Tue
* 10.
* 11.
* 12.
* 13.
* 14.
* 15.
* 16.
* 17.
* 18.
* 19.
* 20.

# 6.4 Wed
# 6.5 Thur
# 6.6 Fri
# 6.7 Sat
# 6.8 Sun

# 6.9 Mon
# 6.10 Tue
# 6.11 Wed
# 6.12 Thur
# 6.13 Fri
# 6.14 Sat
# 6.15 Sun

# 6.16 Mon
# 6.17 Tue
# 6.18 Wed
# 6.19 Thur
# 6.20 Fri
# 6.21 Sat
# 6.22 Sun

# 6.23 Mon
# 6.24 Tue
# 6.25 Wed
# 6.26 Thur
# 6.27 Fri
# 6.28 Sat
# 6.29 Sun

# 6.30 Mon
