# 6.1 Sun
* 1.从推理到学习：基于大语言模型的假设发现与规则学习综述  专知  https://mp.weixin.qq.com/s/S8iWkp5Ob6b17ScgF903ng \
  From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models
* 2.SFT在帮倒忙？新研究：直接进行强化学习，模型多模态推理上限更高  机器之心  https://mp.weixin.qq.com/s/oJNtHlfz4Jwv2a-9JvqoZA \
  SFT 可能会阻碍学习 —— 经常导致出现伪推理路径，而 RL 则是在促进真正的多模态推理！ \
  SFT or RL? An Early Investigation into Training R1-Like Reasoning Large Vision-Language Models \
  https://ucsc-vlaa.github.io/VLAA-Thinking/
* 3.Mamba核心作者新作：取代DeepSeek在用的注意力机制，专为推理打造  量子位  https://mp.weixin.qq.com/s/61k_W7m21hWBYv2Er00E9A \
  Grouped-Tied Attention（GTA）  Grouped Latent Attention（GLA） \
  在保持模型性能不变的情况下，将解码速度和吞吐量最高提升2倍，大大优化了模型的长上下文推理能力

# 6.2 Mon
* 4.AI数学能力暴涨100%，自进化直逼RL极限！CMU新作颠覆认知  图灵人工智能  https://mp.weixin.qq.com/s/PVi5J3pX9IdcwKgl0CXihA \
  「自奖励训练」（SRT） \
  Can Large Reasoning Models Self-Train? \
  https://github.com/tajwarfahim/srt
* 5.LeCun新作反杀AGI派！AI连「鸟」都搞不懂，拿什么超越人类？  新智元  https://mp.weixin.qq.com/s/nv59rJhXkkUgEE19uEr4zg \
  LLM根本不会思考！LeCun团队新作直接戳破了大模型神话。最新实验揭示了，AI仅在粗糙分类任务表现优秀，却在精细任务中彻底失灵。 \
  From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning \
  究其原因，LLM的内部概念结构和人类直觉，有着根本性错位。也就是说，它们可能知道「鸟」这个词，却理解不了「鸟」的深层含义。LLM追求的是极致的统计压缩，而人类追求适应性语义丰富。
* 6.《元强化学习教程》书册，164页pdf  专知  https://mp.weixin.qq.com/s/_2z--RMORCetCpJFd7vmVw \
  A Tutorial on Meta-Reinforcement Learning
* 7.LSTM之父22年前构想将成真？一周内AI「自我进化」论文集中发布，新趋势涌现？  机器之心  https://mp.weixin.qq.com/s/0PPw4t2YCwu-7zrxpjglcA \
  Can Large Reasoning Models Self-Train?  \
  项目地址：https://self-rewarding-llm-training.github.io/ \
  代码地址：https://github.com/tajwarfahim/srt \
  数据集：https://huggingface.co/collections/ftajwar/self-rewarding-llm-training-6835218091832c3664176553 
* 8.微软等提出「模型链」新范式，与Transformer性能相当，扩展性灵活性更好  机器之心  https://mp.weixin.qq.com/s/UFqC41KYaE3h6KnbLw5iXQ \
  Chain-of-Model Learning for Language Model  \
  CoM 可以将不同规模的多个子模型集成到一个模型中，能够在现有模型的基础上进行扩展。这种能力直接赋予了基础模型更好的可扩展性和灵活性。
* 9.AI竟会「自己认错」？破解多智能体协作「罗生门」，斩获ICML 2025 Spotlight  新智元  https://mp.weixin.qq.com/s/dIhJj6Z6WmBAobM3Ay1YjQ \
  在多智能体AI系统中，一旦任务失败，开发者常陷入「谁错了、错在哪」的谜团。PSU、杜克大学与谷歌DeepMind等机构首次提出「自动化失败归因」，发布Who&When数据集，探索三种归因方法，揭示该问题的复杂性与挑战性。 \
  Which Agent Causes Task Failures and When? On Automated Failure Attribution of LL Multi-Agent Systems \
  自动化失败归因（Automated Failure Attribution）

# 6.3 Tue
* 10.图灵奖得主杨立昆：等基于50年前旧数据打造信息论框架，驳斥大模型能复制人类认知的观点  图灵人工智能  https://mp.weixin.qq.com/s/6k0NA1RxZyxwcOnQbwpgpA \
  图灵奖得主&美国纽约大学教授杨立昆（Yann LeCun）联合美国斯坦福大学团队打造出一款信息论框架，借此揭示了大模型和人类的一个根本差异：即两者在平衡信息压缩和语义意义上采用了截然不同的策略。 \
  From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning \
  虽然大模型形成了与人类判断相一致的广泛概念类别，但它们很难捕捉到对人类理解至关重要的细粒度语义区别。从更根本的层面看，大模型展现出对激进的统计压缩的强烈偏好，而人类的概念系统似乎更重视适应性的细腻差别与语境的丰富性，即便这在研究团队的衡量标准下意味着较低的压缩效率。
* 11.李飞飞空间智能独角兽开源底层技术！AI生成3D世界在所有设备流畅运行空间智能的“着色器”来了  量子位  https://mp.weixin.qq.com/s/rUtF0BIGxUZxR65h5ZzAGQ \
  Forge渲染器，可在桌面端、低功耗移动设备、XR等所有设备上实时、流畅地渲染AI生成的3D世界
* 12.过程监督>结果监督！华为港城重构RAG推理训练，5k样本性能反超90k模型  PaperWeekly  https://mp.weixin.qq.com/s/4N66Ezu4si1q8ymlPzaaXw \
  Process vs. Outcome Reward: Which is Better for Agentic RAG Reinforcement Learning \
  https://github.com/wlzhang2020/ReasonRAG
* 13.经典ReLU回归！重大缺陷「死亡ReLU问题」已被解决  机器之心  https://mp.weixin.qq.com/s/b29WfOloGFIyh-j8EfV96A 
* 14.思维链也会「跳帧」？浙大团队提出CoT-Bridge，显著提升数学推理性能  机器之心  https://mp.weixin.qq.com/s/Gjz9CLEGngOBpKRnZ_GC_A \
  Thought Leap 指的是 CoT 推理链中，前后步骤之间存在中间推理内容的省略，导致逻辑跳跃，破坏推理的连贯性。 \
  CoT-Bridge：为模型补上思维跳跃的 “桥梁” \
  Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning

# 6.4 Wed
* 15.让AI像人类一样认知真实世界！UCLA谷歌强强联手，长时记忆+3D空间理解超越基线16.5%  量子位  https://mp.weixin.qq.com/s/Vv8VtTUtCx0wH1aG5Ig-Pg \
  3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model \
  https://3dllm-mem.github.io
* 16.万字追问：如何用“时间的本质”，丈量人脑、意识与人工智能？  追问  https://mp.weixin.qq.com/s/RRY-rIqgChuVfXNAox9odw 
* 17.(**值得看看**)最新发现！每参数3.6比特，语言模型最多能记住这么多  机器之心  https://mp.weixin.qq.com/s/DAoNui-_u0IlBjHl16wn-g \
  语言模型到底能记住多少信息？Meta、DeepMind、康奈尔大学和英伟达的一项测量结果显示：每个参数大约 3.6 比特。一旦达到这个极限，它们就会停止记忆并开始泛化。 \
  How much do language models memorize? \
  研究团队从形式上将记忆分为两个组成部分：(1)非预期记忆 —— 模型包含的关于特定数据集的信息；(2)泛化 —— 模型包含的关于真实数据生成过程的信息。 \
  研究团队在规模不断增大的数据集上训练语言模型，观察到模型会持续记忆，直到其容量饱和，此时「顿悟」（grokking）现象开始出现，非预期记忆随之减少，模型开始泛化。也就是说，在海量数据上训练的语言模型根本不可能记住所有训练数据，因为根本没有足够的容量。
* 18.英伟达揭示RL Scaling魔力！训练步数翻倍=推理能力质变，小模型突破推理极限  机器之心  https://mp.weixin.qq.com/s/RmeTW83hjTQYJLpl435o6A \
  强化学习（RL）到底是语言模型能力进化的「发动机」，还是只是更努力地背题、换个方式答题？这个问题，学界争论已久：RL 真能让模型学会新的推理技能吗，还是只是提高了已有知识的调用效率？ \
  过去的研究多数持悲观态度：认为 RL 带来的收益非常有限，有时甚至会让模型「同质化」加重，失去多样性。然而，来自英伟达的这项研究指出，造成这一现象的根本原因在于：数学、编程等任务在 base model 的训练数据中被过度呈现，以及 RL 训练步数不足。 \
  ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models \
  ProRL 来了！长期训练 = 推理能力质变！

# 6.5 Thur
* 19.OpenAI久违发了篇「正经」论文：线性布局实现高效张量计算  机器之心  https://mp.weixin.qq.com/s/iln4Kz0A2ou8r-P2qgKz4w \
  Linear Layouts: Robust Code Generation of Efficient Tensor Computation Using 𝔽₂
* 20.上海AI实验室造出首个「通才」机器人大脑：看懂世界+空间推理+精准操控全拿下  量子位  https://mp.weixin.qq.com/s/SBQVZgZ8mVJRqkwstoCJUA \
  通用具身智能大脑框架：Visual Embodied Brain，简称VeBrain \
  该模型通过同时集成视觉感知、空间推理和机器人控制能力，可实现多模态大模型（MLLM）对物理实体的直接操控，使机器人能像人类一样“看到-思考-行动” \
  论文链接：https://huggingface.co/papers/2506.00123/ \
  项目主页：https://internvl.github.io/blog/2025-05-26-VeBrain/ \
  推理代码&模型链接：https://internvl.github.io/blog/2025-05-26-VeBrain/
* 21.(**非常值得看看**)DeepMind揭惊人答案：智能体就是世界模型！跟Ilya 2年前预言竟不谋而合  新智元  https://mp.weixin.qq.com/s/8y8DmrxxBLSbxCpf9reNoA \
  General agents need world models \
  Intrinsically Motivated Discovery of TemporallyAbstract World Model Graphs \
  任何能够泛化到多步目标导向任务的智能体，必然已经学习了其环境的预测模型。这个模型可以从智能体的策略中提取出来；而要提升智能体的性能，或让其完成更复杂的目标任务，就必须学习更精确的世界模型。 \
  这些算法补全了规划和逆强化学习的三位一体关系。 \
  规划：世界模型+目标→策略 \
  逆强化学习：世界模型+策略→目标 \
  研究者提出的这一环：策略+目标→世界模型

# 6.6 Fri
* 22.Entropy速递：冥想时，你的大脑经历了什么？  集智俱乐部  https://mp.weixin.qq.com/s/luXvlmAtmNfmp0kqSMH5zA \
  Thoughtseeds: A Hierarchical and Agentic Framework for Investigating Thought Dynamics in Meditative States \
  思想种子框架引入了一种新颖的计算方法来模拟冥想状态下思维动态过程，将思想种子概念化为整合信息的动态注意力主体。该分层模型由嵌套的马尔可夫毯构成，包含三个相互关联的层级：（一）作为信息库的知识领域；（二）思想种子相互竞争的思想种子网络；（三）调节意识的元认知。该模型通过基于规则的训练来模拟专注注意力的内观冥想，训练依据的是关于注意力稳定性和神经动态的实证神经科学研究。四种状态——呼吸控制、走神、元意识和重新调整呼吸——从思想种子的相互作用中自然产生，展示了自组织动态。结果表明，专家能够保持控制主导地位以强化专注注意力，而初学者则频繁出现长时间的走神情况，反映出其不稳定性。将全局工作空间理论（Global Workspace Theory）与内在激发框架（Intrinsic Ignition Framework）相结合，该模型阐明了思维种子如何通过元意识塑造统一的冥想体验，通过主动推理平衡认知和实用功能。将计算建模与现象学见解相结合，它为认知状态的出现和转变提供了一种具身视角，并对冥想技能的发展提出了可检验的预测。该框架为注意力调节、元认知意识和冥想状态的出现提供了见解，为未来对各种冥想实践（例如开放监测、非二元意识）、整个生命周期的认知发展以及基于正念的注意力障碍干预的临床应用的研究奠定了灵活的基础，从而加深了我们对心智和思维本质的理解。

# 6.7 Sat
* 23.李飞飞最新访谈：世界模型即将“降临”  Datawhale  https://mp.weixin.qq.com/s/TsF4uYlBND5Tw3BwR-m7Gw \
  “语言固然是一种极其强大的思想与信息编码方式，但它在描述所有动物及生命体赖以生存的三维物理世界方面，其实并非一种强大的编码。”她认为，人类智能的绝大部分都超越了语言范畴，语言在捕捉和描绘真实世界时是一种“有损的途径”，且其本质是“纯粹是生成性的”，自然界中本不存在固有的音节或词汇。相反，“整个物理的、感知的、视觉的世界却真实存在。”

# 6.8 Sun
* 24.SFT+RL双阶训练突破LLM自我监督！人大DeepCritic实现AI批判自主进化  PaperWeekly  https://mp.weixin.qq.com/s/SsMm67zPds9gPWLk45weTA \
  DeepCritic: Deliberate Critique with Large Language Models \
  https://github.com/RUCBM/DeepCritic
* 25.苹果炮轰推理模型全是假思考！4个游戏戳破神话，o3/DeepSeek高难度全崩溃  量子位  https://mp.weixin.qq.com/s/WRPjXZRm4QRGOUzsJ4FxGA \
  The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity \
  这篇论文称推理模型全都没在真正思考，无论DeepSeek、o3-mini还是Claude 3.7都只是另一种形式的“模式匹配”，所谓思考只是一种假象。再遇到真正高复杂度的任务时所有模型都会崩溃，即使给他们足够的时间和计算资源也无济于事。 \
  有网友讽刺纵使苹果拥有最多的资金，2年了也没有拿出像样的成果，现在自己落后了，却来否定别人的成果。
* 26.为什么用错奖励，模型也能提分？新研究：模型学的不是新知识，是思维  机器之心  https://mp.weixin.qq.com/s/gJYfFvNHg3O8ACFGns_tYA \
  研究者解释道，强化学习对下游任务的提升，关键不仅在于奖励的准确性，而更在于模型是否能够产生高质量的思考过程。仅通过奖励模型输出中关键思考词的出现频率，而非基于答案正确性的奖励，语言模型依然能够在下游任务中取得非常高的峰值表现。这表明，强化学习对下游任务的提升，更多来源于让模型学会采用恰当的思考路径接近正确答案。而相关的解题基础能力，模型已在预训练阶段获得。因此，预训练阶段的能力提升依然至关重要。
* 27.告别「失忆」AI！首个大模型记忆操作系统开源框架来了！  机器之心  https://mp.weixin.qq.com/s/YNId1fSqST2Cw5BF_I3cRg \
  大语言模型受限于固定上下文窗口，长期对话中「失忆」、记忆断裂等问题频发，北邮百家 AI 团队重磅推出首个大模型记忆操作系统开源框架 MemoryOS。巧妙融合计算机操作系统原理与人脑分层记忆机制，构建段页式三级存储架构及四大核心模块（存储、更新、检索、生成），提供全链路用户记忆管理方案，让 AI 智能体拥有持久「记性」与深度「个性」。 \
  https://github.com/BAI-LAB/MemoryOS
* 28.算力终结者来了！华人天团「降维打击」注意力瓶颈，AI狂飙进对数时代  新智元  https://mp.weixin.qq.com/s/6yIV2yCnAFe7CognsjNqng \
  Log-Linear Attention
* 29.逆向工程：ChatGPT 的记忆是如何工作的  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/s0vkEu1tu9MWn7lM2gHlDg \
  当前会话历史 (Current Session History) 对话历史 (Conversation History)  用户洞察 (User Insights)

# 6.9 Mon
* 30.Nature：大脑中的多时间尺度强化学习  集智俱乐部  https://mp.weixin.qq.com/s/sLKJuhsPmp1YRQgZikrLPw \
  Multi-timescale reinforcement learning in the brain
  为了在复杂环境中生存并获得成功，动物和人工智能体必须学会自适应地行动，以最大化适应度（fitness）和奖励（rewards）。这种自适应行为可以通过强化学习（reinforcement learning）习得，这类算法不仅在训练人工智能主体方面取得了成功，还在刻画中脑多巴胺能神经元（dopaminergic neurons）放电活动中发挥了作用。在经典强化学习模型中，智能体根据单一时间尺度（timescale）——即折扣因子（discount factor）——对未来奖励进行指数折扣。本文探讨了生物强化学习中多个时间尺度（multiple timescales）的存在。我们首先展示了在多重时间尺度上学习的强化学习智能体所具有的独特计算优势。随后，我们报道了在执行两种行为任务的小鼠中，多巴胺能神经元以多种折扣时间常数（discount time constants）编码奖励预测误差（reward prediction error）。模型解释了在由线索诱发的瞬时响应和称为多巴胺攀升（dopamine ramps）的更慢时间尺度波动中观察到的时间折扣异质性。更重要的是，单个神经元在两种任务中测得的折扣因子呈现高度相关性，表明这是一种细胞特异性（cell-specific）的属性。综合而言，我们的研究为理解多巴胺能神经元功能异质性提供了新的范式，并为人类和动物在多种情境下采用非指数折扣（non-exponential discounts）的经验观察提供了机理基础，同时也为设计更高效的强化学习算法开辟了新途径。
* 31.记忆传递的神经细胞自动机模型  CreateAMind  https://mp.weixin.qq.com/s/ojaGipGs4IAJeHS66pg86A \
  EngramNCA: a Neural Cellular Automaton Model of Memory Transfer
* 32.首创像素空间推理，7B模型领先GPT-4o，让VLM能像人类一样「眼脑并用」  量子位  https://mp.weixin.qq.com/s/wjW2UIi6x4fNU0sqSRzxzQ \
  Pixel Reasoner: Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning \
  「像素空间推理」赋予模型「视觉手术刀」般的能力：视觉主动操作、视觉主导推理 \
  https://tiger-ai-lab.github.io/Pixel-Reasoner/
* 33.大模型能够自发形成“人类思维地图”！Nature子刊重磅研究揭示多模态大模型类脑机制  量子位  https://mp.weixin.qq.com/s/UfkEV0Hu48Y0Hje9N4JRKQ \
  大模型内部存在着类似人类对现实世界概念的理解。 \
  Human-like object concept representations emerge naturally in multimodal large language models \
  何晖光老师NB
* 34.李飞飞自曝详细创业经历：五年前因眼睛受伤，坚定要做世界模型  量子位  https://mp.weixin.qq.com/s/8Eq__c8nV7tghJ4XMadUMg \
  而当前的技术突破点在于：如何让AI像人类一样，从单目视觉输入中重建完整三维场景理解。 
* 35.苹果炮轰AI推理遭打脸，GitHub大佬神怒怼！复杂任务≠推理能力  新智元  https://mp.weixin.qq.com/s/F3ngj_UJzRuKlmcdLxRJHQ 
* 36.3B超越DeepSeek，大模型终于理解时间了！Time-R1一统过去/未来/生成  新智元  https://mp.weixin.qq.com/s/HOG8Es3sefi91f7XoMDhNQ \
  最近，来自伊利诺伊大学香槟分校的研究人员发布了一份突破性成果Time-R1，基于一个仅3B的小模型，通过精心设计的三阶段的课程强化学习，实现理解过去、预测未来甚至创造性生成大一统。 \
  Time-Rl: Towards Comprehensive Temporal Reasoning in LLMs \
  代码地址：https://github.com/ulab-uiuc/Time-R1/tree/master \
  模型地址：https://huggingface.co/collections/ulab-ai/time-r1-682626aea47cb2b876285a16 \
  数据集地址：https://huggingface.co/datasets/ulab-ai/Time-Bench \
  直播回放：https://b23.tv/aArKNSY

# 6.10 Tue
* 37.通向通用神经细胞自动机的道路A Path to Universal Neural Cellular Automata  CreateAMind  https://mp.weixin.qq.com/s/DUlWrhlawaW-yWoGFCvOvw \
  A Path to Universal Neural Cellular Automata
* 38.大模型是「躲在洞穴里」观察世界？ 强化学习大佬「吹哨」提醒LLM致命缺点  机器之心  https://mp.weixin.qq.com/s/_5M7uc86kCTWxqSUSPkIfg \
  不是视频模型“学习”慢，而是LLM走捷径｜18万引大牛Sergey Levine  量子位  https://mp.weixin.qq.com/s/_AdhSCLGifNxtvVrZttI9Q \
  当前的大语言模型（LLM）只是对人类大脑和思维的间接「扫描」。这些模型如同被困在洞穴之中，只能看到人类智慧的「投影」，并试图通过这些「投影」来逆向推导出产生它们的思维过程。这种「逆向工程」并不能代替真正的思维。 \
  Language Models in Plato's Cave \
  未来十年，AI 研究面临的关键挑战是：既要从大语言模型的成功中汲取正确的经验，又要发现支撑真正灵活、适应性智能的基本原理 —— 那种能够从经验中学习、理解物理世界、为人类从未解决过的全新问题找到创新解决方案的智能。 \
  https://sergeylevine.substack.com/p/language-models-in-platos-cave
* 39.(**有趣**)揭秘LLM“思考”之谜：推理即“梯度下降”，元学习框架解构训练过程，还给优化提供新思路  量子位  https://mp.weixin.qq.com/s/siLzumwywCZEj9yA-TCn9g \
  上海AI Lab的研究团队的近期提出Reasoning as Meta-Learning（RaML)，尝试从梯度下降和元学习（Meta-Learning）的角度，揭示了LLM如何“思考”，并为优化其性能提供了新思路。 \
  Deciphering Trajectory-Aided LLM ReasoningAn Optimization Perspective 
* 40.李飞飞团队新作：DiT不训练直接改架构，模型深度减半，质量还提高了  机器之心  https://mp.weixin.qq.com/s/RGNoe4F9Eq188apb42UooA \
  Exploring Diffusion Transformer Designs via Grafting \
  https://grafting.stanford.edu/ 
* 41.扩散语言模型真的会比自回归好？理论分析结果可能恰恰相反  机器之心  https://mp.weixin.qq.com/s/TlzREeTdopcZNLLC2ZaCYQ \
  Theoretical Benefit and Limitation of Diffusion Language Model

# 6.11 Wed
* 42.「Next-Token」范式改变！刚刚，强化学习预训练来了  机器之心  https://mp.weixin.qq.com/s/UABVUoHYTDlFWWNvD5R9Og \
  Reinforcement Pre-Training  \
  RPT 将传统的对 next-token 的预测任务重构为对 next-token 的推理过程：对于预训练语料中的任意上下文，模型需在预测前对后续 Token 进行推理，并通过与语料真实的 next-token 比对获得可验证的内在奖励。

# 6.12 Thur
* 43.刚刚，LeCun亲自出镜，Meta推出新世界模型！  机器之心  https://mp.weixin.qq.com/s/i2lMeFX6VWWxqL_ZKmznfw \
  基于视频训练的世界模型 V-JEPA 2（全称 Video Joint Embedding Predictive Architecture 2）。其能够实现最先进的环境理解与预测能力，并在新环境中完成零样本规划与机器人控制。 \
  V-JEPA 2 拥有 12 亿参数，基于联合嵌入预测架构（JEPA）构建。在此之前，Meta 已经证明，JEPA 架构在处理图像和 3D 点云等模态方面出色的表现。 \
  V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning \
  项目链接：https://github.com/facebookresearch/vjepa2 \
  HuggingFace链接：https://huggingface.co/collections/facebook/v-jepa-2-6841bad8413014e185b497a6 \
  项目网站：https://ai.meta.com/vjepa/ \
  WM具备以下几种能力：(1)理解：世界模型应该能够理解世界的观察，包括识别视频中物体、动作和运动等事物。(2)预测：一个世界模型应该能够预测世界将如何演变，以及如果智能体采取行动，世界将如何变化。(3)规划：基于预测能力，世界模型应能用于规划实现给定目标的行动序列。
* 44.LeCun世界模型出2代了！62小时搞定机器人训练，开启物理推理新时代  量子位  https://mp.weixin.qq.com/s/M1mKgpz4ecCIC3xKq50k-A \
  GitHub：https://github.com/facebookresearch/vjepa2 \
  Hugging Face：https://huggingface.co/collections/facebook/v-jepa-2-6841bad8413014e185b497a6
* 45.何恺明新作：给扩散模型加正则化，无需预训练无需数据增强，超简单实现性能提升  量子位  https://mp.weixin.qq.com/s/jjxYNTbdlT5VO05hQMxkkQ \
  Diffuse and Disperse: Image Generation with Representation Regularization \
  让中间表示在隐藏空间中分散
* 46.CVPR 2025 多模态大一统：斯坦福 x 复旦提出符号主义建模生成式任务  机器之心  https://mp.weixin.qq.com/s/_kGEve0032Tjklh2mh1r5w \
  Symbolic Representation for Any-to-Any Generative Tasks \
  https://github.com/Jiaqi-Chen-00/Any-2-Any \
  框架设计的核心思路在于对生成任务本质的解构：任何复杂的多模态生成过程，本质上都可以拆解为「做什么」（函数）、「怎么做」（参数）和「执行顺序」（拓扑）三个要素

# 6.13 Fri
* 47.图灵奖得主、强化学习之父Richard Sutton：LLM主导只是暂时，扩展计算才是正解  图灵人工智能  https://mp.weixin.qq.com/s/cbPq4iSl-efEzuGg_xSRKA \
  Welcome to the Era of Experience \
  设计出能自主设计的Agent
* 48.AGI真方向？谷歌证明：智能体在自研世界模型，世界模型is all You Need  机器之心  https://mp.weixin.qq.com/s/k-hd-M1XK7fsH2LI80r5AA \
  General agents need world models \
  世界模型是实现灵活、目标导向行为的必要要素，还是无需模型的学习就已足够？Google DeepMind 研究人员为这个问题提供了一个正式的答案——任何能够泛化到多步骤目标导向任务的智能体都必须学习其环境的预测模型。

# 6.14 Sat
* 49.(**值得看看**)LLM已能自我更新权重，自适应、知识整合能力大幅提升，AI醒了？   机器之心  https://mp.weixin.qq.com/s/WvC7kX1_XfNO218YBsAa8g \
  本月初我们就曾梳理报道了一些，包括 Sakana AI 与不列颠哥伦比亚大学等机构合作的「达尔文-哥德尔机（DGM）」、CMU 的「自我奖励训练（SRT）」、上海交通大学等机构提出的多模态大模型的持续自我改进框架「MM-UPT」、香港中文大学联合 vivo 等机构的自改进框架「UI-Genie」，参阅文章《LSTM 之父 22 年前构想将成真？一周内 AI「自我进化」论文集中发布，新趋势涌现？》 \
  MIT 昨日发布的《Self-Adapting Language Models》就是最新的例证之一，其中提出了一种可让 LLM 更新自己的权重的方法：SEAL🦭，即 Self-Adapting LLMs。在该框架中，LLM 可以生成自己的训练数据（自编辑 /self-editing），并根据新输入对权重进行更新。而这个自编辑可通过强化学习学习实现，使用的奖励是更新后的模型的下游性能。
  Self-Adapting Language Models \
  https://jyopari.github.io/posts/seal \
  https://github.com/Continual-Intelligence/SEAL
* 50.苹果《思考的错觉》再挨批，Claude与人类共著论文指出其三大关键缺陷  机器之心  https://mp.weixin.qq.com/s/hK8ruewbC-LR4vwHnJh4Pg \
  https://garymarcus.substack.com/p/seven-replies-to-the-viral-apple

# 6.15 Sun
* 51.模型遗忘不代表记忆抹除！首次系统发现「可逆性遗忘」背后规律  新智元  https://mp.weixin.qq.com/s/V2M5w0ImgIKT5kPmsLjz1Q \
  Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs \
  论文中整理成了一个统一的表示层分析工具箱（PCA相似度与偏移、CKA、Fisher信息），支持诊断大模型在Unlearning / Relearning / Finetuning等过程中的内在变化。
* 52.复旦大学/上海创智学院邱锡鹏：Context Scaling，通往AGI的下一幕  机器之心  https://mp.weixin.qq.com/s/Knej0qbyr5j5KX_BO7FGew 

# 6.16 Mon
* 53.

# 6.17 Tue
# 6.18 Wed
# 6.19 Thur
# 6.20 Fri
# 6.21 Sat
# 6.22 Sun

# 6.23 Mon
# 6.24 Tue
# 6.25 Wed
# 6.26 Thur
# 6.27 Fri
# 6.28 Sat
# 6.29 Sun

# 6.30 Mon
