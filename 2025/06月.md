# 6.1 Sun
* 1.从推理到学习：基于大语言模型的假设发现与规则学习综述  专知  https://mp.weixin.qq.com/s/S8iWkp5Ob6b17ScgF903ng \
  From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models
* 2.SFT在帮倒忙？新研究：直接进行强化学习，模型多模态推理上限更高  机器之心  https://mp.weixin.qq.com/s/oJNtHlfz4Jwv2a-9JvqoZA \
  SFT 可能会阻碍学习 —— 经常导致出现伪推理路径，而 RL 则是在促进真正的多模态推理！ \
  SFT or RL? An Early Investigation into Training R1-Like Reasoning Large Vision-Language Models \
  https://ucsc-vlaa.github.io/VLAA-Thinking/
* 3.Mamba核心作者新作：取代DeepSeek在用的注意力机制，专为推理打造  量子位  https://mp.weixin.qq.com/s/61k_W7m21hWBYv2Er00E9A \
  Grouped-Tied Attention（GTA）  Grouped Latent Attention（GLA） \
  在保持模型性能不变的情况下，将解码速度和吞吐量最高提升2倍，大大优化了模型的长上下文推理能力

# 6.2 Mon
* 4.AI数学能力暴涨100%，自进化直逼RL极限！CMU新作颠覆认知  图灵人工智能  https://mp.weixin.qq.com/s/PVi5J3pX9IdcwKgl0CXihA \
  「自奖励训练」（SRT） \
  Can Large Reasoning Models Self-Train? \
  https://github.com/tajwarfahim/srt
* 5.LeCun新作反杀AGI派！AI连「鸟」都搞不懂，拿什么超越人类？  新智元  https://mp.weixin.qq.com/s/nv59rJhXkkUgEE19uEr4zg \
  LLM根本不会思考！LeCun团队新作直接戳破了大模型神话。最新实验揭示了，AI仅在粗糙分类任务表现优秀，却在精细任务中彻底失灵。 \
  From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning \
  究其原因，LLM的内部概念结构和人类直觉，有着根本性错位。也就是说，它们可能知道「鸟」这个词，却理解不了「鸟」的深层含义。LLM追求的是极致的统计压缩，而人类追求适应性语义丰富。
* 6.《元强化学习教程》书册，164页pdf  专知  https://mp.weixin.qq.com/s/_2z--RMORCetCpJFd7vmVw \
  A Tutorial on Meta-Reinforcement Learning
* 7.LSTM之父22年前构想将成真？一周内AI「自我进化」论文集中发布，新趋势涌现？  机器之心  https://mp.weixin.qq.com/s/0PPw4t2YCwu-7zrxpjglcA \
  Can Large Reasoning Models Self-Train?  \
  项目地址：https://self-rewarding-llm-training.github.io/ \
  代码地址：https://github.com/tajwarfahim/srt \
  数据集：https://huggingface.co/collections/ftajwar/self-rewarding-llm-training-6835218091832c3664176553 
* 8.微软等提出「模型链」新范式，与Transformer性能相当，扩展性灵活性更好  机器之心  https://mp.weixin.qq.com/s/UFqC41KYaE3h6KnbLw5iXQ \
  Chain-of-Model Learning for Language Model  \
  CoM 可以将不同规模的多个子模型集成到一个模型中，能够在现有模型的基础上进行扩展。这种能力直接赋予了基础模型更好的可扩展性和灵活性。
* 9.AI竟会「自己认错」？破解多智能体协作「罗生门」，斩获ICML 2025 Spotlight  新智元  https://mp.weixin.qq.com/s/dIhJj6Z6WmBAobM3Ay1YjQ \
  在多智能体AI系统中，一旦任务失败，开发者常陷入「谁错了、错在哪」的谜团。PSU、杜克大学与谷歌DeepMind等机构首次提出「自动化失败归因」，发布Who&When数据集，探索三种归因方法，揭示该问题的复杂性与挑战性。 \
  Which Agent Causes Task Failures and When? On Automated Failure Attribution of LL Multi-Agent Systems \
  自动化失败归因（Automated Failure Attribution）

# 6.3 Tue
* 10.图灵奖得主杨立昆：等基于50年前旧数据打造信息论框架，驳斥大模型能复制人类认知的观点  图灵人工智能  https://mp.weixin.qq.com/s/6k0NA1RxZyxwcOnQbwpgpA \
  图灵奖得主&美国纽约大学教授杨立昆（Yann LeCun）联合美国斯坦福大学团队打造出一款信息论框架，借此揭示了大模型和人类的一个根本差异：即两者在平衡信息压缩和语义意义上采用了截然不同的策略。 \
  From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning \
  虽然大模型形成了与人类判断相一致的广泛概念类别，但它们很难捕捉到对人类理解至关重要的细粒度语义区别。从更根本的层面看，大模型展现出对激进的统计压缩的强烈偏好，而人类的概念系统似乎更重视适应性的细腻差别与语境的丰富性，即便这在研究团队的衡量标准下意味着较低的压缩效率。
* 11.李飞飞空间智能独角兽开源底层技术！AI生成3D世界在所有设备流畅运行空间智能的“着色器”来了  量子位  https://mp.weixin.qq.com/s/rUtF0BIGxUZxR65h5ZzAGQ \
  Forge渲染器，可在桌面端、低功耗移动设备、XR等所有设备上实时、流畅地渲染AI生成的3D世界
* 12.过程监督>结果监督！华为港城重构RAG推理训练，5k样本性能反超90k模型  PaperWeekly  https://mp.weixin.qq.com/s/4N66Ezu4si1q8ymlPzaaXw \
  Process vs. Outcome Reward: Which is Better for Agentic RAG Reinforcement Learning \
  https://github.com/wlzhang2020/ReasonRAG
* 13.经典ReLU回归！重大缺陷「死亡ReLU问题」已被解决  机器之心  https://mp.weixin.qq.com/s/b29WfOloGFIyh-j8EfV96A 
* 14.思维链也会「跳帧」？浙大团队提出CoT-Bridge，显著提升数学推理性能  机器之心  https://mp.weixin.qq.com/s/Gjz9CLEGngOBpKRnZ_GC_A \
  Thought Leap 指的是 CoT 推理链中，前后步骤之间存在中间推理内容的省略，导致逻辑跳跃，破坏推理的连贯性。 \
  CoT-Bridge：为模型补上思维跳跃的 “桥梁” \
  Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning

# 6.4 Wed
* 15.让AI像人类一样认知真实世界！UCLA谷歌强强联手，长时记忆+3D空间理解超越基线16.5%  量子位  https://mp.weixin.qq.com/s/Vv8VtTUtCx0wH1aG5Ig-Pg \
  3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model \
  https://3dllm-mem.github.io
* 16.万字追问：如何用“时间的本质”，丈量人脑、意识与人工智能？  追问  https://mp.weixin.qq.com/s/RRY-rIqgChuVfXNAox9odw 
* 17.(**值得看看**)最新发现！每参数3.6比特，语言模型最多能记住这么多  机器之心  https://mp.weixin.qq.com/s/DAoNui-_u0IlBjHl16wn-g \
  语言模型到底能记住多少信息？Meta、DeepMind、康奈尔大学和英伟达的一项测量结果显示：每个参数大约 3.6 比特。一旦达到这个极限，它们就会停止记忆并开始泛化。 \
  How much do language models memorize? \
  研究团队从形式上将记忆分为两个组成部分：(1)非预期记忆 —— 模型包含的关于特定数据集的信息；(2)泛化 —— 模型包含的关于真实数据生成过程的信息。 \
  研究团队在规模不断增大的数据集上训练语言模型，观察到模型会持续记忆，直到其容量饱和，此时「顿悟」（grokking）现象开始出现，非预期记忆随之减少，模型开始泛化。也就是说，在海量数据上训练的语言模型根本不可能记住所有训练数据，因为根本没有足够的容量。
* 18.英伟达揭示RL Scaling魔力！训练步数翻倍=推理能力质变，小模型突破推理极限  机器之心  https://mp.weixin.qq.com/s/RmeTW83hjTQYJLpl435o6A \
  强化学习（RL）到底是语言模型能力进化的「发动机」，还是只是更努力地背题、换个方式答题？这个问题，学界争论已久：RL 真能让模型学会新的推理技能吗，还是只是提高了已有知识的调用效率？ \
  过去的研究多数持悲观态度：认为 RL 带来的收益非常有限，有时甚至会让模型「同质化」加重，失去多样性。然而，来自英伟达的这项研究指出，造成这一现象的根本原因在于：数学、编程等任务在 base model 的训练数据中被过度呈现，以及 RL 训练步数不足。 \
  ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models \
  ProRL 来了！长期训练 = 推理能力质变！

# 6.5 Thur
* 19.OpenAI久违发了篇「正经」论文：线性布局实现高效张量计算  机器之心  https://mp.weixin.qq.com/s/iln4Kz0A2ou8r-P2qgKz4w \
  Linear Layouts: Robust Code Generation of Efficient Tensor Computation Using 𝔽₂
* 20.上海AI实验室造出首个「通才」机器人大脑：看懂世界+空间推理+精准操控全拿下  量子位  https://mp.weixin.qq.com/s/SBQVZgZ8mVJRqkwstoCJUA \
  通用具身智能大脑框架：Visual Embodied Brain，简称VeBrain \
  该模型通过同时集成视觉感知、空间推理和机器人控制能力，可实现多模态大模型（MLLM）对物理实体的直接操控，使机器人能像人类一样“看到-思考-行动” \
  论文链接：https://huggingface.co/papers/2506.00123/ \
  项目主页：https://internvl.github.io/blog/2025-05-26-VeBrain/ \
  推理代码&模型链接：https://internvl.github.io/blog/2025-05-26-VeBrain/
* 21.(**非常值得看看**)DeepMind揭惊人答案：智能体就是世界模型！跟Ilya 2年前预言竟不谋而合  新智元  https://mp.weixin.qq.com/s/8y8DmrxxBLSbxCpf9reNoA \
  General agents need world models \
  Intrinsically Motivated Discovery of TemporallyAbstract World Model Graphs \
  任何能够泛化到多步目标导向任务的智能体，必然已经学习了其环境的预测模型。这个模型可以从智能体的策略中提取出来；而要提升智能体的性能，或让其完成更复杂的目标任务，就必须学习更精确的世界模型。 \
  这些算法补全了规划和逆强化学习的三位一体关系。 \
  规划：世界模型+目标→策略 \
  逆强化学习：世界模型+策略→目标 \
  研究者提出的这一环：策略+目标→世界模型

# 6.6 Fri
* 22.Entropy速递：冥想时，你的大脑经历了什么？  集智俱乐部  https://mp.weixin.qq.com/s/luXvlmAtmNfmp0kqSMH5zA \
  Thoughtseeds: A Hierarchical and Agentic Framework for Investigating Thought Dynamics in Meditative States \
  思想种子框架引入了一种新颖的计算方法来模拟冥想状态下思维动态过程，将思想种子概念化为整合信息的动态注意力主体。该分层模型由嵌套的马尔可夫毯构成，包含三个相互关联的层级：（一）作为信息库的知识领域；（二）思想种子相互竞争的思想种子网络；（三）调节意识的元认知。该模型通过基于规则的训练来模拟专注注意力的内观冥想，训练依据的是关于注意力稳定性和神经动态的实证神经科学研究。四种状态——呼吸控制、走神、元意识和重新调整呼吸——从思想种子的相互作用中自然产生，展示了自组织动态。结果表明，专家能够保持控制主导地位以强化专注注意力，而初学者则频繁出现长时间的走神情况，反映出其不稳定性。将全局工作空间理论（Global Workspace Theory）与内在激发框架（Intrinsic Ignition Framework）相结合，该模型阐明了思维种子如何通过元意识塑造统一的冥想体验，通过主动推理平衡认知和实用功能。将计算建模与现象学见解相结合，它为认知状态的出现和转变提供了一种具身视角，并对冥想技能的发展提出了可检验的预测。该框架为注意力调节、元认知意识和冥想状态的出现提供了见解，为未来对各种冥想实践（例如开放监测、非二元意识）、整个生命周期的认知发展以及基于正念的注意力障碍干预的临床应用的研究奠定了灵活的基础，从而加深了我们对心智和思维本质的理解。

# 6.7 Sat
* 23.李飞飞最新访谈：世界模型即将“降临”  Datawhale  https://mp.weixin.qq.com/s/TsF4uYlBND5Tw3BwR-m7Gw \
  “语言固然是一种极其强大的思想与信息编码方式，但它在描述所有动物及生命体赖以生存的三维物理世界方面，其实并非一种强大的编码。”她认为，人类智能的绝大部分都超越了语言范畴，语言在捕捉和描绘真实世界时是一种“有损的途径”，且其本质是“纯粹是生成性的”，自然界中本不存在固有的音节或词汇。相反，“整个物理的、感知的、视觉的世界却真实存在。”

# 6.8 Sun
* 24.SFT+RL双阶训练突破LLM自我监督！人大DeepCritic实现AI批判自主进化  PaperWeekly  https://mp.weixin.qq.com/s/SsMm67zPds9gPWLk45weTA \
  DeepCritic: Deliberate Critique with Large Language Models \
  https://github.com/RUCBM/DeepCritic
* 25.苹果炮轰推理模型全是假思考！4个游戏戳破神话，o3/DeepSeek高难度全崩溃  量子位  https://mp.weixin.qq.com/s/WRPjXZRm4QRGOUzsJ4FxGA \
  The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity \
  这篇论文称推理模型全都没在真正思考，无论DeepSeek、o3-mini还是Claude 3.7都只是另一种形式的“模式匹配”，所谓思考只是一种假象。再遇到真正高复杂度的任务时所有模型都会崩溃，即使给他们足够的时间和计算资源也无济于事。 \
  有网友讽刺纵使苹果拥有最多的资金，2年了也没有拿出像样的成果，现在自己落后了，却来否定别人的成果。
* 26.为什么用错奖励，模型也能提分？新研究：模型学的不是新知识，是思维  机器之心  https://mp.weixin.qq.com/s/gJYfFvNHg3O8ACFGns_tYA \
  研究者解释道，强化学习对下游任务的提升，关键不仅在于奖励的准确性，而更在于模型是否能够产生高质量的思考过程。仅通过奖励模型输出中关键思考词的出现频率，而非基于答案正确性的奖励，语言模型依然能够在下游任务中取得非常高的峰值表现。这表明，强化学习对下游任务的提升，更多来源于让模型学会采用恰当的思考路径接近正确答案。而相关的解题基础能力，模型已在预训练阶段获得。因此，预训练阶段的能力提升依然至关重要。
* 27.告别「失忆」AI！首个大模型记忆操作系统开源框架来了！  机器之心  https://mp.weixin.qq.com/s/YNId1fSqST2Cw5BF_I3cRg \
  大语言模型受限于固定上下文窗口，长期对话中「失忆」、记忆断裂等问题频发，北邮百家 AI 团队重磅推出首个大模型记忆操作系统开源框架 MemoryOS。巧妙融合计算机操作系统原理与人脑分层记忆机制，构建段页式三级存储架构及四大核心模块（存储、更新、检索、生成），提供全链路用户记忆管理方案，让 AI 智能体拥有持久「记性」与深度「个性」。 \
  https://github.com/BAI-LAB/MemoryOS
* 28.算力终结者来了！华人天团「降维打击」注意力瓶颈，AI狂飙进对数时代  新智元  https://mp.weixin.qq.com/s/6yIV2yCnAFe7CognsjNqng \
  Log-Linear Attention
* 29.逆向工程：ChatGPT 的记忆是如何工作的  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/s0vkEu1tu9MWn7lM2gHlDg \
  当前会话历史 (Current Session History) 对话历史 (Conversation History)  用户洞察 (User Insights)

# 6.9 Mon
* 30.Nature：大脑中的多时间尺度强化学习  集智俱乐部  https://mp.weixin.qq.com/s/sLKJuhsPmp1YRQgZikrLPw \
  Multi-timescale reinforcement learning in the brain
  为了在复杂环境中生存并获得成功，动物和人工智能体必须学会自适应地行动，以最大化适应度（fitness）和奖励（rewards）。这种自适应行为可以通过强化学习（reinforcement learning）习得，这类算法不仅在训练人工智能主体方面取得了成功，还在刻画中脑多巴胺能神经元（dopaminergic neurons）放电活动中发挥了作用。在经典强化学习模型中，智能体根据单一时间尺度（timescale）——即折扣因子（discount factor）——对未来奖励进行指数折扣。本文探讨了生物强化学习中多个时间尺度（multiple timescales）的存在。我们首先展示了在多重时间尺度上学习的强化学习智能体所具有的独特计算优势。随后，我们报道了在执行两种行为任务的小鼠中，多巴胺能神经元以多种折扣时间常数（discount time constants）编码奖励预测误差（reward prediction error）。模型解释了在由线索诱发的瞬时响应和称为多巴胺攀升（dopamine ramps）的更慢时间尺度波动中观察到的时间折扣异质性。更重要的是，单个神经元在两种任务中测得的折扣因子呈现高度相关性，表明这是一种细胞特异性（cell-specific）的属性。综合而言，我们的研究为理解多巴胺能神经元功能异质性提供了新的范式，并为人类和动物在多种情境下采用非指数折扣（non-exponential discounts）的经验观察提供了机理基础，同时也为设计更高效的强化学习算法开辟了新途径。
* 31.记忆传递的神经细胞自动机模型  CreateAMind  https://mp.weixin.qq.com/s/ojaGipGs4IAJeHS66pg86A \
  EngramNCA: a Neural Cellular Automaton Model of Memory Transfer
* 32.首创像素空间推理，7B模型领先GPT-4o，让VLM能像人类一样「眼脑并用」  量子位  https://mp.weixin.qq.com/s/wjW2UIi6x4fNU0sqSRzxzQ \
  Pixel Reasoner: Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning \
  「像素空间推理」赋予模型「视觉手术刀」般的能力：视觉主动操作、视觉主导推理 \
  https://tiger-ai-lab.github.io/Pixel-Reasoner/
* 33.大模型能够自发形成“人类思维地图”！Nature子刊重磅研究揭示多模态大模型类脑机制  量子位  https://mp.weixin.qq.com/s/UfkEV0Hu48Y0Hje9N4JRKQ \
  大模型内部存在着类似人类对现实世界概念的理解。 \
  Human-like object concept representations emerge naturally in multimodal large language models \
  何晖光老师NB
* 34.李飞飞自曝详细创业经历：五年前因眼睛受伤，坚定要做世界模型  量子位  https://mp.weixin.qq.com/s/8Eq__c8nV7tghJ4XMadUMg \
  而当前的技术突破点在于：如何让AI像人类一样，从单目视觉输入中重建完整三维场景理解。 
* 35.苹果炮轰AI推理遭打脸，GitHub大佬神怒怼！复杂任务≠推理能力  新智元  https://mp.weixin.qq.com/s/F3ngj_UJzRuKlmcdLxRJHQ 
* 36.3B超越DeepSeek，大模型终于理解时间了！Time-R1一统过去/未来/生成  新智元  https://mp.weixin.qq.com/s/HOG8Es3sefi91f7XoMDhNQ \
  最近，来自伊利诺伊大学香槟分校的研究人员发布了一份突破性成果Time-R1，基于一个仅3B的小模型，通过精心设计的三阶段的课程强化学习，实现理解过去、预测未来甚至创造性生成大一统。 \
  Time-Rl: Towards Comprehensive Temporal Reasoning in LLMs \
  代码地址：https://github.com/ulab-uiuc/Time-R1/tree/master \
  模型地址：https://huggingface.co/collections/ulab-ai/time-r1-682626aea47cb2b876285a16 \
  数据集地址：https://huggingface.co/datasets/ulab-ai/Time-Bench \
  直播回放：https://b23.tv/aArKNSY

# 6.10 Tue
* 37.通向通用神经细胞自动机的道路A Path to Universal Neural Cellular Automata  CreateAMind  https://mp.weixin.qq.com/s/DUlWrhlawaW-yWoGFCvOvw \
  A Path to Universal Neural Cellular Automata
* 38.大模型是「躲在洞穴里」观察世界？ 强化学习大佬「吹哨」提醒LLM致命缺点  机器之心  https://mp.weixin.qq.com/s/_5M7uc86kCTWxqSUSPkIfg \
  不是视频模型“学习”慢，而是LLM走捷径｜18万引大牛Sergey Levine  量子位  https://mp.weixin.qq.com/s/_AdhSCLGifNxtvVrZttI9Q \
  当前的大语言模型（LLM）只是对人类大脑和思维的间接「扫描」。这些模型如同被困在洞穴之中，只能看到人类智慧的「投影」，并试图通过这些「投影」来逆向推导出产生它们的思维过程。这种「逆向工程」并不能代替真正的思维。 \
  Language Models in Plato's Cave \
  未来十年，AI 研究面临的关键挑战是：既要从大语言模型的成功中汲取正确的经验，又要发现支撑真正灵活、适应性智能的基本原理 —— 那种能够从经验中学习、理解物理世界、为人类从未解决过的全新问题找到创新解决方案的智能。 \
  https://sergeylevine.substack.com/p/language-models-in-platos-cave
* 39.(**有趣**)揭秘LLM“思考”之谜：推理即“梯度下降”，元学习框架解构训练过程，还给优化提供新思路  量子位  https://mp.weixin.qq.com/s/siLzumwywCZEj9yA-TCn9g \
  上海AI Lab的研究团队的近期提出Reasoning as Meta-Learning（RaML)，尝试从梯度下降和元学习（Meta-Learning）的角度，揭示了LLM如何“思考”，并为优化其性能提供了新思路。 \
  Deciphering Trajectory-Aided LLM ReasoningAn Optimization Perspective 
* 40.李飞飞团队新作：DiT不训练直接改架构，模型深度减半，质量还提高了  机器之心  https://mp.weixin.qq.com/s/RGNoe4F9Eq188apb42UooA \
  Exploring Diffusion Transformer Designs via Grafting \
  https://grafting.stanford.edu/ 
* 41.扩散语言模型真的会比自回归好？理论分析结果可能恰恰相反  机器之心  https://mp.weixin.qq.com/s/TlzREeTdopcZNLLC2ZaCYQ \
  Theoretical Benefit and Limitation of Diffusion Language Model

# 6.11 Wed
* 42.「Next-Token」范式改变！刚刚，强化学习预训练来了  机器之心  https://mp.weixin.qq.com/s/UABVUoHYTDlFWWNvD5R9Og \
  Reinforcement Pre-Training  \
  RPT 将传统的对 next-token 的预测任务重构为对 next-token 的推理过程：对于预训练语料中的任意上下文，模型需在预测前对后续 Token 进行推理，并通过与语料真实的 next-token 比对获得可验证的内在奖励。

# 6.12 Thur
* 43.刚刚，LeCun亲自出镜，Meta推出新世界模型！  机器之心  https://mp.weixin.qq.com/s/i2lMeFX6VWWxqL_ZKmznfw \
  基于视频训练的世界模型 V-JEPA 2（全称 Video Joint Embedding Predictive Architecture 2）。其能够实现最先进的环境理解与预测能力，并在新环境中完成零样本规划与机器人控制。 \
  V-JEPA 2 拥有 12 亿参数，基于联合嵌入预测架构（JEPA）构建。在此之前，Meta 已经证明，JEPA 架构在处理图像和 3D 点云等模态方面出色的表现。 \
  V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning \
  项目链接：https://github.com/facebookresearch/vjepa2 \
  HuggingFace链接：https://huggingface.co/collections/facebook/v-jepa-2-6841bad8413014e185b497a6 \
  项目网站：https://ai.meta.com/vjepa/ \
  WM具备以下几种能力：(1)理解：世界模型应该能够理解世界的观察，包括识别视频中物体、动作和运动等事物。(2)预测：一个世界模型应该能够预测世界将如何演变，以及如果智能体采取行动，世界将如何变化。(3)规划：基于预测能力，世界模型应能用于规划实现给定目标的行动序列。
* 44.LeCun世界模型出2代了！62小时搞定机器人训练，开启物理推理新时代  量子位  https://mp.weixin.qq.com/s/M1mKgpz4ecCIC3xKq50k-A \
  GitHub：https://github.com/facebookresearch/vjepa2 \
  Hugging Face：https://huggingface.co/collections/facebook/v-jepa-2-6841bad8413014e185b497a6
* 45.何恺明新作：给扩散模型加正则化，无需预训练无需数据增强，超简单实现性能提升  量子位  https://mp.weixin.qq.com/s/jjxYNTbdlT5VO05hQMxkkQ \
  Diffuse and Disperse: Image Generation with Representation Regularization \
  让中间表示在隐藏空间中分散
* 46.CVPR 2025 多模态大一统：斯坦福 x 复旦提出符号主义建模生成式任务  机器之心  https://mp.weixin.qq.com/s/_kGEve0032Tjklh2mh1r5w \
  Symbolic Representation for Any-to-Any Generative Tasks \
  https://github.com/Jiaqi-Chen-00/Any-2-Any \
  框架设计的核心思路在于对生成任务本质的解构：任何复杂的多模态生成过程，本质上都可以拆解为「做什么」（函数）、「怎么做」（参数）和「执行顺序」（拓扑）三个要素

# 6.13 Fri
* 47.图灵奖得主、强化学习之父Richard Sutton：LLM主导只是暂时，扩展计算才是正解  图灵人工智能  https://mp.weixin.qq.com/s/cbPq4iSl-efEzuGg_xSRKA \
  Welcome to the Era of Experience \
  设计出能自主设计的Agent
* 48.AGI真方向？谷歌证明：智能体在自研世界模型，世界模型is all You Need  机器之心  https://mp.weixin.qq.com/s/k-hd-M1XK7fsH2LI80r5AA \
  General agents need world models \
  世界模型是实现灵活、目标导向行为的必要要素，还是无需模型的学习就已足够？Google DeepMind 研究人员为这个问题提供了一个正式的答案——任何能够泛化到多步骤目标导向任务的智能体都必须学习其环境的预测模型。

# 6.14 Sat
* 49.(**值得看看**)LLM已能自我更新权重，自适应、知识整合能力大幅提升，AI醒了？   机器之心  https://mp.weixin.qq.com/s/WvC7kX1_XfNO218YBsAa8g \
  本月初我们就曾梳理报道了一些，包括 Sakana AI 与不列颠哥伦比亚大学等机构合作的「达尔文-哥德尔机（DGM）」、CMU 的「自我奖励训练（SRT）」、上海交通大学等机构提出的多模态大模型的持续自我改进框架「MM-UPT」、香港中文大学联合 vivo 等机构的自改进框架「UI-Genie」，参阅文章《LSTM 之父 22 年前构想将成真？一周内 AI「自我进化」论文集中发布，新趋势涌现？》 \
  MIT 昨日发布的《Self-Adapting Language Models》就是最新的例证之一，其中提出了一种可让 LLM 更新自己的权重的方法：SEAL🦭，即 Self-Adapting LLMs。在该框架中，LLM 可以生成自己的训练数据（自编辑 /self-editing），并根据新输入对权重进行更新。而这个自编辑可通过强化学习学习实现，使用的奖励是更新后的模型的下游性能。
  Self-Adapting Language Models \
  https://jyopari.github.io/posts/seal \
  https://github.com/Continual-Intelligence/SEAL
* 50.苹果《思考的错觉》再挨批，Claude与人类共著论文指出其三大关键缺陷  机器之心  https://mp.weixin.qq.com/s/hK8ruewbC-LR4vwHnJh4Pg \
  https://garymarcus.substack.com/p/seven-replies-to-the-viral-apple

# 6.15 Sun
* 51.模型遗忘不代表记忆抹除！首次系统发现「可逆性遗忘」背后规律  新智元  https://mp.weixin.qq.com/s/V2M5w0ImgIKT5kPmsLjz1Q \
  Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs \
  论文中整理成了一个统一的表示层分析工具箱（PCA相似度与偏移、CKA、Fisher信息），支持诊断大模型在Unlearning / Relearning / Finetuning等过程中的内在变化。
* 52.复旦大学/上海创智学院邱锡鹏：Context Scaling，通往AGI的下一幕  机器之心  https://mp.weixin.qq.com/s/Knej0qbyr5j5KX_BO7FGew 

# 6.16 Mon

# 6.17 Tue
* 53.AGI理论比较：主动推理、强化学习、控制论、贝叶斯大脑、效用决策、有限理性、情感动机、动态体内平衡  图灵人工智能  https://mp.weixin.qq.com/s/tecDyfkB-oFWSUQIRC7o7w
* 54.(**值得看看**)大脑的“压缩算法”：Nat Commun研究揭示人类泛化学习背后的机制  集智俱乐部  https://mp.weixin.qq.com/s/h_c9eEAAxxASEBECEMCENw \
  Humans learn generalizable representations through efficient coding \
  强化学习理论将人类行为解释为受最大化奖励这一目标的驱动。然而，传统方法对于人们如何从过往经验推广到新情境提供的见解有限。在此，我们提出通过纳入高效编码原则来改进经典强化学习框架，该原则强调使用最简必要的表征来最大化奖励。这一改进后的框架预测，受更简单表征所限的智能体必然：1）将环境刺激提炼为更少的抽象内部状态，以及 2）检测并利用环境中的奖励特征。因此，复杂刺激被映射到紧凑的表征，从而为泛化奠定基础。我们在两项考察人类泛化能力的实验中检验了这一想法。我们的研究结果表明，传统模型在泛化方面表现不佳，但纳入高效编码的模型达到了人类水平的表现。我们认为，将高效编码加入经典强化学习目标，能构建一个更全面的计算框架，有助于理解人类在学习和泛化方面的行为。

# 6.18 Wed
55.通向世界模型关键一步：EX-4D来了，实现单目视频到自由视角生成  机器之心  https://mp.weixin.qq.com/s/U4zom1havvpV4NwNXL65Vg \
  EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh
  项目主页链接: https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html \
  代码链接: https://github.com/tau-yihouxiang/EX-4D
56.(**非常重要**)沉迷贪吃蛇，7B小模型竟变身「数学天才」！几何推理碾压GPT-4o  新智元  https://mp.weixin.qq.com/s/_gXH6dImQ2o6YU8PHjFJdQ \
  Play to Generalize: Learning to Reason Through Game Play \
  NVIDIA等研究团队提出了一种革命性的AI训练范式——视觉游戏学习ViGaL。通过让7B参数的多模态模型玩贪吃蛇和3D旋转等街机游戏，AI不仅掌握了游戏技巧，还培养出强大的跨领域推理能力，在数学、几何等复杂任务上击败GPT-4o等顶级模型。 \
  研究者发现，AI从贪吃蛇这类简单游戏中领悟到的，并非只是如何通关的技巧，而是一种更加底层、更通用的认知能力——一种可以跨领域迁移的「直觉」与推理能力。也许，智能并不一定只是来源于海量知识的「压缩」，也可能蕴藏于最简单的规则和最纯粹的游戏之中。
57.√N并行+84倍计算加速！英伟达港大全新图像注意力：空间结构都保留  新智元  https://mp.weixin.qq.com/s/sRWVPluSQHehKWsMFEJVqQ 
58.统一框架下的具身多模态推理：自变量机器人让AI放下海德格尔的锤子  机器之心  https://mp.weixin.qq.com/s/PAMxpArVFwyAEVOhcq_UAw \
  真正的具身智能不应该是多个专门模块的协作，而应该像人类认知一样，在统一的计算框架内同时处理感知、推理和行动。

# 6.19 Thur
59.(**值得看看**)田渊栋：连续思维链效率更高，可同时编码多个路径，“叠加态”式并行搜索  量子位  https://mp.weixin.qq.com/s/y0AxT-nUivq2oPSf5RktmQ \
  Reasoning by Superposition: A TheoreticalPerspective on Chain of Continuous Thought \
  田渊栋领衔来自UC伯克利、UCSD的科学家们利用连续空间中的 “叠加态”，让大模型进行并行推理，大幅提升了模型在图可达性等任务中的表现，给上述连续思维链提供了理论支持。

# 6.20 Fri
60.大模型参与推理崩溃论战！从「思维错觉」到「错觉的错觉」再到「错觉的错觉的错觉」  量子位  https://mp.weixin.qq.com/s/o6UkRmLa4Pq_VSWBxVGKoA \
  当问题复杂度继续增加并超过某个临界点时，无论是推理模型还是标准模型都会经历完全的性能崩溃，准确率直线下降至零，甚至会减少思考token。
61.突破开放世界移动操作！首个室内移动抓取多模态智能体亮相，微调模型真实环境零样本动作准确率达 90%  机器之心  https://mp.weixin.qq.com/s/K3AKhf9ctt4qsFukQFOb4g \
  近日，上海人工智能实验室联合新加坡国立大学、香港大学等机构的研究团队，提出了 "OWMM-Agent" 具身智能体——首个专为开放世界移动操作（OWMM）设计的多模态智能体 (VLM Agent) 架构，首次实现了全局场景理解、机器人状态跟踪和多模态动作生成的统一建模。 \
  OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data Synthesis \
  https://github.com/HHYHRHY/OWMM-Agent

# 6.21 Sat
62.那些相信AI必然产生意识的科学家们  追问nextquestion  https://mp.weixin.qq.com/s/18Tp3fKAj-CIWDYL39Pc1g \
  布卢姆夫妇指出，当AI和LLMs通过连接摄像头与触觉传感器获得更多实时感官输入时，意识就可能涌现
63.陶哲轩罕见长长长长长访谈：数学、AI和给年轻人的建议  量子位  https://mp.weixin.qq.com/s/W_rtX_YX4P_9NdDQ6uZYSg \
  菲尔兹奖得主陶哲轩，首次3小时非学术机构访谈来了！  Datawhale  https://mp.weixin.qq.com/s/m9Dx54ZIqCNtmjx1fEfd0g 
64.世界模型版《模拟人生》：AI虚拟小人街头演讲拉票，GPT-4o选举获胜  机器之心  https://mp.weixin.qq.com/s/ycuftcoJ60ua4vv3AtKuUA \
  地球副本上线！人类机器人蜂拥进入「世界模拟器」，复刻全球3D真实空间  新智元  https://mp.weixin.qq.com/s/zICxQp2DYXXJ6u4KJH-OQw \
  Virtual Community: An Open World for Humans, Robots, and Society \
  项目链接：https://virtual-community-ai.github.io/
65.月之暗面「调教」出最强Agent，在「人类最后一场考试」拿下最新 SOTA  机器之心  https://mp.weixin.qq.com/s/1ektvvMVp_9z2VGgaK1_bw \
  这款 Agent 擅长多轮搜索和推理，平均每项任务执行 23 个推理步骤，访问超过 200 个网址。它是基于 Kimi k 系列模型的内部版本构建，并完全通过端到端智能体强化学习进行训练，也是国内少有的基于自研模型打造的 Agent。 \
  GitHub 链接：https://moonshotai.github.io/Kimi-Researcher/
66.通俗易懂的总结：对RL for LLM本质的理解  Datawhale  https://mp.weixin.qq.com/s/OBoCgJReCU8_eHhykbxqHg 
67.(**值得看看**)知识储备≠模型能力！DeepMind强化学习微调：大幅缩小「知行差距」  新智元  https://mp.weixin.qq.com/s/agjpg0oED-IanpSVHNm4IA \
  ILMs are Greedy Agents: Effects of RIFine-tuning on Decision-Making Abilities \
  大语言模型（LLMs）在决策场景中常因贪婪性、频率偏差和知行差距表现欠佳。研究者提出强化学习微调（RLFT），通过自我生成的推理链（CoT）优化模型，提升决策能力。实验表明，RLFT可增加模型探索性，缩小知行差距，但探索策略仍有改进空间。

# 6.22 Sun
68.主动推理世界模型实现分钟级游戏策略学习，开源可复现，仅10000步骤内掌握多种游戏  CreateAMind  https://mp.weixin.qq.com/s/Goh-knkSlDxZsghJqMQ3GA \
  AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models \
  https://github.com/VersesTech/axiom
69.英伟达笑到最后！训练2000步，1.5B逆袭7B巨兽，Scaling真来了  新智元  https://mp.weixin.qq.com/s/WwLzBO-EZLwsZM9weaGufQ \
  刚刚，英伟达团队提出全新训练方法——ProRL，成功将RL扩展到2000步。基于此方法，研究团队训出的1.5B模型，性能直接媲美Deepseek-R1-7B！这就是强化学习的Scaling Law：强化学习训练越长，LLM推理能力越强。 \
  只要将RL训练足够久，AI推理能力就能实现质的飞跃！ \
  ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models
70.大模型到底是怎么「思考」的？第一篇系统性综述SAE的文章来了  机器之心  https://mp.weixin.qq.com/s/DNg4O4pirbiT56PP_6VtAQ \
  A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models
71.(**值得看看**)从RLHF、PPO到GRPO再训练推理模型，这是你需要的强化学习入门指南  机器之心  https://mp.weixin.qq.com/s/TZRqK8Waj3bt2VTeyZYjmg \
  Reinforcement Learning Guide \
  https://docs.unsloth.ai/basics/reinforcement-learning-guide \
  https://github.com/unslothai/unsloth

# 6.23 Mon
72.Dify MCP 保姆级教程来了！  Datawhale  https://mp.weixin.qq.com/s/w_43x5fFVfDPDgMorn3XfA
73.我在哪？要去哪？要怎么去？字节跳动提出Astra双模型架构助力机器人自由导航  机器之心  https://mp.weixin.qq.com/s/wsAytJe6TQpsGfjlNbbCyA \
  Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal Learning \
  https://astra-mobility.github.io/
74.AI真的需要「像人类」那样思考吗？AlphaOne揭示属于大模型的「思考之道」  机器之心  https://mp.weixin.qq.com/s/FxMSNJqEHImzGbmW8BXReg \
  AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time \
  项目主页：https://alphaone-project.github.io/ \
  代码地址：https://github.com/ASTRAL-Group/AlphaOne \
  AlphaOne 的核心，是引入统一的调控点 α-moment：α-moment 之前通过 Bernoulli 过程插入「慢思考」标记，之后用终止标记切换为快思考，实现无需训练的连续推理调控。

# 6.24 Tue
75.LLM推理能力深度解析  CreateAMind  https://mp.weixin.qq.com/s/gfTyFsC8buUwOQ1xhp0s5w \
  Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus
76.强化学习新发现：无需数学样本，仅游戏训练AI推理大增  机器之心  https://mp.weixin.qq.com/s/d1h7y12PRF7OYhiW7Z5EuA \
  Play to Generalize: Learning to Reason Through Game Play \
  https://yunfeixie233.github.io/ViGaL/
77.(**有趣**)ACL 2025 | 让小说角色 「活」起来！复旦BookWorld打造沉浸式小说世界模拟系统  机器之心  https://mp.weixin.qq.com/s/3GboKJgQDwL8aefNbk4I4g \
  BookWorld: From Novels to Interactive Agent Societies for Creative Story Generation \
  在BookWorld中，作者们提出了一个“小说->AI世界->故事创作”的系统。BookWorld能从小说中提取角色和世界观的数据，构建一个AI世界，让角色AI在世界中进行长期的交互，自己创造自己的故事。为了实现流畅自然的长期交互，BookWorld建模了角色AI、世界AI、空间关系、世界观构建，并支持用户干预来引导故事发展。 \
  传统的小说创作往往受限于作者的想象力，一旦故事完结，角色们就被 "封印" 在书页中。而现有的 AI 系统虽然能够生成文本、模拟社会互动，但大多是从零开始构建角色，缺乏对已有小说世界的深度理解和还原。BookWorld 的突破在于，它能够从原著小说中提取角色特征、世界观设定和背景知识，构建出一个完整的虚拟社会。在这个世界里，每个角色都拥有自己的记忆、状态和目标，能够像真实人物一样工作、交流和交易。
78.万字长文深入浅出教你优雅开发复杂AI Agent  Datawhale  https://mp.weixin.qq.com/s/-EVLZLMeJpfRGIZbYOPFbg 
79.7B小模型超越DeepSeek-R1：模仿人类教师，弱模型也能教出强推理LLM | Transformer作者团队  量子位  https://mp.weixin.qq.com/s/TQBWalcM4fdB--m2oR8CJQ

# 6.25 Wed
80.Cache Me If You Can：陈丹琦团队如何「抓住」关键缓存，解放LLM内存？  机器之心  https://mp.weixin.qq.com/s/hzXU3-0Jz7t9173A2_NOnw 
81.机器人视觉语言导航进入R1时代！港大联合上海AI Lab提出全新具身智能框架  量子位  https://mp.weixin.qq.com/s/XhcnUxYUXi2jvX51u3zpsw \
  VLN-R1：让LVLM采用类Deepseek-R1范式成为具身导航会思考的“大脑”
82.谷歌发布本地具身智能模型！全程无联网执行精细操作，从人形机器人到工业机器人全覆盖  量子位  https://mp.weixin.qq.com/s/oyT1CRRdbUxfF9cvApePRg \
  刚刚，首个能在机器人上本地运行的具身Gemini来了  机器之心  https://mp.weixin.qq.com/s/mjZAAvVtPevYDD5HfexN6g \
  Gemini Robotics On-Device
83.提示词工程、RAG之后，LangChain：上下文工程开始火了！  机器之心  https://mp.weixin.qq.com/s/saoLsddSpku3aWpQQYVGww \
  https://blog.langchain.com/the-rise-of-context-engineering/ \
  我们可以将提示工程视为上下文工程的一个子集。即使你拥有所有的上下文，如何在提示中组装它仍然至关重要。区别在于，你不仅仅是在设计一个与单一输入数据有效的提示，而是要处理一组动态数据并将其正确格式化。
84.人形机器人首次打通视觉感知与运动断层，UC伯克利华人博士让宇树G1现场演示  量子位  https://mp.weixin.qq.com/s/NWGQQblD-yEf1DKquZNZTg \
  这是来自UC伯克利、卡内基梅隆大学等团队的最新研究成果LeVERB框架——基于模拟数据训练实现零样本部署，让人形机器人通过感知新环境，理解语言指令就能直接完成全身动作。 \
  LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction
85.让多模态大模型「想明白再画」！港大等开源GoT-R1：强化学习解锁视觉生成推理新范式  机器之心  https://mp.weixin.qq.com/s/sPdhPeNMkdBLjtLzI5urwg \
  GoT-Rl: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning
86.人类创造力的核心机制，AI已经开始掌握了 | 北大CogSci 2025（Oral）  量子位  https://mp.weixin.qq.com/s/ZkkVx3TXUIiwe-XNyyWj3Q \
  Probing and Inducing Combinational Creativity in Vision-Language Models

# 6.26 Thur
87.全模态RAG突破文本局限，港大构建跨模态一体化系统  量子位  https://mp.weixin.qq.com/s/lFKyKvm0luZTpx8_nGyWEw \
  RAG终极框架！港大开源RAG-Anything：统一多模态知识图谱  新智元  https://mp.weixin.qq.com/s/VuowC1hvE3P4RxIfYDZlLA \
  RAG-Anything
88.让LLM自己上网搞科研！WebDancer实现DeepResearch级自主推理  PaperWeekly  https://mp.weixin.qq.com/s/-_JSLkUpjFF1YE7SsYh_xg
89.什么是认知地图？  CreateAMind  https://mp.weixin.qq.com/s/GFdTbQjouhKxiz9DrPF-5w \
  What Is a Cognitive Map? Organizing Knowledge for Flexible Behavior \
  认知地图的核心在于其结构性知识的抽象与泛化能力 ，能够通过有限的经验进行推理、规划和泛化到新情境。这种结构不仅支持空间导航，也参与社会关系、时间序列、因果推理等多种非空间任务

# 6.27 Fri
90.从二维到三维认知：通用世界模型简要综述  专知  https://mp.weixin.qq.com/s/2YXwIOCj0NPsl7Lqe6qHqA \
  From 2D to 3D Cognition: A Brief Survey of General World Models
91.(**好奇心奖励**)AI 开始「自由玩电脑」了！吉大提出「屏幕探索者」智能体  机器之心  https://mp.weixin.qq.com/s/NF6CfOVsSPVU--M8YMNu5Q \
  ScreenExplorer: Training a Vision-Language Model for Diverse Exploration in Open GUI World
  ???什么是世界模型的好奇心奖励 -> 针对开放 GUI 环境反馈稀疏问题，创新性地引入「好奇心机制」，利用世界模型预测环境状态转移，估算环境状态的新颖度，从而有效激励智能体主动探索多样化的界面状态，告别「原地打转」
92.ICML 2025 | 何恺明的“残差连接”被魔改，新架构给Transformer建了个“动态立交”，28亿参数打平69亿  夕小瑶  https://mp.weixin.qq.com/s/2NfrxGYd1V_YQzcqqh9E9A \
  多路动态密集连接（Multiway Dynamic Dense Connection, MUDD）
93.一文读懂向量数据库，原理到应用全解析！  Datawhale  https://mp.weixin.qq.com/s/MZzv85dhsDjM-A29NrEfHA 
94.一文详细了解：大模型三大缩放定律（Scaling Law）  AINLPer  https://mp.weixin.qq.com/s/TmANwuqCawcq1Zr3vfNgFg \
  「预训练Scaling法则（Pretraining Scaling Law）」、「后训练Scaling法则（Post-Training Scaling Law）和推理阶段Scaling法则（Test-Time Scaling Law，又称Long Thinking）」

# 6.28 Sat

# 6.29 Sun
95.Gary Marcus惊世之言：纯LLM上构建AGI彻底没了希望！MIT、芝大、哈佛论文火了  机器之心  https://mp.weixin.qq.com/s/rWvDwEjf-E8faRSSBQmY0Q \
  Potemkin Understanding in Large Language Models
  这项研究揭示了一种被称为「波将金式」（Potemkins）的推理不一致性模式（见下文图 1）。研究表明，即使是像 o3 这样的顶级模型也频繁犯此类错误。基于这些连自身论断都无法保持一致的机器，你根本不可能创造出通用人工智能（AGI）
96.打破长视频理解瓶颈：HoPE混合位置编码提升VLM长度泛化能力  机器之心  https://mp.weixin.qq.com/s/KQHGw8_v0rEY8pS7jufRbQ 
97.盘一盘，2017年Transformer之后，LLM领域的重要论文  机器之心  https://mp.weixin.qq.com/s/1lUSlc0tvEWLuOFOP0WkUA \
  信息过载时代，如何真正「懂」LLM？从MIT分享的50个面试题开始  机器之心  https://mp.weixin.qq.com/s/u7aIm6jP1Nblfjr2NvakLw 
98.“观测的主体性不可忽视”：量子与类量子理论中的互补性、因果性及事件之矢  集智俱乐部  https://mp.weixin.qq.com/s/U0RovM3nQgTBUL9FUzHMSw \
  ‘The agency of observation not to be neglected’: complementarity, causality and the arrow of events in quantum and quantum-like theories \
  我们在量子实验中通过观察和测量去扰动并定义现实，这一过程与人类的创造性心理活动有某种相似之处，比如诗人 Eliot 在写作时所经历的反复抉择与修改。短短一分钟内，我们体验到大量主观感受（称为“感受质（qualia）”），这些构成了意识难题的核心。如此多的内在体验，使得任何数学模型都难以准确预测人在短时间内做出又推翻的决定。文学（如 Eliot 的诗、Proust 或 Joyce 的作品[31]）正是这种复杂心理过程的体现。它们展现了意识流、记忆重构与语言创造之间无尽的互动，其深度和丰富性远超当前任何形式化模型所能捕捉。尽管类量子理论在某些认知情境下比经典模型更具解释力，但它依然无法完全涵盖人类思维的全部层面，尤其是在涉及意识、情感、意义和创造力的领域。这些正是科学尚未能触及的人类经验核心。
99.本地模型接入本地MCP实践！保姆教程来了  Datawhale  https://mp.weixin.qq.com/s/_xg4uQ6-IGjri7lIBxUOqQ 

# 6.30 Mon
100.马斯克Neuralink脑机接口新成果！看完头皮发麻  量子位  https://mp.weixin.qq.com/s/MCseDe2DhwX3kHpJX_9UWA \
  https://www.youtube.com/watch?v=FASMejN_5gs
101.LeCun发布最新世界模型：首次实现16秒连贯场景预测，具身智能掌握第一视角！还打脸用了VAE  量子位  https://mp.weixin.qq.com/s/MBTNAYeu-J_9MI_-jpxQBA \
  Whole-Body Conditioned Egocentric Video Prediction \
  项目地址：https://dannytran123.github.io/PEVA/
102.比女皇报告还炸裂！67页AI深度调研刷屏，全球LLM大决战真正开始  新智元  https://mp.weixin.qq.com/s/XKHqP-dDIaK0ny8iIJK9aA \
  如何高效构建AI？如何规模化落地？如何快速试错？ \
  https://cdn.prod.website-files.com/65d0d38fc4ec8ce8a8921654/685ac42fd2ed80e09b44e889_ICONIQ%20Analytics_Insights_The_AI_Builders_Playbook_2025.pdf
103.(**可以看看**)只用2700万参数，这个推理模型超越了DeepSeek和Claude  机器之心  https://mp.weixin.qq.com/s/PousJsp2TP7cTUTUwtf6ZA \
  Hierarchical Reasoning Model 层次化推理模型
104.(**可以看看**)会“思考”的目标检测模型来了！IDEA提出Rex-Thinker：基于思维链的指代物体检测模型，准确率+可解释性双突破  机器之心  https://mp.weixin.qq.com/s/I0YU0lkrkJ7_bNLdYdY72w \
  Rex-Thinker: Grounded Obiect Referring viaChain-of-Thought Reasoning \
  项目主页：https://rexthinker.github.io/  \
  开源代码：https://github.com/IDEA-Research/Rex-Thinker
105.新鲜出炉！斯坦福2025 CS336课程全公开：从零开始搓大模型  Datawhale  https://mp.weixin.qq.com/s/QtBvFInkl3UDPdpRHp67_w \
  斯坦福大学 2025 年春季的 CS336 课程「从头开始创造语言模型（Language Models from Scratch）」相关课程和材料现已在网上全面发布！  \
  课程视频：https://www.youtube.com/watch?v=SQ3fZ1sAqXI&list=PLoROMvodv4rOY23Y0BoGoBGgQ1zmU_MT_ \
  课程主页：https://stanford-cs336.github.io/spring2025/

