# 4.1 Tue
* 1.R1–Zero强化学习路线新发现及R1思路用于GUI Agent动作预测方案  老刘说NLP  https://mp.weixin.qq.com/s/cFkOEyrG3bnFPldX9VWP2w \
  继续来看大模型可解释性，最近的工作 《Understanding R1-Zero-Like Training: A Critical Perspective》（https://arxiv.org/abs/2503.20783，https://github.com/sail-sg/understand-r1-zero） ，结论很有趣，研究了多种基础模型，以了解预训练特性如何影响RL性能。 \
  看第二个工作，《UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning》(https://arxiv.org/pdf/2503.21620，https://github.com/lll6gg/UI-R1)，基于规则的RL如何增强多模态大模型(MLLM)对图形用户界面(GUI)动作预测任务的推理能力。
* 2.给GRPO提提速！厦大 | 提出强化学习算法：CPPO，最高8倍加速！  AINLPer  https://mp.weixin.qq.com/s/ijlMoLwlkG9AXYZC89376A \
  CPPO: Accelerating the Training of Group Relative Policy Optimization-Based Reasoning Models \
  https://github.com/lzhxmu/CPPO

# 4.2 Wed
* 3.主动推理隐含最小意识理论  CreateAMind  https://mp.weixin.qq.com/s/knGg6C2PTTA-D1d9B5eHSA \
  On the minimal theory of consciousness implicit in active inference \
  体验的多面性给意识的研究带来了挑战。传统神经科学方法通常专注于孤立的方面，例如感知意识或意识的整体状态，并围绕相关的经验范式和发现构建理论。因此，意识理论往往难以比较；事实上，这些理论试图解释的现象可能几乎没有重叠之处。在这里，我们采用了一种不同的方法：从主动推理（active inference）开始，这是一种基于贝叶斯推理（Bayesian inference）建模行为的首要原则框架，并逐步构建出一种最小化的意识理论，这种理论从主动推理下推导出的计算模型的共同特征中涌现出来。我们回顾了一系列将主动推理模型应用于意识研究的工作，并认为所有这些模型中都隐含着一组小的理论承诺，这些承诺指向了一种最小化（且可检验的）意识理论。
* 4.是什么、如何、何处，以及效果如何？——大语言模型测试时扩展的调研  专知  https://mp.weixin.qq.com/s/7uTIt9Z3-DFnJtEw4deDnw \
  从四个核心维度来结构化 TTS 研究：扩展什么、如何扩展、在何处扩展、扩展效果如何 \
  What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models
* 5.一个LangChain与MCP结合使用的案例！  Datawhale  https://mp.weixin.qq.com/s/MA17aivO4Oe3iv_trlj2Ag 
* 6.动态场景，开放文本查询！清华哈佛联合建模4D语言场 | CVPR 2025  新智元  https://mp.weixin.qq.com/s/x4JTo-eujTPnPFRP3R-Dhg 
* 7.AI理解27分钟长视频超越GPT-4o，港理工新国立开源新框架：角色化推理+链式LoRA  量子位  https://mp.weixin.qq.com/s/Tw_eZmeCYTTCtIkvbkjX7w \
  港理工、新加坡国立团队推出VideoMind框架，核心创新在于角色化推理（Role-based Reasoning）和链式LoRA（Chain-of-LoRA）策略。 \
  VideoMind的提出不仅在于视频理解性能的突破，更在于提出了一个模块化、可扩展、可解释的多模态推理框架。该框架首次实现了类似人类行为的“指定计划、搜索片段、验证结果、回答问题”流程，真正让AI能“像人类一样理解视频”，为未来的视频理解和多模态智能系统领域奠定了基础。 \
  VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning \
  https://videomind.github.io/
* 8.脑波解码延迟仅80毫秒，实时「意念对话」技术登Nature子刊  机器之心  https://mp.weixin.qq.com/s/HcgdYRHYQxRHuRvE7nbgbg \
  A streaming brain-to-voice neuroprosthesis to restore naturalistic communication
* 9.2025美国最新奥数题，让大模型集体翻车，DeepSeek R1平均分也不到5%  机器之心  https://mp.weixin.qq.com/s/TT1Owl925f4Ky1vReKpYwA \
  PROOF OR BLUFF? EVALUATING LLMS ON 2025 USA MATH OLYMPIAD \
  https://github.com/eth-sri/matharena \
  所有模型都无法解决超过一个问题，这凸显了当前大型语言模型在奥林匹克级数学推理任务中的局限性。这表明现有优化方法如 GRPO 对需要高度逻辑精确性的任务可能尚不足够。
* 10.用 MCP 让大模型自动批量解读文献，保姆级教程来了！  Datawhale  https://mp.weixin.qq.com/s/VWlntkxCtB-FLzAistng_w
* 11.有深度！Transformer | 万字长文：详细了解前馈神经网络（FFN），内含对大模型的理解  AINLPer  https://mp.weixin.qq.com/s/XLW0iU2XLwDmv5jGd6tckg

# 4.3 Thur
* 12.视觉SSL终于追上了CLIP！Yann LeCun、谢赛宁等新作，逆转VQA任务固有认知  机器之心  https://mp.weixin.qq.com/s/V7Ml_xgiiQalxnGQmIWi_Q \
  CLIP被淘汰了？LeCun谢赛宁新作，多模态训练无需语言监督更强！  新智元  https://mp.weixin.qq.com/s/FpisxJQ9AXHV26lHPwzy5A \ 
  在最近的一项研究中，Yann LeCun、谢赛宁等研究者探讨了一个基本问题： 语言监督对于多模态建模的视觉表征预训练是否必要？ \
  Scaling Language-Free Visual Representation Learning
* 13.智能体丝滑玩手机，决策延迟0.7秒！MSRA等提出验证器架构，不直接依赖大模型生成最终操作  量子位  https://mp.weixin.qq.com/s/GxTJrTp-gfg0N1wchpYptg \
  Advancing Mobile GUl Agents: A Verifier-Driven Approach to Practical Deployment
* 14.DeepMind闭关修炼「我的世界」，自学成才挖钻登Nature！人类玩家瑟瑟发抖  新智元  https://mp.weixin.qq.com/s/OgjLy_jE9Rk9iZhioPRTDQ \
  Mastering diverse control tasks through world models
* 15.浙大校友重磅革新Transformer！多token注意力让LLM开挂，错误率归0  新智元  https://mp.weixin.qq.com/s/LoVCN-4WsEEK8ZuEyWCyrA \
  Multi-Token Attention

# 4.4 Fri
* 16.信息分解和大脑的信息架构  CreateAMind  https://mp.weixin.qq.com/s/3tV9f-Vq6E14lLjdOB8OZQ \
  Information decomposition and the informational architecture of the brain \
  为了阐述大脑如何协调信息处理以实现认知功能，我们必须理解信息本身。至关重要的是，信息并非是一个单一的实体。信息分解技术提供了一种将信息拆分为其构成要素的方法：独特信息、冗余信息和协同信息。我们回顾了如何通过区分协同和冗余的相互作用来重新定义我们对大脑整合功能及其神经组织的理解。为了阐释大脑如何在冗余和协同之间权衡取舍，我们回顾了整合多方面证据，包括协同和冗余的结构、分子和功能基础；它们在认知和计算中的作用；以及它们是如何在进化和发育过程中产生的。总体而言，区分协同和冗余信息为理解大脑和认知的信息架构提供了一个指导原则。
* 17.动态框架中的挑战与解决方案  CreateAMind  https://mp.weixin.qq.com/s/QH9JNdUBJIcSdo82i5yWJg \
  Integrated Information Theory and the Phenomenal Binding Problem: Challenges and Solutions in a Dynamic Framework \
  基于神经科学的意识理论必须解释现象学的结合问题，例如微观信息单元是如何组合成人类现象学中常见的宏观意识体验的。一个例子是，视觉场景中的单个“像素”被体验为“心灵之眼”中的单一整体图像，而不是作为个体的、分离的、大规模并行的体验，这些体验可能分别对应于单个神经元激活、神经元集合或中央凹扫视，从信息处理的角度来看，任何一种都可能提供相同的功能。现象学结合问题存在多个有争议的候选解决方案。本文探讨了集成信息理论（IIT）4.0版本的形而上学基础如何提供一种独特的解决方案。这种解决方案——即可以从多个单元聚合而成的特定实体（“复合体”）定义了存在——可能在静态图像中有效，但在动态系统中引入了问题。我们问，当主要复合体在生物神经网络中移动时，我们的现象学自我会发生什么。我们对意识实体随时间发展的描述，导致了 IIT 理论家面临的一个明显困境，即非局域实体转换与连续自我的选择：“动态实体演化问题”。除了明确这一困境外，我们还描述了 IIT 可能在其站稳脚跟之前化解这一困境的三种方式。阐明 IIT 在现象学结合问题上的立场，可能借助新的实证或理论研究作为支撑，有助于研究人员理解 IIT 并评估其合理性。我们认为我们的论文有助于 IIT 当前的研究重点，即从静态分析向动态分析的转变。 \
  像素（感知单元）如何连接成一幅图像（感知整体）
* 18.元认知，元元认知  CreateAMind  https://mp.weixin.qq.com/s/Z3gwFb0mADh8s0O-33GY5g \
  元认知粒子、心理行动与代理感知 \
  主动推理隐含最小意识理论 \
  意识理论列表
* 19.DeepSeek R2来了？全新推理时Scaling论文联手清华震撼发布！  新智元  https://mp.weixin.qq.com/s/kZF1sJlIxIlCXv9j0iBWgQ \
  Inference-Time Scaling for Generalist Reward Modeling

# 4.5 Sat
* 20.7B扩散LLM，居然能跟671B的DeepSeek V3掰手腕，扩散vs自回归，谁才是未来？  机器之心  https://mp.weixin.qq.com/s/CVssj4w-UPXodjIO640_Ww \
  香港大学和华为诺亚方舟实验室的一项研究就是其中之一。他们刚刚发布的扩散推理模型 Dream 7B 拿下了开源扩散语言模型的新 SOTA，在各方面都大幅超越现有的扩散语言模型。 \
  Dream 7B 最终选择了 Qwen2.5 7B 的权重作为初始化基础。在训练过程中，作者发现学习率参数至关重要：设置过高会迅速冲淡初始权重中宝贵的从左到右知识，对扩散训练几无助益；设置过低则会束缚扩散训练的进展。作者精心选择了这个参数以及其他训练参数。 \
  https://hkunlp.github.io/blog/2025/dream/
* 21.三思而后行，让大模型推理更强的秘密是「THINK TWICE」？  机器之心  https://mp.weixin.qq.com/s/xCN70_gwjkRTAh7nWdtggA \
  Think Twice: Enhancing LLM Reasoning by Scaling Multi-round Test-time Thinking \
  https://github.com/a-m-team/a-m-models \
  “Think Twice” 展示了一种简单有效的思路：鼓励大模型主动 “反思”，用多轮推理激发更强的认知能力。它不仅提升了准确率，更令模型在语言表达上变得更加理性、紧凑、自信。 \
  在训练成本不断攀升的今天，这种无需再训练的 “轻量级优化” 无疑具有极强的现实吸引力。未来，多轮推理或许能成为一种标准机制，帮助模型更接近真正意义上的 “会思考”。
* 22.对神经流形与认知回路的统一视角  CreateAMind  https://mp.weixin.qq.com/s/68IJc8HzJyqhOCu7RqmCOg \
  A unifying perspective on neural manifolds and circuits for cognition \
  两种不同的视角为解释大脑与行为之间的联系提供了理论基础。一种方法试图识别执行特定功能的神经回路元件，强调神经元之间的连接性作为神经计算的基础。另一种方法则聚焦于神经流形——即在神经群体活动中行为信号的低维表示——并提出神经计算通过涌现动力学来实现。尽管神经流形揭示了异质性神经活动中的可解释结构，但在连接性中找到相应的结构仍然是一项挑战。我们重点介绍了一些例子，在这些例子中，建立低维活动与连接性之间的对应关系是可能的，从而统一了神经流形和神经回路的观点。这种关系在神经反应的几何结构反映其在大脑中空间布局的系统中尤为显著，例如苍蝇导航系统。此外，我们描述了证据表明，在神经反应具有异质性的系统中，回路由通过低秩连接性作用于流形上的活动模式间的相互作用组成。我们认为，如果我们要能够因果性地测试关于行为背后的神经计算理论，那么统一流形和回路的方法至关重要。

# 4.6 Sun
* 23.LLM「想太多」有救了！高效推理让大模型思考过程更精简  新智元  https://mp.weixin.qq.com/s/dTNB7ueI5Vd8OC9TrvqBjA \
  Stop Overthinking: A Survey on Effcient Reasoning for Large Language Models \
  https://github.com/Eclipsess/Awesome-Efficient-Reasoning-LLMs
* 24.多模态融合与视觉-语言模型：面向机器人视觉的综述  专知  https://mp.weixin.qq.com/s/DWoXDlh_bBe9-E96v-zKEw \
  Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision \
  https://github.com/Xiaofeng-Han-Res/MF-RV
* 25.Meta深夜开源Llama 4！首次采用MoE，一张H100就能跑，竞技场超越DeepSeek  Datawhale  https://mp.weixin.qq.com/s/m8SWReTOvVyeAhY0uyX4Zg \
  Llama 4 Scout，16位专家的170亿激活参数的多模态模型，单个H100 GPU可运行， 同类SOTA，并拥有10M上下文窗口 \
  Llama 4 Maverick，128位专家的170亿激活参数多模态模型，击败GPT-4o和Gemini 2.0 Flash，与DeepSeek-V3同等代码能力参数只要一半，主打与DeepSeek一样的性价比，单个H100主机即可运行。

# 4.7 Mon
* 26.Science颠覆认知：你的大脑不是“机器”，而是一支交响乐团！  图灵人工智能  https://mp.weixin.qq.com/s/XOcyTVWrMbHnYk_vlJfnSQ \
  传统神经科学聚焦于孤立脑区的功能定位，但行为和认知是多个脑区协同作用的“涌现特性”（emergent properties）。传统神经科学建立在Brodmann分区基础上，其本质是笛卡尔式机械还原论。现代连接组学（Connectomics）揭示：认知功能是分布式网络在相空间中涌现的吸引子状态。oni的整合信息理论）。
* 27.深入解析图神经网络注意力机制：数学原理与可视化实现  图灵人工智能  https://mp.weixin.qq.com/s/LNrek7vcAwvdyB0UtQXsig 
* 28.视觉中的检索增强生成与理解：综述与新展望  专知  https://mp.weixin.qq.com/s/xRP86lob8QmKhiX9_QXiWg \
  Retrieval Augmented Generation and Understanding in Vision: A Survey and New Outlook
* 29.反向传播、前向传播都不要，这种无梯度学习方法是Hinton想要的吗？  机器之心  https://mp.weixin.qq.com/s/xXOe0Xw9kk3MGKvnoQejyQ \
  最近，来自牛津大学和 Mila 实验室的研究者向这一问题发起了挑战。他们开发了一种名为 NoProp 的新型学习方法，该方法既不依赖前向传播也不依赖反向传播。相反，NoProp 从扩散和流匹配（flow matching）方法中汲取灵感，每一层独立地学习对噪声目标进行去噪。 \
  NOPROP: TRAINING NEURAL NETWORKS WITHOUT BACK-PROPAGATION OR FORWARD-PROPAGATION
* 30.Rule-based强化学习≠古早逻辑规则！万字拆解o1多模态推理最新进展  PaperWeekly  https://mp.weixin.qq.com/s/8pwCPuXzXoMJsDmdL9tPGA \
  rule-based 的强化学习通过基于规则的奖励机制，成功地为模型提供了一种高效且可靠的优化途径 \
  本篇文章将讨论来自 Aligning Multimodal LLM with Human Preference: A Survey（https://arxiv.org/abs/2503.14504）中五篇近期关注多模态 O1-reasoning 相关的文章。
* 31.LLM幻觉，竟因知识「以大欺小」！华人团队祭出对数线性定律与CoDA策略  新智元  https://mp.weixin.qq.com/s/twUUI_esahGg6u3xGqMGIQ \
  「知识遮蔽」，即模型中的主导知识可以在文本生成过程中，掩盖那些不太突出的知识，从而导致模型编造不准确的细节 \
  The Law of Knowledge Overshadowing: Towards Understanding, Predicting, and Preventing LLM Hallucination \
  此研究深入研究了LLM幻觉，有4大亮点： \
  1 发现幻觉的对数线性规律：幻觉率随着相对知识流行度、相对知识长度和模型规模的对数线性增长 \
  2 在训练或推理前预测幻觉：在训练前「知识遮蔽效应」可预测幻觉发生的可能性 \
  3 提出全新解码策略CoDA（Contrastive Decoding with Attenuation）强调被遮蔽的知识，降低主流知识偏差，大幅提升LLM事实性（Factuality） \
  4 更可预测、更可控的语言模型正在成为现实！研究加深了对LLM幻觉机制的理解，为未来的可解释性与可控性研究打开新方向

# 4.8 Tue
* 32.通过三个条件对最小意识进行了特征描述：一个可证伪的新兴感知框架  CreateAMind  https://mp.weixin.qq.com/s/P3WUIWEiZlmVf5ZOCvcOOQ \
  Beyond Imitation Games: A Falsifiable Emergent Sentience Framework \
  自由能原理和意识是什么关系？
* 33.实现类比推理：概念超空间  CreateAMind  https://mp.weixin.qq.com/s/AdwK5rLbclpA1aBV9cwVjA \
  Analogical Reasoning Within a Conceptual Hyperspace \
  ?什么是类比推理
* 34.三个LLM顶一个OpenAI？2亿条性能记录加持，路由n个「小」模型逆袭  新智元  https://mp.weixin.qq.com/s/z8x6tMeqV98xacixq7m8ZA \
  RouterEval:A Comprehensive Benchmark for Routing LLMs to Explore Model-level Scaling Up in LLMs \
  https://github.com/MilkThink-Lab/RouterEval \
  https://github.com/MilkThink-Lab/Awesome-Routing-LLMs
* 35.Science：人类意识感知的“闸门”——高阶丘脑核团  集智俱乐部  https://mp.weixin.qq.com/s/Z43TimwVChC9Auyx8MaX8A \
  Human high-order thalamic nuclei gate conscious perception through the thalamofrontal loop

# 4.9 Wed
* 36.整合信息论IIT与现象绑定问题：自我意识动态演化框架中的挑战与解决方案模型  CreateAMind  https://mp.weixin.qq.com/s/mwiDXq67rHZ7WLTxOkteNg \
  Integrated Information Theory and the Phenomenal Binding Problem: Challenges and Solutions in a Dynamic Framework \
  基于神经科学的意识理论必须解释现象学的绑定结合问题，例如微观信息单元是如何组合成人类现象学中常见的宏观意识体验的。一个例子是，视觉场景中的单个“像素”被体验为“心灵之眼”中的单一整体图像，而不是作为个体的、分离的、大规模并行的体验，这些体验可能分别对应于单个神经元激活、神经元集合或中央凹扫视，从信息处理的角度来看，任何一种都可能提供相同的功能。现象学绑定结合问题存在多个有争议的候选解决方案。本文探讨了整合信息理论（IIT）4.0版本的形而上学基础如何提供一种独特的解决方案。这种解决方案——即可以从多个单元聚合而成的特定实体（“复合体”）定义了存在——可能在静态图像中有效，但在动态系统中引入了问题。我们问，当主要复合体在生物神经网络中移动时，我们的现象学自我会发生什么。我们对意识实体随时间发展的描述，导致了 IIT 理论家面临的一个明显困境，即非局域实体转换与连续自我的选择：“动态实体演化问题”。除了明确这一困境外，我们还描述了 IIT 可能在其站稳脚跟之前化解这一困境的三种方式。阐明 IIT 在现象学结合问题上的立场，可能借助新的实证或理论研究作为支撑，有助于研究人员理解 IIT 并评估其合理性。我们认为我们的论文有助于 IIT 当前的研究重点，即从静态分析向动态分析的转变。
* 37.英伟达253B开源新王登场，Llama 4三天变陪衬！直逼DeepSeek-R1成推理天花板  新智元  https://mp.weixin.qq.com/s/QbUTBKG9vrIVTA-6qII2gg 
* 38.从零搭一套可复现、可教学、可观察的RL for VLM训练流程，我们试了试  机器之心  https://mp.weixin.qq.com/s/SDUbYwWcwJMCZ2hrlnIqVA \
  Rethinking RL Scaling for Vision Language Models: A Transparent, From-Scratch Framework and Comprehensive Evaluation Scheme \
  https://github.com/GAIR-NLP/MAYE

# 4.10 Thur
* 39.统一 世界模型+认知架构+神经网络  CreateAMind  https://mp.weixin.qq.com/s/Xn6tV8FycSGr4W6irGmBPA \
  Bridging Cognitive Architectures and Generative Models with Vector Symbolic Algebras
* 40.上下文长度扩展：从RoPE到YARN  关于NLP那些你不知道的事 
https://mp.weixin.qq.com/s/gHUEufvzCeyNb-kMSjEDlg 
* 41.重磅：建模各种依赖概念信息的推理机制：统一框架，常识的构建  CreateAMind  https://mp.weixin.qq.com/s/J1_s5wYtw6Lefu72EFNVyQ \
  Reasoning with Concepts: A Unifying Framework

# 4.11 Fri
* 42.概念、连接主义与思维语言  CreateAMind  https://mp.weixin.qq.com/s/oE3296E4gfvJE7HkqPkR9g \
  Concepts, Connectionism, and the Language of Thought \
  http://www.mkdavies.net/Martin_Davies/Mind_files/ConceptsConnLoT.pdf
* 43.如何赋予大型语言模型三维能力？—大型语言模型中的空间推理综述  专知  https://mp.weixin.qq.com/s/YDFkVOLfsWJg4O4rQy0K_A \
  How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM

# 4.12 Sat
* 44.意义的几何与动态，概念空间语义学  CreateAMind  https://mp.weixin.qq.com/s/MvgsmJChHiMuBEo6lTQkhw \
  The Geometry and Dynamics of Meaning
* 45.手机实现GPT级智能，比MoE更极致的稀疏技术：省内存效果不减｜对话面壁&清华肖朝军  量子位  https://mp.weixin.qq.com/s/kANQBUD5-Y8I9JdLrSd3hg \
  面壁智能和清华走出了一条与MoE不同的路径——神经元级稀疏激活，让模型在保持性能的同时大幅降低资源消耗。 \
  Configurable Foundation Models: Building LLMs from a Modular Perspective \
  ???CFM（Configurable Foundation Models）
* 46.魔改AlphaZero后，《我的世界》AI老玩家问世，干活不用下指令  机器之心  https://mp.weixin.qq.com/s/Md2FJh0IQ3X-ztpRW4G5mA \
  现在，AI 可以不断主动学习、纠正错误，展现出了此前大模型智能体无法实现的一系列能力。 \
  看起来，新版的 AI 在与我们共同游戏时不再是催一下动一下了，它已经是一个有「主观能动性」的玩家，就像个和你共同玩过几百局游戏的老友一样。 \
  这项技术名为 AssistanceZero，出自加州大学伯克利分校（UC Berkeley）。值得注意的是，它并未接受大模型常见的 RLHF 训练。相反，它是由「assistance games」强化学习驱动的，研究人员认为，这是构建 AI 助手的更好途径。 \
  AI 在这个框架中并不会被动地接受人类反馈，而是寻求主动与人合作，通过推断目标而不断优化行为，这避免了 RLHF 中 AI 可能会出现的作弊行为，让 AI 可以采取更加协作的策略。 \
  AssistanceZero: Scalably Solving Assistance Games \
  https://github.com/cassidylaidlaw/minecraft-building-assistance-game
* 47.谢赛宁等新作上线，多模态理解生成大一统！思路竟与GPT-4o相似？  新智元  https://mp.weixin.qq.com/s/qUE7D8RDcTmmB1ZNNDB4mQ \
  Transfer betweenModalitieswithMetaQueries \
  https://xichenpan.com/metaquery/

# 4.13 Sun
* 48.意识计算模型-最小体验现象  CreateAMind  https://mp.weixin.qq.com/s/iQPPWnkfpbbbTFlN2F_lww \
  A Computational Model of Minimal Phenomenal Experience (MPE) \
  最小现象体验（MPE），或称“纯粹意识”，是一种基础的意识体验形式，其特征是具有反身性元意识，且缺乏常规现象学中的许多特征。它被描述为例如非概念化的、非时间性的、无自我的、无视角的。本文旨在利用自由能量原理（FEP）推导出的变分自由能量最小化的数学方法，开发一个MPE的计算模型。我采用计算神经现象学方法，在主动推断框架内形式化MPE的关键现象学特征。该模型包含参数深度，允许对生成模型参数进行高阶推断。我将特定的模型参数化与报告的MPE品质（如元意识、平静、无努力感和非概念化）联系起来。所提出的模型表明，当一个主体通过自我导向的意识和对其生成模型的调节实现极低的自由能量时，尤其是通过强调对意识本身的意识，MPE就会产生。该模型预测了MPE现象学的元素，包括一种无努力感、无时间感以及“零人称视角”的可能性。文中概述了对所提模型进行模拟的实施细节，以及实证验证的方向。
* 49.解释AGI，实现AGI，联想学习与主动推理  CreateAMind  https://mp.weixin.qq.com/s/bbbp7Ts0_ob3Kkw0AoOhJA \
  Associative Learning and Active Inference \
  联想学习是一种行为现象，个体基于刺激或事件的共同出现而发展出它们之间的联系。最初由巴甫洛夫在他的条件反射实验中研究，学习的基本原则已经通过发现广泛的学习现象而得到扩展。基于最小化奖励预测误差的概念，已经开发出了计算模型。特别是Rescorla-Wagner模型，是一个极大地影响了强化学习领域的著名模型。然而，这些模型的简单性限制了它们充分解释与学习相关的行为现象的多样性。在本研究中，我们采用了自由能原理，该原理表明生物系统努力在其对世界的内部模型下最小化惊讶或不确定性。我们将学习过程视为自由能的最小化，并研究其与Rescorla-Wagner模型的关系，重点关注学习的信息方面、不同类型的惊讶以及基于信念和价值的预测误差。此外，我们探讨了如何在主动推断框架内模拟众所周知的行为现象，如阻断、掩盖和潜在抑制。我们通过使用注意力的信息和新颖性方面来实现这一点，这些方面与看似矛盾的模型（如Mackintosh和Pearce-Hall模型）提出的类似想法共享。因此，我们证明了自由能原理，作为一个从第一性原理推导出的理论框架，可以整合基于经验实验提出的联想学习的思想和模型，并作为更好地理解大脑联想学习背后的计算过程的框架。
* 50.人类一生所学不过4GB，加州理工顶刊新研究引热议  量子位  https://mp.weixin.qq.com/s/tssPnTg1Bwk1_qkvBevTiA \
  人类信息处理速度仅为每秒10bit，而我们的感官系统却能以每秒10亿bit的速率收集数据。
* 51.强化学习带来的改进只是「噪音」？最新研究预警：冷静看待推理模型的进展  机器之心  https://mp.weixin.qq.com/s/acQeGwuSaxZrl8Mo1GPDLQ \
  A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths to Reproducibility \
  一些使用强化学习训练的模型确实表现出了适度的改进，但这些改进通常比监督微调所取得的成果更弱，而且它们通常不能很好地推广到新的基准 \
  尽管强化学习在某些情况下可能有助于改进较小的蒸馏模型，但它的好处被夸大了，需要更好的评估标准来了解哪些方法真正有效。此外，这不仅仅是强化学习和推理模型的问题，我认为 LLM 研究整体上都受到了影响
* 52.142页DeepSeek-R1 思维链技术：让我们一起<思考>大语言模型（LLM）的推理能力  专知  https://mp.weixin.qq.com/s/dqKsk_D1_1_M_giDfBHnzQ \
  DeepSeek-R1 Thoughtology: Let's <think>about LLM reasoning

# 4.14 Mon
* 53.浙大、OPPO等发布最新综述：基于多模态大模型的计算机、手机与浏览器智能体研究  PaperWeekly  https://mp.weixin.qq.com/s/ISafMq3tcWi5QyAP48h5vQ \
  OS Agents: A Survey on MLLM-based Agents for Computer, Phone and Browser Use \
  https://github.com/OS-Agent-Survey/OS-Agent-Survey
* 54.【CVPR2025】神经运动模拟器：在强化学习中突破世界模型的极限  专知  https://mp.weixin.qq.com/s/ne5naYW8BSNbY9Hw8LlOLg \
  Neural Motion Simulator: Pushing the Limit of World Models in Reinforcement Learning \
  具身系统不仅要模拟外部世界的模式，还需理解自身的运动动态。运动动态模型对于高效的技能习得和有效的规划至关重要。在本工作中，我们提出了神经运动模拟器 (MoSim)，这是一种基于当前观测和动作预测具身系统未来物理状态的世界模型。
* 55.更长思维并不等于更强推理性能，强化学习可以很简洁  机器之心  https://mp.weixin.qq.com/s/CXUScYyWJiTif0k8XpgQ4Q \
  有研究者认为这项研究揭示了强化学习存在的一个普遍问题：训练的目标只是为了获得奖励，而并非是解决问题。 \
  Concise Reasoning via Reinforcement Learning  \
  更长响应不一定能带来更好的性能
* 56.过程奖励模型也可以测试时扩展？清华、上海AI Lab 23K数据让1.5B小模型逆袭GPT-4o  机器之心  https://mp.weixin.qq.com/s/P2OPxTMzB6Zp8Rb3RN86wQ \
  GenPRM: Scaling Test-Time Compute of Process Reward Models via Generative Reasoning \
  通过测试时拓展提升过程奖励模型的过程监督推理能力
* 57.中科大、中兴提出新后训练范式：小尺寸多模态模型，成功复现R1推理  机器之心  https://mp.weixin.qq.com/s/Gj8Gr-WilIqfff2uuNRaLw \
  Boosting the Generalization and Reasoning of Vision Language Models with Curriculum Reinforcement Learning \
  本研究聚焦于提升小规模视觉-语言模型（VLMs）在推理能力和域外（OOD）泛化性能两个关键方面的表现。通过实证研究，我们发现强化学习不仅能有效提升模型的推理能力，更在视觉任务中展现出超出预期的泛化性能提升。
* 58.推理AI「脑补」成瘾，废话拉满！马里兰华人学霸揭开内幕  新智元  https://mp.weixin.qq.com/s/t5mVHRrWG4Y6pEPA1GJ0jg \
  研究发现，推理模型（如DeepSeek-R1、o1）遇到「缺失前提」（MiP）的问题时，这些模型往往表现失常：回答长度激增、计算资源浪费。本文基于马里兰大学和利哈伊大学的最新研究，深入剖析推理模型在MiP问题上的「过度思考」现象，揭示其背后的行为模式，带你一窥当前AI推理能力的真实边界。 \
  Missing Premise exacerbates Overthinking:Are Reasoning Models losings Critical Thinking Skil? \
  让模型意识到“缺失前提”的问题，避免对其进行过度思考
* 59.图灵奖得主LeCun：人类智能不是通用智能，下一代AI可能基于非生成式  量子位  https://mp.weixin.qq.com/s/kl2rkb1d4aoS2PsNK3I5_w \
  人类智能并非通用智能。我们的大脑是进化的产物，只擅长解决对生存有用的问题，而不是真正“通用”的计算…… \
  省流版如下： \
  LeCun直觉认为，下一代AI的突破可能基于非生成式； \
  否认AGI会在未来两年内实现，但十年内可能取得重大进展； \
  人类和动物的智能核心，不是语言，而是对物理世界的建模和行动规划； \
  创新可以来自世界任何角落；智能眼镜代表着AI技术落地的一个重要方向。 \
  A Path Towards Autonomous Machine Intelligence \
  我认为，未来的AI必须具备几个关键能力：(1)理解物理世界——不仅仅是处理符号或文本，而是真正“懂”现实世界的运作规律；(2)具备推理和规划能力——能够像人类一样思考“如果这样做，会发生什么”，并制定策略；(3)拥有持久记忆——不是简单的数据存储，而是能像人类一样长期积累和调用经验；(4)安全可控——AI必须严格遵循我们设定的目标，不能偏离或“自作主张”。 
* 60.学习即编程  CreateAMind  https://mp.weixin.qq.com/s/Xp7bXeppDYJ_nqQRCq7Tlg \
  Human spatiotemporal pattern learningas probabilistic program synthesis \
  人类能够从小量数据中学习各种结构化模式，从偏差-方差权衡的角度来看，这提出了一个难题：什么样的表示和算法能够支持人类学习的灵活性与数据稀缺性？一种可能性是人类通过“编程学习”：诱导概率模型以拟合观测数据。在此，我们通过一个实验测试人类在二维结构化模式领域的学习能力，实验中参与者根据点的先前轨迹反复预测其移动位置。我们将人类表现与标准的参数化和非参数化时间序列模型进行比较，同时还评估了两种贝叶斯程序合成模型，这些模型的假设在结构程度上有所不同：一种是组合高斯过程模型，另一种是结构化的“思维语言”（Language of Thought，LoT）模型。我们发现，人类模式学习的特征最好由LoT模型解释，这支持了人类结构学习的灵活性和数据效率可以通过在富有表现力的程序空间中进行概率推理来理解的观点。 \
  ???概率程序合成
  ???思维语言模型LoT
* 61.论文浅尝 | 迈向更全面的多模态大模型：多模态大模型如何突破模态与任务限制？（哈工大SCIR）  机器学习研究组订阅  https://mp.weixin.qq.com/s/8NQQiXsHId_ySHWM5jNKPw \
  https://github.com/threegold116/Awesome-Omni-MLLMs \
  全模态MLLMs（Omni-MLLMs）

# 4.15 Tue
* 62.类比作为一种搜索过程：维度视角  CreateAMind  https://mp.weixin.qq.com/s/RcgUOaBMI3j_l8uGoOdPpA \
  Analogy as a search procedure: a dimensional view \
  在本文中，我们基于概念空间理论，概述了一种综合性的复合类比方法。我们的算法模型将类比视为一种搜索程序，并基于类比相似性依赖于一种称为“维度显著性”的概念现象这一观点。我们区分了基于类别的类比、基于属性的类比、基于事件的类比和基于部分 - 整体的类比，并提出了用以在概念空间中明确表达它们的计算导向方法。
* 63.AI能看懂图像却算不好距离，上交时间-空间智能基准难倒9大顶尖多模态模型  量子位  https://mp.weixin.qq.com/s/yIRoyI1HbChLZv4GuvI7BQ \
  上海交通大学联合中国地质大学、南洋理工大学、智源研究院以及斯坦福大学的研究团队推出首个多模态大模型（MLLM）时空智能评测基准STI-Bench（Spatial-Temporal Intelligence Benchmark），向当前最先进的多模态大语言模型发起了关于精确空间时间理解的严峻挑战 \
  结果显示，即便是Gemini-2.5-Pro、GPT-4o、Claude-3.7-Sonnet、Qwen 2.5 VL等当前最强的多模态大模型，在需要定量分析真实世界空间关系和动态变化的任务上，表现并不尽人意 \
  发现了三大核心瓶颈：1.定量空间属性不准确;2.时间动态理解缺陷;3.跨模态整合能力薄弱
* 64.视觉自回归生成理解编辑大一统！北大团队多模态新突破，训练数据代码全面开源  量子位  https://mp.weixin.qq.com/s/96yyriyCmwnrGk4_M9_ZUg \
  VARGPT-v1.1: Improve Visual Autoregressive Large Unifed Model via Iterative Instruction Tuning and Reinforcement Learning \
  ???具体怎么用RL的
* 65.万字长文！一文了解归一化：从Transformer归一化到主流大模型归一化的演变！  AINLPer  https://mp.weixin.qq.com/s/FGriRlLnZFmEn3hwZorPnA \
  归一化（Normalization）又叫正则化、规范化、标准化等，它是一种数据处理方式，「能将数据经过处理后限制在某个固定范围内」，来方便后面神经网络对数据的处理
* 66.可扩展且可解释的概率模型学习用于知识发现（第一、第二章）  CreateAMind  https://mp.weixin.qq.com/s/BvV_whrPRwMOtZk6vtLRyw \
  Scalable and Interpretable Learning with Probabilistic Models for Knowledge Discovery
* 67.通过超维计算实现认知地图学习器的模块化与组装  CreateAMind  https://mp.weixin.qq.com/s/k4Rux3S_9C-rBmiMRDk3KQ \
  Modularizing and Assembling Cognitive MapLearners via Hyperdimensional Computing 

# 4.16 Wed
* 68.盒子里的老鼠  CreateAMind  https://mp.weixin.qq.com/s/OFIs4jdSgrpcVuw_h4iC3Q \
  RatInABox（见论文）是一种工具包，用于在复杂的连续环境中为空间和/或速度选择性细胞类型生成合成行为和神经数据。 \
  有了RatInABox它，您可以：(1)在平滑随机策略、外部控制信号或您自己的轨迹数据下，为探索复杂 1D 和 2D 环境的老鼠生成真实的轨迹。(2)为大脑中发现的各种位置或速度选择性细胞（例如但不限于海马细胞类型）生成人工神经元数据，或构建您自己的更复杂的细胞类型。(3)构建和训练复杂的多层细胞网络，由生成的数据提供支持RatInABox。
* 69.MIT惊人神作：AI独立提出哈密顿物理！0先验知识，一天破译人类百年理论  新智元  https://mp.weixin.qq.com/s/Y7JngMxe-RW7P1OpjuS4KA \
  MIT物理学大牛Max Tegmark团队，再出重磅力作。他们发现：AI能够在没有任何先验知识的情况下，完全独立地提出哈密顿物理量，或拉格朗日方程式。仅仅通过尝试解释数据，AI就自己收敛到了这些物理原则，发现了宇宙间的奥秘！ \
  Do Two AI Scientists Agree? \
  ???LNN
* 70.视频推理R1时刻，7B模型反超GPT-4o！港中文清华推出首个Video-R1  新智元  https://mp.weixin.qq.com/s/sNTqVQcyPTwYIqRExKyszA \
  Video-R1: Reinforcing Video Reasoning in MLLMs \
  https://github.com/tulerfeng/Video-R1
* 71.(**长CoT综述**)迈向推理时代：900+篇参考文献揭示长链思维的前世今生，最全综述来了  机器之心  https://mp.weixin.qq.com/s/chrerdwU5vRVhwkgsxAOOg \
  Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models \
  https://long-cot.github.io/ \
  https://github.com/LightChen233/Awesome-Long-Chain-of-Thought-Reasoning \
  长思维链（Long CoT）与短思维链（Short CoT）代表了两种截然不同的推理范式。短思维链以浅层、线性的推理方式快速得出结论，逻辑路径短，探索性低，适用于结构清晰、解答明确的问题。而长思维链则强调深度推理、广泛探索和可行性反思，允许模型在更复杂的逻辑网络中展开深入分析，发现隐藏关系，并优化推理路径 \
  该论文深入拆解 长思维链的三大关键特性，即深度推理、广泛探索和可行性反思，揭示其如何在提升推理能力的同时，也带来了计算开销、冗余推理等挑战 \
  该论文进一步探讨 长思维链相关的核心推理现象，如过度思考（Overthinking）、推理扩展性（Test-Time Scaling）以及 AI 的 “顿悟时刻”（Aha Moment），分析这些现象如何影响模型的推理效率和答案质量，并讨论其可能的优化方案
* 72.(**值得看看**)智能体版《苦涩的教训》，图灵奖得主Sutton、谷歌RL大佬Silver新作：超人智能靠经验  机器之心  https://mp.weixin.qq.com/s/Rl-YUOIMxmpw_Ca6vf2YxA \
  强化学习之父当头一棒：RL版「苦涩的教训」来了！通往ASI，绝非靠人类数据  新智元  https://mp.weixin.qq.com/s/MGrSWh-wcBrLKPboUmg05w \
  Welcome to the Era of Experience \
  从模仿时代到人类数据时代再到经验时代，每个时代都有相对应的 AI（或大模型）涌现，朝着超人智能不断 \
  要取得进一步的显著进步，需要一个新的数据来源。这种数据的生成方式必须随着智能体变得更强而不断改进；任何静态的合成数据生成程序都会很快被超越。这可以通过让智能体从自己的经验中持续学习来实现，即由智能体与环境互动产生的数据。AI 正处于新时期的边缘，在这个时期，经验将成为提升的主要媒介，并最终使当今系统中使用的人类数据规模相形见绌。 \
  DeepSeek 的最近工作「强调了强化学习的力量和美学：与其明确教导模型如何解决问题，我们只需提供正确的激励，它就会自主开发高级问题解决策略。」 \
  一个经验型智能体可以在整个生命周期中持续学习 \
  强大的智能体应该有自己的经验流，像人类一样，在长时间尺度上发展。这将使智能体能够采取行动实现未来目标，并随着时间的推移不断适应新的行为模式。例如，连接到用户可穿戴设备的健康和健身智能体可以在几个月内监测睡眠模式、活动水平和饮食习惯。然后，这些智能体可以提供个性化建议、鼓励，并根据长期趋势和用户的具体健康目标调整其指导 \
  除了人类数据，奖励还能从何而来？一旦智能体通过丰富的行动和观察空间连接到世界，将不缺乏提供奖励基础的基础信号。事实上，世界充满了诸如成本、错误率、饥饿、生产力、健康指标、气候指标、利润、销量、考试结果、成功与否、访问量、产量、股票、收入、愉悦 / 痛苦、经济指标、准确性、功率、距离、速度、效率或能源消耗等数量。此外，还有无数来自特定事件或从原始观察和行动序列派生的特征的额外信号。 \
  持续学习、终身学习、互动学习、agent形成自己的经验流、自己产生数据
* 73.智能的本质：大模型能否走向AGI  图灵人工智能  https://mp.weixin.qq.com/s/FxpC6tliH2aaO9-Rl-r85A 

# 4.17 Thur
* 74.从思考到行动：大模型自主工具调用能力的深度实现  机器之心  https://mp.weixin.qq.com/s/hjPf68M5qciZBc3zczctYQ \
  https://github.com/lsdefine/simple_GRPO/tree/main/Auto_Program \
  复旦大学知识工场实验室团队在开源项目 SimpleGRPO 中开源实现了大模型自主工具调用机制，通过引入大模型的深度思考能力，从根本上重构了大模型工具调用的范式。该技术使大模型实现了从被动执行的「提线木偶」到具备自主决策能力的智能体的根本跃迁。 \
  边想边干和专业分工
* 75.大语言模型复杂推理的自我进化机制：研究综述与前沿展望  集智俱乐部  https://mp.weixin.qq.com/s/2TnUHa_1-dq68qOVJEVheQ \
  A Survey on Complex Reasoning of Large Language Models through the Lens of Self-Evolution
* 76.使用超维计算组装模块化、分层的认知地图学习器  CreateAMind  https://mp.weixin.qq.com/s/jvglC7pk2mTiftcfDSdZ3w \
  Assembling Modular, Hierarchical Cognitive MapLearners with Hyperdimensional Computing \
  认知地图学习器（CML）是一组独立但协同训练的单层人工神经网络（矩阵），通过学习节点状态、边动作和边动作可用性的内部表示来导航抽象图。这种非典型的信 息分离的结果是，CML 能够在任意两个图节点状态之间执行接近最优的路径规划。然而，CML 并未学习何时或为何从一个节点转移到另一个节点。本文创建了节点状态以高维向量表示的 CML，与高维计算（HDC）一致，这是一种符号机器学习（ML）形式。本文评估了基于 HDC 的 CML 作为 ML 模块的能力，这些模块能够接收外部输入并计算对其他基于 HDC 的模块语义上有意义的输出响应。多个 CML 独立准备后被重新用于解决汉诺塔（Tower of Hanoi）谜题，而无需重新训练这些 CML，也无需明确参考其各自的图拓扑结构。本文提出了一种构建生物学上可信的认知抽象和协调层次的模板。  
* 77.重新思考预训练中的反思现象  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/peaEqhCvwMZRdAxy8ZQBJg \
  Rethinking Reflection in Pre-Training \
  反思是一种元认知形式，涉及审视信息，评估其背后的推理过程，并基于该评估调整未来的行为。在大型语言模型的背景下，这个过程可以应用于从外部来源引入的信息或模型自身生成的信息 \
  反思在模型预训练时便开始显现
* 78.小型推理模型简要综述：训练、推理、应用与研究方向  专知  https://mp.weixin.qq.com/s/DibNnf-XdKTcEqYpC5u0oA \
  A Short Survey on Small Reasoning Models: Training, Inference.Applications and Research Directions
* 79.多模态检索增强生成综述  专知  https://mp.weixin.qq.com/s/MC0WN8frtoS5Hz3iJCPx9g \
  A Survey on Multimodal Retrieval-Augmented Generation
* 80.可训练编码和自适应训练的高效准确学习的HDC  CreateAMind  https://mp.weixin.qq.com/s/bMDZQZhhEzUtNnFOO6cyXg \
  Advancing Hyperdimensional Computing Based on Trainable Encoding and Adaptive Training for Efficient and Accurate Learning
* 81.UC伯克利：让推理模型少思考，准确率反而更高了！  量子位  https://mp.weixin.qq.com/s/l1ZvVPZSTr1GfZ8Z0jY_Bw \
  推理模型其实无需「思考」？伯克利发现有时跳过思考过程会更快、更准确  机器之心  https://mp.weixin.qq.com/s/XTSimXbcpp7b9B9jlIErvg \
  Reasoning Models Can Be Effective Without Thinking \
  解决大模型的冗长思考过程问题 \
  别再卷 token 了，无需显式思维链，推理模型也能实现高效且准确的推理。

# 4.18 Fri
* 82.Jeff Dean演讲回顾LLM发展史，Transformer、蒸馏、MoE、思维链等技术都来自谷歌  机器之心  https://mp.weixin.qq.com/s/5EUQlD5isnEEzXBw1AJEig \
  https://video.ethz.ch/speakers/d-infk/2025/spring/251-0100-00L.html \
  https://drive.google.com/file/d/12RAfy-nYi1ypNMIqbYHjkPXF_jILJYJP/view
* 83.深圳又出了个智能机器人：DeepSeek加持，全球首款全域全身VLA  量子位  https://mp.weixin.qq.com/s/Bo90PXJ6MiKl39JT-sTxSg \
  GOVLA大模型采用创新的三模块架构，包含空间交互基础模型、慢思考系统（System2）和快反应系统（System1） \
  空间交互模型？？？
* 84.突破AI视觉“选择性失明”，哈工大首次实现指令驱动的全景式感知  量子位  https://mp.weixin.qq.com/s/44VfT8CsKBwI1_TmMNlyIg \
  当今的多模态大模型（如BLIP-2、LLaVA）看似可以理解图像，实则存在一个根本性的缺陷：它们像戴着“眼罩”的观察者，只能关注图片中最显眼的主体，却对用户关心的细节视而不见。 \
  哈工大（深圳）博士生李俊劼最新研究成果《GiVE: Guiding Visual Encoder to Perceive Overlooked Information》，为AI视觉装上“动态变焦镜头，首次实现“指令驱动的全景式感知”！与传统模型的“固定视角”不同，GIVE能根据用户需求灵活调整注意力焦点：无论是被遮挡的物体（如鞋盒中的鞋子）、分散的同类目标（如人群中的特定行人），还是隐藏在复杂背景中的特定目标（如路边草地），都能精准捕捉并关联语义信息。 \
  GiVE:Guiding Visual Encoder to Perceive Overlooked Information \
  GiVE引入了Attention-Guided Adapter（AG-Adapter）模块，能够根据文本提示动态调整视觉编码器的关注区域 \
  不同于传统编码器只聚焦于图像中显著的部分，AG-Adapter使得模型在解析图像时能关注到容易被忽略的细节，从而提高了有效视觉信息的提取效果。
* 85.三维物体与场景生成的最新进展：综述  专知  https://mp.weixin.qq.com/s/l2kkyNiRx8Is2zpgwN9GNg \
  Recent Advance in 3D Object and Scene Generation: A Survey
* 86.意识的信息处理逻辑与意识结合的核心结构图  createAMind  https://mp.weixin.qq.com/s/jPOFwJ2pTeCparR53L91hQ \
  意识的信息处理架构草图 \
  意识理论列表 \
  通过三个条件对最小意识进行了特征描述：一个可证伪的新兴感知框架 \
  整合信息论IIT与现象绑定问题：自我意识动态演化框架中的挑战与解决方案模型 \
  意识复杂性的剖析：理论与反思（3万字）
* 87.RSS 2025｜ConRFT: 真实环境下基于强化学习的VLA模型微调方法  机器之心  https://mp.weixin.qq.com/s/qmKMdDRuNc7WFx9k-pz-Tg 

# 4.19 Sat
* 88.DeepSeek-R1「内心世界」首次曝光！AI显微镜破解R1大脑，发现神秘推理机制  新智元  https://mp.weixin.qq.com/s/hf72DoZQNGvROwxWqW_dHQ \
  推理模型与普通大语言模型有何本质不同？它们为何会「胡言乱语」甚至「故意撒谎」？Goodfire最新发布的开源稀疏自编码器（SAEs），基于DeepSeek-R1模型，为我们提供了一把「AI显微镜」，窥探推理模型的内心世界。 \
  稀疏自编码器（SAE）是一种特殊的神经网络，类似于「压缩包」，能将复杂的数据压缩成更简单的形式，然后再恢复原来的数据。不同之处在于，SAE会确保中间处理层（隐藏层）中只有少数神经元被激活，大部分神经元保持「沉默」（接近零的激活）。这种「稀疏性」就像团队合作：假设你有一个团队，每次任务只需要少数几个人完成，SAE通过让大部分神经元「休息」，只让少数神经元「工作」，来学习数据的关键特征。这不仅使模型更高效，还能让结果更容易理解，比如减少数据维度，同时保留重要信息。简单地说，SAE就像一个「挑剔的专家」，它只保留数据中最有价值的部分，特别适用于需要高可解释性的场景。像DeepSeek-R1、o3和Claude 3.7这样的推理模型能够通过增加「思考」计算量，为复杂问题提供更可靠、更连贯的响应。但理解它们的内部机制仍然是个挑战。不过，Goodfire这个基于DeepSeek-R1训练的SAE，则可以像显微镜一样，深入模型内部，揭示R1如何处理和响应信息。 \
  研究者从SAE中发现了一些有趣的早期洞察，通俗点说就是：想要有效「引导」模型，得等到它生成完「好的，用户问了个关于……」这样的语句，而不是直接用类似<think>这样的明确标签。这说明模型内部的推理token方式挺出人意料的。如果「引导」过头，模型反而可能退回到原本的行为，感觉它内部好像有种更深的「自我意识」。 \
  https://www.goodfire.ai/blog/under-the-hood-of-a-reasoning-model \
  https://github.com/goodfire-ai/r1-interpretability \
  如果AI无法通过观察世界来学习其运行规律，我们就永远到不了人类级别——因为文字里根本没有那么多信息 \
  高级机器智能（Advanced Machine Intelligence，AMI）: \
  1.能通过感官输入自行学习世界模型与心智模型，从而掌握直觉物理与常识； \
  2.拥有持久记忆； \
  3.能够规划复杂的动作序列； \
  4.具备推理能力； \
  5.在设计之初就保证可控与安全，而不是事后靠微调弥补。 \
  AMI的认知架构：（1）世界模型；（2）若干目标函数；（3）行动体——负责优化动作以最小化代价；（4）短期记忆，对应大脑中的海马体；（5）感知模块——几乎整个大脑后部都在做这件事；（5）以及一个配置器。
* 89.仅需0.4GB，参数只有0和±1！微软开源首个原生1 bit模型，CPU轻松跑  新智元  https://mp.weixin.qq.com/s/G9ZbMnBVbeH1m45HY2JIKA \
  BitNet b1.58 2B4T

# 4.20 Sun
* 90.264页智能体综述来了！MetaGPT等20家顶尖机构、47位学者参与  机器之心  https://mp.weixin.qq.com/s/KLbiikJaYqhp9K1-D_pq2A \
  Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems \
  Huggingface 链接：https://huggingface.co/papers/2504.01990Github  \
  链接：https://github.com/FoundationAgents/awesome-foundation-agents \
  在面对复杂的真实世界时，Agent 往往会暴露出推理规划、长期记忆、世界模型、自主进化以及安全对齐等核心能力不足的问题 \
  在这篇论文中，作者们首次定义并提出了基础智能体 (Foundation Agent) 这一新概念框架。Foundation Agent 并非具体的智能体实例，而是一个更宏大且更根本性的技术蓝图及科学理念。它旨在通过认知科学和神经科学的洞见，构建一个由复杂认知、多层记忆、世界模型、奖励 & 价值、情绪 & 动机、多模感知、行动系统等模块化组件构成的智能系统 \
  它不再将智能体视为 LLM 的简单应用，而是将其看作一个由认知、记忆、学习、感知、行动等多个核心组件构成的复杂、有机的系统。其核心意义在于提供了系统性框架，强调了自主性，关注协作与生态，并突出了安全与对齐
* 91.扩散LLM推理用上类GRPO强化学习！优于单独SFT，UCLA、Meta新框架d1开源  机器之心  https://mp.weixin.qq.com/s/57onGdSBuiQfvEJpOdU_eg \
  d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning \
  项目主页：https://dllm-reasoning.github.io/GitHub  \
  地址：https://github.com/dllm-reasoning/d1
* 92.大型语言模型驱动空间智能综述：具身智能体、智慧城市与地球科学的进展  专知  https://mp.weixin.qq.com/s/raJtnBOZvU9iAJwP39C_oQ \
  A Survey of Large Language Model-Powered Spatial Intelligence Across Scales: Advances in Embodied Agents, Smart Cities, and Earth Science \
  本文从神经科学与认知科学视角出发，探讨了人类空间智能的相关研究，并对不同学科领域，尤其是在大型语言模型（LLMs）时代背景下，不同空间尺度上的空间智能研究进行了系统回顾与总结。文章旨在提供一份关于跨学科空间智能研究的全面综述，既有助于现有研究的归类与理解，也为未来研究方向提供启发与参考 \
  2.1.1 认知地图？？？ \
  2.1.2 空间图式？？？

# 4.21 Mon
* 93.DeepSeek-R1之后推理模型发展如何？Raschka长文梳理后R1时代14篇重要论文  图灵人工智能  https://mp.weixin.qq.com/s/MUOKFpN-zeqxdJbXuAz-Vw \
  前统计学教授，现 AI/ML 研究员 Sebastian Raschka 在综述《The State of LLM Reasoning Models》中探讨并总结了推理 LLM 的最新研究进展，特别关注自 DeepSeek R1 发布以来出现的推理时间计算扩展。  \
  顺带一提，Sebastian Raschka 前段时间还曾写过另一篇与推理模型相关的长篇博客，感兴趣的读者可访问《Sebastian Raschka：关于 DeepSeek R1 和推理模型，我有几点看法》
* 94.大语言模型推理前沿综述：推理扩展、推理学习与智能体系统  专知  https://mp.weixin.qq.com/s/NS9zHHPAFbf_H3V89tDApQ \
  A Survey of Frontiers in LLM Reasoning: Inference Scaling Learning to Reason, and Agentic Systems 
* 95.采样越多越聪明？隐式扩展颠覆认知，采样搜索如何挑出完美解  新智元  https://mp.weixin.qq.com/s/AVjWS5IkzamELly8zIm5og \
  采样多就一定准吗？研究人员用实验告诉你：是的，而且超乎想象！基于采样的搜索不仅能在并行处理中大展身手，还通过隐式扩展让验证更精准。 \
  Sample, Scrutinize and Scale: Efective Inference-Time Search by Scaling Verifcation
* 96.95后打造世界首个行动型浏览器——Fellou，从「浏览」到「行动」一键直达！  新智元  https://mp.weixin.qq.com/s/ad82kvoPPSddQ8QgOZnhzg \
  Fellou尝试开创第四种浏览器：Agentic Browser行动型浏览器，侧重端到端自主行动，一种集成了具备思考和行动能力的智能代理的浏览器，其不仅展示信息，更能根据用户高层目标自主拆解任务、跨界操作并完成端到端任务交付。
* 97.(**值得看看**)Sebastian Raschka长文：DeepSeek-R1、o3背后，RL推理训练正悄悄突破上限  机器之心  https://mp.weixin.qq.com/s/Bmiimack-HEzlsgu-WiHKg \
  The State of Reinforcement Learning for LLM Reasoning \
  博客地址：https://magazine.sebastianraschka.com/p/the-state-of-llm-reasoning-model-training
* 98.UIUC联手谷歌发布Search-R1：大模型学会「边想边查」，推理、搜索无缝切换  机器之心  https://mp.weixin.qq.com/s/enuxKcfEqG2lvs5ZODa9ww \
  Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning \
  https://github.com/PeterGriffinJin/Search-R1 \
  https://huggingface.co/collections/PeterJinGo/search-r1-67d1a021202731cb065740f5
* 99.具身空间推理的秘密武器！清华推出Embodied-R，定义AI动态推理能力  独角噬元兽  https://mp.weixin.qq.com/s/ioz6XhoOVAxiodom5e4sZg \
  如何让人工智能也能在三维物理世界中拥有具身空间认知能力呢 \
  https://github.com/EmbodiedCity/Embodied-R.code \
  https://embodiedcity.github.io/Embodied-R/
* 100.物体、实体的概念认知本质  CreateAMind  https://mp.weixin.qq.com/s/AVa_eGnQA6Dj_DhNWeX8Qg 

# 4.22 Tue
* 101.LLM 构建过程（Andrej Karpath ）  图灵人工智能  https://mp.weixin.qq.com/s/iw-2Pz3am_kqMFY0v6tiiw 
* 102.图灵奖得主杨立昆最新访谈实录：让LLM投入更多“思考”时间分步推理，是一种很糟糕的技巧  图灵人工智能  https://mp.weixin.qq.com/s/JEIoeDCghoKSGLRNyiqXaA \
  核心观点是：我们需要能理解物理世界的机器；需要能进行推理和规划的机器；需要拥有持久记忆的机器；并且这些机器必须是可控且安全的，这意味着它们需由我们设定的目标驱动——给它们任务就去完成，问它们问题就给出答案，不能偏离指令
* 103.AI也要007？Letta、伯克利提出「睡眠时间计算」，推理效率翻倍还不加钱  机器之心  https://mp.weixin.qq.com/s/iZe_NpvAM_-GtG_vacRm7Q \
  Sleep-time Compute: Beyond Inference Scaling at Test-time \
  https://github.com/letta-ai/sleep-time-compute \
  睡眠时间计算的核心理念在于：智能体即使在「睡眠」（即用户未提出查询时的闲置状态）时段，也应持续运行，利用这些非交互期重组信息、提前完成推理。当前许多智能体都运行于存在持久化上下文的环境中。例如，代码智能体可以在编程请求到来前预先研习代码库；对话智能体则可反思用户过往的交流记录，在交互前重新整理信息。 \
  在睡眠时段执行推理的过程将「原始上下文」（raw context）转化为「学习到的上下文」（learned context）。与仅拥有原始上下文的智能体相比，具备预处理能力的智能体可在实际应答时减少即时推理计算的负担，因为它们已经提前进行了思考。
* 104.142页长文揭秘DeepSeek-R1「思维大脑」！开启全新「思维链学」研究  新智元  https://mp.weixin.qq.com/s/6eVSwap0tZzoruzkMGWwQA \
  DeepSeek-Rl Thoughtology: Let's <think> about LLM reasoning \
  DeepSeek-R1是近年来推理模型领域的一颗新星，它不仅突破了传统LLM的局限，还开启了全新的研究方向「思维链学」（Thoughtology）。这份长达142页的报告深入剖析了DeepSeek-R1的推理过程，揭示了其推理链的独特结构与优势，为未来推理模型的优化提供了重要启示。 \
  虽然LLM的输出中可能包含一些中间推理过程，但它们通常不会探索不同的思路。而一旦模型出错，也无法回退并尝试其它解法。相比之下，LRM则通过探索与验证多个方案来进行推理，最终总结出最佳解法。 \
  DeepSeek-R1是在一个复杂的多阶段训练流程中构建出来的。在这个流程中，多个阶段都大量使用了由前一阶段模型生成的合成训练数据。 
* 105.「全球首个自回归视频生成大模型」，刚刚，Swin Transformer作者创业团队重磅开源！  机器之心  https://mp.weixin.qq.com/s/4Bzgadxdb8i6UHbQxjrXVA \
  马尔奖、清华特奖得主曹越的创业公司 Sand AI 推出了自己的视频生成大模型 ——MAGI-1。这是一个通过自回归预测视频块序列来生成视频的世界模型，生成效果自然流畅 \
  特点： \
    1.流畅度高，不卡顿，可以无限续写。它可以一镜到底生成连续的长视频场景，没有尴尬的剪辑或奇怪的拼接，就像电影一样流畅自然。 \
    2.精准时间轴控制。MAGI-1 是唯一具有秒级时间轴控制的模型 —— 你可以按自己设想的那样，精准地雕琢每一秒。 \
    3.运动更加自然，更有生机。不少 AI 生成的视频，画面动作不是慢吞吞，就是僵硬死板、幅度过小。Magi-1 克服了这些问题，生成的动作更加流畅、有活力，且场景切换更加顺滑。 \
  MAGI-1: Autoregressive Video Generation at Scale \
  技术报告：https://static.magi.world/static/files/MAGI_1.pdf \
  GitHub页面：https://github.com/SandAI-org/Magi-1 \
  HuggingFace页面：https://huggingface.co/sand-ai/MAGI-1 \
  MAGI-1 是一种通过自回归预测视频块序列生成视频的世界模型，视频块被定义为连续帧的固定长度片段。MAGI-1 可对随时间单调增加的每块噪声进行去噪训练，从而实现因果时间建模，并自然支持流式生成。 \
  MAGI-1 建立在 DiT 的基础上，融入了多项关键创新，以提高大规模训练的效率和稳定性。相关技术包括因果注意力 block、并行注意力 block、QK-Norm 和 GQA、FFN 中的三明治层归一化、SwiGLU 和 Softcap Modulation。
* 106.
* 107.
* 108.
* 109.
* 110.

# 4.23 Wed
# 4.24 Thur
# 4.25 Fri
# 4.26 Sat
# 4.27 Sun
# 4.28 Mon

# 4.29 Tue
# 4.30 Wed
