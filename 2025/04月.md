# 4.1 Tue
* 1.R1–Zero强化学习路线新发现及R1思路用于GUI Agent动作预测方案  老刘说NLP  https://mp.weixin.qq.com/s/cFkOEyrG3bnFPldX9VWP2w \
  继续来看大模型可解释性，最近的工作 《Understanding R1-Zero-Like Training: A Critical Perspective》（https://arxiv.org/abs/2503.20783，https://github.com/sail-sg/understand-r1-zero） ，结论很有趣，研究了多种基础模型，以了解预训练特性如何影响RL性能。 \
  看第二个工作，《UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning》(https://arxiv.org/pdf/2503.21620，https://github.com/lll6gg/UI-R1)，基于规则的RL如何增强多模态大模型(MLLM)对图形用户界面(GUI)动作预测任务的推理能力。
* 2.给GRPO提提速！厦大 | 提出强化学习算法：CPPO，最高8倍加速！  AINLPer  https://mp.weixin.qq.com/s/ijlMoLwlkG9AXYZC89376A \
  CPPO: Accelerating the Training of Group Relative Policy Optimization-Based Reasoning Models \
  https://github.com/lzhxmu/CPPO

# 4.2 Wed
* 3.主动推理隐含最小意识理论  CreateAMind  https://mp.weixin.qq.com/s/knGg6C2PTTA-D1d9B5eHSA \
  On the minimal theory of consciousness implicit in active inference \
  体验的多面性给意识的研究带来了挑战。传统神经科学方法通常专注于孤立的方面，例如感知意识或意识的整体状态，并围绕相关的经验范式和发现构建理论。因此，意识理论往往难以比较；事实上，这些理论试图解释的现象可能几乎没有重叠之处。在这里，我们采用了一种不同的方法：从主动推理（active inference）开始，这是一种基于贝叶斯推理（Bayesian inference）建模行为的首要原则框架，并逐步构建出一种最小化的意识理论，这种理论从主动推理下推导出的计算模型的共同特征中涌现出来。我们回顾了一系列将主动推理模型应用于意识研究的工作，并认为所有这些模型中都隐含着一组小的理论承诺，这些承诺指向了一种最小化（且可检验的）意识理论。
* 4.是什么、如何、何处，以及效果如何？——大语言模型测试时扩展的调研  专知  https://mp.weixin.qq.com/s/7uTIt9Z3-DFnJtEw4deDnw \
  从四个核心维度来结构化 TTS 研究：扩展什么、如何扩展、在何处扩展、扩展效果如何 \
  What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models
* 5.一个LangChain与MCP结合使用的案例！  Datawhale  https://mp.weixin.qq.com/s/MA17aivO4Oe3iv_trlj2Ag 
* 6.动态场景，开放文本查询！清华哈佛联合建模4D语言场 | CVPR 2025  新智元  https://mp.weixin.qq.com/s/x4JTo-eujTPnPFRP3R-Dhg 
* 7.AI理解27分钟长视频超越GPT-4o，港理工新国立开源新框架：角色化推理+链式LoRA  量子位  https://mp.weixin.qq.com/s/Tw_eZmeCYTTCtIkvbkjX7w \
  港理工、新加坡国立团队推出VideoMind框架，核心创新在于角色化推理（Role-based Reasoning）和链式LoRA（Chain-of-LoRA）策略。 \
  VideoMind的提出不仅在于视频理解性能的突破，更在于提出了一个模块化、可扩展、可解释的多模态推理框架。该框架首次实现了类似人类行为的“指定计划、搜索片段、验证结果、回答问题”流程，真正让AI能“像人类一样理解视频”，为未来的视频理解和多模态智能系统领域奠定了基础。 \
  VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning \
  https://videomind.github.io/
* 8.脑波解码延迟仅80毫秒，实时「意念对话」技术登Nature子刊  机器之心  https://mp.weixin.qq.com/s/HcgdYRHYQxRHuRvE7nbgbg \
  A streaming brain-to-voice neuroprosthesis to restore naturalistic communication
* 9.2025美国最新奥数题，让大模型集体翻车，DeepSeek R1平均分也不到5%  机器之心  https://mp.weixin.qq.com/s/TT1Owl925f4Ky1vReKpYwA \
  PROOF OR BLUFF? EVALUATING LLMS ON 2025 USA MATH OLYMPIAD \
  https://github.com/eth-sri/matharena \
  所有模型都无法解决超过一个问题，这凸显了当前大型语言模型在奥林匹克级数学推理任务中的局限性。这表明现有优化方法如 GRPO 对需要高度逻辑精确性的任务可能尚不足够。
* 10.用 MCP 让大模型自动批量解读文献，保姆级教程来了！  Datawhale  https://mp.weixin.qq.com/s/VWlntkxCtB-FLzAistng_w
* 11.有深度！Transformer | 万字长文：详细了解前馈神经网络（FFN），内含对大模型的理解  AINLPer  https://mp.weixin.qq.com/s/XLW0iU2XLwDmv5jGd6tckg

# 4.3 Thur
* 12.视觉SSL终于追上了CLIP！Yann LeCun、谢赛宁等新作，逆转VQA任务固有认知  机器之心  https://mp.weixin.qq.com/s/V7Ml_xgiiQalxnGQmIWi_Q \
  CLIP被淘汰了？LeCun谢赛宁新作，多模态训练无需语言监督更强！  新智元  https://mp.weixin.qq.com/s/FpisxJQ9AXHV26lHPwzy5A \ 
  在最近的一项研究中，Yann LeCun、谢赛宁等研究者探讨了一个基本问题： 语言监督对于多模态建模的视觉表征预训练是否必要？ \
  Scaling Language-Free Visual Representation Learning
* 13.智能体丝滑玩手机，决策延迟0.7秒！MSRA等提出验证器架构，不直接依赖大模型生成最终操作  量子位  https://mp.weixin.qq.com/s/GxTJrTp-gfg0N1wchpYptg \
  Advancing Mobile GUl Agents: A Verifier-Driven Approach to Practical Deployment
* 14.DeepMind闭关修炼「我的世界」，自学成才挖钻登Nature！人类玩家瑟瑟发抖  新智元  https://mp.weixin.qq.com/s/OgjLy_jE9Rk9iZhioPRTDQ \
  Mastering diverse control tasks through world models
* 15.浙大校友重磅革新Transformer！多token注意力让LLM开挂，错误率归0  新智元  https://mp.weixin.qq.com/s/LoVCN-4WsEEK8ZuEyWCyrA \
  Multi-Token Attention

# 4.4 Fri
* 16.信息分解和大脑的信息架构  CreateAMind  https://mp.weixin.qq.com/s/3tV9f-Vq6E14lLjdOB8OZQ \
  Information decomposition and the informational architecture of the brain \
  为了阐述大脑如何协调信息处理以实现认知功能，我们必须理解信息本身。至关重要的是，信息并非是一个单一的实体。信息分解技术提供了一种将信息拆分为其构成要素的方法：独特信息、冗余信息和协同信息。我们回顾了如何通过区分协同和冗余的相互作用来重新定义我们对大脑整合功能及其神经组织的理解。为了阐释大脑如何在冗余和协同之间权衡取舍，我们回顾了整合多方面证据，包括协同和冗余的结构、分子和功能基础；它们在认知和计算中的作用；以及它们是如何在进化和发育过程中产生的。总体而言，区分协同和冗余信息为理解大脑和认知的信息架构提供了一个指导原则。
* 17.动态框架中的挑战与解决方案  CreateAMind  https://mp.weixin.qq.com/s/QH9JNdUBJIcSdo82i5yWJg \
  Integrated Information Theory and the Phenomenal Binding Problem: Challenges and Solutions in a Dynamic Framework \
  基于神经科学的意识理论必须解释现象学的结合问题，例如微观信息单元是如何组合成人类现象学中常见的宏观意识体验的。一个例子是，视觉场景中的单个“像素”被体验为“心灵之眼”中的单一整体图像，而不是作为个体的、分离的、大规模并行的体验，这些体验可能分别对应于单个神经元激活、神经元集合或中央凹扫视，从信息处理的角度来看，任何一种都可能提供相同的功能。现象学结合问题存在多个有争议的候选解决方案。本文探讨了集成信息理论（IIT）4.0版本的形而上学基础如何提供一种独特的解决方案。这种解决方案——即可以从多个单元聚合而成的特定实体（“复合体”）定义了存在——可能在静态图像中有效，但在动态系统中引入了问题。我们问，当主要复合体在生物神经网络中移动时，我们的现象学自我会发生什么。我们对意识实体随时间发展的描述，导致了 IIT 理论家面临的一个明显困境，即非局域实体转换与连续自我的选择：“动态实体演化问题”。除了明确这一困境外，我们还描述了 IIT 可能在其站稳脚跟之前化解这一困境的三种方式。阐明 IIT 在现象学结合问题上的立场，可能借助新的实证或理论研究作为支撑，有助于研究人员理解 IIT 并评估其合理性。我们认为我们的论文有助于 IIT 当前的研究重点，即从静态分析向动态分析的转变。 \
  像素（感知单元）如何连接成一幅图像（感知整体）
* 18.元认知，元元认知  CreateAMind  https://mp.weixin.qq.com/s/Z3gwFb0mADh8s0O-33GY5g \
  元认知粒子、心理行动与代理感知 \
  主动推理隐含最小意识理论 \
  意识理论列表
* 19.DeepSeek R2来了？全新推理时Scaling论文联手清华震撼发布！  新智元  https://mp.weixin.qq.com/s/kZF1sJlIxIlCXv9j0iBWgQ \
  Inference-Time Scaling for Generalist Reward Modeling

# 4.5 Sat
* 20.7B扩散LLM，居然能跟671B的DeepSeek V3掰手腕，扩散vs自回归，谁才是未来？  机器之心  https://mp.weixin.qq.com/s/CVssj4w-UPXodjIO640_Ww \
  香港大学和华为诺亚方舟实验室的一项研究就是其中之一。他们刚刚发布的扩散推理模型 Dream 7B 拿下了开源扩散语言模型的新 SOTA，在各方面都大幅超越现有的扩散语言模型。 \
  Dream 7B 最终选择了 Qwen2.5 7B 的权重作为初始化基础。在训练过程中，作者发现学习率参数至关重要：设置过高会迅速冲淡初始权重中宝贵的从左到右知识，对扩散训练几无助益；设置过低则会束缚扩散训练的进展。作者精心选择了这个参数以及其他训练参数。 \
  https://hkunlp.github.io/blog/2025/dream/
* 21.三思而后行，让大模型推理更强的秘密是「THINK TWICE」？  机器之心  https://mp.weixin.qq.com/s/xCN70_gwjkRTAh7nWdtggA \
  Think Twice: Enhancing LLM Reasoning by Scaling Multi-round Test-time Thinking \
  https://github.com/a-m-team/a-m-models \
  “Think Twice” 展示了一种简单有效的思路：鼓励大模型主动 “反思”，用多轮推理激发更强的认知能力。它不仅提升了准确率，更令模型在语言表达上变得更加理性、紧凑、自信。 \
  在训练成本不断攀升的今天，这种无需再训练的 “轻量级优化” 无疑具有极强的现实吸引力。未来，多轮推理或许能成为一种标准机制，帮助模型更接近真正意义上的 “会思考”。
* 22.对神经流形与认知回路的统一视角  CreateAMind  https://mp.weixin.qq.com/s/68IJc8HzJyqhOCu7RqmCOg \
  A unifying perspective on neural manifolds and circuits for cognition \
  两种不同的视角为解释大脑与行为之间的联系提供了理论基础。一种方法试图识别执行特定功能的神经回路元件，强调神经元之间的连接性作为神经计算的基础。另一种方法则聚焦于神经流形——即在神经群体活动中行为信号的低维表示——并提出神经计算通过涌现动力学来实现。尽管神经流形揭示了异质性神经活动中的可解释结构，但在连接性中找到相应的结构仍然是一项挑战。我们重点介绍了一些例子，在这些例子中，建立低维活动与连接性之间的对应关系是可能的，从而统一了神经流形和神经回路的观点。这种关系在神经反应的几何结构反映其在大脑中空间布局的系统中尤为显著，例如苍蝇导航系统。此外，我们描述了证据表明，在神经反应具有异质性的系统中，回路由通过低秩连接性作用于流形上的活动模式间的相互作用组成。我们认为，如果我们要能够因果性地测试关于行为背后的神经计算理论，那么统一流形和回路的方法至关重要。

# 4.6 Sun
* 23.LLM「想太多」有救了！高效推理让大模型思考过程更精简  新智元  https://mp.weixin.qq.com/s/dTNB7ueI5Vd8OC9TrvqBjA \
  Stop Overthinking: A Survey on Effcient Reasoning for Large Language Models \
  https://github.com/Eclipsess/Awesome-Efficient-Reasoning-LLMs
* 24.多模态融合与视觉-语言模型：面向机器人视觉的综述  专知  https://mp.weixin.qq.com/s/DWoXDlh_bBe9-E96v-zKEw \
  Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision \
  https://github.com/Xiaofeng-Han-Res/MF-RV
* 25.Meta深夜开源Llama 4！首次采用MoE，一张H100就能跑，竞技场超越DeepSeek  Datawhale  https://mp.weixin.qq.com/s/m8SWReTOvVyeAhY0uyX4Zg \
  Llama 4 Scout，16位专家的170亿激活参数的多模态模型，单个H100 GPU可运行， 同类SOTA，并拥有10M上下文窗口 \
  Llama 4 Maverick，128位专家的170亿激活参数多模态模型，击败GPT-4o和Gemini 2.0 Flash，与DeepSeek-V3同等代码能力参数只要一半，主打与DeepSeek一样的性价比，单个H100主机即可运行。

# 4.7 Mon
* 26.Science颠覆认知：你的大脑不是“机器”，而是一支交响乐团！  图灵人工智能  https://mp.weixin.qq.com/s/XOcyTVWrMbHnYk_vlJfnSQ \
  传统神经科学聚焦于孤立脑区的功能定位，但行为和认知是多个脑区协同作用的“涌现特性”（emergent properties）。传统神经科学建立在Brodmann分区基础上，其本质是笛卡尔式机械还原论。现代连接组学（Connectomics）揭示：认知功能是分布式网络在相空间中涌现的吸引子状态。oni的整合信息理论）。
* 27.深入解析图神经网络注意力机制：数学原理与可视化实现  图灵人工智能  https://mp.weixin.qq.com/s/LNrek7vcAwvdyB0UtQXsig 
* 28.视觉中的检索增强生成与理解：综述与新展望  专知  https://mp.weixin.qq.com/s/xRP86lob8QmKhiX9_QXiWg \
  Retrieval Augmented Generation and Understanding in Vision: A Survey and New Outlook
* 29.反向传播、前向传播都不要，这种无梯度学习方法是Hinton想要的吗？  机器之心  https://mp.weixin.qq.com/s/xXOe0Xw9kk3MGKvnoQejyQ \
  最近，来自牛津大学和 Mila 实验室的研究者向这一问题发起了挑战。他们开发了一种名为 NoProp 的新型学习方法，该方法既不依赖前向传播也不依赖反向传播。相反，NoProp 从扩散和流匹配（flow matching）方法中汲取灵感，每一层独立地学习对噪声目标进行去噪。 \
  NOPROP: TRAINING NEURAL NETWORKS WITHOUT BACK-PROPAGATION OR FORWARD-PROPAGATION
* 30.Rule-based强化学习≠古早逻辑规则！万字拆解o1多模态推理最新进展  PaperWeekly  https://mp.weixin.qq.com/s/8pwCPuXzXoMJsDmdL9tPGA \
  rule-based 的强化学习通过基于规则的奖励机制，成功地为模型提供了一种高效且可靠的优化途径 \
  本篇文章将讨论来自 Aligning Multimodal LLM with Human Preference: A Survey（https://arxiv.org/abs/2503.14504）中五篇近期关注多模态 O1-reasoning 相关的文章。
* 31.LLM幻觉，竟因知识「以大欺小」！华人团队祭出对数线性定律与CoDA策略  新智元  https://mp.weixin.qq.com/s/twUUI_esahGg6u3xGqMGIQ \
  「知识遮蔽」，即模型中的主导知识可以在文本生成过程中，掩盖那些不太突出的知识，从而导致模型编造不准确的细节 \
  The Law of Knowledge Overshadowing: Towards Understanding, Predicting, and Preventing LLM Hallucination \
  此研究深入研究了LLM幻觉，有4大亮点： \
  1 发现幻觉的对数线性规律：幻觉率随着相对知识流行度、相对知识长度和模型规模的对数线性增长 \
  2 在训练或推理前预测幻觉：在训练前「知识遮蔽效应」可预测幻觉发生的可能性 \
  3 提出全新解码策略CoDA（Contrastive Decoding with Attenuation）强调被遮蔽的知识，降低主流知识偏差，大幅提升LLM事实性（Factuality） \
  4 更可预测、更可控的语言模型正在成为现实！研究加深了对LLM幻觉机制的理解，为未来的可解释性与可控性研究打开新方向

# 4.8 Tue
* 32.通过三个条件对最小意识进行了特征描述：一个可证伪的新兴感知框架  CreateAMind  https://mp.weixin.qq.com/s/P3WUIWEiZlmVf5ZOCvcOOQ \
  Beyond Imitation Games: A Falsifiable Emergent Sentience Framework \
  自由能原理和意识是什么关系？
* 33.实现类比推理：概念超空间  CreateAMind  https://mp.weixin.qq.com/s/AdwK5rLbclpA1aBV9cwVjA \
  Analogical Reasoning Within a Conceptual Hyperspace \
  ?什么是类比推理
* 34.三个LLM顶一个OpenAI？2亿条性能记录加持，路由n个「小」模型逆袭  新智元  https://mp.weixin.qq.com/s/z8x6tMeqV98xacixq7m8ZA \
  RouterEval:A Comprehensive Benchmark for Routing LLMs to Explore Model-level Scaling Up in LLMs \
  https://github.com/MilkThink-Lab/RouterEval \
  https://github.com/MilkThink-Lab/Awesome-Routing-LLMs
* 35.Science：人类意识感知的“闸门”——高阶丘脑核团  集智俱乐部  https://mp.weixin.qq.com/s/Z43TimwVChC9Auyx8MaX8A \
  Human high-order thalamic nuclei gate conscious perception through the thalamofrontal loop

# 4.9 Wed
* 36.整合信息论IIT与现象绑定问题：自我意识动态演化框架中的挑战与解决方案模型  CreateAMind  https://mp.weixin.qq.com/s/mwiDXq67rHZ7WLTxOkteNg \
  Integrated Information Theory and the Phenomenal Binding Problem: Challenges and Solutions in a Dynamic Framework \
  基于神经科学的意识理论必须解释现象学的绑定结合问题，例如微观信息单元是如何组合成人类现象学中常见的宏观意识体验的。一个例子是，视觉场景中的单个“像素”被体验为“心灵之眼”中的单一整体图像，而不是作为个体的、分离的、大规模并行的体验，这些体验可能分别对应于单个神经元激活、神经元集合或中央凹扫视，从信息处理的角度来看，任何一种都可能提供相同的功能。现象学绑定结合问题存在多个有争议的候选解决方案。本文探讨了整合信息理论（IIT）4.0版本的形而上学基础如何提供一种独特的解决方案。这种解决方案——即可以从多个单元聚合而成的特定实体（“复合体”）定义了存在——可能在静态图像中有效，但在动态系统中引入了问题。我们问，当主要复合体在生物神经网络中移动时，我们的现象学自我会发生什么。我们对意识实体随时间发展的描述，导致了 IIT 理论家面临的一个明显困境，即非局域实体转换与连续自我的选择：“动态实体演化问题”。除了明确这一困境外，我们还描述了 IIT 可能在其站稳脚跟之前化解这一困境的三种方式。阐明 IIT 在现象学结合问题上的立场，可能借助新的实证或理论研究作为支撑，有助于研究人员理解 IIT 并评估其合理性。我们认为我们的论文有助于 IIT 当前的研究重点，即从静态分析向动态分析的转变。
* 37.英伟达253B开源新王登场，Llama 4三天变陪衬！直逼DeepSeek-R1成推理天花板  新智元  https://mp.weixin.qq.com/s/QbUTBKG9vrIVTA-6qII2gg 
* 38.从零搭一套可复现、可教学、可观察的RL for VLM训练流程，我们试了试  机器之心  https://mp.weixin.qq.com/s/SDUbYwWcwJMCZ2hrlnIqVA \
  Rethinking RL Scaling for Vision Language Models: A Transparent, From-Scratch Framework and Comprehensive Evaluation Scheme \
  https://github.com/GAIR-NLP/MAYE

# 4.10 Thur
* 39.统一 世界模型+认知架构+神经网络  CreateAMind  https://mp.weixin.qq.com/s/Xn6tV8FycSGr4W6irGmBPA \
  Bridging Cognitive Architectures and Generative Models with Vector Symbolic Algebras
* 40.上下文长度扩展：从RoPE到YARN  关于NLP那些你不知道的事 
https://mp.weixin.qq.com/s/gHUEufvzCeyNb-kMSjEDlg 
* 41.重磅：建模各种依赖概念信息的推理机制：统一框架，常识的构建  CreateAMind  https://mp.weixin.qq.com/s/J1_s5wYtw6Lefu72EFNVyQ \
  Reasoning with Concepts: A Unifying Framework

# 4.11 Fri
* 42.概念、连接主义与思维语言  CreateAMind  https://mp.weixin.qq.com/s/oE3296E4gfvJE7HkqPkR9g \
  Concepts, Connectionism, and the Language of Thought \
  http://www.mkdavies.net/Martin_Davies/Mind_files/ConceptsConnLoT.pdf
* 43.如何赋予大型语言模型三维能力？—大型语言模型中的空间推理综述  专知  https://mp.weixin.qq.com/s/YDFkVOLfsWJg4O4rQy0K_A \
  How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM

# 4.12 Sat
* 44.意义的几何与动态，概念空间语义学  CreateAMind  https://mp.weixin.qq.com/s/MvgsmJChHiMuBEo6lTQkhw \
  The Geometry and Dynamics of Meaning
* 45.手机实现GPT级智能，比MoE更极致的稀疏技术：省内存效果不减｜对话面壁&清华肖朝军  量子位  https://mp.weixin.qq.com/s/kANQBUD5-Y8I9JdLrSd3hg \
  面壁智能和清华走出了一条与MoE不同的路径——神经元级稀疏激活，让模型在保持性能的同时大幅降低资源消耗。 \
  Configurable Foundation Models: Building LLMs from a Modular Perspective \
  ???CFM（Configurable Foundation Models）
* 46.魔改AlphaZero后，《我的世界》AI老玩家问世，干活不用下指令  机器之心  https://mp.weixin.qq.com/s/Md2FJh0IQ3X-ztpRW4G5mA \
  现在，AI 可以不断主动学习、纠正错误，展现出了此前大模型智能体无法实现的一系列能力。 \
  看起来，新版的 AI 在与我们共同游戏时不再是催一下动一下了，它已经是一个有「主观能动性」的玩家，就像个和你共同玩过几百局游戏的老友一样。 \
  这项技术名为 AssistanceZero，出自加州大学伯克利分校（UC Berkeley）。值得注意的是，它并未接受大模型常见的 RLHF 训练。相反，它是由「assistance games」强化学习驱动的，研究人员认为，这是构建 AI 助手的更好途径。 \
  AI 在这个框架中并不会被动地接受人类反馈，而是寻求主动与人合作，通过推断目标而不断优化行为，这避免了 RLHF 中 AI 可能会出现的作弊行为，让 AI 可以采取更加协作的策略。 \
  AssistanceZero: Scalably Solving Assistance Games \
  https://github.com/cassidylaidlaw/minecraft-building-assistance-game
* 47.谢赛宁等新作上线，多模态理解生成大一统！思路竟与GPT-4o相似？  新智元  https://mp.weixin.qq.com/s/qUE7D8RDcTmmB1ZNNDB4mQ \
  Transfer betweenModalitieswithMetaQueries \
  https://xichenpan.com/metaquery/

# 4.13 Sun
* 48.意识计算模型-最小体验现象  CreateAMind  https://mp.weixin.qq.com/s/iQPPWnkfpbbbTFlN2F_lww \
  A Computational Model of Minimal Phenomenal Experience (MPE) \
  最小现象体验（MPE），或称“纯粹意识”，是一种基础的意识体验形式，其特征是具有反身性元意识，且缺乏常规现象学中的许多特征。它被描述为例如非概念化的、非时间性的、无自我的、无视角的。本文旨在利用自由能量原理（FEP）推导出的变分自由能量最小化的数学方法，开发一个MPE的计算模型。我采用计算神经现象学方法，在主动推断框架内形式化MPE的关键现象学特征。该模型包含参数深度，允许对生成模型参数进行高阶推断。我将特定的模型参数化与报告的MPE品质（如元意识、平静、无努力感和非概念化）联系起来。所提出的模型表明，当一个主体通过自我导向的意识和对其生成模型的调节实现极低的自由能量时，尤其是通过强调对意识本身的意识，MPE就会产生。该模型预测了MPE现象学的元素，包括一种无努力感、无时间感以及“零人称视角”的可能性。文中概述了对所提模型进行模拟的实施细节，以及实证验证的方向。
* 49.解释AGI，实现AGI，联想学习与主动推理  CreateAMind  https://mp.weixin.qq.com/s/bbbp7Ts0_ob3Kkw0AoOhJA \
  Associative Learning and Active Inference \
  联想学习是一种行为现象，个体基于刺激或事件的共同出现而发展出它们之间的联系。最初由巴甫洛夫在他的条件反射实验中研究，学习的基本原则已经通过发现广泛的学习现象而得到扩展。基于最小化奖励预测误差的概念，已经开发出了计算模型。特别是Rescorla-Wagner模型，是一个极大地影响了强化学习领域的著名模型。然而，这些模型的简单性限制了它们充分解释与学习相关的行为现象的多样性。在本研究中，我们采用了自由能原理，该原理表明生物系统努力在其对世界的内部模型下最小化惊讶或不确定性。我们将学习过程视为自由能的最小化，并研究其与Rescorla-Wagner模型的关系，重点关注学习的信息方面、不同类型的惊讶以及基于信念和价值的预测误差。此外，我们探讨了如何在主动推断框架内模拟众所周知的行为现象，如阻断、掩盖和潜在抑制。我们通过使用注意力的信息和新颖性方面来实现这一点，这些方面与看似矛盾的模型（如Mackintosh和Pearce-Hall模型）提出的类似想法共享。因此，我们证明了自由能原理，作为一个从第一性原理推导出的理论框架，可以整合基于经验实验提出的联想学习的思想和模型，并作为更好地理解大脑联想学习背后的计算过程的框架。
* 50.人类一生所学不过4GB，加州理工顶刊新研究引热议  量子位  https://mp.weixin.qq.com/s/tssPnTg1Bwk1_qkvBevTiA \
  人类信息处理速度仅为每秒10bit，而我们的感官系统却能以每秒10亿bit的速率收集数据。
* 51.强化学习带来的改进只是「噪音」？最新研究预警：冷静看待推理模型的进展  机器之心  https://mp.weixin.qq.com/s/acQeGwuSaxZrl8Mo1GPDLQ \
  A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths to Reproducibility \
  一些使用强化学习训练的模型确实表现出了适度的改进，但这些改进通常比监督微调所取得的成果更弱，而且它们通常不能很好地推广到新的基准 \
  尽管强化学习在某些情况下可能有助于改进较小的蒸馏模型，但它的好处被夸大了，需要更好的评估标准来了解哪些方法真正有效。此外，这不仅仅是强化学习和推理模型的问题，我认为 LLM 研究整体上都受到了影响
* 52.142页DeepSeek-R1 思维链技术：让我们一起<思考>大语言模型（LLM）的推理能力  专知  https://mp.weixin.qq.com/s/dqKsk_D1_1_M_giDfBHnzQ \
  DeepSeek-R1 Thoughtology: Let's <think>about LLM reasoning

# 4.14 Mon
* 53.浙大、OPPO等发布最新综述：基于多模态大模型的计算机、手机与浏览器智能体研究  PaperWeekly  https://mp.weixin.qq.com/s/ISafMq3tcWi5QyAP48h5vQ \
  OS Agents: A Survey on MLLM-based Agents for Computer, Phone and Browser Use \
  https://github.com/OS-Agent-Survey/OS-Agent-Survey
* 54.【CVPR2025】神经运动模拟器：在强化学习中突破世界模型的极限  专知  https://mp.weixin.qq.com/s/ne5naYW8BSNbY9Hw8LlOLg \
  Neural Motion Simulator: Pushing the Limit of World Models in Reinforcement Learning \
  具身系统不仅要模拟外部世界的模式，还需理解自身的运动动态。运动动态模型对于高效的技能习得和有效的规划至关重要。在本工作中，我们提出了神经运动模拟器 (MoSim)，这是一种基于当前观测和动作预测具身系统未来物理状态的世界模型。
* 55.更长思维并不等于更强推理性能，强化学习可以很简洁  机器之心  https://mp.weixin.qq.com/s/CXUScYyWJiTif0k8XpgQ4Q \
  有研究者认为这项研究揭示了强化学习存在的一个普遍问题：训练的目标只是为了获得奖励，而并非是解决问题。 \
  Concise Reasoning via Reinforcement Learning  \
  更长响应不一定能带来更好的性能
* 56.过程奖励模型也可以测试时扩展？清华、上海AI Lab 23K数据让1.5B小模型逆袭GPT-4o  机器之心  https://mp.weixin.qq.com/s/P2OPxTMzB6Zp8Rb3RN86wQ \
  GenPRM: Scaling Test-Time Compute of Process Reward Models via Generative Reasoning \
  通过测试时拓展提升过程奖励模型的过程监督推理能力
* 57.中科大、中兴提出新后训练范式：小尺寸多模态模型，成功复现R1推理  机器之心  https://mp.weixin.qq.com/s/Gj8Gr-WilIqfff2uuNRaLw \
  Boosting the Generalization and Reasoning of Vision Language Models with Curriculum Reinforcement Learning \
  本研究聚焦于提升小规模视觉-语言模型（VLMs）在推理能力和域外（OOD）泛化性能两个关键方面的表现。通过实证研究，我们发现强化学习不仅能有效提升模型的推理能力，更在视觉任务中展现出超出预期的泛化性能提升。
* 58.推理AI「脑补」成瘾，废话拉满！马里兰华人学霸揭开内幕  新智元  https://mp.weixin.qq.com/s/t5mVHRrWG4Y6pEPA1GJ0jg \
  研究发现，推理模型（如DeepSeek-R1、o1）遇到「缺失前提」（MiP）的问题时，这些模型往往表现失常：回答长度激增、计算资源浪费。本文基于马里兰大学和利哈伊大学的最新研究，深入剖析推理模型在MiP问题上的「过度思考」现象，揭示其背后的行为模式，带你一窥当前AI推理能力的真实边界。 \
  Missing Premise exacerbates Overthinking:Are Reasoning Models losings Critical Thinking Skil? \
  让模型意识到“缺失前提”的问题，避免对其进行过度思考
* 59.图灵奖得主LeCun：人类智能不是通用智能，下一代AI可能基于非生成式  量子位  https://mp.weixin.qq.com/s/kl2rkb1d4aoS2PsNK3I5_w \
  人类智能并非通用智能。我们的大脑是进化的产物，只擅长解决对生存有用的问题，而不是真正“通用”的计算…… \
  省流版如下： \
  LeCun直觉认为，下一代AI的突破可能基于非生成式； \
  否认AGI会在未来两年内实现，但十年内可能取得重大进展； \
  人类和动物的智能核心，不是语言，而是对物理世界的建模和行动规划； \
  创新可以来自世界任何角落；智能眼镜代表着AI技术落地的一个重要方向。 \
  A Path Towards Autonomous Machine Intelligence \
  我认为，未来的AI必须具备几个关键能力：(1)理解物理世界——不仅仅是处理符号或文本，而是真正“懂”现实世界的运作规律；(2)具备推理和规划能力——能够像人类一样思考“如果这样做，会发生什么”，并制定策略；(3)拥有持久记忆——不是简单的数据存储，而是能像人类一样长期积累和调用经验；(4)安全可控——AI必须严格遵循我们设定的目标，不能偏离或“自作主张”。 
* 60.学习即编程  CreateAMind  https://mp.weixin.qq.com/s/Xp7bXeppDYJ_nqQRCq7Tlg \
  Human spatiotemporal pattern learningas probabilistic program synthesis \
  人类能够从小量数据中学习各种结构化模式，从偏差-方差权衡的角度来看，这提出了一个难题：什么样的表示和算法能够支持人类学习的灵活性与数据稀缺性？一种可能性是人类通过“编程学习”：诱导概率模型以拟合观测数据。在此，我们通过一个实验测试人类在二维结构化模式领域的学习能力，实验中参与者根据点的先前轨迹反复预测其移动位置。我们将人类表现与标准的参数化和非参数化时间序列模型进行比较，同时还评估了两种贝叶斯程序合成模型，这些模型的假设在结构程度上有所不同：一种是组合高斯过程模型，另一种是结构化的“思维语言”（Language of Thought，LoT）模型。我们发现，人类模式学习的特征最好由LoT模型解释，这支持了人类结构学习的灵活性和数据效率可以通过在富有表现力的程序空间中进行概率推理来理解的观点。 \
  ???概率程序合成
  ???思维语言模型LoT
* 61.论文浅尝 | 迈向更全面的多模态大模型：多模态大模型如何突破模态与任务限制？（哈工大SCIR）  机器学习研究组订阅  https://mp.weixin.qq.com/s/8NQQiXsHId_ySHWM5jNKPw \
  https://github.com/threegold116/Awesome-Omni-MLLMs \
  全模态MLLMs（Omni-MLLMs）

# 4.15 Tue
* 62.类比作为一种搜索过程：维度视角  CreateAMind  https://mp.weixin.qq.com/s/RcgUOaBMI3j_l8uGoOdPpA \
  Analogy as a search procedure: a dimensional view \
  在本文中，我们基于概念空间理论，概述了一种综合性的复合类比方法。我们的算法模型将类比视为一种搜索程序，并基于类比相似性依赖于一种称为“维度显著性”的概念现象这一观点。我们区分了基于类别的类比、基于属性的类比、基于事件的类比和基于部分 - 整体的类比，并提出了用以在概念空间中明确表达它们的计算导向方法。
* 63.AI能看懂图像却算不好距离，上交时间-空间智能基准难倒9大顶尖多模态模型  量子位  https://mp.weixin.qq.com/s/yIRoyI1HbChLZv4GuvI7BQ \
  上海交通大学联合中国地质大学、南洋理工大学、智源研究院以及斯坦福大学的研究团队推出首个多模态大模型（MLLM）时空智能评测基准STI-Bench（Spatial-Temporal Intelligence Benchmark），向当前最先进的多模态大语言模型发起了关于精确空间时间理解的严峻挑战 \
  结果显示，即便是Gemini-2.5-Pro、GPT-4o、Claude-3.7-Sonnet、Qwen 2.5 VL等当前最强的多模态大模型，在需要定量分析真实世界空间关系和动态变化的任务上，表现并不尽人意 \
  发现了三大核心瓶颈：1.定量空间属性不准确;2.时间动态理解缺陷;3.跨模态整合能力薄弱
* 64.视觉自回归生成理解编辑大一统！北大团队多模态新突破，训练数据代码全面开源  量子位  https://mp.weixin.qq.com/s/96yyriyCmwnrGk4_M9_ZUg \
  VARGPT-v1.1: Improve Visual Autoregressive Large Unifed Model via Iterative Instruction Tuning and Reinforcement Learning \
  ???具体怎么用RL的
* 65.万字长文！一文了解归一化：从Transformer归一化到主流大模型归一化的演变！  AINLPer  https://mp.weixin.qq.com/s/FGriRlLnZFmEn3hwZorPnA \
  归一化（Normalization）又叫正则化、规范化、标准化等，它是一种数据处理方式，「能将数据经过处理后限制在某个固定范围内」，来方便后面神经网络对数据的处理
* 66.可扩展且可解释的概率模型学习用于知识发现（第一、第二章）  CreateAMind  https://mp.weixin.qq.com/s/BvV_whrPRwMOtZk6vtLRyw \
  Scalable and Interpretable Learning with Probabilistic Models for Knowledge Discovery
* 67.通过超维计算实现认知地图学习器的模块化与组装  CreateAMind  https://mp.weixin.qq.com/s/k4Rux3S_9C-rBmiMRDk3KQ \
  Modularizing and Assembling Cognitive MapLearners via Hyperdimensional Computing 

# 4.16 Wed
* 68.盒子里的老鼠  CreateAMind  https://mp.weixin.qq.com/s/OFIs4jdSgrpcVuw_h4iC3Q \
  RatInABox（见论文）是一种工具包，用于在复杂的连续环境中为空间和/或速度选择性细胞类型生成合成行为和神经数据。 \
  有了RatInABox它，您可以：(1)在平滑随机策略、外部控制信号或您自己的轨迹数据下，为探索复杂 1D 和 2D 环境的老鼠生成真实的轨迹。(2)为大脑中发现的各种位置或速度选择性细胞（例如但不限于海马细胞类型）生成人工神经元数据，或构建您自己的更复杂的细胞类型。(3)构建和训练复杂的多层细胞网络，由生成的数据提供支持RatInABox。
* 69.MIT惊人神作：AI独立提出哈密顿物理！0先验知识，一天破译人类百年理论  新智元  https://mp.weixin.qq.com/s/Y7JngMxe-RW7P1OpjuS4KA \
  MIT物理学大牛Max Tegmark团队，再出重磅力作。他们发现：AI能够在没有任何先验知识的情况下，完全独立地提出哈密顿物理量，或拉格朗日方程式。仅仅通过尝试解释数据，AI就自己收敛到了这些物理原则，发现了宇宙间的奥秘！ \
  Do Two AI Scientists Agree? \
  ???LNN
* 70.视频推理R1时刻，7B模型反超GPT-4o！港中文清华推出首个Video-R1  新智元  https://mp.weixin.qq.com/s/sNTqVQcyPTwYIqRExKyszA \
  Video-R1: Reinforcing Video Reasoning in MLLMs \
  https://github.com/tulerfeng/Video-R1
* 71.(**长CoT综述**)迈向推理时代：900+篇参考文献揭示长链思维的前世今生，最全综述来了  机器之心  https://mp.weixin.qq.com/s/chrerdwU5vRVhwkgsxAOOg \
  Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models \
  https://long-cot.github.io/ \
  https://github.com/LightChen233/Awesome-Long-Chain-of-Thought-Reasoning \
  长思维链（Long CoT）与短思维链（Short CoT）代表了两种截然不同的推理范式。短思维链以浅层、线性的推理方式快速得出结论，逻辑路径短，探索性低，适用于结构清晰、解答明确的问题。而长思维链则强调深度推理、广泛探索和可行性反思，允许模型在更复杂的逻辑网络中展开深入分析，发现隐藏关系，并优化推理路径 \
  该论文深入拆解 长思维链的三大关键特性，即深度推理、广泛探索和可行性反思，揭示其如何在提升推理能力的同时，也带来了计算开销、冗余推理等挑战 \
  该论文进一步探讨 长思维链相关的核心推理现象，如过度思考（Overthinking）、推理扩展性（Test-Time Scaling）以及 AI 的 “顿悟时刻”（Aha Moment），分析这些现象如何影响模型的推理效率和答案质量，并讨论其可能的优化方案
* 72.(**值得看看**)智能体版《苦涩的教训》，图灵奖得主Sutton、谷歌RL大佬Silver新作：超人智能靠经验  机器之心  https://mp.weixin.qq.com/s/Rl-YUOIMxmpw_Ca6vf2YxA \
  强化学习之父当头一棒：RL版「苦涩的教训」来了！通往ASI，绝非靠人类数据  新智元  https://mp.weixin.qq.com/s/MGrSWh-wcBrLKPboUmg05w \
  Welcome to the Era of Experience \
  从模仿时代到人类数据时代再到经验时代，每个时代都有相对应的 AI（或大模型）涌现，朝着超人智能不断 \
  要取得进一步的显著进步，需要一个新的数据来源。这种数据的生成方式必须随着智能体变得更强而不断改进；任何静态的合成数据生成程序都会很快被超越。这可以通过让智能体从自己的经验中持续学习来实现，即由智能体与环境互动产生的数据。AI 正处于新时期的边缘，在这个时期，经验将成为提升的主要媒介，并最终使当今系统中使用的人类数据规模相形见绌。 \
  DeepSeek 的最近工作「强调了强化学习的力量和美学：与其明确教导模型如何解决问题，我们只需提供正确的激励，它就会自主开发高级问题解决策略。」 \
  一个经验型智能体可以在整个生命周期中持续学习 \
  强大的智能体应该有自己的经验流，像人类一样，在长时间尺度上发展。这将使智能体能够采取行动实现未来目标，并随着时间的推移不断适应新的行为模式。例如，连接到用户可穿戴设备的健康和健身智能体可以在几个月内监测睡眠模式、活动水平和饮食习惯。然后，这些智能体可以提供个性化建议、鼓励，并根据长期趋势和用户的具体健康目标调整其指导 \
  除了人类数据，奖励还能从何而来？一旦智能体通过丰富的行动和观察空间连接到世界，将不缺乏提供奖励基础的基础信号。事实上，世界充满了诸如成本、错误率、饥饿、生产力、健康指标、气候指标、利润、销量、考试结果、成功与否、访问量、产量、股票、收入、愉悦 / 痛苦、经济指标、准确性、功率、距离、速度、效率或能源消耗等数量。此外，还有无数来自特定事件或从原始观察和行动序列派生的特征的额外信号。 \
  持续学习、终身学习、互动学习、agent形成自己的经验流、自己产生数据
* 73.智能的本质：大模型能否走向AGI  图灵人工智能  https://mp.weixin.qq.com/s/FxpC6tliH2aaO9-Rl-r85A 

# 4.17 Thur
* 74.从思考到行动：大模型自主工具调用能力的深度实现  机器之心  https://mp.weixin.qq.com/s/hjPf68M5qciZBc3zczctYQ \
  https://github.com/lsdefine/simple_GRPO/tree/main/Auto_Program \
  复旦大学知识工场实验室团队在开源项目 SimpleGRPO 中开源实现了大模型自主工具调用机制，通过引入大模型的深度思考能力，从根本上重构了大模型工具调用的范式。该技术使大模型实现了从被动执行的「提线木偶」到具备自主决策能力的智能体的根本跃迁。 \
  边想边干和专业分工
* 75.大语言模型复杂推理的自我进化机制：研究综述与前沿展望  集智俱乐部  https://mp.weixin.qq.com/s/2TnUHa_1-dq68qOVJEVheQ \
  A Survey on Complex Reasoning of Large Language Models through the Lens of Self-Evolution
* 76.使用超维计算组装模块化、分层的认知地图学习器  CreateAMind  https://mp.weixin.qq.com/s/jvglC7pk2mTiftcfDSdZ3w \
  Assembling Modular, Hierarchical Cognitive MapLearners with Hyperdimensional Computing \
  认知地图学习器（CML）是一组独立但协同训练的单层人工神经网络（矩阵），通过学习节点状态、边动作和边动作可用性的内部表示来导航抽象图。这种非典型的信 息分离的结果是，CML 能够在任意两个图节点状态之间执行接近最优的路径规划。然而，CML 并未学习何时或为何从一个节点转移到另一个节点。本文创建了节点状态以高维向量表示的 CML，与高维计算（HDC）一致，这是一种符号机器学习（ML）形式。本文评估了基于 HDC 的 CML 作为 ML 模块的能力，这些模块能够接收外部输入并计算对其他基于 HDC 的模块语义上有意义的输出响应。多个 CML 独立准备后被重新用于解决汉诺塔（Tower of Hanoi）谜题，而无需重新训练这些 CML，也无需明确参考其各自的图拓扑结构。本文提出了一种构建生物学上可信的认知抽象和协调层次的模板。  
* 77.重新思考预训练中的反思现象  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/peaEqhCvwMZRdAxy8ZQBJg \
  Rethinking Reflection in Pre-Training \
  反思是一种元认知形式，涉及审视信息，评估其背后的推理过程，并基于该评估调整未来的行为。在大型语言模型的背景下，这个过程可以应用于从外部来源引入的信息或模型自身生成的信息 \
  反思在模型预训练时便开始显现
* 78.小型推理模型简要综述：训练、推理、应用与研究方向  专知  https://mp.weixin.qq.com/s/DibNnf-XdKTcEqYpC5u0oA \
  A Short Survey on Small Reasoning Models: Training, Inference.Applications and Research Directions
* 79.多模态检索增强生成综述  专知  https://mp.weixin.qq.com/s/MC0WN8frtoS5Hz3iJCPx9g \
  A Survey on Multimodal Retrieval-Augmented Generation
* 80.可训练编码和自适应训练的高效准确学习的HDC  CreateAMind  https://mp.weixin.qq.com/s/bMDZQZhhEzUtNnFOO6cyXg \
  Advancing Hyperdimensional Computing Based on Trainable Encoding and Adaptive Training for Efficient and Accurate Learning
* 81.UC伯克利：让推理模型少思考，准确率反而更高了！  量子位  https://mp.weixin.qq.com/s/l1ZvVPZSTr1GfZ8Z0jY_Bw \
  推理模型其实无需「思考」？伯克利发现有时跳过思考过程会更快、更准确  机器之心  https://mp.weixin.qq.com/s/XTSimXbcpp7b9B9jlIErvg \
  Reasoning Models Can Be Effective Without Thinking \
  解决大模型的冗长思考过程问题 \
  别再卷 token 了，无需显式思维链，推理模型也能实现高效且准确的推理。

# 4.18 Fri
* 82.Jeff Dean演讲回顾LLM发展史，Transformer、蒸馏、MoE、思维链等技术都来自谷歌  机器之心  https://mp.weixin.qq.com/s/5EUQlD5isnEEzXBw1AJEig \
  https://video.ethz.ch/speakers/d-infk/2025/spring/251-0100-00L.html \
  https://drive.google.com/file/d/12RAfy-nYi1ypNMIqbYHjkPXF_jILJYJP/view
* 83.深圳又出了个智能机器人：DeepSeek加持，全球首款全域全身VLA  量子位  https://mp.weixin.qq.com/s/Bo90PXJ6MiKl39JT-sTxSg \
  GOVLA大模型采用创新的三模块架构，包含空间交互基础模型、慢思考系统（System2）和快反应系统（System1） \
  空间交互模型？？？
* 84.突破AI视觉“选择性失明”，哈工大首次实现指令驱动的全景式感知  量子位  https://mp.weixin.qq.com/s/44VfT8CsKBwI1_TmMNlyIg \
  当今的多模态大模型（如BLIP-2、LLaVA）看似可以理解图像，实则存在一个根本性的缺陷：它们像戴着“眼罩”的观察者，只能关注图片中最显眼的主体，却对用户关心的细节视而不见。 \
  哈工大（深圳）博士生李俊劼最新研究成果《GiVE: Guiding Visual Encoder to Perceive Overlooked Information》，为AI视觉装上“动态变焦镜头，首次实现“指令驱动的全景式感知”！与传统模型的“固定视角”不同，GIVE能根据用户需求灵活调整注意力焦点：无论是被遮挡的物体（如鞋盒中的鞋子）、分散的同类目标（如人群中的特定行人），还是隐藏在复杂背景中的特定目标（如路边草地），都能精准捕捉并关联语义信息。 \
  GiVE:Guiding Visual Encoder to Perceive Overlooked Information \
  GiVE引入了Attention-Guided Adapter（AG-Adapter）模块，能够根据文本提示动态调整视觉编码器的关注区域 \
  不同于传统编码器只聚焦于图像中显著的部分，AG-Adapter使得模型在解析图像时能关注到容易被忽略的细节，从而提高了有效视觉信息的提取效果。
* 85.三维物体与场景生成的最新进展：综述  专知  https://mp.weixin.qq.com/s/l2kkyNiRx8Is2zpgwN9GNg \
  Recent Advance in 3D Object and Scene Generation: A Survey
* 86.意识的信息处理逻辑与意识结合的核心结构图  createAMind  https://mp.weixin.qq.com/s/jPOFwJ2pTeCparR53L91hQ \
  意识的信息处理架构草图 \
  意识理论列表 \
  通过三个条件对最小意识进行了特征描述：一个可证伪的新兴感知框架 \
  整合信息论IIT与现象绑定问题：自我意识动态演化框架中的挑战与解决方案模型 \
  意识复杂性的剖析：理论与反思（3万字）
* 87.RSS 2025｜ConRFT: 真实环境下基于强化学习的VLA模型微调方法  机器之心  https://mp.weixin.qq.com/s/qmKMdDRuNc7WFx9k-pz-Tg 

# 4.19 Sat
* 88.DeepSeek-R1「内心世界」首次曝光！AI显微镜破解R1大脑，发现神秘推理机制  新智元  https://mp.weixin.qq.com/s/hf72DoZQNGvROwxWqW_dHQ \
  推理模型与普通大语言模型有何本质不同？它们为何会「胡言乱语」甚至「故意撒谎」？Goodfire最新发布的开源稀疏自编码器（SAEs），基于DeepSeek-R1模型，为我们提供了一把「AI显微镜」，窥探推理模型的内心世界。 \
  稀疏自编码器（SAE）是一种特殊的神经网络，类似于「压缩包」，能将复杂的数据压缩成更简单的形式，然后再恢复原来的数据。不同之处在于，SAE会确保中间处理层（隐藏层）中只有少数神经元被激活，大部分神经元保持「沉默」（接近零的激活）。这种「稀疏性」就像团队合作：假设你有一个团队，每次任务只需要少数几个人完成，SAE通过让大部分神经元「休息」，只让少数神经元「工作」，来学习数据的关键特征。这不仅使模型更高效，还能让结果更容易理解，比如减少数据维度，同时保留重要信息。简单地说，SAE就像一个「挑剔的专家」，它只保留数据中最有价值的部分，特别适用于需要高可解释性的场景。像DeepSeek-R1、o3和Claude 3.7这样的推理模型能够通过增加「思考」计算量，为复杂问题提供更可靠、更连贯的响应。但理解它们的内部机制仍然是个挑战。不过，Goodfire这个基于DeepSeek-R1训练的SAE，则可以像显微镜一样，深入模型内部，揭示R1如何处理和响应信息。 \
  研究者从SAE中发现了一些有趣的早期洞察，通俗点说就是：想要有效「引导」模型，得等到它生成完「好的，用户问了个关于……」这样的语句，而不是直接用类似<think>这样的明确标签。这说明模型内部的推理token方式挺出人意料的。如果「引导」过头，模型反而可能退回到原本的行为，感觉它内部好像有种更深的「自我意识」。 \
  https://www.goodfire.ai/blog/under-the-hood-of-a-reasoning-model \
  https://github.com/goodfire-ai/r1-interpretability \
  如果AI无法通过观察世界来学习其运行规律，我们就永远到不了人类级别——因为文字里根本没有那么多信息 \
  高级机器智能（Advanced Machine Intelligence，AMI）: \
  1.能通过感官输入自行学习世界模型与心智模型，从而掌握直觉物理与常识； \
  2.拥有持久记忆； \
  3.能够规划复杂的动作序列； \
  4.具备推理能力； \
  5.在设计之初就保证可控与安全，而不是事后靠微调弥补。 \
  AMI的认知架构：（1）世界模型；（2）若干目标函数；（3）行动体——负责优化动作以最小化代价；（4）短期记忆，对应大脑中的海马体；（5）感知模块——几乎整个大脑后部都在做这件事；（5）以及一个配置器。
* 89.仅需0.4GB，参数只有0和±1！微软开源首个原生1 bit模型，CPU轻松跑  新智元  https://mp.weixin.qq.com/s/G9ZbMnBVbeH1m45HY2JIKA \
  BitNet b1.58 2B4T

# 4.20 Sun
* 90.264页智能体综述来了！MetaGPT等20家顶尖机构、47位学者参与  机器之心  https://mp.weixin.qq.com/s/KLbiikJaYqhp9K1-D_pq2A \
  Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems \
  Huggingface 链接：https://huggingface.co/papers/2504.01990Github  \
  链接：https://github.com/FoundationAgents/awesome-foundation-agents \
  在面对复杂的真实世界时，Agent 往往会暴露出推理规划、长期记忆、世界模型、自主进化以及安全对齐等核心能力不足的问题 \
  在这篇论文中，作者们首次定义并提出了基础智能体 (Foundation Agent) 这一新概念框架。Foundation Agent 并非具体的智能体实例，而是一个更宏大且更根本性的技术蓝图及科学理念。它旨在通过认知科学和神经科学的洞见，构建一个由复杂认知、多层记忆、世界模型、奖励 & 价值、情绪 & 动机、多模感知、行动系统等模块化组件构成的智能系统 \
  它不再将智能体视为 LLM 的简单应用，而是将其看作一个由认知、记忆、学习、感知、行动等多个核心组件构成的复杂、有机的系统。其核心意义在于提供了系统性框架，强调了自主性，关注协作与生态，并突出了安全与对齐
* 91.扩散LLM推理用上类GRPO强化学习！优于单独SFT，UCLA、Meta新框架d1开源  机器之心  https://mp.weixin.qq.com/s/57onGdSBuiQfvEJpOdU_eg \
  d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning \
  项目主页：https://dllm-reasoning.github.io/GitHub  \
  地址：https://github.com/dllm-reasoning/d1
* 92.大型语言模型驱动空间智能综述：具身智能体、智慧城市与地球科学的进展  专知  https://mp.weixin.qq.com/s/raJtnBOZvU9iAJwP39C_oQ \
  A Survey of Large Language Model-Powered Spatial Intelligence Across Scales: Advances in Embodied Agents, Smart Cities, and Earth Science \
  本文从神经科学与认知科学视角出发，探讨了人类空间智能的相关研究，并对不同学科领域，尤其是在大型语言模型（LLMs）时代背景下，不同空间尺度上的空间智能研究进行了系统回顾与总结。文章旨在提供一份关于跨学科空间智能研究的全面综述，既有助于现有研究的归类与理解，也为未来研究方向提供启发与参考 \
  2.1.1 认知地图？？？ \
  2.1.2 空间图式？？？

# 4.21 Mon
* 93.DeepSeek-R1之后推理模型发展如何？Raschka长文梳理后R1时代14篇重要论文  图灵人工智能  https://mp.weixin.qq.com/s/MUOKFpN-zeqxdJbXuAz-Vw \
  前统计学教授，现 AI/ML 研究员 Sebastian Raschka 在综述《The State of LLM Reasoning Models》中探讨并总结了推理 LLM 的最新研究进展，特别关注自 DeepSeek R1 发布以来出现的推理时间计算扩展。  \
  顺带一提，Sebastian Raschka 前段时间还曾写过另一篇与推理模型相关的长篇博客，感兴趣的读者可访问《Sebastian Raschka：关于 DeepSeek R1 和推理模型，我有几点看法》
* 94.大语言模型推理前沿综述：推理扩展、推理学习与智能体系统  专知  https://mp.weixin.qq.com/s/NS9zHHPAFbf_H3V89tDApQ \
  A Survey of Frontiers in LLM Reasoning: Inference Scaling Learning to Reason, and Agentic Systems 
* 95.采样越多越聪明？隐式扩展颠覆认知，采样搜索如何挑出完美解  新智元  https://mp.weixin.qq.com/s/AVjWS5IkzamELly8zIm5og \
  采样多就一定准吗？研究人员用实验告诉你：是的，而且超乎想象！基于采样的搜索不仅能在并行处理中大展身手，还通过隐式扩展让验证更精准。 \
  Sample, Scrutinize and Scale: Efective Inference-Time Search by Scaling Verifcation
* 96.95后打造世界首个行动型浏览器——Fellou，从「浏览」到「行动」一键直达！  新智元  https://mp.weixin.qq.com/s/ad82kvoPPSddQ8QgOZnhzg \
  Fellou尝试开创第四种浏览器：Agentic Browser行动型浏览器，侧重端到端自主行动，一种集成了具备思考和行动能力的智能代理的浏览器，其不仅展示信息，更能根据用户高层目标自主拆解任务、跨界操作并完成端到端任务交付。
* 97.(**值得看看**)Sebastian Raschka长文：DeepSeek-R1、o3背后，RL推理训练正悄悄突破上限  机器之心  https://mp.weixin.qq.com/s/Bmiimack-HEzlsgu-WiHKg \
  The State of Reinforcement Learning for LLM Reasoning \
  博客地址：https://magazine.sebastianraschka.com/p/the-state-of-llm-reasoning-model-training
* 98.UIUC联手谷歌发布Search-R1：大模型学会「边想边查」，推理、搜索无缝切换  机器之心  https://mp.weixin.qq.com/s/enuxKcfEqG2lvs5ZODa9ww \
  Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning \
  https://github.com/PeterGriffinJin/Search-R1 \
  https://huggingface.co/collections/PeterJinGo/search-r1-67d1a021202731cb065740f5
* 99.具身空间推理的秘密武器！清华推出Embodied-R，定义AI动态推理能力  独角噬元兽  https://mp.weixin.qq.com/s/ioz6XhoOVAxiodom5e4sZg \
  如何让人工智能也能在三维物理世界中拥有具身空间认知能力呢 \
  https://github.com/EmbodiedCity/Embodied-R.code \
  https://embodiedcity.github.io/Embodied-R/
* 100.物体、实体的概念认知本质  CreateAMind  https://mp.weixin.qq.com/s/AVa_eGnQA6Dj_DhNWeX8Qg 

# 4.22 Tue
* 101.LLM 构建过程（Andrej Karpath ）  图灵人工智能  https://mp.weixin.qq.com/s/iw-2Pz3am_kqMFY0v6tiiw 
* 102.图灵奖得主杨立昆最新访谈实录：让LLM投入更多“思考”时间分步推理，是一种很糟糕的技巧  图灵人工智能  https://mp.weixin.qq.com/s/JEIoeDCghoKSGLRNyiqXaA \
  核心观点是：我们需要能理解物理世界的机器；需要能进行推理和规划的机器；需要拥有持久记忆的机器；并且这些机器必须是可控且安全的，这意味着它们需由我们设定的目标驱动——给它们任务就去完成，问它们问题就给出答案，不能偏离指令
* 103.AI也要007？Letta、伯克利提出「睡眠时间计算」，推理效率翻倍还不加钱  机器之心  https://mp.weixin.qq.com/s/iZe_NpvAM_-GtG_vacRm7Q \
  Sleep-time Compute: Beyond Inference Scaling at Test-time \
  https://github.com/letta-ai/sleep-time-compute \
  睡眠时间计算的核心理念在于：智能体即使在「睡眠」（即用户未提出查询时的闲置状态）时段，也应持续运行，利用这些非交互期重组信息、提前完成推理。当前许多智能体都运行于存在持久化上下文的环境中。例如，代码智能体可以在编程请求到来前预先研习代码库；对话智能体则可反思用户过往的交流记录，在交互前重新整理信息。 \
  在睡眠时段执行推理的过程将「原始上下文」（raw context）转化为「学习到的上下文」（learned context）。与仅拥有原始上下文的智能体相比，具备预处理能力的智能体可在实际应答时减少即时推理计算的负担，因为它们已经提前进行了思考。
* 104.142页长文揭秘DeepSeek-R1「思维大脑」！开启全新「思维链学」研究  新智元  https://mp.weixin.qq.com/s/6eVSwap0tZzoruzkMGWwQA \
  DeepSeek-Rl Thoughtology: Let's <think> about LLM reasoning \
  DeepSeek-R1是近年来推理模型领域的一颗新星，它不仅突破了传统LLM的局限，还开启了全新的研究方向「思维链学」（Thoughtology）。这份长达142页的报告深入剖析了DeepSeek-R1的推理过程，揭示了其推理链的独特结构与优势，为未来推理模型的优化提供了重要启示。 \
  虽然LLM的输出中可能包含一些中间推理过程，但它们通常不会探索不同的思路。而一旦模型出错，也无法回退并尝试其它解法。相比之下，LRM则通过探索与验证多个方案来进行推理，最终总结出最佳解法。 \
  DeepSeek-R1是在一个复杂的多阶段训练流程中构建出来的。在这个流程中，多个阶段都大量使用了由前一阶段模型生成的合成训练数据。 
* 105.「全球首个自回归视频生成大模型」，刚刚，Swin Transformer作者创业团队重磅开源！  机器之心  https://mp.weixin.qq.com/s/4Bzgadxdb8i6UHbQxjrXVA \
  马尔奖、清华特奖得主曹越的创业公司 Sand AI 推出了自己的视频生成大模型 ——MAGI-1。这是一个通过自回归预测视频块序列来生成视频的世界模型，生成效果自然流畅 \
  特点： \
    1.流畅度高，不卡顿，可以无限续写。它可以一镜到底生成连续的长视频场景，没有尴尬的剪辑或奇怪的拼接，就像电影一样流畅自然。 \
    2.精准时间轴控制。MAGI-1 是唯一具有秒级时间轴控制的模型 —— 你可以按自己设想的那样，精准地雕琢每一秒。 \
    3.运动更加自然，更有生机。不少 AI 生成的视频，画面动作不是慢吞吞，就是僵硬死板、幅度过小。Magi-1 克服了这些问题，生成的动作更加流畅、有活力，且场景切换更加顺滑。 \
  MAGI-1: Autoregressive Video Generation at Scale \
  技术报告：https://static.magi.world/static/files/MAGI_1.pdf \
  GitHub页面：https://github.com/SandAI-org/Magi-1 \
  HuggingFace页面：https://huggingface.co/sand-ai/MAGI-1 \
  MAGI-1 是一种通过自回归预测视频块序列生成视频的世界模型，视频块被定义为连续帧的固定长度片段。MAGI-1 可对随时间单调增加的每块噪声进行去噪训练，从而实现因果时间建模，并自然支持流式生成。 \
  MAGI-1 建立在 DiT 的基础上，融入了多项关键创新，以提高大规模训练的效率和稳定性。相关技术包括因果注意力 block、并行注意力 block、QK-Norm 和 GQA、FFN 中的三明治层归一化、SwiGLU 和 Softcap Modulation。
* 106.知识蒸馏全面综述  专知  https://mp.weixin.qq.com/s/K3vHMW7QdPNLxnlpR0ij3w \
  A Comprehensive Survey on Knowledge Distillation \
  https://github.com/IPL-Sharif/KD-Survey \
  本文提出了一个关于知识蒸馏方法的全面综述，涵盖多个角度的分析：蒸馏源、蒸馏策略、蒸馏算法、跨模态蒸馏、知识蒸馏的应用，以及现有方法之间的对比分析 \
  本综述还纳入了多个关键子领域的研究进展，包括扩散模型（Diffusion Models）、三维输入（3D Inputs）、基础模型、Transformer结构与大语言模型（LLMs）中的知识蒸馏
* 107.海马体模型中的霍普菲尔德网络的情境控制  CreateAMind  https://mp.weixin.qq.com/s/O4a3i37q834ZvPwYVND7CQ \
  Contextual Control of Hopfield Networks in a Hippocampal Model \
  执行功能引导情景记忆以检索对适应性行为至关重要的信息。前额叶皮层通过解剖学上的投射——目标为内嗅皮层和CA1区域——影响海马体的处理过程，从而实现这一功能。然而，大多数关于海马体的计算模型忽略了这种认知控制，要么完全忽视它，要么通过不切实际的直接连接到海马体来实现。本文探讨了在受海马体启发的自编码器中，由现代霍普菲尔德网络实现的情景记忆的上下文控制。我们的实验强调了前额叶传入与记忆存储位置之间的接近性对于情景记忆高效上下文调节的重要性，这对标准的海马体处理模型提出了挑战。这些发现不仅增进了我们对高级认知的理解，还为更具适应性的机器学习算法提供了设计原则。 
* 108.Transformer原作打脸DeepSeek观点？一句Wait就能引发反思，RL都不用  新智元  https://mp.weixin.qq.com/s/65SkhsnxpOIJZYGfcUmVSg \
  Transformer作者Ashish Vaswani团队重磅LLM研究！简单指令：「Wait，」就能有效激发LLM显式反思，表现堪比直接告知模型存在错误。 \
  只要预训练，LLM就能涌现自我反思、自我纠正！ \
  Rethinking Reflection in Pre-Training 
* 109.生成式AI进入第二幕：交大携手创智学院提出「认知工程」，AI新纪元开始了  机器之心  https://mp.weixin.qq.com/s/G3WTW2RiYNA6epyQoZZ9Ng \
  Generative AI Act II: Test Time Scaling Drives Cognition Engineering \
  https://github.com/GAIR-NLP/cognition-engineering \
  上海交通大学联合创智学院，耗时超过半年，创建了教科书级别的长达 76 的文章（并提供了双语版本），首次提出：「认知工程」的概念：认为生成式 AI 发展已进入第二幕，从原来的以预训练技术为核心的提示词工程 (Prompt engineering) 转变为以 Test-Time scaling 为核心的认知工程 (Cognition Engineering)，结合 400 多篇论文和最新的研究工作全景式介绍了 Test-time scaling 技术驱动下的范式变革 \
  生成式AI第一幕：\
    能力特点：掌握海量已有知识，处理日常高频任务，完成简单推理 \
    局限性：知识更新滞后，难以深度思考，推理能力有限 \
  生成式 AI 的第二幕：认知工程，需要一个真正会深度思考的模型，而不仅仅是一个高效的知识检索工具 \
  认知工程？？？
* 110.从Minecraft到虚幻5，AI首次实现3D游戏零样本迁移，跨游戏直接上手  机器之心  https://mp.weixin.qq.com/s/J3AP3yWr1_1gP8BlvZdA-w \
  ROCKET-2:Steering Visuomotor Policy viaCross-View Goal Alignment \
  https://craftjarvis.github.io/ROCKET-2 \
  https://github.com/CraftJarvis/ROCKET-2 \
  https://github.com/CraftJarvis/MineStudio \
  仅在 Minecraft 上预训练，却能直接泛化到多个从未见过的 3D 游戏环境中

# 4.23 Wed
* 111.由图灵奖得主辛顿的获奖感言反思语言学研究的路向  图灵人工智能  https://mp.weixin.qq.com/s/KGugak1wStoRcYWWbObTgA \
  ???语言天生论 生成语法理论
* 112.通过生物启发式强化学习在游戏中定时动作  CreateAMind  https://mp.weixin.qq.com/s/VtgivctMDjLtXs87Z8p5lw \
  Timing Actions in Games through Bio-InspiredReinforcement Learning \
  一种受生物启发的强化学习（RL）版本可以用于在完全神经形态的机器人中学习规划动作，允许感知、处理、动作规划和控制，同时保持端到端的脉冲信号。这样的智能体可以充分利用稀疏、低功耗的编码，并揭示生物智能的秘密。当前神经形态RL的最先进水平使用神经元群体来实现传统的RL方程，结合新颖的脉冲状态表示方法，并通过在一个8×8网格世界中离散状态定义下更新神经连接权重来实现学习。我们调整并扩展了该算法，使其适用于能够玩高度动态游戏的全神经形态机器人。在本文中，我们将RL算法与一个空气曲棍球机器人模拟器集成在一起；将维度加倍，现在状态是连续的。我们展示了我们可以调整该方法以学习精确的“击打时机”，当冰球在机器人前面移动时，机器人必须选择正确的时机拦截冰球，并将其击向对手的球门。我们还引入了一种发展性的学习方法——课程学习（CL），使机器人首先学习简单的任务，然后可以将其推广并完善为更复杂的场景。简化的空气曲棍球场景展示了未来全神经形态管道的良好前景。
* 113.GPT-4o能拼好乐高吗？首个多步空间推理评测基准来了：闭源模型领跑，但仍远不及人类  量子位  https://mp.weixin.qq.com/s/VvLgPqq2TujCCPKw5-3PLw \
  LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning? \
  https://github.com/Tangkexian/LEGO-Puzzles \
  https://tangkexian.github.io/LEGO-Puzzles \
  上海人工智能实验室联合同济大学与清华大学，提出了全新基准LEGO-Puzzles，以乐高拼搭为载体，首次系统评估现有多模态大模型（MLLMs）在多步空间推理（multi-step spatial reasoning）任务中的实际表现。 \
  多模态大语言模型真的具备理解和推理空间结构的能力吗？在多步空间推理任务上，现有 MLLMs 究竟表现得如何？
* 114.告别“AI失忆症”！新型SD-LoRA算法实现终身学习｜ICLR 2025  量子位  https://mp.weixin.qq.com/s/-F9U7ne2NxHZ8TMSiF9Atg \
  SD-LORA:SCALABLE DECOUPLED LOW-RANK ADAPTATION FOR CLASS INCREMENTAL LEARNING \
  https://github.com/WuYichen-97/SD-Lora-CL \
  彻底摆脱传统方法对旧数据存储的依赖！哈佛团队联手香港城大、西安交大最新发布的SD-LoRA技术，通过固定已学习任务的方向参数，仅调整幅度权重，完全避免了历史数据的存储需求。能够在减少50%以上参数存储的同时保持最高准确率，并且在不增加推理开销的前提下显著缓解了灾难性遗忘问题。 \
  作者针对预训练模型的持续学习，不同于之前⼴泛采⽤的混合专家模型的思路（将CL的瓶颈转化为选择准确的对应专家模型）， 本⽂提出的SD-LoRA算法逐步引入低秩矩阵，通过分解其⽅向和幅值，在提升持续学习性能的同时，实现了更好的参数效率。 \
  本文提出的SD-LoRA是一种rehearsal-free、推理高效、可端到端优化的持续学习方法。不同于以往依赖混合专家模型的做法，SD-LoRA通过逐步引入低秩矩阵，并将其方向与幅值分解，实现了参数高效、无路由机制的持续学习。在多个基准任务和预训练模型上的实验表明，SD-LoRA在不增加推理开销的前提下显著缓解了灾难性遗忘问题。同时，本文还从经验和理论两个角度深入分析了SD-LoRA的工作机制，揭示了其能有效挖掘不同任务共享低损路径的本质，提供了一种全新的持续学习解决思路。
* 115.Adam获时间检验奖！清华揭示保辛动力学本质，提出全新RAD优化器  新智元  https://mp.weixin.qq.com/s/5Tq92-4ErC1k13ukPPQmBQ \
  Adam优化器是深度学习中常用的优化算法，但其性能背后的理论解释一直不完善。近日，来自清华大学的团队提出了RAD优化器，扩展了Adam的理论基础，提升了训练稳定性。实验显示RAD在多种强化学习任务中表现优于Adam。 \
  Adam优化器虽在工程实践中表现优异，但长期以来缺乏对其优异性能的理论解释。近期，清华大学李升波教授课题组发文 《Conformal Symplectic Optimization for Stable Reinforcement Learning》，解析了这一「黑箱」算法的优化动力学机理。 \
  该课题组的研究发现了神经网络优化过程与共形哈密顿系统演化存在「完美」的数学对偶性，揭示了Adam优化器暗藏的「相对论动力学」和「保辛离散化」本质，并由此提出了训练更加稳定、性能更加优秀的RAD优化器（Relativistic Adaptive Gradient Descent），这一研究工作为神经网络优化动力学的分析及全新算法的设计开辟了新航道。 
* 116.几行代码，一窥上帝造物！帝国理工开源CAX，引爆人工生命新纪元  新智元  https://mp.weixin.qq.com/s/ffDikOiEww8X-ZLIjLFiXA \
  人工生命的革命来临！帝国理工的研究人员，开源了名为CAX的硬件加速工具。只需几行代码，就能复刻人工生命实验，模拟速度可提升2000倍，部分表现甚至超过了GPT-4！ \
  「人工生命」(artificial life，或简写为ALife)，旨在模拟生命的行为、特性和演化过程，理解生命的本质，涉及涌现现象、自组织系统或形态发生机制 \
  CAX:CELLULAR AUTOMATA ACCELERATED IN JAX \
  https://github.com/maxencefaldor/cax
* 117.序列预测学习是海马体表征和重放的统一理论  CreateAMind  https://mp.weixin.qq.com/s/740oVfRct652S2-2dvU8GA \
  Sequential predictive learning is a unifying theory for hippocampal representationand replay \
  哺乳动物的海马体包含一个认知地图，用于表示动物在环境中的位置，并生成离线“回放”，以实现回忆、规划和形成长期记忆的目的。最近的研究发现，经过训练以预测感官输入的人工神经网络会发展出空间调谐细胞，这与海马体功能的预测理论一致。然而，预测性学习是否也能解释生成离线回放的能力尚不清楚。在这里，我们发现，通过各种形式的预测性学习稳健出现的空间调谐细胞，并不能保证具有生成回放能力的认知地图的存在。离线模拟仅出现在使用递归连接和头部方向信息来预测多步观察序列的网络中，这种方式促进了反映环境几何结构的连续吸引子的形成。这些离线轨迹能够展示出类似于清醒状态的统计特性，自主回放最近经历的位置，并可以由虚拟头部方向信号引导。此外，我们发现，经过训练以循环预测未来观察序列的网络能够快速学习认知地图，并生成类似于海马体θ波扫描的未来位置表征。这些结果表明，类似海马体的表征和回放可以在参与预测性学习的神经网络中出现，并提示海马体θ序列反映了实现高效数据算法的电路，用于顺序预测性学习。总之，这一框架为海马体功能以及受海马体启发的人工智能方法提供了一个统一的理论
* 118.迈向长上下文视频生成！NUS团队新作FAR同时实现短视频和长视频预测SOTA，代码已开源  机器之心  https://mp.weixin.qq.com/s/ZNeMG4hWGo6vntNfbFWydg \
  Long-Context Autoregressive Video Modeling with Next-Frame Prediction \
  https://farlongctx.github.io/ \
  https://github.com/showlab/FAR
* 119.业内首次! 全面复现DeepSeek-R1-Zero数学代码能力，训练步数仅需其1/10  机器之心  https://mp.weixin.qq.com/s/q7TkEe76WH6mBDDfiRdFUg \
  GRPO 训练过程中存在多项常见问题，如性能瓶颈、样本利用效率低下，以及在处理混合领域数据集时难以培养专业推理技能等，这些挑战使得强化学习方法的有效扩展变得更加复杂。针对这些挑战，来自快手Kwaipilot团队的研究者提出了一种创新的强化学习框架——两阶段历史重采样策略优化（two-Staged history-Resampling Policy Optimization，SRPO），旨在从多个维度系统性地解决上述训练难题。他们对外发布了SRPO的技术报告，详细披露了该训练方法的技术细节，同时也开源了SRPO-Qwen-32B 模型 \
  SRPO: A Cross-Domain Implementation of Large-Scale Reinforcement Learning on LLM \
  https://huggingface.co/Kwaipilot/SRPO-Qwen-32B
* 120.扩散模型还原被遮挡物体，几张稀疏照片也能"脑补"完整重建交互式3D场景｜CVPR'25  量子位  https://mp.weixin.qq.com/s/N6Ceo86jGpZwc3WCme36RQ \
  Decompositional Neural Scene Reconstruction with Generative Diffusion Prior \
  https://dp-recon.github.io/ \
  https://github.com/DP-Recon/DP-Recon

# 4.24 Thur
* 121.如何模拟人类日常活动？通研院构建欲求驱动的自主智能体D2A  北京通用人工智能研究院  https://mp.weixin.qq.com/s/0uS2geptcO9pbMyVtHJMWg \
  Simulating Human-like Daily Activities with Desire-driven Autonomy \
  欲求驱动自主智能体D2A（Desire-driven Autonomous Agent） \
  D2A的架构主要包含欲求价值系统（Desire Value System，V）以及欲求价值驱动任务规划器（Desire-driven Planner，U）两个部分 \
  **欲求价值系统**负责维护预定义的一系列欲求维度以数值形式的更新，并模拟人类欲求的动态变化机制（如随着时间，饥饿感会增加，干净度会下降），在行动前将欲求维度数值对应的感官状态以文本描述的形式呈现给智能体，并在智能体行动得到环境反馈后进行欲求维度数值的更新； \
  **欲求价值驱动任务规划器**用了一种符合人类直觉的动作提出和选择的方法，首先让智能体提出多个可行的活动，之后想象采取这些行动后可能对各个欲求维度带来的满足度变化，之后根据以上想象的结果选择能最好满足当前欲求的活动作为当前步骤的行动。 \
  在这两个主要模块之外，还引入了情境记忆，自我反思等模块，以保证智能体稳定生成理性、持续的行为。 \
  具体的决策过程包括以下四步：1、感知欲求：动态价值系统实时评估当前状态（如“饥饿值8/10，社交值2/10”）；2、生成候选行为：基于环境物品和自身特征，提出可能的活动（如“吃早餐”“约朋友聊天”）；3、预判效果：想象每种行为对欲求的影响（“吃饭降低饥饿，但占用时间可能加剧孤独”）；4、自主选择：权衡后执行最优解，像人类一样“在有限条件下做最合理的事”。
* 122.意识的神经理论多尺度整合视角  CreateAMind  https://mp.weixin.qq.com/s/sULrmABhUL4x7WiDKqQMGg \
  An integrative, multiscale view on neural theories of consciousness \
  意识体验如何与物质性的大脑过程相关联？近年来，随着意识研究的激增，许多旨在回答这一古老问题的理论应运而生，并且一些理论目前正受到激烈争论。尽管大多数研究者迄今为止主要孤立地专注于发展和验证他们偏好的理论，本文由代表不同理论的一组科学家撰写，采取了一种不同的方法。我们注意到，各种理论通常试图解释意识的不同方面或机制层次，因此我们认为这些理论并不一定相互矛盾。相反，其中几种理论可能在基本的神经元机制上趋于一致，并且部分兼容、互补，从而可以同时为我们的理解做出贡献。在此，我们考虑了迄今为止被广泛忽视的统一性和整合导向的方法，寻求将各种理论中的有价值元素结合起来。
* 123.被《经验时代》刷屏之后，剑桥博士长文讲述RL破局之路  机器之心  https://mp.weixin.qq.com/s/dLfbu56f02BtQR4bCjzNfw 
* 124.TTS和TTT已过时？TTRL横空出世，推理模型摆脱「标注数据」依赖，性能暴涨  机器之心  https://mp.weixin.qq.com/s/yUfpJj6O2cddwnC3yENQ9w \
  TTRL: Test-Time Reinforcement Learning \
  https://github.com/PRIME-RL/TTRL \
  https://huggingface.co/papers/2504.16084 \
  TTS TTT TTRL的递进关系？ \
  TTS 依赖预训练知识，在面对未标注新数据或输入分布变化时，泛化能力受限 \
  TTT 通过在测试阶段利用 RL 等技术动态更新模型参数，使模型适应新数据或任务，弥补了 TTS 在泛化能力上的不足。但 TTT 同样面临自身的挑战：测试阶段缺乏奖励函数或验证信号，而人工标注数据的高成本使得无监督环境下的 RL 应用受限 \
  TTRL能够在无标注数据上对 LLM 进行强化学习训练 \
  TTRL 通过利用预训练模型中的先验知识，使 LLM 具备自我演化的能力 \
  实验过程中，强化学习的数据均由被训练的模型自身生成 \
  DeepMind工程师评价，这种测试时强化学习的方式将改变LLM的格局：它利用预训练模型和特定任务的提示进行实时自适应，而无需大量带标签的数据集，这是向前迈出的重要一步。
* 125.7B超越GPT！1/20数据，无需知识蒸馏，马里兰等推出全新视觉推理方法  新智元  https://mp.weixin.qq.com/s/9qmNXjMmGrynzbPERRpFng \
  能否通过自我提升，训练出高性能的推理模型？ \
  论文主要关注一个核心问题：如果不给VLM额外的「教师指导」（如知识蒸馏），能否仅通过自身的反馈机制和强化学习训练，获得强大的推理能力？ \
  直觉上，答案是肯定的：人类也可以通过不断尝试、失败和总结来提升自己的推理能力。但对模型而言，这需要我们解决一个关键挑战——如何准确判断哪些训练样本是「值得学」的？ \
  SoTA with Less: CTS-Guided Sample Selection for Data-Efficient Visual Reasoning Self-Improvement \
  https://github.com/si0wang/ThinkLite-VL \
  https://huggingface.co/russwang/ThinkLite-VL-7B
* 126.DeepMind果蝇登Nature，强化学习再立功！AI模拟飞行，逼真到腿毛颤抖  新智元  https://mp.weixin.qq.com/s/KQcIjsqIVgA_4jSyBzA5sw \
  Whole-bodyphysics simulation offruit flylocomotion \
  https://github.com/TuragaLab/flybody
* 127.逆向设计智能物质：可微分逻辑元胞自动机破解数十年难题  集智俱乐部  https://mp.weixin.qq.com/s/5CxgXH-s8Egmj33Z9kxBiw 

# 4.25 Fri
* 128.你以为在追 AI，其实你落下的是思考力——诺奖得主 Hinton 的提醒，刺痛所有人  图灵人工智能  https://mp.weixin.qq.com/s/7rZGPAhuJ_KQfWZTBHcqjA \
  “我们不是逻辑动物，而是类比动物。”
* 129.RL真让大模型更会推理？清华新研究：其能力边界或仍被基座「锁死」  机器之心  https://mp.weixin.qq.com/s/2-GDxs8j1QYh1VnW9iBnXw \
  强化学习被高估！清华上交：RL不能提升推理能力，新知识得靠蒸馏  新智元  https://mp.weixin.qq.com/s/Lvr2t3-pe0mR8S8GQRq-uw \
  Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model? \
  https://limit-of-RLVR.github.io \
  强化学习真的能让大模型获得超越基础模型的新推理能力吗？ \
  当前的 RLVR 方法似乎尚未突破基座模型的能力上限 \
  论文的核心发现是：RLVR 模型中的所有推理路径均已存在于基础模型中 \
  所谓「能力边界」是指模型是否具有正确解决某类问题的潜质，而「效率」是在给定时间和资源成本下模型的表现，因而不能将大模型的「能力边界」和「效率」混为一谈。这项研究从未否定 RL 带来的「效率」上的提升，而是更深入地发起对其能力边界的探讨。 \
  研究团队还发现，RLVR 与蒸馏训练存在本质区别。RL 仅能提升采样效率，而蒸馏训练能真正为模型注入新知识。因此蒸馏模型通过学习蒸馏数据往往能拓展基础模型的推理能力边界，这与能力始终受限于基础模型的 RLVR 训练模型形成鲜明对比。 \
  若将 base 模型比作一棵树，RLVR 只能修剪枝叶使其更整齐，却无法让树长出新的枝干 \
  真正的「进化」，或许需要更根本的范式变革 —— 让模型不仅能高效利用既有知识，更能主动跳出先验去探索未知领域。 \
  RLVR被认为是打造自我进化大模型的关键，但实验表明，它可能只是提高了采样效率，而非真正赋予模型全新推理能力 \
  RL并不能实现模型自进化，还需要找到更强大的自进化方法，突破模型的能力边界 
* 130.李飞飞/DeepSeek前员工领衔，复现R1强化学习框架，训练Agent在行动中深度思考  量子位  https://mp.weixin.qq.com/s/VSKrpqLldrPWY0DA3K4xmA \
  https://github.com/RAGEN-AI/RAGEN/blob/main/RAGEN.pdf \
  代码 \
  https://github.com/RAGEN-AI/RAGEN \
  https://github.com/RAGEN-AI/VAGEN \
  新强化学习框架RAGEN，作者包括DeepSeek前员工Zihan Wang、斯坦福李飞飞团队等，可训练Agent在行动中深度思考。
* 131.Anthropic CEO豪言LLM黑箱5年内必破！研究员爆料：AI有意识概率已达15%  新智元  https://mp.weixin.qq.com/s/C8LS6rgh8z6JTGYq3xczGQ 
* 132.腾讯低调开源「作业终结者」：3B参数实现多模态SOTA，数学物理全通吃  PaperWeekly  https://mp.weixin.qq.com/s/1AgsMegyrtoQbSBqgM8CUA \
  https://hf-mirror.com/TencentBAC/TBAC-VLR1-3B-preview
* 133.等到了！VLM-R1完整细节首度公开：RL的一小步，视觉语言模型推理的一大步  PaperWeekly  https://mp.weixin.qq.com/s/IrbnovrjW-vLQOFbfaMONw \
  VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model \
  https://github.com/om-ai-lab/VLM-R1 \
  总的来说，VLM-R1 证明了 R1 类似的思路完全可以成功复现于视觉任务，并且强化学习显著提升了视觉模型的泛化能力。通过精心设计的奖励机制和高质量的训练数据，VLM-R1 在特定任务上实现了突破性表现。 
* 134.英伟达开源「描述一切」模型，拿下7个基准SOTA  机器之心  https://mp.weixin.qq.com/s/FhARyS4bkqY3A6Z7ihmZcA \
  Describe Anything: Detailed Localized Image and Video Captioning \
  https://describe-anything.github.io/ \
  来自英伟达、UC 伯克利等机构的研究者推出了「描述一切模型」 (DAM，Describe Anything Model)。这是一个强大的多模态大语言模型，可以生成图像或视频中特定区域的详细描述。用户可以使用点、框、涂鸦或蒙版来指定区域，DAM 将提供这些区域丰富的上下文描述。
* 135.北航推出全开源TinyLLaVA-Video-R1，小尺寸模型在通用视频问答数据上也能复现Aha Moment！  机器之心  https://mp.weixin.qq.com/s/McUNFXvboPzcIWkohppXLg \
  TinyLLaVA-Video-R1: Towards Smaller LMMs for Video Reasoning \
  https://github.com/ZhangXJ199/TinyLLaVA-Video-R1
* 136.大模型何以擅长小样本学习？ICLR 2025这项研究给出详细分析  机器之心  https://mp.weixin.qq.com/s/KxbzaVMLiJdWhDWApetOnQ \
  上下文学习能力（In-Context Learning, ICL）是 LLM 最显著且重要的能力之一，它允许 LLM 在给定包含输入输出示例的提示（prompt）后，直接生成新输入的输出，这一过程仅通过前向传播而无需调整模型权重 \
  这种能力使得 LLM 能够基于上下文中的示例快速理解并适应新任务，展现出强大的小样本学习和泛化能力。理解 LLM 是如何实现 ICL 的，对于提高模型性能与效率、提升模型可解释性与 AI 安全、推广大模型应用与改进小样本学习算法具有重要意义，也是近来机器学习研究热点之一。有以下关键问题需要回答： \
  1.LLM 能够学到哪些学习算法，例如梯度下降、比较近邻等？ \
  2. 在具体问题的 ICL 过程中在执行哪一种学习算法？ \
  3. 如何进一步提升 LLM 的 ICL 能力？ \
  Why In-Context Learning Models are Good Few-Shot Learners? \
  https://github.com/ovo67/Uni_ICL \
  本文通过将 ICL 模型建模为元学习器，证明了 ICL 模型具有超过已有元学习器的表达学习算法的能力；ICL 执行在预训练数据分布上最优的算法，而不一定具有可泛化的规则；可以将传统深度网络有关技术迁移到元学习层面用以提升 ICL，如元 - 课程学习加速预训练收敛，元 - 元学习提升少数据领域微调快速适应能力。

# 4.26 Sat
* 137.我们误会智能太久了：图灵奖得主LeCun 正在修正AI的底层架构  图灵人工智能  https://mp.weixin.qq.com/s/mNbKT86-nn0kdVI8_DPzmA \
  GPT 是个装满应用的手机，世界模型才是能调动这些能力的操作系统。
* 138.诺奖得主Demis Hassabis：当AGI到来，我们需要一批伟大的哲学家……  图灵人工智能  https://mp.weixin.qq.com/s/upOSU9MSta2zgxg09uo1lA \
  “AI 的意识，可能是隐式发生的。问题是——我们可能无法察觉。”
* 139.人类内嗅皮层中序列记忆的层级坐标系统  CreateAMind  https://mp.weixin.qq.com/s/XbmglLIPE40w8v6OgRvv0w \
  A hierarchical coordinate system for sequence memory inhuman entorhinal cortex \
  这篇论文提出了人类内嗅皮层（entorhinal cortex）中存在一个层级式坐标系统（hierarchical coordinate system），用于支持序列记忆（sequence memory）。它不仅揭示了空间导航中坐标系统的记忆功能扩展，也为我们理解人脑如何编码事件顺序提供了神经基础
* 140.首份空间智能研究报告来了！一文全面获得空间智能认知、要素、玩家图谱  量子位  https://mp.weixin.qq.com/s/xTOQ2cvgbIGMPCHuGrKQJQ \
  https://jkhbjkhb.feishu.cn/wiki/W5D7wuDcbiPXDLkaRLQcAJpOn8f
* 141.全球开发者组团训练，首个异步强化学习32B推理模型震撼来袭！数据已开源  新智元  https://mp.weixin.qq.com/s/8hDTEjk_AqU_nORp-qdheA \
  全球首个去中心化强化学习训练的32B模型震撼发布！无需授权，就能用自家异构计算资源参与其中，让编码、数学与科学领域的推理性能迈向新高度。 \
  博客链接：https://www.primeintellect.ai/blog/intellect-2
* 142.OpenAI、谷歌等一线大模型科学家公开课，斯坦福CS 25春季上新！  机器之心  https://mp.weixin.qq.com/s/SdvRA7xmDOTXrC7GwASFeg \
  课程地址：https://web.stanford.edu/class/cs25/recordings/
* 143.具身交互推理: 图像-思考-行动交织思维链让机器人会思考、会交互  机器之心  https://mp.weixin.qq.com/s/yO0uylWGF8Mv7T9y1tjDcA \
  来自浙江大学、中科院软件所和阿里巴巴的团队提出了 Embodied-Reasoner，让机器人或智能体拥有深度思考和交互决策能力，从而在真实物理世界完成环境探索、隐藏物体搜索、交互和搬运等长序列复杂任务。 \
  Embodied-Reasoner: Synergizing Visual Search, Reasoning, and Action for Embodied Interactive Tasks \
  项目主页：https://embodied-reasoner.github.io \
  代码地址：https://gitee.com/agiros/EmbodiedReasonerhttps://github.com/zwq2018/embodied_reasoner \
  HuggingFace：https://huggingface.co/datasets/zwq2018/embodied_reasoner
* 144.70%大小，100%准确！完美压缩LLM性能0损失，推理速度最高飙升39倍  新智元  https://mp.weixin.qq.com/s/uX6UEl1lUCNI_OFcseZz3Q \
  LLM的规模爆炸式增长，传统量化技术虽能压缩模型，却以牺牲精度为代价。莱斯大学团队的最新研究DFloat11打破这一僵局：它将模型压缩30%且输出与原始模型逐位一致！更惊艳的是，通过针对GPU的定制化解压缩内核，DFloat11使推理吞吐量提升最高38.8倍。

# 4.27 Sun
* 145.机器意识能否实现？来自人脑的启发  CreateAMind  https://mp.weixin.qq.com/s/2abgPjDQxyODfz2pZsnCUg \
  Is artificial consciousness achievable? Lessons from the human brain \
  我们在此从进化的角度分析开发人工意识的问题，以人类大脑的进化及其与意识的关系作为参考模型或基准。这种分析揭示了人类大脑的若干结构和功能特征，这些特征似乎是实现类人复杂意识体验的关键，当前的人工智能（AI）研究在试图开发具备类人意识处理能力的系统时应予以考虑。我们认为，即使人工智能在模拟人类意识方面受到限制，无论是由于内在原因（即结构和架构上的限制）还是外在原因（即当前科学技术知识的局限性），借鉴那些使类人意识处理成为可能或对其产生调节作用的大脑特性，仍是一种具有潜在前景的策略，可推动意识AI的发展。 \
  此外，从理论上不能排除人工智能研究可能开发出部分或替代形式的意识，这些意识在质量上与人类的意识形式不同，并且可能根据不同的视角而表现出更高的复杂性或更低的复杂性。因此，我们建议在讨论人工意识时采取受神经科学启发的谨慎态度：由于将“意识”一词同时用于人类和AI可能会引起歧义并导致潜在误导，我们建议明确说明人工智能研究旨在开发何种层次或类型的意识，以及人工智能的意识处理与人类意识体验之间有哪些共同点和差异。
* 146.【NYU博士论文】面向开放世界的人工智能：学习原则  专知  https://mp.weixin.qq.com/s/kWe2Dhd0JWTGTMWjFjpddg \
  AI for the Open-World: the Learning Principles \
  本论文探索了构建开放世界 AI 所需的重要学习原则，包括丰富特征（类比为一套庞大的工具箱）、解耦表示（类比为一套井然有序的工具箱）以及推理时学习（类比为一只灵活运用工具的手）
Principles
* 147.大型语言模型的知识蒸馏与数据集蒸馏：新兴趋势、挑战与未来方向  专知  https://mp.weixin.qq.com/s/qim66Aqvnq4f7mfDDfQZ9w \
  Knowledge Distillation and Dataset Distillation of Large Language Models: Emerging Trends, Challenges, and Future Directions 
* 148.OpenAI没说的秘密，Meta全揭了？华人一作GPT-4o同款技术，爆打扩散王者  新智元  https://mp.weixin.qq.com/s/idGmfXkEuI6PzNY52gQDnA \
  自回归模型，首次生成2048×2048分辨率图像！来自Meta、东北大学、新加坡国立大学等机构的研究人员，专门为多模态大语言模型（MLLMs）设计的TokenShuffle，显著减少了计算中的视觉Token数量，提升效率并支持高分辨率图像合成。 \
  Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models

# 4.28 Mon
* 149.Nature | 用自然语言做梯度，多智能体系统也能「反向传播」了？  计算神经语言学  https://mp.weixin.qq.com/s/cV__AisKIuSPRJr14aaNng \
  TextGrad：通过LLM生成的文本，反向传播优化多智能体系统
* 150.首个系统性工具使用奖励范式，ToolRL刷新大模型训练思路  机器之心  https://mp.weixin.qq.com/s/IVZJlhfU8uaeFZZvPSkG-g \
  ToolRL: Reward is All Tool Learning Needs \
  https://github.com/qiancheng0/ToolRL
* 151.AGI幻灭，LeCun观点得证？哈佛研究实锤AI不懂因果，世界模型神话破灭  机器学习研究组订阅  https://mp.weixin.qq.com/s/rolmaS1vB7uVgf6d90xqEA \
* 152.2万字长文！从Transformer到DeepSeek位置编码，全面了解「大模型位置编码」！  AINLPer  https://mp.weixin.qq.com/s/aG5pZgUIuUe6EQC4yRia8Q 
* 153.语句的含义隐藏在何处？范畴论可能告诉我们答案  集智俱乐部  https://mp.weixin.qq.com/s/pal0W6PmOr8ySCqoFzStCQ 

# 4.29 Tue
* 154.【博士论文】物体学习与鲁棒的三维重建  专知  https://mp.weixin.qq.com/s/9CX8sFhsK8uUSa3e1upP7g \
  OBJECT LEARNING AND ROBUST 3D RECONSTRUCTION
* 155.模仿or探索？LUFFY：我全都要！巧妙融合外部指导，RL推理不再死板  PaperWeekly  https://mp.weixin.qq.com/s/EB70T7PAL4EQUYKJLUm1UA \
  Learning to Reason under Off-policy Guidance \
  https://github.com/ElliottYan/LUFFY \
  https://huggingface.co/papers/2504.14945

# 4.30 Wed
* 156.只花9美元，推理能力暴涨20%！小模型Tina震撼登场，成本缩减260倍  机器之心  https://mp.weixin.qq.com/s/i4fxMSspTxZ5HSKo0ibMTw \
  Tina: Tiny Reasoning Models via LoRA \
  Notion 博客: https://shangshangwang.notion.site/tina \
  代码仓库: https://github.com/shangshang-wang/Tina \
  训练日志: https://wandb.ai/upup-ashton-wang-usc/Tina \
  模型权重及检查点: https://huggingface.co/Tina-YiNotion \
  博客: https://shangshangwang.notion.site/tina \
  代码仓库: https://github.com/shangshang-wang/Tina \
  训练日志: https://wandb.ai/upup-ashton-wang-usc/Tina \
  模型权重及检查点: https://huggingface.co/Tina-Yi \
  团队将「小型」 模型架构以及通过基于 LoRA 的强化学习这两个要素整合后发布了 Tina（通过 LoRA 的微型推理模型）系列模型，该系列模型以极低的成本实现了出色的推理性能
* 157.R1-Zero的无监督版本来了！SFT不再是必须，EMPO重新定义大模型推理微调  PaperWeekly  https://mp.weixin.qq.com/s/rIzRIoi-h4PH5TB7JLIpiA \
  Right Question is Already Half the Answer: Fully Unsupervised LLM Reasoning Incentivization
