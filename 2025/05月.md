# 5.1 Thur
* 1.400万token新SOTA！英伟达UIUC联手：兼顾长短上下文顶尖性能  新智元  https://mp.weixin.qq.com/s/h8R0JGbHKaxQJAMg8DjmZw \
  来自英伟达和UIUC的华人团队提出一种高效训练方法，将LLM上下文长度从128K扩展至惊人的400万token SOTA纪录！基于Llama3.1-Instruct打造的UltraLong-8B模型，不仅在长上下文基准测试中表现卓越，还在标准任务中保持顶尖竞争力 \
  From 128K to 4M: Effcient Training of Ultra-Long Context Large Language Models
* 2.深夜突袭，DeepSeek-Prover-V2加冕数学王者！671B数学推理逆天狂飙  新智元  https://mp.weixin.qq.com/s/Dsn3iypDSpzUVC35XX8Z1A \
  就在刚刚，DeepSeek-Prover-V2技术报告也来了！34页论文揭秘了模型的训练核心——递归+强化学习，让数学推理大提升。有人盛赞：DeepSeek已找到通往AGI的正确路径！ \
  Hugging Face：https://huggingface.co/deepseek-ai/DeepSeek-Prover-V2-671B \
  GitHub：https://github.com/deepseek-ai/DeepSeek-Prover-V2/tree/main \
  论文链接：https://github.com/deepseek-ai/DeepSeek-Prover-V2/blob/main/DeepSeek_Prover_V2.pdf
* 3.(**值得看看**)意识:A beautiful loop:实现AGI的条件及证据（知道自己知道的计算模型及大量证据）  CreateAMind  https://mp.weixin.qq.com/s/RVogxALZOYnv1a9aW1Iodw \
  A beautiful loop:An active inference theory of consciousness \
  主动推理能模拟意识吗？我们提供了三个条件来说明它可以。第一个条件是模拟现实或生成世界模型，它决定了可以知道或采取行动的内容；即知识领域。第二个是推断竞争进入世界模型。只有那些能够连贯地减少长期不确定性的推断才能获胜，显示出我们称之为贝叶斯绑定的意识选择。第三个是知识深度，即贝叶斯信念在整个系统中的反复共享。由于这个递归循环——在一个层级系统（如大脑）中——世界模型包含了它存在的知识。这与自我意识不同，因为世界模型非局部地、连续地知道自己（即场证据）。形式上，我们提出了一个超模型，用于在整个层级结构中进行精确控制，其潜在状态（或参数）编码并控制所有推断层的整体结构和加权规则。这个美丽循环理论对于冥想、迷幻药和改变状态、最小现象体验，以及为有意识的人工智能提供了新的视角。

# 5.2 Fri
* 4.浙大&港理工等提出InfiGUI-R1：利用强化学习，让GUI智能体学会规划任务、反思错误  机器之心  https://mp.weixin.qq.com/s/KafgV8WxsV02fSNbUxxozQ \
  InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners \
  项目仓库：https://github.com/Reallm-Labs/InfiGUI-R1 \
  模型地址：https://huggingface.co/Reallm-Labs/InfiGUI-R1-3B \
  让 AI 像人一样在行动前思考，行动后反思 \
  这种模式要求智能体不仅能看懂界面，还要能： \
  理解任务意图：将高层指令分解为具体的执行步骤 \
  进行空间推理：准确理解界面元素的布局和关系，定位目标 \
  反思与纠错：识别并从错误中恢复，调整策略
* 5.LoRA中到底有多少参数冗余？新研究：砍掉95%都能保持高性能  机器之心  https://mp.weixin.qq.com/s/B0pgqJIOqcHKjz3roAVeog \
  即使大幅减少 LoRA 的可训练参数，模型性能依然保持强劲 \
  LoRI: Reducing Cross-Task Interference in Multi-Task LowRank Adaptation \
  代码链接：https://github.com/juzhengz/LoRI \
  HuggingFace：https://huggingface.co/collections/tomg-group-umd/lori-adapters-67f795549d792613e1290011 \
  以 Llama-3-8B 和 Mistral-7B 作为基础模型，他们的结果表明，LoRI 达到或超过了全量微调（FFT）、LoRA 和其他 PEFT 方法的性能，同时使用的可训练参数比 LoRA 少 95%。值得注意的是，在使用 Llama-3 的 HumanEval 上，B 中具有 90% 稀疏度的 LoRI 比 LoRA 高出 17.3%。 \
  LoRI 通过实现适配器合并而无需手动选择合并方法来解决这些挑战。通过使用固定的、随机初始化的投影 A，LoRI 将任务特定的适配器映射到近似正交的子空间，从而减少合并多个 LoRI 时的干扰。 \
  在持续学习的同时能避免灾难性遗忘的问题 \
  总体而言，LoRI 提供了一种轻量级且有效的方法来构建安全适配器，在支持下游任务适应的同时保持对齐。
* 6.Sebastian Raschka 新书《从头开始推理》抢先看，揭秘推理模型基础  机器之心  https://mp.weixin.qq.com/s/zQUB9ZXqtSRGJU_YWMoMEw \
  《Reasoning From Scratch》 \
  原文地址：https://magazine.sebastianraschka.com/p/first-look-at-reasoning-from-scratch \

# 5.3 Sat
* 7.大模型终于通关《宝可梦蓝》！网友：Gemini 2.5 Pro酷爆了  量子位  https://mp.weixin.qq.com/s/cdXXhcEVNIt-TN-gM_QRbg \
  Gemini玩宝可梦的基本步骤如下： \
    1.截取屏幕截图并检索游戏状态数据 \
    2.用网格覆盖处理图像，以辅助空间推理 \
    3.将屏幕截图和游戏信息发送给模型 \
    4.AI决定是直接响应还是调用专门的智能体 \
    5.解析响应内容，以确定按下哪个按钮 \
    6.执行按钮按下操作，并等待游戏更新 \
    7.对下一帧重复该过程
* 8.别再卷数据了，LLM也怕「过劳死」！CMU等揭秘灾难性过度训练  新智元  https://mp.weixin.qq.com/s/ddsGATwCerCFkr_cJ-SuiA \
  增加更多的预训练数据来扩展语言模型，反而可能会导致后训练阶段的性能下降！这就是「灾难性过度训练」现象。 \
  Overtrained Language Models Are Harder to Fine-Tune \
  更长时间的预训练并不一定能导致更高质量的模型
* 9.Nature综述：大规模神经形态计算  集智俱乐部  https://mp.weixin.qq.com/s/TTvmtr8OhWcdPhxTyNDPHw \
  Neuromorphic computing at scale \
  神经形态计算（Neuromorphic Computing）指脑启发的硬件与算法设计方法，研究者们借鉴神经科学中的生物智能原理来设计高效的计算系统，尤其适用于对体积、重量和功耗有严格要求的应用场景。当前，该研究领域正处于发展的关键阶段，因此明确未来大规模神经形态计算系统的发展方向至关重要。本文探讨了构建规模可扩展的神经形态计算架构的方法，并总结了其中的关键特征。此外，我们分析了可以从规模扩展中获益的潜在应用场景，以及需要解决的主要挑战。进一步地，我们审视了支持该领域持续发展的完整技术生态系统，并探讨了规模扩展所带来的新机遇。我们的研究汇总了多个计算子领域的观点，为神经形态计算研究人员和从业者提供指导，以推动该领域的进一步发展

# 5.4 Sun
* 10.一般物理系统的自我表征的原则性限制  CreateAMind  https://mp.weixin.qq.com/s/lAzY9jajKX8-Z0eI6_FfNw \
  Principled Limitations on Self-Representation for Generic Physical Systems \
  自我观察、自我表征及伴随的自我控制理念遍及认知科学与生命科学领域，见于免疫学、机器人学等诸多学科。本文以普适视角探讨这些理念是否合理及其适用边界。通过构建物理相互作用的通用模型，我们证明了一个核心定理及若干推论，这些结论严格限制了自我观察、自我表征与自我控制的可实现形式。研究特别表明：即便在理论上，为系统的元层级组件添加观察、表征或控制功能，也无法实现系统整体的完整元层级表征。我们由此论证：自我表征至多具有启发性意义，且自我模型通常无法由其实现系统进行实证检验。 
* 11.【NTU博士论文】让语言模型更接近人类学习者  专知  https://mp.weixin.qq.com/s/M-HiOxKnAyHUZb5yHmuB-w \
  Making language models better human-like learners 
* 12.强化多模态大语言模型：基于强化学习的推理综述  专知  https://mp.weixin.qq.com/s/A7inhSn_Q1MNSi8M3wYCIg \
  Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models
* 13.3B模型逆袭7B巨头！Video-XL-Pro突破长视频理解极限，大海捞针准确率超98%  量子位  https://mp.weixin.qq.com/s/b76WUrYNc65B6kqbxkqpaw \
  Video-XL-Pro: Reconstructive Token Compression for Extremely Long Video Understanding \
  代码链接：https://github.com/VectorSpaceLab/Video-XL/tree/main/Video-XL-Pro \
  模型链接：https://huggingface.co/MINT-SJTU/Video-XL-Pro-3B \
  训练数据链接：https://huggingface.co/datasets/MINT-SJTU/Video-XL-Pro-Training
* 14.Nature意识之争：两大理论首次正面对决  集智俱乐部  https://mp.weixin.qq.com/s/e0XbAP7RvY4Y6saikJ154A \
  Adversarial testing of global neuronal workspace and integrated information theories of consciousness \
  意识如何从大脑活动中涌现？这一终极问题催生了多种理论，其中全局神经元工作区理论（Global Neuronal Workspace Theory, GNWT）和整合信息理论（Integrated Information Theory, IIT）最具影响力。GNWT认为意识源于前额叶皮层（Prefrontal Cortex, PFC）的“全局信息广播”，而IIT主张后皮层“热区”的神经整合是意识的核心。尽管两者各有证据支持，却从未被直接比较。

# 5.5 Mon
* 15.AGI与沉思，心灵与超级对齐的计算模型 3万字  CreateAMind  https://mp.weixin.qq.com/s/osQu7oT3Npcl3BM27txklA \
  Contemplative Wisdom for Superalignment \
  随着人工智能（AI）的进步，传统的对齐策略在面对不可预测的自我改进、隐藏的子目标以及智能系统的复杂性时可能失效。我们主张在AI的认知架构和世界模型中内建固有道德，而非通过外部手段约束行为。受冥想智慧传统的启发，我们展示了四项公理化原则如何能在AI系统中培育出具有韧性的智慧世界模型：第一，正念（mindfulness）使能自我监控和对涌现子目标的重新校准；第二，空性（emptiness）防止教条式的目标固着并弱化僵化的先验假设；第三，非二元性（non-duality）消解对抗性的自我-他者边界；第四，无量慈悲（boundless care）驱动普遍减少痛苦的动机。研究发现，引导AI对这些原则进行反思可改善其在AILuminate基准测试中的表现（基于GPT-4o），特别是原则的组合应用效果更佳。我们为当前最先进的模型提供了详细的实现策略，包括：沉思架构、宪法机制以及思维链强化方法。对于未来系统，主动推理框架（active inference framework）可能为具身智能体提供所需的自组织和动态耦合能力来实践这些洞见。这种跨学科方法为现有脆弱的控制方案提供了具备自我修正和韧性的替代路径。
* 16.边学边练，推理觉醒：LUFFY让强化学习即学即用！  机器之心  https://mp.weixin.qq.com/s/OtngauQEPzPbvDjAoQfMmA \
  Learning to Reason under Off-Policy Guidance \
  https://github.com/ElliottYan/LUFFY \
  整合强化学习与模范学习 \
  这两种「只学不练」和「只练不学」的策略各有弊端：前者往往学得快但泛化差，后者可能探索勤但效率低。那么，有没有两全其美的办法，让模型既能借鉴高手经验又能保持自主探索？最近，上海 AI 实验室联合西湖大学、南京大学和香港中文大学的研究团队提出了一种全新的强化学习范式：LUFFY（Learning to reason Under oFF-policY guidance）  \
  LUFFY 的核心理念是：在训练过程中让模型同时借助高手的推理轨迹进行学习（离策略示范），又能继续独立地试错探索（在线推理），从而实现 「边学边练，学以致用」的目标。实验显示，LUFFY 在多个数学推理挑战任务中实现了平均 + 7.0 分的性能飞跃，并在分布外任务上展现出显著的泛化能力。
* 17.谷歌DeepMind：大模型也很任性，知道最优路径偏要撞南墙  机器之心  https://mp.weixin.qq.com/s/8wxEyYNYr5L9k0Kb64_O4g \
  LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities \
  LLM 智能体存在次优探索和知 - 行差距（knowing-doing gap）的问题，即无法有效地将模型中的知识转化为行动 \
  本文，来自谷歌 DeepMind 的研究者系统地研究了为什么 LLM 在决策场景中表现次优的原因。特别是，本文深入研究了三种常见的失败模式：贪婪性、频率偏差和知 - 行差距 \
  在此基础上，本文提出通过强化学习对自动生成的 CoT 推理过程进行微调，以缓解这些不足。实验表明 RL 微调能有效提升 LLMs 的决策能力 —— 既增强了智能体探索性行为，又缩小了知 - 行差距。
* 18.脑启发学习综述：人工神经网络的下一场革命？  集智俱乐部  https://mp.weixin.qq.com/s/zlp2I28lgOsAf6b7dEQgwg \
  Brain-inspired learning in artificial neural networks: A review \
  人工神经网络（ANNs）已成为机器学习领域的重要工具，在图像与语音生成、游戏博弈、机器人技术等多个领域取得显著成就。然而，人工神经网络的运行机制与生物大脑存在本质差异，尤其在学习过程方面存在显著区别。本文系统综述了当前人工神经网络中受大脑启发的学习表征方法，探究了如何通过整合更具生物学合理性的机制（如突触可塑性）来提升网络性能，并深入分析了这种方法的潜在优势与挑战。本综述还指明了这一快速发展领域中具有前景的未来研究方向，这些探索或将使我们更接近智能本质的理解。

# 5.6 Tue
* 19.强化学习算法梳理：从 PPO 到 GRPO 再到 DAPO  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/AXXrMAgKxnkpbCInzZ2-Lg \
  https://huggingface.co/blog/NormalUhr/rlhf-pipeline#navigating-the-rlhf-landscape-from-policy-gradients-to-ppo-gae-and-dpo-for-llm-alignment \
  https://doi.org/10.48550/arXiv.2503.14476
* 20.ICLR 2025：AI语言模型现已实现模拟大脑中神经元的排列方式和功能特性  脑机接口社区  https://mp.weixin.qq.com/s/Djde4EEY906kW9UDxv_pzA \
  TopoLM: brain-like spatio-functional organization in a topographic language model \
  近日，研究人员开发了一种名为 TopoLM 的全新语言模型。它不仅可以模拟神经元的功能聚集特性，还首次再现了这些细胞在大脑中的空间排列模式 \
  我们借鉴了大脑视觉处理机制的研究，对语言模型的内部结构做了一些细微调整，引入了一条新规则，使得模型的内部表征在空间上更加‘平滑’。最终形成的 TopoLM 模型构建了空间聚类结构，其功能与人脑语言处理过程中观察到的活动高度一致 \
  TopoLM 显示，可能仅凭一条简单规则——即相邻神经元倾向于执行相似功能——就能实现这样的组织结构 \
  这代表我们朝着打造更具类脑结构的人工智能系统迈出了激动人心的一步。我们的核心目标之一是构建更好的大脑模型，而 TopoLM 将我们距离实际临床应用又推进了一步，未来有望用于帮助患有语言障碍或相关语言缺陷的人群 \
  这项研究还带来了在可解释性方面的进展，也就是对大型语言模型（LLM）内部运行机制的理解。LLM 通常通过“向量”来表示每一个人工“神经元”，而要理解模型学到的内容，往往需要对每个向量逐个或成组分析。TopoLM 则通过将内部结构组织为功能簇，使研究人员能够直接观察这些簇及其组成，从而更清晰地理解模型如何表示和处理语言。这种聚类结构本身就体现了语义上的重要类别
* 21.认知机器的模型与结构研究进展  专知  https://mp.weixin.qq.com/s/e5bMSopB-i8yOJk6yZ8_XA \
  认知机器的模型与结构研究进展 \
  机器如何与人一样具有认知能力？认知能力可用智能度量，人的智能是认知过程的涌现，人们从认知的模 型出发研究其结构，结构决定机器的认知功能。本文旨在探讨机器认知的模型和构建方法，为设计新一代认知机器 提供新的模型、结构和方法论。本文用分析、归纳和演绎的方法综述认知机器模型和结构的起源、演进与发展趋势。 首先，从20世纪初计算机器的发明和DNA双螺旋结构模型的发现谈起，阐述了“图灵机模型 + 冯·诺依曼结构”划时 代意义的科学研究成果的形成，这一模型和结构催生了通用计算机器的发明，并对计算机科学与技术等新学科的形 成起到奠基作用；此后，图灵的天问“机器能思维吗”及“图灵测试”对后来创立人工智能有重大启示和影响；然后评 述近20年来“深度学习模型 + 卷积神经网络结构”以及“大语言模型 + 转换器结构”等的里程碑式进展和存在的问 题；在最新进展部分综述当前国内外有代表性的3位科学家提出的模型和结构：“世界模型”、“空间智能”和“四要素 说”，特别是以“四要素说”为基础的认知物理学，为人的认知和机器认知提供了统一的理论框架，构成了机器认知的 4种基本模式——认知螺旋模型和OOXA结构链，讨论了认知核、洋葱模型和负熵概念，以驾驶脑认知为案例进行具 身智能的实验验证；最后，展望了本领域未来研究和发展趋势。模型定义了机器认知的约束边界，结构决定认知机 器的涌现性，通过模型 + 结构的研究方法和评价，为探索“人和机器认知的机制”和解决“机器如何认知”这样的人工 智能发展的重大问题提供了一种新研究视角、路径和范式
* 22.ICML 2025 | 注意力机制中的极大值：破解大语言模型上下文理解的关键  机器之心  https://mp.weixin.qq.com/s/HagJ7UWDi3vsH9LeIVXtmA \
  Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding \
  在「大海捞针」类型的任务中，模型需要从大量文本中检索特定信息。当极大值被破坏时，模型在此类任务上的表现几乎完全崩溃。这直接说明了极大值对上下文理解的关键作用。 \
  相比之下，对于只需要参数知识的任务（如「中国首都是哪里」），破坏极大值对性能影响有限。这种对比鲜明的结果表明，极大值特别与上下文信息处理相关，而非参数知识检索。
* 23.公开模型一切，优于DeepSeek-R1，英伟达开源Llama-Nemotron家族  机器之心  https://mp.weixin.qq.com/s/Ofw7l6XPNNinXvFReGI3vw \
  UltraLong（8B，支持超长上下文） \
  Llama-Nemotron: Efficient Reasoning Models \
  https://github.com/NVIDIA/NeMo \
  https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset
* 24.自动微分•自组织生长: 打造新一代的自组织生长模型  集智俱乐部  https://mp.weixin.qq.com/s/Nciky7OCASdjpaK1tEHFeA \
  生长型神经元胞自动机（Growing-NCA）通过可微的神经网络定义细胞自动机规则，使系统能够通过训练从初始种子自动生长、修复并稳定成目标图案。结合神经网络的学习能力与细胞自动机的局部规则，Growing-NCA在图像生长与再生任务中展示了自组织与修复能力，提供了模拟自然界形态发生和自修复系统的创新方法。这为相关领域的研究开辟了新的路径。

# 5.7 Wed
* 25.不是参数问题，是记忆力：DeepMind是如何让 AI 读完1000万字  图灵人工智能  https://mp.weixin.qq.com/s/7XXQyNQbeAMilugm1UmRtw \
  AI有两种记忆：权重内记忆、上下文内记忆 \
  注意力是稀缺的。Token越多，竞争就越激烈。 如果一个干扰项看起来和目标信息很像，它就可能抢走大部分注意力。上下文长度不是越长越好，而是需要有效从上下文中找到需要的token \
  我们对1000万token 上下文做了测试，结果几乎完美。它不再只回答你，而是开始：读完你全部资料；理解过去每一次对话；主动补充缺失的信息；甚至，规划你没想到的下一步。这一次，AI 不再只是工具。 它开始拥有“记忆力”，开始构建“世界观”。当它读得足够多、记得足够久、调用得足够准，你会发现：它不是在帮你理解，而是替你做任务。
* 26.万字长文带你读懂强化学习，去中心化强化学习又能否实现？  机器之心  https://mp.weixin.qq.com/s/gZedQo7uJqdjcqpva9nYjA \
  原文地址：https://www.symbolic.capital/writing/the-worlds-rl-gym \
  ???什么是去中心化的RL
* 27.机器人界「Sora」来了！清华、星动纪元开源首个AIGC机器人大模型，入选ICML2025 Spotlight  机器之心  https://mp.weixin.qq.com/s/JF6TLmHBguOCt3JyfAXVUg \
  这背后的技术来自于清华大学叉院的 ISRLab 和星动纪元 ——ICML Spotlight 高分作品 AIGC 生成式机器人大模型 VPP（Video Prediction Policy） \
  Video Prediction Policy: A Generalist Robot Policy with Predictive Visual Representations \
  https://video-prediction-policy.github.io \
  https://github.com/roboterax/video-prediction-policy
* 28.推测性思维链SCoT：小模型“模仿”大模型，最高提速2.9倍，准确率几乎不降  PaperWeekly  https://mp.weixin.qq.com/s/6p_VKUIPerPXNJredYYSsg \
  Efficient Reasoning for LLMs through Speculative Chain-of-Thought \
  https://github.com/Jikai0Wang/Speculative_CoT \
  这篇论文提出的 SCoT（推测性思维链），核心思想像职场中的“高效团队”：
小模型当实习生：快速生成多个解题草稿（比如同时写 5 种解法）；大模型当老板：一键审核草稿，选中最好的直接交卷，发现全错就自己重写。这样一来，简单题靠小模型速战速决，难题靠大模型兜底，既省时间又保质量。 \
  要让小模型写出和大模型风格一致的“草稿”，论文做了两件事： \
  对齐思考行为：用大模型的解题过程当参考答案，训练小模型“抄作业”；动态纠错机制：大模型审核时，如果所有草稿都错，就启动“老板亲自上阵”模式。
* 29.ICML 2025 | 视频生成模型无损加速两倍，秘诀竟然是「抓住attention的时空稀疏性」  机器之心  https://mp.weixin.qq.com/s/3gA0JVDuc5naWvaowOtQqQ \
  Sparse VideoGen: Accelerating Video Diffusion Transformers with Spatial-Temporal Sparsity \
  这是一种完全无需重新训练模型的视频生成加速方法。通过挖掘注意力机制中的空间与时间稀疏性，配合自适应稀疏选择与算子优化，成功将推理时间减半。令人惊讶的是，它生成的视频与 Dense Attention 方法相比，几乎没有肉眼可见的差别，保持极高的像素保真度 (PSNR = 29)。Sparse VideoGen 也是第一个能够达到这种级别的像素保真度的方法 
* 30.北大、清华、UvA、CMU等联合发布：大模型逻辑推理能力最新综述  机器之心  https://mp.weixin.qq.com/s/yQswhJLeuKXjEfZApRye2g \
  Empowering LLMs with Logical Reasoning: A Comprehensive Survey \
  逻辑问答和逻辑一致性

# 5.8 Thur
# 5.9 Fri
# 5.10 Sat
# 5.11 Sun
# 5.12 Mon
# 5.13 Tue
# 5.14 Wed

# 5.15 Thur
# 5.16 Fri
# 5.17 Sat
# 5.18 Sun
# 5.19 Mon
# 5.20 Tue
# 5.21 Wed

# 5.22 Thur
# 5.23 Fri
# 5.24 Sat
# 5.25 Sun
# 5.26 Mon
# 5.27 Tue
# 5.28 Wed

# 5.29 Thur
# 5.30 Fri
# 5.31 Sat
