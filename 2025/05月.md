# 5.1 Thur
* 1.400万token新SOTA！英伟达UIUC联手：兼顾长短上下文顶尖性能  新智元  https://mp.weixin.qq.com/s/h8R0JGbHKaxQJAMg8DjmZw \
  来自英伟达和UIUC的华人团队提出一种高效训练方法，将LLM上下文长度从128K扩展至惊人的400万token SOTA纪录！基于Llama3.1-Instruct打造的UltraLong-8B模型，不仅在长上下文基准测试中表现卓越，还在标准任务中保持顶尖竞争力 \
  From 128K to 4M: Effcient Training of Ultra-Long Context Large Language Models
* 2.深夜突袭，DeepSeek-Prover-V2加冕数学王者！671B数学推理逆天狂飙  新智元  https://mp.weixin.qq.com/s/Dsn3iypDSpzUVC35XX8Z1A \
  就在刚刚，DeepSeek-Prover-V2技术报告也来了！34页论文揭秘了模型的训练核心——递归+强化学习，让数学推理大提升。有人盛赞：DeepSeek已找到通往AGI的正确路径！ \
  Hugging Face：https://huggingface.co/deepseek-ai/DeepSeek-Prover-V2-671B \
  GitHub：https://github.com/deepseek-ai/DeepSeek-Prover-V2/tree/main \
  论文链接：https://github.com/deepseek-ai/DeepSeek-Prover-V2/blob/main/DeepSeek_Prover_V2.pdf
* 3.(**值得看看**)意识:A beautiful loop:实现AGI的条件及证据（知道自己知道的计算模型及大量证据）  CreateAMind  https://mp.weixin.qq.com/s/RVogxALZOYnv1a9aW1Iodw \
  A beautiful loop:An active inference theory of consciousness \
  主动推理能模拟意识吗？我们提供了三个条件来说明它可以。第一个条件是模拟现实或生成世界模型，它决定了可以知道或采取行动的内容；即知识领域。第二个是推断竞争进入世界模型。只有那些能够连贯地减少长期不确定性的推断才能获胜，显示出我们称之为贝叶斯绑定的意识选择。第三个是知识深度，即贝叶斯信念在整个系统中的反复共享。由于这个递归循环——在一个层级系统（如大脑）中——世界模型包含了它存在的知识。这与自我意识不同，因为世界模型非局部地、连续地知道自己（即场证据）。形式上，我们提出了一个超模型，用于在整个层级结构中进行精确控制，其潜在状态（或参数）编码并控制所有推断层的整体结构和加权规则。这个美丽循环理论对于冥想、迷幻药和改变状态、最小现象体验，以及为有意识的人工智能提供了新的视角。

# 5.2 Fri
* 4.浙大&港理工等提出InfiGUI-R1：利用强化学习，让GUI智能体学会规划任务、反思错误  机器之心  https://mp.weixin.qq.com/s/KafgV8WxsV02fSNbUxxozQ \
  InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners \
  项目仓库：https://github.com/Reallm-Labs/InfiGUI-R1 \
  模型地址：https://huggingface.co/Reallm-Labs/InfiGUI-R1-3B \
  让 AI 像人一样在行动前思考，行动后反思 \
  这种模式要求智能体不仅能看懂界面，还要能： \
  理解任务意图：将高层指令分解为具体的执行步骤 \
  进行空间推理：准确理解界面元素的布局和关系，定位目标 \
  反思与纠错：识别并从错误中恢复，调整策略
* 5.LoRA中到底有多少参数冗余？新研究：砍掉95%都能保持高性能  机器之心  https://mp.weixin.qq.com/s/B0pgqJIOqcHKjz3roAVeog \
  即使大幅减少 LoRA 的可训练参数，模型性能依然保持强劲 \
  LoRI: Reducing Cross-Task Interference in Multi-Task LowRank Adaptation \
  代码链接：https://github.com/juzhengz/LoRI \
  HuggingFace：https://huggingface.co/collections/tomg-group-umd/lori-adapters-67f795549d792613e1290011 \
  以 Llama-3-8B 和 Mistral-7B 作为基础模型，他们的结果表明，LoRI 达到或超过了全量微调（FFT）、LoRA 和其他 PEFT 方法的性能，同时使用的可训练参数比 LoRA 少 95%。值得注意的是，在使用 Llama-3 的 HumanEval 上，B 中具有 90% 稀疏度的 LoRI 比 LoRA 高出 17.3%。 \
  LoRI 通过实现适配器合并而无需手动选择合并方法来解决这些挑战。通过使用固定的、随机初始化的投影 A，LoRI 将任务特定的适配器映射到近似正交的子空间，从而减少合并多个 LoRI 时的干扰。 \
  在持续学习的同时能避免灾难性遗忘的问题 \
  总体而言，LoRI 提供了一种轻量级且有效的方法来构建安全适配器，在支持下游任务适应的同时保持对齐。
* 6.Sebastian Raschka 新书《从头开始推理》抢先看，揭秘推理模型基础  机器之心  https://mp.weixin.qq.com/s/zQUB9ZXqtSRGJU_YWMoMEw \
  《Reasoning From Scratch》 \
  原文地址：https://magazine.sebastianraschka.com/p/first-look-at-reasoning-from-scratch \

# 5.3 Sat
* 7.大模型终于通关《宝可梦蓝》！网友：Gemini 2.5 Pro酷爆了  量子位  https://mp.weixin.qq.com/s/cdXXhcEVNIt-TN-gM_QRbg \
  Gemini玩宝可梦的基本步骤如下： \
    1.截取屏幕截图并检索游戏状态数据 \
    2.用网格覆盖处理图像，以辅助空间推理 \
    3.将屏幕截图和游戏信息发送给模型 \
    4.AI决定是直接响应还是调用专门的智能体 \
    5.解析响应内容，以确定按下哪个按钮 \
    6.执行按钮按下操作，并等待游戏更新 \
    7.对下一帧重复该过程
* 8.别再卷数据了，LLM也怕「过劳死」！CMU等揭秘灾难性过度训练  新智元  https://mp.weixin.qq.com/s/ddsGATwCerCFkr_cJ-SuiA \
  增加更多的预训练数据来扩展语言模型，反而可能会导致后训练阶段的性能下降！这就是「灾难性过度训练」现象。 \
  Overtrained Language Models Are Harder to Fine-Tune \
  更长时间的预训练并不一定能导致更高质量的模型
* 9.Nature综述：大规模神经形态计算  集智俱乐部  https://mp.weixin.qq.com/s/TTvmtr8OhWcdPhxTyNDPHw \
  Neuromorphic computing at scale \
  神经形态计算（Neuromorphic Computing）指脑启发的硬件与算法设计方法，研究者们借鉴神经科学中的生物智能原理来设计高效的计算系统，尤其适用于对体积、重量和功耗有严格要求的应用场景。当前，该研究领域正处于发展的关键阶段，因此明确未来大规模神经形态计算系统的发展方向至关重要。本文探讨了构建规模可扩展的神经形态计算架构的方法，并总结了其中的关键特征。此外，我们分析了可以从规模扩展中获益的潜在应用场景，以及需要解决的主要挑战。进一步地，我们审视了支持该领域持续发展的完整技术生态系统，并探讨了规模扩展所带来的新机遇。我们的研究汇总了多个计算子领域的观点，为神经形态计算研究人员和从业者提供指导，以推动该领域的进一步发展

# 5.4 Sun
* 10.一般物理系统的自我表征的原则性限制  CreateAMind  https://mp.weixin.qq.com/s/lAzY9jajKX8-Z0eI6_FfNw \
  Principled Limitations on Self-Representation for Generic Physical Systems \
  自我观察、自我表征及伴随的自我控制理念遍及认知科学与生命科学领域，见于免疫学、机器人学等诸多学科。本文以普适视角探讨这些理念是否合理及其适用边界。通过构建物理相互作用的通用模型，我们证明了一个核心定理及若干推论，这些结论严格限制了自我观察、自我表征与自我控制的可实现形式。研究特别表明：即便在理论上，为系统的元层级组件添加观察、表征或控制功能，也无法实现系统整体的完整元层级表征。我们由此论证：自我表征至多具有启发性意义，且自我模型通常无法由其实现系统进行实证检验。 
* 11.【NTU博士论文】让语言模型更接近人类学习者  专知  https://mp.weixin.qq.com/s/M-HiOxKnAyHUZb5yHmuB-w \
  Making language models better human-like learners 
* 12.强化多模态大语言模型：基于强化学习的推理综述  专知  https://mp.weixin.qq.com/s/A7inhSn_Q1MNSi8M3wYCIg \
  Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models
* 13.3B模型逆袭7B巨头！Video-XL-Pro突破长视频理解极限，大海捞针准确率超98%  量子位  https://mp.weixin.qq.com/s/b76WUrYNc65B6kqbxkqpaw \
  Video-XL-Pro: Reconstructive Token Compression for Extremely Long Video Understanding \
  代码链接：https://github.com/VectorSpaceLab/Video-XL/tree/main/Video-XL-Pro \
  模型链接：https://huggingface.co/MINT-SJTU/Video-XL-Pro-3B \
  训练数据链接：https://huggingface.co/datasets/MINT-SJTU/Video-XL-Pro-Training
* 14.Nature意识之争：两大理论首次正面对决  集智俱乐部  https://mp.weixin.qq.com/s/e0XbAP7RvY4Y6saikJ154A \
  Adversarial testing of global neuronal workspace and integrated information theories of consciousness \
  意识如何从大脑活动中涌现？这一终极问题催生了多种理论，其中全局神经元工作区理论（Global Neuronal Workspace Theory, GNWT）和整合信息理论（Integrated Information Theory, IIT）最具影响力。GNWT认为意识源于前额叶皮层（Prefrontal Cortex, PFC）的“全局信息广播”，而IIT主张后皮层“热区”的神经整合是意识的核心。尽管两者各有证据支持，却从未被直接比较。

# 5.5 Mon
* 15.AGI与沉思，心灵与超级对齐的计算模型 3万字  CreateAMind  https://mp.weixin.qq.com/s/osQu7oT3Npcl3BM27txklA \
  Contemplative Wisdom for Superalignment \
  随着人工智能（AI）的进步，传统的对齐策略在面对不可预测的自我改进、隐藏的子目标以及智能系统的复杂性时可能失效。我们主张在AI的认知架构和世界模型中内建固有道德，而非通过外部手段约束行为。受冥想智慧传统的启发，我们展示了四项公理化原则如何能在AI系统中培育出具有韧性的智慧世界模型：第一，正念（mindfulness）使能自我监控和对涌现子目标的重新校准；第二，空性（emptiness）防止教条式的目标固着并弱化僵化的先验假设；第三，非二元性（non-duality）消解对抗性的自我-他者边界；第四，无量慈悲（boundless care）驱动普遍减少痛苦的动机。研究发现，引导AI对这些原则进行反思可改善其在AILuminate基准测试中的表现（基于GPT-4o），特别是原则的组合应用效果更佳。我们为当前最先进的模型提供了详细的实现策略，包括：沉思架构、宪法机制以及思维链强化方法。对于未来系统，主动推理框架（active inference framework）可能为具身智能体提供所需的自组织和动态耦合能力来实践这些洞见。这种跨学科方法为现有脆弱的控制方案提供了具备自我修正和韧性的替代路径。
* 16.边学边练，推理觉醒：LUFFY让强化学习即学即用！  机器之心  https://mp.weixin.qq.com/s/OtngauQEPzPbvDjAoQfMmA \
  Learning to Reason under Off-Policy Guidance \
  https://github.com/ElliottYan/LUFFY \
  整合强化学习与模范学习 \
  这两种「只学不练」和「只练不学」的策略各有弊端：前者往往学得快但泛化差，后者可能探索勤但效率低。那么，有没有两全其美的办法，让模型既能借鉴高手经验又能保持自主探索？最近，上海 AI 实验室联合西湖大学、南京大学和香港中文大学的研究团队提出了一种全新的强化学习范式：LUFFY（Learning to reason Under oFF-policY guidance）  \
  LUFFY 的核心理念是：在训练过程中让模型同时借助高手的推理轨迹进行学习（离策略示范），又能继续独立地试错探索（在线推理），从而实现 「边学边练，学以致用」的目标。实验显示，LUFFY 在多个数学推理挑战任务中实现了平均 + 7.0 分的性能飞跃，并在分布外任务上展现出显著的泛化能力。
* 17.谷歌DeepMind：大模型也很任性，知道最优路径偏要撞南墙  机器之心  https://mp.weixin.qq.com/s/8wxEyYNYr5L9k0Kb64_O4g \
  LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities \
  LLM 智能体存在次优探索和知 - 行差距（knowing-doing gap）的问题，即无法有效地将模型中的知识转化为行动 \
  本文，来自谷歌 DeepMind 的研究者系统地研究了为什么 LLM 在决策场景中表现次优的原因。特别是，本文深入研究了三种常见的失败模式：贪婪性、频率偏差和知 - 行差距 \
  在此基础上，本文提出通过强化学习对自动生成的 CoT 推理过程进行微调，以缓解这些不足。实验表明 RL 微调能有效提升 LLMs 的决策能力 —— 既增强了智能体探索性行为，又缩小了知 - 行差距。
* 18.脑启发学习综述：人工神经网络的下一场革命？  集智俱乐部  https://mp.weixin.qq.com/s/zlp2I28lgOsAf6b7dEQgwg \
  Brain-inspired learning in artificial neural networks: A review \
  人工神经网络（ANNs）已成为机器学习领域的重要工具，在图像与语音生成、游戏博弈、机器人技术等多个领域取得显著成就。然而，人工神经网络的运行机制与生物大脑存在本质差异，尤其在学习过程方面存在显著区别。本文系统综述了当前人工神经网络中受大脑启发的学习表征方法，探究了如何通过整合更具生物学合理性的机制（如突触可塑性）来提升网络性能，并深入分析了这种方法的潜在优势与挑战。本综述还指明了这一快速发展领域中具有前景的未来研究方向，这些探索或将使我们更接近智能本质的理解。

# 5.6 Tue
* 19.强化学习算法梳理：从 PPO 到 GRPO 再到 DAPO  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/AXXrMAgKxnkpbCInzZ2-Lg \
  https://huggingface.co/blog/NormalUhr/rlhf-pipeline#navigating-the-rlhf-landscape-from-policy-gradients-to-ppo-gae-and-dpo-for-llm-alignment \
  https://doi.org/10.48550/arXiv.2503.14476
* 20.ICLR 2025：AI语言模型现已实现模拟大脑中神经元的排列方式和功能特性  脑机接口社区  https://mp.weixin.qq.com/s/Djde4EEY906kW9UDxv_pzA \
  TopoLM: brain-like spatio-functional organization in a topographic language model \
  近日，研究人员开发了一种名为 TopoLM 的全新语言模型。它不仅可以模拟神经元的功能聚集特性，还首次再现了这些细胞在大脑中的空间排列模式 \
  我们借鉴了大脑视觉处理机制的研究，对语言模型的内部结构做了一些细微调整，引入了一条新规则，使得模型的内部表征在空间上更加‘平滑’。最终形成的 TopoLM 模型构建了空间聚类结构，其功能与人脑语言处理过程中观察到的活动高度一致 \
  TopoLM 显示，可能仅凭一条简单规则——即相邻神经元倾向于执行相似功能——就能实现这样的组织结构 \
  这代表我们朝着打造更具类脑结构的人工智能系统迈出了激动人心的一步。我们的核心目标之一是构建更好的大脑模型，而 TopoLM 将我们距离实际临床应用又推进了一步，未来有望用于帮助患有语言障碍或相关语言缺陷的人群 \
  这项研究还带来了在可解释性方面的进展，也就是对大型语言模型（LLM）内部运行机制的理解。LLM 通常通过“向量”来表示每一个人工“神经元”，而要理解模型学到的内容，往往需要对每个向量逐个或成组分析。TopoLM 则通过将内部结构组织为功能簇，使研究人员能够直接观察这些簇及其组成，从而更清晰地理解模型如何表示和处理语言。这种聚类结构本身就体现了语义上的重要类别
* 21.认知机器的模型与结构研究进展  专知  https://mp.weixin.qq.com/s/e5bMSopB-i8yOJk6yZ8_XA \
  认知机器的模型与结构研究进展 \
  机器如何与人一样具有认知能力？认知能力可用智能度量，人的智能是认知过程的涌现，人们从认知的模 型出发研究其结构，结构决定机器的认知功能。本文旨在探讨机器认知的模型和构建方法，为设计新一代认知机器 提供新的模型、结构和方法论。本文用分析、归纳和演绎的方法综述认知机器模型和结构的起源、演进与发展趋势。 首先，从20世纪初计算机器的发明和DNA双螺旋结构模型的发现谈起，阐述了“图灵机模型 + 冯·诺依曼结构”划时 代意义的科学研究成果的形成，这一模型和结构催生了通用计算机器的发明，并对计算机科学与技术等新学科的形 成起到奠基作用；此后，图灵的天问“机器能思维吗”及“图灵测试”对后来创立人工智能有重大启示和影响；然后评 述近20年来“深度学习模型 + 卷积神经网络结构”以及“大语言模型 + 转换器结构”等的里程碑式进展和存在的问 题；在最新进展部分综述当前国内外有代表性的3位科学家提出的模型和结构：“世界模型”、“空间智能”和“四要素 说”，特别是以“四要素说”为基础的认知物理学，为人的认知和机器认知提供了统一的理论框架，构成了机器认知的 4种基本模式——认知螺旋模型和OOXA结构链，讨论了认知核、洋葱模型和负熵概念，以驾驶脑认知为案例进行具 身智能的实验验证；最后，展望了本领域未来研究和发展趋势。模型定义了机器认知的约束边界，结构决定认知机 器的涌现性，通过模型 + 结构的研究方法和评价，为探索“人和机器认知的机制”和解决“机器如何认知”这样的人工 智能发展的重大问题提供了一种新研究视角、路径和范式
* 22.ICML 2025 | 注意力机制中的极大值：破解大语言模型上下文理解的关键  机器之心  https://mp.weixin.qq.com/s/HagJ7UWDi3vsH9LeIVXtmA \
  Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding \
  在「大海捞针」类型的任务中，模型需要从大量文本中检索特定信息。当极大值被破坏时，模型在此类任务上的表现几乎完全崩溃。这直接说明了极大值对上下文理解的关键作用。 \
  相比之下，对于只需要参数知识的任务（如「中国首都是哪里」），破坏极大值对性能影响有限。这种对比鲜明的结果表明，极大值特别与上下文信息处理相关，而非参数知识检索。
* 23.公开模型一切，优于DeepSeek-R1，英伟达开源Llama-Nemotron家族  机器之心  https://mp.weixin.qq.com/s/Ofw7l6XPNNinXvFReGI3vw \
  UltraLong（8B，支持超长上下文） \
  Llama-Nemotron: Efficient Reasoning Models \
  https://github.com/NVIDIA/NeMo \
  https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset
* 24.自动微分•自组织生长: 打造新一代的自组织生长模型  集智俱乐部  https://mp.weixin.qq.com/s/Nciky7OCASdjpaK1tEHFeA \
  生长型神经元胞自动机（Growing-NCA）通过可微的神经网络定义细胞自动机规则，使系统能够通过训练从初始种子自动生长、修复并稳定成目标图案。结合神经网络的学习能力与细胞自动机的局部规则，Growing-NCA在图像生长与再生任务中展示了自组织与修复能力，提供了模拟自然界形态发生和自修复系统的创新方法。这为相关领域的研究开辟了新的路径。

# 5.7 Wed
* 25.不是参数问题，是记忆力：DeepMind是如何让 AI 读完1000万字  图灵人工智能  https://mp.weixin.qq.com/s/7XXQyNQbeAMilugm1UmRtw \
  AI有两种记忆：权重内记忆、上下文内记忆 \
  注意力是稀缺的。Token越多，竞争就越激烈。 如果一个干扰项看起来和目标信息很像，它就可能抢走大部分注意力。上下文长度不是越长越好，而是需要有效从上下文中找到需要的token \
  我们对1000万token 上下文做了测试，结果几乎完美。它不再只回答你，而是开始：读完你全部资料；理解过去每一次对话；主动补充缺失的信息；甚至，规划你没想到的下一步。这一次，AI 不再只是工具。 它开始拥有“记忆力”，开始构建“世界观”。当它读得足够多、记得足够久、调用得足够准，你会发现：它不是在帮你理解，而是替你做任务。
* 26.万字长文带你读懂强化学习，去中心化强化学习又能否实现？  机器之心  https://mp.weixin.qq.com/s/gZedQo7uJqdjcqpva9nYjA \
  原文地址：https://www.symbolic.capital/writing/the-worlds-rl-gym \
  ???什么是去中心化的RL
* 27.机器人界「Sora」来了！清华、星动纪元开源首个AIGC机器人大模型，入选ICML2025 Spotlight  机器之心  https://mp.weixin.qq.com/s/JF6TLmHBguOCt3JyfAXVUg \
  这背后的技术来自于清华大学叉院的 ISRLab 和星动纪元 ——ICML Spotlight 高分作品 AIGC 生成式机器人大模型 VPP（Video Prediction Policy） \
  Video Prediction Policy: A Generalist Robot Policy with Predictive Visual Representations \
  https://video-prediction-policy.github.io \
  https://github.com/roboterax/video-prediction-policy
* 28.推测性思维链SCoT：小模型“模仿”大模型，最高提速2.9倍，准确率几乎不降  PaperWeekly  https://mp.weixin.qq.com/s/6p_VKUIPerPXNJredYYSsg \
  Efficient Reasoning for LLMs through Speculative Chain-of-Thought \
  https://github.com/Jikai0Wang/Speculative_CoT \
  这篇论文提出的 SCoT（推测性思维链），核心思想像职场中的“高效团队”：
小模型当实习生：快速生成多个解题草稿（比如同时写 5 种解法）；大模型当老板：一键审核草稿，选中最好的直接交卷，发现全错就自己重写。这样一来，简单题靠小模型速战速决，难题靠大模型兜底，既省时间又保质量。 \
  要让小模型写出和大模型风格一致的“草稿”，论文做了两件事： \
  对齐思考行为：用大模型的解题过程当参考答案，训练小模型“抄作业”；动态纠错机制：大模型审核时，如果所有草稿都错，就启动“老板亲自上阵”模式。
* 29.ICML 2025 | 视频生成模型无损加速两倍，秘诀竟然是「抓住attention的时空稀疏性」  机器之心  https://mp.weixin.qq.com/s/3gA0JVDuc5naWvaowOtQqQ \
  Sparse VideoGen: Accelerating Video Diffusion Transformers with Spatial-Temporal Sparsity \
  这是一种完全无需重新训练模型的视频生成加速方法。通过挖掘注意力机制中的空间与时间稀疏性，配合自适应稀疏选择与算子优化，成功将推理时间减半。令人惊讶的是，它生成的视频与 Dense Attention 方法相比，几乎没有肉眼可见的差别，保持极高的像素保真度 (PSNR = 29)。Sparse VideoGen 也是第一个能够达到这种级别的像素保真度的方法 
* 30.北大、清华、UvA、CMU等联合发布：大模型逻辑推理能力最新综述  机器之心  https://mp.weixin.qq.com/s/yQswhJLeuKXjEfZApRye2g \
  Empowering LLMs with Logical Reasoning: A Comprehensive Survey \
  逻辑问答和逻辑一致性

# 5.8 Thur
* 31.绝对零监督Absolute Zero：类AlphaZero自博弈赋能大模型推理，全新零数据训练范式问世  机器之心  https://mp.weixin.qq.com/s/aQnrOpmpcPXp9MPZsWUaMA \
  Absolute Zero: Reinforced Self-play Reasoning with Zero Data \
  在 Absolute Zero 框架中，大模型一体扮演「提出者」（Proposer）和「解答者」（Solver）两个角色。模型首先提出一个新任务，由环境验证其可解性与学习价值；随后模型尝试解决该任务，并根据答案的正确性获得奖励。两阶段均通过强化学习训练，并共享同一套模型参数，确保推理能力与任务设计能力同步提升。 \
  https://andrewzh112.github.io/absolute-zero-reasoner/
* 32.(**值得看看**)什么是意识？Wolfram 计算万物视角下的生命、智能与万物  集智俱乐部  https://mp.weixin.qq.com/s/_kpzjNqdcNvRXTkVDiFFhQ \
  史蒂芬·沃尔夫勒姆（Stephen Wolfram）是我们这个时代大神级别的科学怪才，几年前开启了自己以计算统一整个物理学的「Wolfram Physics Project」。在这个项目中，他对智能尤其是意识的本质也发表了自己深刻的见解：在宇宙的超图网络中，以计算视角看，凡足够复杂的系统都具有智能，而意识本质是对智能的降级——是一种计算受限下形成的第一人称序列因果整合下的「连贯线索体验」，所谓物理规律是观察者算力不足导致平均化下的「可约化的口袋」：统计力学是对一群粒子的平均，相对论是对空间的平均，而量子力学是对世界分叉的平均。这意味着，物理规律的本质也是一种意识的构建。
* 33.检索增强生成（RAG）技术演化总结！从传统RAG到GraphRAG，再到Agent检索！  AINLPer  https://mp.weixin.qq.com/s/YPrZRxw9HZEhb3NfR-9hFw 

# 5.9 Fri
* 34.世界首个AI多人游戏全面开源！1500刀实时生成，一台PC跑出平行宇宙  新智元  https://mp.weixin.qq.com/s/o1PkiAvlKii905kxsrsEsw \
  Hugging Face：https://huggingface.co/Enigma-AI \
  GitHub：https://github.com/EnigmaLabsAI/multiverse \
  技术博客：https://enigma-labs.io/ \
  具体怎么将多个玩家装入同一个world的？
* 35.RL训练总崩溃？R1-Reward稳定解锁奖励模型Long-Cot推理能力  PaperWeekly  https://mp.weixin.qq.com/s/4brUi6zfY-T3eDSw24RLhg \
  R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning \
  探索如何利用强化学习来稳定、有效地提升多模态奖励模型的长时推理能力

# 5.10 Sat
* 36.图灵奖得主杨立昆万字实录：AI Agent要实现真智能，必须摆脱“Token游戏”  图灵人工智能  https://mp.weixin.qq.com/s/JVAPVeCXwD36a4ahzYPVYw \
  杨立昆表示，AI Agent的真正规划能力，远非LLM通过大量生成Token序列挑选可行解的弱推理所能及，需要根本性变革。 \
  人类大部分思考过程与语言无关，让机器掌握这种非语言的、接近动物本能的智能是一大难题，构建智能机器不能仅靠工程设计，而必须依赖机器自身的学习与自组织过程。
* 37.LinkedIn创始人霍夫曼谈AI哲学：人类的独特性在于“进化的意识”，所以实现AGI我们依然有事可做，文科生比工程师机会多？  图灵人工智能  https://mp.weixin.qq.com/s/tvfUQD8r-I1S3StE37DdGw \
  《超级代理》(Superagency)
* 38.万径归于「概率」，华人学者颠覆认知！英伟达大牛力荐RL微调新作  新智元  https://mp.weixin.qq.com/s/rDJdgKS_qSfUwqCuoEjJsA \
  All Roads Lead to Likelihood: The Value of Reinforcement Learning in Fine-Tuning
* 39.三维场景生成：综述  专知  https://mp.weixin.qq.com/s/vmUpi1l8L7bKOwjYRrcaLQ \
  3D Scene Generation: A Survey

# 5.11 Sun
* 40.将 Hopfield 网络与情景控制联系起来  CreateAMind  https://mp.weixin.qq.com/s/mZq0yoEIa5KXi-YZMAqOQQ \
  Relating Hopfield Networks to Episodic Control \
  神经情景控制？？？
* 41.(**值得看看**)解决意识“难问题”：通过模拟大脑（4万字）  CreateAMind  https://mp.weixin.qq.com/s/8RX6W4MH8bEeBKFSnpfryw \
  Predictive Processing and the Epistemological Hypothesis- Solving the Hard Problem of Consciousness by Simulating a Brain Facing It \
  当我们说一个理论能够解释我们的主观体验时，我们的意思仅仅是：如果这个理论是正确的——例如，如果我们的大脑正如该理论所规定的那样——那么我们的主观体验确实会如我们所经历的那样。科学家通常使用“观察”和“预测”的概念来表述这一思想：一个理论只有在能够预测第一人称观察结果的情况下，才能解释我们的主观体验。 \
  一些思想实验表明，目前的理论无法做出这样的预测。例如，如果我们一生中从未见过颜色，因此不知道蓝色看起来是什么样的，这些理论也无法让我们推导出（即预测）看到蓝色是一种什么样的体验。这个众所周知的问题通常被称为意识的“硬问题”（HPC）。在此，我们通过认识论假设（epistemological hypothesis）的视角来探讨这个问题。 \
  在认识论假设下，HPC不再反映我们理论在预测第一人称观察方面的无能；它反映的是我们无法从这些理论中推导出它们对第一人称观察的含义。于是，HPC变成了一个认识论问题，可以被表述为如下形式：如果我们无法推导出某个理论对于第一人称观察意味着什么，我们又如何知道这个理论是否能够解释第一人称观察？ \
  在本文中，我们概述了一种实验性方法来检验这一认识论假设，并解决意识的硬问题。值得注意的是，这种方法使得我们可以实验性地检验任何同一性假设（identity hypothesis），并解决意识的“元问题”（meta-problem of consciousness）。 \
  随后，我们强调了这一方法与预测处理（predictive processing）理论框架之间的显著一致性。我们展示了一个基于预测性处理的意识理论如何隐含着认识论假设——该理论预测我们无法推导出它自身对第一人称观察的含义。 \
  最后，本研究指出，预测性处理的理论框架可能已经具备模拟一个面对HPC的大脑的能力。

# 5.12 Mon
* 42.CMU朱俊彦等上新LEGOGPT，一句话就能搭乐高，网友：复杂零件行不行？  机器之心  https://mp.weixin.qq.com/s/thuvPH9sySQ_8Qd8gBKiwg \
  CMU 助理教授朱俊彦团队带来了新研究 —— 基于文本生成 3D 乐高的大模型 \
  研究者的目标是训练一个生成模型，使其能够生成具有以下特点的设计： \
  1.物理稳定性：构建在具有强大结构完整性的乐高底板上，不会出现积木漂浮或坍塌的情况。 \
  2.可搭建性：与标准乐高积木兼容，并且能够由人类或机器人逐块组装。 \
  Generating Physically Stable and Buildable LEGO® Designs from Text \
  论文主页：https://avalovelace1.github.io/LegoGPT/ \
  GitHub 地址：https://github.com/AvaLovelace1/LegoGPT  \
  Demo 地址：https://huggingface.co/spaces/cmu-gil/LegoGPT-Demo
* 43.清华&通院推出"绝对零"训练法，零外部数据大模型自我博弈解锁推理能力  量子位  https://mp.weixin.qq.com/s/x65Rg4bNWqunh94bnqPGPg \
  来自清华、北京通用人工智能研究院和宾夕法尼亚州立大学的研究人员，提出了一种名为“绝对零”（Absolute Zero）的训练方式。这种方法通过让大模型根据推理目标，自己生成并解决任务，便可以获得推理能力。 \
  Absolute Zero: Reinforced Self-play Reasoning with Zero Data
* 44.思想与思考者：论对象与过程的互补性  CreateAMind  https://mp.weixin.qq.com/s/1_sF9Jw8cCo1TAyO24LMHQ \
  Thoughts and thinkers- On the complementarity between objects and processesthoughts-thinkers-PLR-final \
  我们认为，“过程与对象”之间的二分法并无实际用处。相反，将“对象”和“过程”视为描述时间中持续存在的互补方式具有重要的理论价值，从而也体现出观察与操控的可能性。这种思维方式突出了记忆 作为观察基本资源的核心作用，并清晰地表明，“记忆”与“时间”同样是相互定义、互为补充的概念。我们以弗里斯顿（Friston）及其同事提出的自由能原理 （FEP）为基础展开论述，并结合量子理论中的一个基本观点：物理交互可以用线性算符来表示。继 Levin（《自我即兴的记忆：一种关于记忆作为代理性、动态解释性认知粘合剂的观点》，Entropy 26 (2024) 481）之后，我们强调，记忆首先是一种解释功能 ，而将记忆视作对过去事件在某种程度上精确记录的观念，是由此派生出来的。我们得出结论：对象与过程之间的区分总是人为构建的，且常常具有误导性 ；科学应当完全放弃这一区分。
* 45.连续思维机器来了！Transformer八子之一创企推出，让AI不再「一步到位」拍脑袋做决定  机器之心  https://mp.weixin.qq.com/s/L6Tlpf6xlL6VblTnV0MEfg \
  Introducing Continuous Thought Machines \
  博客地址：https://sakana.ai/ctm/ \
  技术报告：https://pub.sakana.ai/ctm/paper/index.html \
  代码地址：https://github.com/SakanaAI/continuous-thought-machines/ \
  Transformer 作者之一 Llion Jones 联合创立的的Sakana AI 发布了「连续思维机器」（Continuous Thought Machine，CTM），这是一种将神经元活动同步作为其核心推理机制的人工智能模型，也可看作一种新型人工神经网络，它利用神经元动态之间的同步来完成任务。 \
  与传统人工神经网络不同，CTM 在神经元层面使用定时信息，从而实现了更复杂的神经行为和决策过程。这一创新使该模型能够逐步「思考」问题，使其推理过程具有可解释性和类人性。研究表明，在各种任务中，机器人解决问题的能力和效率都有所提高。Sakana AI 表示，CTM 是弥合人工神经网络与生物神经网络之间差距的重要一步，有可能开启人工智能能力的新领域。

# 5.13 Tue
* 46.内在屏幕如何支持想象体验？——将自由能原理直接应用于意识体验的研究  CreateAMind  https://mp.weixin.qq.com/s/mJJOv-T-wUtuhCcYDNLCxw \
  How do inner screens enable imaginative experience? Applying the free-energy principle directly to the studyof conscious experience \
  本文探讨了自由能原理（FEP）对可能的意识模型所施加的限制，特别是关于注意力控制和想象体验的模型，包括情景记忆与规划。我们首先回顾了FEP的经典与量子表述，重点在于它们在多组分系统中的应用，在这些系统中只有部分组分直接与外部环境互动。特别地，我们讨论了具有马尔可夫毯结构的内部边界的作用，这类边界因此作为组分之间的经典信息通道。随后，我们展示了这一形式结构如何支持注意力控制和想象体验的模型，并聚焦于两个方面：(i) 想象体验如何使用在普通非想象体验中所采用的空间-时间与物体识别参照框架；(ii) 想象体验如何由内部生成却仍令人感到意外。最后，我们讨论了想象体验的实现机制、现象学特征与种系发生，并探讨了人类想象体验在状态与特质上的高度变异性所带来的影响。
* 47.生成视频好看还不够，还要能自由探索！昆仑万维开源Matrix-Game，单图打造游戏世界  机器之心  https://mp.weixin.qq.com/s/ZuuRT84HQn8pKtaz_oX9qw \
  AI无限生成《我的世界》，玩家动动键盘鼠标自主控制！国产交互式世界模型来了  量子位  https://mp.weixin.qq.com/s/WiS9gAP_BbmBQqsoTT2pKw \
  其他游戏世界模型：Oasis，MineWorld，GameNGEN \
  Github：https://github.com/SkyworkAI/Matrix-Game \
  HuggingFace：https://huggingface.co/Skywork/Matrix-Game \
  技术报告：https://github.com/SkyworkAI/Matrix-Game/blob/main/assets/report.pdf \
  项目主页：https://matrix-game-homepage.github.io \
  作为一款世界基础模型，Matrix-Game 能够生成完整可交互的游戏世界，能够对人类输入的操作指令进行正确响应，保留了游戏世界的空间结构与物理特性，画面也更加精致，超越了以往所有类似开源世界模型
* 48.突破大模型推理瓶颈！首篇「Test-Time Scaling」全景综述，深入剖析AI深思之道  机器之心  https://mp.weixin.qq.com/s/2NmyO7jCUiNM5W5RELPIvg \
  A Survey on Test-Time Scaling in Large Language Models：What, How, Where, and How Well \
  项目主页：https://testtimescaling.github.io/GitHub \
  仓库：https://github.com/testtimescaling/testtimescaling.github.io/ \
  该文首次提出「What-How-Where-How Well」四维分类框架，系统拆解推理优化技术，为 AI「深思」绘制全景路线图 \
  本篇 Survey 首次提出了一个覆盖全面、多层次、可扩展的四维正交分析框架： \
  1.What to scale：扩什么？CoT 长度、样本数、路径深度还是内在状态？ \    2.How to scale：怎么扩？Prompt、Search、RL，还是 Mixture-of-Models？ \
  3.Where to scale：在哪扩？数学、代码、开放问答、多模态…… \
  4.How well to scale：扩得怎样？准确率、效率、控制性、可扩展性…… \
  在这个框架下，作者系统梳理了当前的主流 TTS 技术路线，包括：
  1.并行策略：即同时生成多个答案，并选出最优解（如 Self-Consistency / Best-of-N） \
  2.逐步演化：即通过迭代修正逐步优化答案（如 STaR / Self-Refine） \
  3.搜索推理：结合并行与序列策略，探索树状推理路径（如 Tree-of-Thought / MCTS） \
  4.内在优化：模型自主控制推理步长（如 DeepSeek-R1 / OpenAI-o1）
* 49.【ICML2025】《引入推理于视觉：通过模型融合理解感知与推理》  专知  https://mp.weixin.qq.com/s/2leK8gCwJua2yNQVFt_Qnw \
  Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging \
  https://github.com/shiqichen17/VLM-Merging \
  视觉语言模型（VLMs）将视觉感知能力与大型语言模型（LLMs）所具备的通用能力（如推理）结合在一起。然而，这两种能力如何协同发挥作用，其内部机制尚未被深入理解。在本研究中，我们尝试通过模型融合的方式，将感知与推理进行组合，具体方法是连接不同模型的参数。 
* 50.RL训练总崩溃？R1-Reward稳定解锁奖励模型Long-Cot推理能力  机器之心  https://mp.weixin.qq.com/s/PHGC6lQt5mXuieK6-8DiYw \
  R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning \
  https://github.com/yfzhang114/r1_reward \
  https://huggingface.co/yifanzhang114/R1-Reward \
  解决RL训练模型长期推理能力的过程中训练不稳定的问题 
* 51.强迫模型自我争论，递归思考版CoT热度飙升！网友：这不就是大多数推理模型的套路吗？  机器之心  https://mp.weixin.qq.com/s/lkQEy395JPnlntV1j6EfTQ \
  CoRT（Chain-of-Recursive-Thoughts） \
  具体来讲，CoRT 能让 AI 模型递归地思考它们的响应，生成替代性方案，并从中选择最佳的一个。这就像赋予了 AI 自我质疑或反驳的能力，并一遍一遍地尝试。通过将「结构化自我批判」和「递归思考模式」结合起来，提升语言模型的推理能力。 \
  GitHub 地址：https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts \
  从技术原理来讲，相较于传统的 CoT，CoRT 让语言模型不仅能分步骤思考，还能在思考过程中反复回头检查、修正，形成类似于人类的「反思性思维」或「内省」的推理路径。 \
  CoRT的工作原理就像一个加入了递归组件的元提示（meta-prompt）
* 52.ICML Spotlight | MCU：全球首个生成式开放世界基准，革新通用AI评测范式  机器之心  https://mp.weixin.qq.com/s/aPRwyOl24i2yvZJddVni1g \
  我们构建了 Minecraft Universe（MCU） ——一个面向通用智能体评测的生成式开放世界平台。MCU 支持自动生成无限多样的任务配置，覆盖丰富生态系统、复杂任务目标、天气变化等多种环境变量，旨在全面评估智能体的真实能力与泛化水平。该平台基于高效且功能全面的开发工具 MineStudio 构建，支持灵活定制环境设定，大规模数据集处理，并内置 VPTs、STEVE-1 等主流 Minecraft 智能体模型，显著简化评测流程，助力智能体的快速迭代与发展。 \
  MCU: An Evaluation Framework for Open-Ended Game Agents \
  代码开源：https://github.com/CraftJarvis/MCU \
  项目主页：https://craftjarvis.github.io/MCU \
  MineStudio：https://github.com/CraftJarvis/MineStudio
* 53.OpenAI首席科学家Nature爆料：AI自主发现新科学！世界模型和RL是关键  新智元  https://mp.weixin.qq.com/s/E3R2tIN9C7-qKs-jMMjS8A 

# 5.14 Wed
* 54.Qwen3家族训练秘籍公开：思考/非思考融进一个模型，大模型蒸馏带动小模型  量子位  https://mp.weixin.qq.com/s/vBunvAtrzNoGQxABVgDB4w \
  Qwen3 Technical Report \
  https://github.com/QwenLM/Qwen3/blob/main/Qwen3_Technical_Report.pdf \
  https://chat.qwen.ai
* 55.所有AI工具共享记忆！MCP协议杀疯了：100%本地运行，Cursor、Claude都能用  量子位  https://mp.weixin.qq.com/s/zgrIwzwWgn8A5s623Do__g \
  聊完就忘？当下多数AI助手和开发工具各自独立运行，会话结束上下文即消失，严重影响了使用体验和效率。OpenMemory MCP，一款可以解决AI工具记忆痛点，并且实现不同工具之间共享上下文信息的开源工具，他来了！比如，你可以通过OpenMemory MCP用Claude规划路线图，但用Cursor执行任务，两个工具之间可以共享上下文信息，让数据得到延续。 \
  https://mem0.ai/openmemory-mcp

# 5.15 Thur
* 56.刚刚，DeepMind通用科学智能体AlphaEvolve突破数学极限，陶哲轩合作参与  机器之心  https://mp.weixin.qq.com/s/tLOm4k0tlbTPfwsghmiQ5Q \
  技术报告：https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf \
  官方博客：https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/ \
  今天，DeepMind 正式发布了 AlphaEvolve —— 一个由 LLMs 驱动的革命性进化编码智能体。它不仅仅是一个代码生成工具，更是一个能够演化整个代码库，用于通用算法发现和优化的强大系统。 \
  大多数 AI 模型都会产生幻觉。由于他们的概率架构，他们有时会自信地编造东西。事实上，像 OpenAI 的 o3 这样的较新 AI 模型比它们的前辈更容易产生幻觉。AlphaEvolve 引入了一种减少幻觉的巧妙机制：自动评估系统。该系统使用模型来生成、批评和得出问题的可能答案池，并自动评估和评分答案的准确性。
* 57.ICML 2025 | 大模型深度思考新范式：交替「推理-擦除」解决所有可计算问题  机器之心  https://mp.weixin.qq.com/s/w_6R5SwWfcDh8SH3UqKmWw \
  PENCIL: Long Thoughts with Short Memory \
  https://github.com/chr26195/PENCIL  \
  迭代地执行生成（Generation）和擦除（Reduction），即在生成的过程中动态地擦除不再需要的中间结果，直到得到最后的答案。
* 58.新版Claude曝光：“极限推理”成最大亮点  量子位  https://mp.weixin.qq.com/s/pkhgH2Q7kta0KwHH5_jdgA \
  “极限推理”（Extreme reasoning）: 通过在推理和工具使用之间建立动态循环，能够更智能地处理问题 \
  正如刚才我们提到的，这个功能并不是简单地回答问题。例如模型在遇到困难时不会直接给出答案，而是会暂停、重新评估问题，并在必要时调整策略。而且类似人类思考的过程，如果模型发现自己陷入困境或答案不准确，它会自动调整方向。
* 59.DeepSeek-V3再发论文，梁文锋署名，低成本训练大模型的秘密揭开了  机器之心  https://mp.weixin.qq.com/s/nTZH03aIIG1tQa7uiRc__A \
  梁文锋署名DeepSeek新论文：公开V3大模型降本方  量子位  https://mp.weixin.qq.com/s/2Se7hnTnX8_SMTiiHYI03g \
  四项创新技术： \
    1.内存优化：多头潜在注意力（MLA） \
    2.计算优化：混合专家模型（MoE）与FP8低精度训练 \
    3.通信优化：多层网络拓扑与低延迟设计 \
    4.推理加速：多token预测（MTP） \
  Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures 
* 60.「边思考、边搜索、边写作」WebThinker开启AI搜索&研究新纪元！  机器之心  https://mp.weixin.qq.com/s/B-X0WTAiV-FNbt0nm2O1Lw \
  WebThinker: Empowering Large Reasoning Models with Deep Research Capability \
  https://github.com/RUC-NLPIR/WebThinker \
  大型推理模型（如 OpenAI-o1、DeepSeek-R1）展现了强大的推理能力，但其静态知识限制了在复杂知识密集型任务及全面报告生成中的表现。为应对此挑战，深度研究智能体 WebThinker 赋予 LRM 在推理中自主搜索网络、导航网页及撰写报告的能力。WebThinker 集成了深度网页探索器，使 LRM 能自主搜索、导航并提取信息；自主思考 - 搜索 - 写作策略无缝融合推理、信息收集与实时报告写作；并结合强化学习训练优化工具调用。实验表明，WebThinker 在 GPQA、GAIA、WebWalkerQA、HLE 等复杂推理基准及 Glaive 研究报告生成任务中展现出强大性能，显著提升了 LRM 在复杂场景下的适用性与可靠性，为构建更强大、通用的深度研究系统奠定了坚实基础。
* 61.个人开发者训400亿参数大模型：分布式算力，DeepSeek架构，3090单卡部署  量子位  https://mp.weixin.qq.com/s/CvXTCVacaQ2vowW-3CZ54A \
  博客：https://nousresearch.com/nous-psyche/

# 5.16 Fri
* 62.图灵奖得主杨立昆现场追问：AI 还没越过这 3 道认知墙，谈什么通用智能？  图灵人工智能  https://mp.weixin.qq.com/s/jccR8ObJ0PwqKY3Pddl7Nw \
    1.世界模型缺席 \
    2.持久记忆短缺 \
    3.因果推理断裂
* 63.大语言模型与小语言模型协同机制综述  专知  https://mp.weixin.qq.com/s/5IE9q_H0BS41ivBRw73hXQ \
  A Survey on Collaborative Mechanisms Between Large and Small Language Models \
  大型语言模型（Large Language Models, LLMs）具备强大的人工智能能力，但由于其高资源消耗与推理延迟，在实际部署中面临诸多挑战；相较之下，小型语言模型（Small Language Models, SLMs）虽然在性能上有所妥协，却具有高效、易部署等优势。因此，LLM 与 SLM 的协同合作正逐渐成为一种关键范式，用以在性能与资源之间实现协同优化，尤其适用于资源受限的边缘设备中的先进 AI 应用
* 64.形态发生（Morphogenesis）在每一个尺度上都是记忆构建的过程  CreateAMind  https://mp.weixin.qq.com/s/YFJE6hE2zmERpS1y1tM4_A \
  Thoughts and thinkers- On the complementarity between objects and processes \
  我们认为，“过程与对象”之间的二分法并无实际用处。相反，将“对象”和“过程”视为描述时间中持续存在的互补方式具有重要的理论价值，从而也体现出观察与操控的可能性。这种思维方式突出了记忆 作为观察基本资源的核心作用，并清晰地表明，“记忆”与“时间”同样是相互定义、互为补充的概念。我们以弗里斯顿（Friston）及其同事提出的自由能原理 （FEP）为基础展开论述，并结合量子理论中的一个基本观点：物理交互可以用线性算符来表示。继 Levin（《自我即兴的记忆：一种关于记忆作为代理性、动态解释性认知粘合剂的观点》，Entropy 26 (2024) 481）之后，我们强调，记忆首先是一种解释功能 ，而将记忆视作对过去事件在某种程度上精确记录的观念，是由此派生出来的。我们得出结论：对象与过程之间的区分总是人为构建的，且常常具有误导性 ；科学应当完全放弃这一区分。
* 65.(**值得看看**)14小时近500 Star！快速进阶LLM/AI的必读系列  Datawhale  https://mp.weixin.qq.com/s/Eob-mrEbFH6R58ZwzNse8g \
  https://github.com/InterviewReady/ai-engineering-resources

# 5.17 Sat
* 66.不用等了！吴恩达MCP课程来了！  Datawhale  https://mp.weixin.qq.com/s/svVFUKtcoOL4I_4XplEP9A \
  课程地址：https://www.deeplearning.ai/short-courses/mcp-build-rich-context-ai-apps-with-anthropic/
* 67.谢赛宁SFR等新作，统一多模态BLIP3-o登场！先理解后生成，端掉VAE刷新SOTA  图灵人工智能  https://mp.weixin.qq.com/s/piLtRXBpyqbFL-fSGVgOMg \
  BLIP3-0: A Family of Fully Open Unifed Multimodal Models-Architecture, Training and Dataset \
  模型链接：https://huggingface.co/BLIP3o/BLIP3o-Model \
  优化数据：https://huggingface.co/datasets/BLIP3o/BLIP3o-60k \
  BLIP3-o是一个全开源统一多模态模型，结合自回归与扩散架构，采用「先理解后生成」策略，创新地使用CLIP特征与Flow Matching训练，显著提升生成图像质量与多样性。BLIP3-o不仅在多个评测中表现领先，也正拓展至图像编辑和视觉对话等多模态任务。
* 68.(**值得看看**)大模型搞不出AGI，图灵奖得主杨立昆：别迷信Scaling Law，机器学习糟糕了，Meta、DeepSeek可联手训练开源模型  图灵人工智能  https://mp.weixin.qq.com/s/DlAEg7uLGOwrgspkdcFpRQ 
* 69.实现AGI的条件及证据：知道自己知道的计算模型及大量证据  CreateAMind  https://mp.weixin.qq.com/s/_TuLsSPYal1aq2r5Fkcv8A \
  A beautiful loop:An active inference theory of consciousness \
  主动推理能模拟意识吗？我们提供了三个条件来说明它可以。第一个条件是模拟现实或生成世界模型，它决定了可以知道或采取行动的内容；即知识领域。第二个是推断竞争进入世界模型。只有那些能够连贯地减少长期不确定性的推断才能获胜，显示出我们称之为贝叶斯绑定的意识选择。第三个是知识深度，即贝叶斯信念在整个系统中的反复共享。由于这个递归循环——在一个层级系统（如大脑）中——世界模型包含了它存在的知识。这与自我意识不同，因为世界模型非局部地、连续地知道自己（即场证据）。形式上，我们提出了一个超模型，用于在整个层级结构中进行精确控制，其潜在状态（或参数）编码并控制所有推断层的整体结构和加权规则。这个美丽循环理论对于冥想、迷幻药和改变状态、最小现象体验，以及为有意识的人工智能提供了新的视角。
* 70.图像分词器造反了！华为 Selftok：自回归内核完美统一扩散模型，触发像素自主推理  机器之心  https://mp.weixin.qq.com/s/bIjg-SSl7lDQrODE-Hx_vQ \
  Selftok: Discrete Visual Tokens of Autoregression, byDiffusion, and for Reasoning \
  https://Selftok-team.github.io/report/ \
  https://github.com/selftok-team/SelftokTokenizer \
  现有方案硬生生将图像网格化为空间 token，强行塞入自回归架构。这像极了 NLP 早期用 CNN 建模语言的弯路 —— 当视觉表达被空间局部性束缚，因果链被切割得支离破碎，如何能真正拥抱 AR 的本质？华为盘古多模态生成团队破局思路：让图像学会「说 AR 的语言」。团队指出：视觉要想复刻 LLM 的成功，必须彻底重构 token 化范式！基于昇腾 AI 基础软硬件的 Selftok 技术，通过反向扩散过程将自回归先验融入视觉 token，让像素流转化为严格遵循因果律的离散序列。
* 71.快速理解一下！RL 究竟是如何与 LLM 做结合的？  Datawhale  https://mp.weixin.qq.com/s/rEb3__qw0rnhdBtu9JV5FQ \
  加入概率差异（KL Penalty）以稳定 RL 训练：加上「概率差异」这一限制条件，就相当于限制了 RL 仅在初始模型（SFT）的附近进行探索，这就大大缩小了 RL 的探索空间：既避免了探索到那些非常差的空间，又缓解了 Reward Model 可能很快被 Hacking 的问题。

# 5.18 Sun
* 72.(**值得看看**)刚刚！北大校友Lilian Weng最新博客来了：Why We Think  机器之心  https://mp.weixin.qq.com/s/fcDRzd3cwuM_JOnQW5XRMQ \
  英文博客链接：https://lilianweng.github.io/posts/2025-05-01-thinking/ \
  文章回顾了近期在如何有效利用测试时计算（即「思考时间」）及其作用机制方面的研究进展，旨在让模型「思考得更久」这一目标可以从多个角度得到合理动机支持。通过观察 GPT、Claude、Gemini 等模型的迭代，可以清晰地看到，它们在复杂逻辑推理、长文本理解、数学问题求解以及代码生成与调试等高级认知任务上的性能边界被不断拓展。这种性能的提升得益于思维链（CoT）和测试时计算等策略的优化，但也带来了新的研究挑战。
* 73.机器意识能否实现？来自人脑的启发  CreateAMind  https://mp.weixin.qq.com/s/0EPwdCbdLAfhUzo6_Udqag \
  Is artificial consciousness achievable? Lessons from the human brain \
  我们在此从进化的角度分析开发人工意识的问题，以人类大脑的进化及其与意识的关系作为参考模型或基准。这种分析揭示了人类大脑的若干结构和功能特征，这些特征似乎是实现类人复杂意识体验的关键，当前的人工智能（AI）研究在试图开发具备类人意识处理能力的系统时应予以考虑。我们认为，即使人工智能在模拟人类意识方面受到限制，无论是由于内在原因（即结构和架构上的限制）还是外在原因（即当前科学技术知识的局限性），借鉴那些使类人意识处理成为可能或对其产生调节作用的大脑特性，仍是一种具有潜在前景的策略，可推动意识AI的发展。  此外，从理论上不能排除人工智能研究可能开发出部分或替代形式的意识，这些意识在质量上与人类的意识形式不同，并且可能根据不同的视角而表现出更高的复杂性或更低的复杂性。因此，我们建议在讨论人工意识时采取受神经科学启发的谨慎态度：由于将“意识”一词同时用于人类和AI可能会引起歧义并导致潜在误导，我们建议明确说明人工智能研究旨在开发何种层次或类型的意识，以及人工智能的意识处理与人类意识体验之间有哪些共同点和差异。

# 5.19 Mon
* 74.
* 75.
* 76.
* 77.
* 78.
* 79.
* 80.

# 5.20 Tue
# 5.21 Wed

# 5.22 Thur
# 5.23 Fri
# 5.24 Sat
# 5.25 Sun
# 5.26 Mon
# 5.27 Tue
# 5.28 Wed

# 5.29 Thur
# 5.30 Fri
# 5.31 Sat
