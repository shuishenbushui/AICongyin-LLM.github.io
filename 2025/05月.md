# 5.1 Thur
* 1.400万token新SOTA！英伟达UIUC联手：兼顾长短上下文顶尖性能  新智元  https://mp.weixin.qq.com/s/h8R0JGbHKaxQJAMg8DjmZw \
  来自英伟达和UIUC的华人团队提出一种高效训练方法，将LLM上下文长度从128K扩展至惊人的400万token SOTA纪录！基于Llama3.1-Instruct打造的UltraLong-8B模型，不仅在长上下文基准测试中表现卓越，还在标准任务中保持顶尖竞争力 \
  From 128K to 4M: Effcient Training of Ultra-Long Context Large Language Models
* 2.深夜突袭，DeepSeek-Prover-V2加冕数学王者！671B数学推理逆天狂飙  新智元  https://mp.weixin.qq.com/s/Dsn3iypDSpzUVC35XX8Z1A \
  就在刚刚，DeepSeek-Prover-V2技术报告也来了！34页论文揭秘了模型的训练核心——递归+强化学习，让数学推理大提升。有人盛赞：DeepSeek已找到通往AGI的正确路径！ \
  Hugging Face：https://huggingface.co/deepseek-ai/DeepSeek-Prover-V2-671B \
  GitHub：https://github.com/deepseek-ai/DeepSeek-Prover-V2/tree/main \
  论文链接：https://github.com/deepseek-ai/DeepSeek-Prover-V2/blob/main/DeepSeek_Prover_V2.pdf
* 3.(**值得看看**)意识:A beautiful loop:实现AGI的条件及证据（知道自己知道的计算模型及大量证据）  CreateAMind  https://mp.weixin.qq.com/s/RVogxALZOYnv1a9aW1Iodw \
  A beautiful loop:An active inference theory of consciousness \
  主动推理能模拟意识吗？我们提供了三个条件来说明它可以。第一个条件是模拟现实或生成世界模型，它决定了可以知道或采取行动的内容；即知识领域。第二个是推断竞争进入世界模型。只有那些能够连贯地减少长期不确定性的推断才能获胜，显示出我们称之为贝叶斯绑定的意识选择。第三个是知识深度，即贝叶斯信念在整个系统中的反复共享。由于这个递归循环——在一个层级系统（如大脑）中——世界模型包含了它存在的知识。这与自我意识不同，因为世界模型非局部地、连续地知道自己（即场证据）。形式上，我们提出了一个超模型，用于在整个层级结构中进行精确控制，其潜在状态（或参数）编码并控制所有推断层的整体结构和加权规则。这个美丽循环理论对于冥想、迷幻药和改变状态、最小现象体验，以及为有意识的人工智能提供了新的视角。

# 5.2 Fri
* 4.浙大&港理工等提出InfiGUI-R1：利用强化学习，让GUI智能体学会规划任务、反思错误  机器之心  https://mp.weixin.qq.com/s/KafgV8WxsV02fSNbUxxozQ \
  InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners \
  项目仓库：https://github.com/Reallm-Labs/InfiGUI-R1 \
  模型地址：https://huggingface.co/Reallm-Labs/InfiGUI-R1-3B \
  让 AI 像人一样在行动前思考，行动后反思 \
  这种模式要求智能体不仅能看懂界面，还要能： \
  理解任务意图：将高层指令分解为具体的执行步骤 \
  进行空间推理：准确理解界面元素的布局和关系，定位目标 \
  反思与纠错：识别并从错误中恢复，调整策略
* 5.LoRA中到底有多少参数冗余？新研究：砍掉95%都能保持高性能  机器之心  https://mp.weixin.qq.com/s/B0pgqJIOqcHKjz3roAVeog \
  即使大幅减少 LoRA 的可训练参数，模型性能依然保持强劲 \
  LoRI: Reducing Cross-Task Interference in Multi-Task LowRank Adaptation \
  代码链接：https://github.com/juzhengz/LoRI \
  HuggingFace：https://huggingface.co/collections/tomg-group-umd/lori-adapters-67f795549d792613e1290011 \
  以 Llama-3-8B 和 Mistral-7B 作为基础模型，他们的结果表明，LoRI 达到或超过了全量微调（FFT）、LoRA 和其他 PEFT 方法的性能，同时使用的可训练参数比 LoRA 少 95%。值得注意的是，在使用 Llama-3 的 HumanEval 上，B 中具有 90% 稀疏度的 LoRI 比 LoRA 高出 17.3%。 \
  LoRI 通过实现适配器合并而无需手动选择合并方法来解决这些挑战。通过使用固定的、随机初始化的投影 A，LoRI 将任务特定的适配器映射到近似正交的子空间，从而减少合并多个 LoRI 时的干扰。 \
  在持续学习的同时能避免灾难性遗忘的问题 \
  总体而言，LoRI 提供了一种轻量级且有效的方法来构建安全适配器，在支持下游任务适应的同时保持对齐。
* 6.Sebastian Raschka 新书《从头开始推理》抢先看，揭秘推理模型基础  机器之心  https://mp.weixin.qq.com/s/zQUB9ZXqtSRGJU_YWMoMEw \
  《Reasoning From Scratch》 \
  原文地址：https://magazine.sebastianraschka.com/p/first-look-at-reasoning-from-scratch \

# 5.3 Sat
* 7.
* 8.
* 9.
* 10.

# 5.4 Sun
# 5.5 Mon
# 5.6 Tue
# 5.7 Wed

# 5.8 Thur
# 5.9 Fri
# 5.10 Sat
# 5.11 Sun
# 5.12 Mon
# 5.13 Tue
# 5.14 Wed

# 5.15 Thur
# 5.16 Fri
# 5.17 Sat
# 5.18 Sun
# 5.19 Mon
# 5.20 Tue
# 5.21 Wed

# 5.22 Thur
# 5.23 Fri
# 5.24 Sat
# 5.25 Sun
# 5.26 Mon
# 5.27 Tue
# 5.28 Wed

# 5.29 Thur
# 5.30 Fri
# 5.31 Sat
