# 10.1 周日
* 1、(**值得看看**)走向最小统一意识模型  图灵人工智能  https://mp.weixin.qq.com/s/RexTiOr7F-w45uQZCNlG8g \
  走向最小统一意识模型的步骤：基于自由能原理的意识模型的整合 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/86042724-e5ba-49e4-8bdc-292ce6d470f5) \
* 2、《深度模型融合》综述   专知  https://mp.weixin.qq.com/s/2-ZOAi2qzpWcAjktgaPJOw\
  深度模型融合/合并是一种新兴的技术，它将多个深度学习模型的参数或预测合并成一个。它结合了不同模型的能力，以补偿单一模型的偏差和错误，以实现更好的性能。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/beee0a0d-0c2a-4978-a8ac-7074dcbd9f52) \
* 3、接入大模型的眼睛：一文纵览多模态指令  专知  https://mp.weixin.qq.com/s/99pcSgcOjue9C5pGvj7Taw \
  当前的多模态大模型往往通过给大模型添加一个视觉模块，再通过多模态指令微调来进行两个模型的对齐。这之中，多模态指令微调至关重要。本文将从相关论文出发，梳理当前用于指令微调的多模态指令集，从收集方法，复杂度与指令侧重点来介绍它们。
* 4、Transformer+强化学习，谷歌DeepMind让大模型成为机器人感知世界的大脑  脑机接口社区  https://mp.weixin.qq.com/s/h8Aj5Ua7piSIMY1ar64efw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4de1108a-1884-480e-8067-1c5e3ffeef02) \
  论文：https://q-transformer.github.io/assets/q-transformer.pdf \
  项目：https://q-transformer.github.io/ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/575898a1-c2eb-4b83-898f-32a17032a81e)
* 5、ICLR 2023 | 神经规范场: 渲染引导空间规范变换  CVHub  https://mp.weixin.qq.com/s/Z31wFDdULBOcoACfQxsVKA \
  近期，神经场（Neural Fields）领域的巨大进展，已经显著推动了神经场景表示和神经渲染的发展。为了提高3D场景的计算效率和渲染质量，一个常见的范式是将3D坐标系统映射到另一种测量系统，例如2D流形和哈希表，以建模神经场。 \
  论文：https://arxiv.org/abs/2305.03462 \
  源码：https://github.com/fnzhan/Neural-Gauge-Fields \
  项目：https://fnzhan.com/Neural-Gauge-Fields/
* 6、（**值得看看**）别用GPT-4直出文本摘要！MIT、哥大等发布全新「密度链」提示：实体密度是摘要质量的关键  新智元  https://mp.weixin.qq.com/s/SklBTf_jegeYfRuCNc04YA \
  CoD（Chain of Dense）密度链 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7934fe34-2561-452e-b6d8-fcc841b7f62a) \
  论文链接：https://arxiv.org/pdf/2309.04269.pdf \
  开源数据：https://huggingface.co/datasets/griffin/chain_of_density
* 7、(**可以玩一玩**)以3D视角洞悉矩阵乘法，这就是AI思考的样子  机器之心  https://mp.weixin.qq.com/s/HRcjGjj83o3eVO6-AeGb2w \
  工具地址：https://bhosmer.github.io/mm/ref.html \
  博客原文：https://pytorch.org/blog/inside-the-matrix \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e2af8c80-64a1-488b-9e16-26a1f6a33fdc) \
* 8、(**重要，值得看看**)语言模型有重大缺陷，知识推演竟然是老大难  机器之心  https://mp.weixin.qq.com/s/ZV1_N5w0E2W07zPmCMW5yw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e331c636-6f7b-4578-9f77-9957446c203a) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/63ff7dea-1d96-4006-be27-3bd7f92c4e7f) \
  论文地址：https://arxiv.org/abs/2309.14402
* 9、不装电池也能「自动驾驶」，这个机器人还能无限续航 | 华盛顿大学  量子位  https://mp.weixin.qq.com/s/NXfo2C-60luLdR0EopB7-Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2158af17-e681-45f9-ab7b-c01e3cd1aa05) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b2da28dd-d715-44f5-900c-0a1d979f8b29) \
  参考链接： \
  [1]https://www.washington.edu/news/2023/09/27/millimobile-battery-free-autonomous-self-driving-robot-solar/ \
  [2]论文地址：https://homes.cs.washington.edu/~vsiyer/Papers/millimobile-compressed.pdf \
* 10、选用哪个？华中科大等最新《大型GPT模型》综述，37页pdf详述关于语言、多模态及科学GPT模型  专知  https://mp.weixin.qq.com/s/333ph-SgSVN8qci05TS9Iw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d37ecdd2-a600-4706-a729-998b8dceee38)
* 11、什么是涌现？人工智能给你答案  集智俱乐部  https://mp.weixin.qq.com/s/PmLu2gqDL9Udrf0DCobxjw

# 10.2 周一
* 12、(**重要，看看**)吴恩达力赞！哈佛、MIT学者用下棋证明：大型语言模型确实「理解」了世界  脑机接口社区  https://mp.weixin.qq.com/s/T1g-1bNxvaiURiZLvcetMw \
  MIT惊人证明：大语言模型就是「世界模型」？吴恩达观点再被证实，LLM竟能理解空间和时间  新智元  https://mp.weixin.qq.com/s/9OcaKA6WeniXVvopGSn22A \
  吴恩达相信LLM能够构建出足够复杂的世界模型，理解了这个世界 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a01279c8-ccb2-42ed-9b9f-59786c9c70a5) \
  论文链接：https://arxiv.org/pdf/2210.13382.pdf \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0976bb1d-ed67-4885-99d5-166db10430f2) \
  博客链接：https://www.deeplearning.ai/the-batch/does-ai-understand-the-world/ \
* 13、（**值得看看**）Chinchilla之死：只要训练足够长时间，小模型也能超过大模型  机器之心  https://mp.weixin.qq.com/s/Rx-6odhz1ap1fNEZJw8o_w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/630d3c74-babe-4125-95db-f9da10d88fd8) \
* 14、(**值得看看**)20多种意识理论哪个才是主导？五年了，还没有赢家  机器之心  https://mp.weixin.qq.com/s/ktm93pDX9xCG2WkKAKmi1Q \
* 15、如何评估大语言模型是否可信？这里总结了七大维度  机器之心  https://mp.weixin.qq.com/s/HTbr7aOVuJoeqbYCpY-kTA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/10abbacd-fa90-41a8-a3bd-5633ba3f61db) \
  论文地址：https://arxiv.org/abs/2308.05374 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/65037a94-60b3-4454-ba67-4fa46671e89f) 

# 10.3 周二
* 16、IBM量子计算最新进展：量子计算的chatGPT时刻即将来临？  图灵人工智能  https://mp.weixin.qq.com/s/GnwHw1fzMh0_Zp5gWXDG1Q
* 17、（**miniGPT-4值得研究**）MiniGPT-4：使用先进的大型语言模型提升 AI 视觉语言理解能力  专知  https://mp.weixin.qq.com/s/EY84dwiTCkO2M8DmSJs2xA
* 18、（**GPT-4V**）试过GPT-4V后，微软写了个166页的测评报告，业内人士：高级用户必读  机器之心  https://mp.weixin.qq.com/s/8FtR6JcEFVcRLWCaANXQ6g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4223f388-4421-4a82-bdd6-24cbc3f8d849) \
  报告地址：https://arxiv.org/pdf/2309.17421.pdf 
* 19、从观察、思考到行动，深度强化学习大牛Pieter Abbeel谈如何驯服机器人  机器之心  https://mp.weixin.qq.com/s/vEZAkF_TtbZIoulEBxStNQ
* 20、将LLaMA2上下文扩展至100k，MIT、港中文有了LongLoRA方法  机器之心  https://mp.weixin.qq.com/s/NeAPOblAOhzURy3XDVFV1Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ca456f3f-2a48-47d0-b4a6-d4b802bc9838) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1311f057-4f02-444e-89ee-1a45a534b144) \
  论文地址：https://arxiv.org/pdf/2309.12307.pdf \
  项目地址：https://github.com/dvlab-research/LongLoRA
* 21、(**看看怎么回事儿**)清华、微软等淘汰提示工程师？LLM与进化算法结合，创造超强提示优化器  机器学习研究组订阅  https://mp.weixin.qq.com/s/fCp856ON1YerIp4yhSEHDg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1a402a69-0ffa-4075-ae54-fecc800fdb42) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/38b8cd87-4c51-4036-affa-bb09e6d8c726) \
  论文地址：https://arxiv.org/pdf/2309.08532
* 22、DeepMind创始人：生成式AI只是过渡，AI未来将获得自由，交互式AI将改变人类  新智元  https://mp.weixin.qq.com/s/ICspZRixQ6nG5teJzPgdzQ \
  现阶段的生成式AI只是一个技术阶段，接下来会进入交互式AI的时代：AI将会成为能够根据每个用户的不同任务需求去调用其他软件和人来完成工作的机器人。
* 23、NeurIPS 2023 Spotlight｜高质量多视角图像生成，完美复刻场景材质！SFU等提出MVDiffusion  新智元  https://mp.weixin.qq.com/s/6fFfvKvAA9_zrxZIrYuerA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7454fa49-5a06-479b-8e33-a6371fafe885) \
  论文链接：https://arxiv.org/abs/2307.01097 \
  项目网站：https://mvdiffusion.github.io/ \
  Demo: https://huggingface.co/spaces/tangshitao/MVDiffusion \
  代码：https://github.com/Tangshitao/MVDiffusion \
  发表会议：NeurIPS（spotlight）
* 24、(**值得研究**)纽大具身智能新进展：靠视觉反馈学会开罐头，任务成功率提高135%，LeCun点赞  量子位  https://mp.weixin.qq.com/s/mPWanq2QrNNcCglkGj-leA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ede66bc9-5c68-4561-b498-0a62c6b7eeaa) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/533588bc-9273-4e0f-afe0-6e93710f1c5f) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/169c2169-c213-4bc6-a7fd-33375f1d6a49) \
  论文地址：https://arxiv.org/abs/2309.12300 \
  GitHub项目页：https://github.com/irmakguzey/see-to-touch \
* 25、大脑不对称性的起源：任务复杂性打破神经网络镜像对称性  集智俱乐部  https://mp.weixin.qq.com/s/8BVt61NgiJA1hhwRXP8j8Q \
  动物大脑的神经网络在一定程度上是镜像对称的，不对称性被认为在认知能力更强的物种中更为常见。这个假设源于一个长期存在的理论，即神经任务不断增加的复杂性，可以将镜像对称的神经回路转化为仅存在于大脑一侧的回路。
* 26、(**值得研究**)通院机器人实验室研究成果发表在IJCV 2022，构建机器人场景感知与任务规划的桥梁  北京通用人工智能研究院  https://mp.weixin.qq.com/s/kMw7iFZd6qt7LaAQSFw8Mw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8002754e-253b-43fe-ab80-8f88e05d2403) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ed1ab5b8-2ab1-45d9-ab42-f60935546633) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0ad1a054-857e-402b-a88e-cf0a51e00c8e) \
  论文链接：https://link.springer.com/article/10.1007/s11263-022-01670-0 \
  代码：https://github.com/hmz-15/Interactive-Scene-Reconstruction
* 27、通院机器人实验室IROS 2022研究成果介绍：利用物理常识驱动机器人使用工具  北京通用人工智能研究院  https://mp.weixin.qq.com/s/XF16lWZkplJ_yZ7V7ox3JQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6cfafdb5-e5d8-43c8-9d66-28acad502d61) \
  论文链接：https://ieeexplore.ieee.org/document/9832465 
* 28、(**可以看看**)朱松纯团队研究成果登上Science头条！为机器立“心”、实现通用AI迈出重要一步  北京通用人工智能研究院  https://mp.weixin.qq.com/s/0ZvpcHt8NRBjVw5KWfyMDA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9511bace-67df-4ba9-99cf-af2ec97717e5) \
  论文地址：https://www.science.org/doi/10.1126/scirobotics.abm4183

# 10.4 周三
* 29、(**可以看看怎么回事儿**)词表的选择如何影响语言模型训练？这可能是目前见过最好的词表选择研究  机器之心  https://mp.weixin.qq.com/s/EeD_sk2fSX-_YKsHVa_4Lg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d6693cfb-b8df-42c7-bca0-c8f1d9ba1aad)
* 30、数学家孜孜以求的数学证明本质是一种社会契约，为什么这么说？  机器之心  https://mp.weixin.qq.com/s/oJ3UNUtycg0-vfsa7I94kA
* 31、(**非常重要，仔细研究**)机器人研究迎来ImageNet时刻：一个数据集，让DeepMind具身智能大模型突飞猛进  机器之心  https://mp.weixin.qq.com/s/k3iXMZtdtzoP8ZuA5_Htww \
  DeepMind 全新 AI 项目曝光：可控制各类机器人，数据集有望开源 人机交互研究院  https://mp.weixin.qq.com/s/wl4k-mHAqWHIaH1OKKGKdQ \
  100多位作者！具身智能人进展！谷歌 DeepMind等机构推出《开放 X-实体化：机器人学习数据集与 RT-X 模型》论文  专知  https://mp.weixin.qq.com/s/RsyNU-U6SKwfkkVP50AhqA \
  RT-X、Open X-Embodiment, <Open X-Embodiment: Robotic Learning Datasets and RT-X Models> \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/73951d37-d56c-407e-9230-2d351a2939f4) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6c81c3ee-8e9d-4b56-b0bb-d7f2d2746082) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b4e26402-a3c4-4e25-b629-08da2f00dcba) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5d97aa00-16c1-42d2-9d03-37027d3b8875) \
  参考链接：https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types \
  论文链接：https://robotics-transformer-x.github.io/paper.pdf \
  项目链接：https://robotics-transformer-x.github.io/
* 32、(**重要，研究研究**)背诵不等于理解，深度解析大模型背后的知识储存与提取  机器之心  https://mp.weixin.qq.com/s/iYuykb8HnqhmUe9ZRm2H-g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c4c048bc-6de7-43ae-958e-9248f901f5da) \
  论文地址：https://arxiv.org/pdf/2309.14316.pdf
* 33、（**不错的教程，值得收藏**）llm-action：让天下没有难学的大模型  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/u6StD4IaJ7KuwTsNUaprMA \
  吃果冻不吐果冻皮：今年陆陆续续也写了不少关于大模型的文章，为了方便查看，均梳理了并放置在Github上面: https://github.com/liguodongiot/llm-action \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a0f75c39-3cfa-4963-bad6-3a823e703221)
* 34、【2023新书】决策智能手册：在复杂世界中基于证据做出决策的实用步骤, 270页pdf  专知  https://mp.weixin.qq.com/s/8StCl0zXIumzGoUrFc4DUQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2cb7cad4-2676-44fd-8d77-1175718bb2d9) \
* 35、(**获奖论文值得看看，学习一下**)ICCV2023奖项出炉！斯坦福ControlNet和多伦多大学分别获得最佳论文！Segment Anything最佳提名  专知  https://mp.weixin.qq.com/s/4ayiCpL3nSYTilURfrDwCg \
  Adding Conditional Control to Text-to-Image Diffusion Models \
  tracking everything everywhere all at once \
  segment anything \
* 36、400万token，大模型推理飙升22倍！清华校友爆火一作，GitHub狂揽1.8k星  新智元  https://mp.weixin.qq.com/s/Xjvg_ifh5lPkoQ2gkhY2BQ \
  最多400万token上下文、推理提速22倍，StreamingLLM火了，已获GitHub 2.5K星  机器之心  https://mp.weixin.qq.com/s/qIwYJAfD5bXJS6j0xtp2cw \
  Meta、MIT、CMU的研究者最近刚刚发表了一篇论文，提出了一种被称为是「高效流式语言模型」（Efficient Streaming Language Models，ESLM）的方法，可以让有限上下文能力的语言模型能够支持几乎无限的上下文窗口。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b54620af-b7dd-4dd1-af20-75dd18176ad6) \
  https://arxiv.org/pdf/2309.17453.pdf

# 10.5 周四
* 37、(**值得看看的课程，随便练习英语听力，熟悉人工智能术语**)斯坦福NLP课程XCS224U视频全部放出，干货满满，速来听讲  机器之心  https://mp.weixin.qq.com/s/KFrwkmI_lrH1E1fe7Q187g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/58265041-2eaa-4bff-9141-b7919a113b6e) \
  视频地址：https://www.youtube.com/playlist?list=PLoROMvodv4rOwvldxftJTmoR3kRcWkJBp
* 38、(**非常重要，进行研究**)谷歌推出全球最大通用大模型之一RT-X，并开放训练数据集！  AIGC开放社区  https://mp.weixin.qq.com/s/2472JCigL9RBxicWruJ5_g \
  模型和数据集地址：https://robotics-transformer-x.github.io/ \
  论文地址：https://robotics-transformer-x.github.io/paper.pdf 
* 39、(**立坤教授的演讲，非常值得看看**)Yann LeCun最新AI演讲《从机器学习到自主智能》，大模型不能规划，提出目标驱动AI，附视频与Slides  专知  https://mp.weixin.qq.com/s/I7XyftKGugfWqFF0niLW3A \
  机器如何能够像人类和动物一样高效地学习？机器如何能够学会推理和规划？机器如何能够学习感知和动作计划的多层次抽象表示，使它们能够在多个时间尺度上进行推理、预测和规划？ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/71909c49-fbae-49ac-8dd4-0da4e40c5d6c) 
* 40、(**看看讲了个啥**)【CMU博士论文】持续机器人学习:基准和模块化方法，125页pdf  专知  https://mp.weixin.qq.com/s/qZRbkX-KOAgb8zqkBFb_jQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c3e6efee-2302-4353-b472-247cc70f7bb4)

# 10.6 周五
* 41、(**重要，研究研究**)姚期智领衔提出大模型「思维」框架！逻辑推理正确率达98%，思考方式更像人类了  脑机接口社区  https://mp.weixin.qq.com/s/4AYbVFIWW96kAjcjH-0ndw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6698821d-7858-4838-8f2c-a7d8b6fa5cc6) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0fff46d6-4a0f-470a-a84e-6653d61e3e45) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ea2dc8b3-5dcf-482f-b745-f034882cd7c4) \
  论文链接：https://arxiv.org/abs/2308.04371 
* 42、(**看看怎么做到的**)如何降低视觉Transformer计算成本？时间冗余方法让人大吃一惊  机器之心  https://mp.weixin.qq.com/s/Qa_Fi7bmWWc04zz7NKoaQg \
  在为语言领域带来变革之后，Transformer 正在进军视觉领域，但其也有着高计算成本的问题。近日，威斯康星大学麦迪逊分校一个研究团队提出了 Eventful Transformer，可通过在视觉 Transformer 中利用时间冗余来节省成本。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/51fa37b2-1824-444e-b866-f90915ab3026) \
  论文地址：https://arxiv.org/pdf/2308.13494.pdf \
  项目地址：http://wisionlab.com/project/eventful-transformers
* 43、(**值得看看**)LLM成功不可或缺的基石：RLHF及其替代技术  机器之心  https://mp.weixin.qq.com/s/K0hFyK0bviFdcNrl21achQ \
* 44、(**有趣，值得看看**)在笔记本电脑上从头设计一款会走路的机器人，AI只需26秒  机器之心  https://mp.weixin.qq.com/s/SRH9iLaEttv5kWgeFdRlYQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/626cc85e-d00f-48d1-bd39-b7f562a3d581) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ab4651ed-3e5a-4329-88ae-5414cfcf5690) \
  论文链接：https://www.pnas.org/doi/epdf/10.1073/pnas.2305180120
* 45、3300万美元，谷歌开启5年脑计划！绘制小鼠大脑2-3%图谱，大约一个珠穆朗玛峰的数据量  新智元  https://mp.weixin.qq.com/s/C6xC3i4jdKCEItQIGLb8sw \
  谷歌宣布将绘制出小鼠大脑中海马体的所有连接组，这将是人类有史以来最大的生物数据集。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a694f607-cea6-4199-b767-6af887324684) \
* 46、(**有趣，重要，研究研究**)CMU华人打破大模型黑盒，Llama 2撒谎被一眼看穿！脑电波惨遭曝光，LLM矩阵全破解  新智元  https://mp.weixin.qq.com/s/0fPd86dMUaJmLAC3S_RZAw \
  大语言模型黑盒，居然被CMU等机构的学者打破了？他们发现，LLM内部有可解释的表征，如果撒谎，还能被测谎仪检测出来！ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/dd43632f-0dac-403d-8e7f-daa271102f85) \
  论文地址：https://arxiv.org/pdf/2310.01405.pdf \
  几个月前，OpenAI团队曾发表了一篇论文「语言模型可以解释语言模型中的神经元」，用AI竟然可以解释AI，震惊全网。通过调用GPT-4，能够解释GPT-2三十万个神经元。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7592ddf0-8749-492f-8360-101ba0bfcfc1) \
  论文地址：https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html#sec-intro \
  1972年，诺贝尔奖获得者P. W. Anderson在一篇「More Is Different」文章中，描述了复杂的现象如何不能简单地自下而上地进行解释。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e3596da9-c009-4319-a8a8-4632106fb0ea) \

# 10.7 周六
* 47、(**重要，研究研究**)分解大模型的神经元！Claude团队最新研究火了，网友：打开黑盒  量子位  https://mp.weixin.qq.com/s/FAz3MjN5uRFo9xVpqbgebw \
  打破大模型黑盒，彻底分解神经元！OpenAI对头Anthropic击破AI不可解释性障碍  新智元  https://mp.weixin.qq.com/s/MbjdkEoQt9USU8o_2fZKRg \
  深度学习可解释性新进展！Claude团队利用字典学习分解大模型神经元  夕小瑶科技说  https://mp.weixin.qq.com/s/U3QWO3oyHQ2r9r3Fb5JPUA \
  打破大模型黑盒，彻底分解神经元！OpenAI对头Anthropic击破AI不可解释性障碍  机器学习研究组订阅  https://mp.weixin.qq.com/s/mhaagZvZH0dp9dhWy5NW2Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/808d5dfd-ff45-4972-aed4-6f6a155e81a7) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/48fc517f-1bb3-444c-aa18-86d5b1b7309e) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/53e39f3d-166a-46b4-ab58-039caf49f56d) \
  报告题目为《迈向单义性：通过字典学习分解语言模型》（Towards Monosemanticity: Decomposing Language Models With Dictionary Learning） \
  报告链接： https://transformer-circuits.pub/2023/monosemantic-features/index.html \
  参考链接：https://twitter.com/anthropicai/status/1709986949711200722
* 48、OpenAI造芯计划曝光！拟自研AI芯片，正在评估收购目标  量子位  https://mp.weixin.qq.com/s/2QZdLDC-Z-f3RlTvwpVxVA \
  OpenAI计划研发自己的AI芯片，已有收购目标  机器之心  https://mp.weixin.qq.com/s/2yKiFlri86KXKnrWPP036w \
* 49、致敬TempleOS，有开发者创建了启动Llama 2的操作系统，网友：8G内存老电脑就能跑  机器之心  https://mp.weixin.qq.com/s/3VavBuDPDa49wEiPaGxaXw \
* 50、(**重要，研究研究，可能是LLM未来的应用路线**)7.7亿参数，超越5400亿PaLM！UW谷歌提出「分步蒸馏」，只需80%训练数据｜ACL 2023  新智元  https://mp.weixin.qq.com/s/10Gjkn7Ymed31xilmWOfog \
  LLM不实用，小模型蒸馏才是「现实」的大模型应用路线，全面领先微调技术！土豪请无视。。。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/867237bf-28fd-4d7d-949c-9d9eb7b57ea1) \
  论文链接：https://arxiv.org/abs/2305.02301
* 51、文章分享 | 人脑与人工神经网络中的知识组装  神经计算与控制实验室  https://mp.weixin.qq.com/s/h87cvPmXQ1nuKlD3kbW9UA \
* 52、《机器人语言》美陆军5年项目46页技术总结报告，2023年  专知智能防务  https://mp.weixin.qq.com/s/WVL9WCXo4b9pNemDS1U_-g \
* 53、(**值得看看，值得玩玩**)微软发布AutoGen开源框架，简化大语言模型工作流的编排、优化和自动化  人工智能与算法学习  https://mp.weixin.qq.com/s/M7xHAA4HSH-cJG3kbvgvNg \
  狂揽10k star，微软AutoGen框架太火了，智能体聊聊天就把问题解决了  机器之心  https://mp.weixin.qq.com/s/Frzso6gtsbqSp3x-8Tl6-g \
  碾压GPT-4，微软最强AutoGen爆火！多个智能体协作，编码速度飙升4倍，GitHub狂揽10k星  新智元  https://mp.weixin.qq.com/s/1K0nPE6wY2_bP-PaY0Opcw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9953ca2c-799d-4005-a522-73115c2664ce) 

# 10.8 周日
* 54、有了ModelScope-Agent，小白也能打造专属智能体，附保姆级教程  机器之心  https://mp.weixin.qq.com/s/-nP4eUlBavI6LmM9ASSi7w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7fad0d08-5632-40bb-bb74-5079b387c474) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ea3a7faa-2624-45a9-8d3d-bbd0cc7a5768) \
  论文链接：https://arxiv.org/abs/2309.00986 \
  代码链接：https://github.com/modelscope/modelscope-agent \
  ModelScope 体验地址：https://modelscope.cn/studios/damo/ModelScopeGPT/summary
* 55、(**值得看看**)正面硬刚GPT-4V！浙大校友开源多模态大模型LLaVA-1.5，130亿参数8个A100一天训完  新智元  https://mp.weixin.qq.com/s/luvuIsIBGEJYDezEbCOw5g \
  挑战GPT-4V，浙大校友推出开源版多模态大模型，获GitHub 6k+星标  量子位  https://mp.weixin.qq.com/s/EId9sFo5Qep-h4KiQewgVA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/92787ae7-f7cf-4c1c-9303-0fce8125f659) \
  ???怎么做到的，居然能看懂这种草图，难道训练数据里有吗  
* 56、(**阿尔伯塔计划，实现智能体的计划，了解了解其路线**)强化学习之父入局AGI创业！联手传奇程序员卡马克，放话不依赖大模型  量子位  https://mp.weixin.qq.com/s/YxeIJiO5CFzt8mpADGEcsg \
  Alberta Plan \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/65121437-b4b8-4f54-af12-8900888647db) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/59ebbcbe-1bc0-4127-a127-06267a1f2f05) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9f2e1815-1b84-4365-80b7-eaf2bd59b6be) \
  参考链接： \
  [1]https://www.amii.ca/latest-from-amii/john-carmack-and-rich-sutton-agi/ \
  [2]https://www.youtube.com/watch?v=uTMtGT1RjlY \
  [3]https://arxiv.org/abs/2208.11173  论文链接
* 57、对标GPT-4代码解释器！港中大让模型写代码解决数学难题，得分超越GPT-4  量子位  https://mp.weixin.qq.com/s/xUbGPXw2U9yhET9lvGFhTg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/163aba8d-1052-478b-af03-99e32a546b01) \
  论文地址：https://arxiv.org/abs/2310.03731
* 58、不可错过！斯坦福最新《大型语言模型与应用》课程，讲述LLMs技术栈和应用以及评估  专知  https://mp.weixin.qq.com/s/ygBT-y9HP6HwKb-ziHevkg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e62a8467-8ed6-4518-8a06-47c980aa4857) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/09b6f65c-b08c-49e7-a446-90251becc378) \
  https://web.stanford.edu/class/cs329t/index.html

# 10.9 周一
* 59、贾佳亚团队开源全球首个70B长文本大语言模型，读论文看小说直接ProMax  量子位  https://mp.weixin.qq.com/s/HaTqlerchNV3GmTzDJDS_A \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/3a630b03-f782-4b8b-b9bd-85fd1bd78243) \
* 60、最好的7B模型易主，笔记本轻松跑，免费开源可商用，来自“欧洲的OpenAI”  量子位  https://mp.weixin.qq.com/s/EhDRgNsFHyB3XIpfN9dQyw \
  来自法国的开源大模型Mistral-7B \
  如果你对Mistral-7B感兴趣，可以在Perplexity或HuggingChat试玩。 \
  labs.perplexity.ai \
  https://huggingface.co/chat \
  还有一个与Llama 2同台竞技的小游戏可玩。 \
  https://llmboxing.com 
* 61、迪士尼玩起强化学习，新机器人有星球大战那味了  量子位  https://mp.weixin.qq.com/s/q-V8BAAK__I_RmjKXPyEZw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c5a65c5b-ebe5-442c-b4fa-9a81d783429a)
* 62、(**值得看看，LongLoRA**)2行代码，「三体」一次读完！港中文贾佳亚团队联手MIT发布超长文本扩展技术，打破LLM遗忘魔咒  新智元  https://mp.weixin.qq.com/s/8QoKHgwjxv7fG_CCqouU8w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/dac2d276-761a-4502-ab16-777de2b27b37) \
  论文地址：https://arxiv.org/abs/2309.12307 \
  代码和Demo地址：https://github.com/dvlab-research/LongLoRA
* 63、(**有趣，了解了解**)文生3D模型大突破！MVDream重磅来袭，一句话生成超逼真三维模型  新智元  https://mp.weixin.qq.com/s/EpdblKDrb1T6xjnVRE8TCw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4eaa4a32-0439-4932-80f7-0de4b29bb6d6) \
  参考资料： \
  https://www.louisbouchard.ai/mvdream/ \
  https://arxiv.org/pdf/2308.16512.pdf 
* 64、(**MiniGPT-5，看一看，玩一玩**)统一图像和文字生成的MiniGPT-5来了：Token变Voken，模型不仅能续写，还会自动配图了 \
  野心勃勃的MiniGPT-5出现了！Token变Voken，支持图文交叉生成  夕小瑶科技说  https://mp.weixin.qq.com/s/5qKrE7bHtBEx7IB7ermWqg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4aab77b3-4376-4aa5-b736-a79eb0acd81a) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1ec9b2fc-b3be-4200-8678-93af1c5a6d7d) \
  论文地址：https://browse.arxiv.org/pdf/2310.02239v1.pdf \
  项目地址：https://github.com/eric-ai-lab/MiniGPT-5 \
* 65、500多倍！伯克利 | 提出Ring Attention，Transformer分块，最高支持100M上下文！ AINLPer  https://mp.weixin.qq.com/s/wOCpDcb7acPxioRk_6jm9g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5df91724-f2fc-4529-9d4d-68404116941a) \
  Paper：https://browse.arxiv.org/pdf/2310.01889.pdf \
  Code：coming soon~

# 10.10 周二
* 66、陶哲轩：我用GPT-4辅助证明不等式定理，论文还会上传arXiv  机器之心  https://mp.weixin.qq.com/s/Cezn03Xksu4XLiQYFE9cug \
  GPT-4野生代言人陶哲轩：搞论文学新工具没它得崩溃！11页“超简短”新作已上线  量子位  https://mp.weixin.qq.com/s/l_otQop-xFbFTmML0Bq0cQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5ca3bba9-1f69-4e27-b6b7-66f7732ae4bf)
  论文地址：https://browse.arxiv.org/pdf/2310.05328.pdf
* 67、大模型开启「长」时代，杨植麟的新公司把对话框容量做到了世界第一  机器之心  https://mp.weixin.qq.com/s/ucBkWpdG8PU5rM5OPmK5jw \
* 68、多模态大模型落地的风，最终还是刮了起来  计算机视觉研究院  计算机视觉研究院  https://mp.weixin.qq.com/s/5OgjMrYMDrTZDJZrZNgL2g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/34ec52b9-c103-47dc-9ff5-ad86d383a827) \
  LLaVA-1.5 \
  论文地址：https://browse.arxiv.org/pdf/2310.03744.pdf \
  Demo 地址：https://llava.hliu.cc/
* 69、(**试玩一下**)挑战GPT-4V！清华唐杰&智谱开源多模态14边形战士，在线可玩  量子位  https://mp.weixin.qq.com/s/sKMQUrIGBN2Kh9Nx2ifJtg \
  CogVLM \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1c3bdcbf-7277-4eab-bbd7-88836c321680) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8d273a70-5c79-44ef-9c5e-1d249ecf39a4) \
  试玩地址：http://36.103.203.44:7861 \
  开源及论文地址：https://github.com/THUDM/CogVLM

# 10.11 周三
* 70、EfficientViT：让ViT更高效部署实现实时推理（附源码）  计算机视觉研究院  https://mp.weixin.qq.com/s/-kivpJIjouIuDew2Jog3MA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/01e0aff9-67e3-4a15-a248-d1f10f4c51e3) \
  论文地址：https://arxiv.org/pdf/2305.07027.pdf \
  项目代码：https://github.com/microsoft/Cream/tree/main/EfficientViT
* 71、InternImage：探索具有可变形卷积的大规模视觉基础模型  计算机视觉研究院  https://mp.weixin.qq.com/s/ELIzsTJ5l881SyxcbF7LNg \
* 72、(**重要，听一听**)OpenAI科学家最新演讲：GPT-4即将超越拐点，1000倍性能必定涌现！  新智元  https://mp.weixin.qq.com/s/48Brr7APBBYT2X28Z724AA \
  OpenAI科学家最新演讲：GPT-4即将超越拐点，1000倍性能必定涌现！  机器学习研究组订阅  https://mp.weixin.qq.com/s/XLgKurtiXEba9TUNju760w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f127d284-593d-436b-974f-3e0eed9f0056) \
  参考资料：\
  https://twitter.com/xiaohuggg/status/1711714757802369456?s=20 \
  https://twitter.com/dotey/status/1711504620025942243 \
  https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g27b7c310230_0_496
* 73、(**值得看看**)Meta再放「长文本」杀器Llama 2-Long：70B尺寸登顶最强「32k上下文」模型，超越ChatGPT  新智元  https://mp.weixin.qq.com/s/-6thXLygj-TUaZWhPTmMcQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a8311e1f-7a89-4ad4-b1e0-4b80e84d977c) \
  论文链接：https://arxiv.org/pdf/2309.16039.pdf 
* 74、(**可以看看**)在图像、视频生成上，语言模型首次击败扩散模型，tokenizer是关键  机器之心  https://mp.weixin.qq.com/s/fHWTbv_yvqKb-GiBqDUAsA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/903f72a6-2e60-4030-83b0-74fa730ac3eb)
  论文链接：https://arxiv.org/pdf/2310.05737.pdf
* 75、MetaMath：新数学推理语言模型，训练大模型的逆向思维  机器之心  https://mp.weixin.qq.com/s/Rtao_IXfY3hXIvYZPxIBGA \
  ？？？怎么实现逆向思维的 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d871f99d-e5d5-48ef-aec4-562eef975e9a) \
  项目地址：https://meta-math.github.io/ \
  论文地址：https://arxiv.org/abs/2309.12284 \
  数据地址：https://huggingface.co/datasets/meta-math/MetaMathQA \
  模型地址：https://huggingface.co/meta-math \
  代码地址：https://github.com/meta-math/MetaMath
* 76、清华全球首颗片上学习忆阻器存算一体芯片，成果登上Science  机器之心  https://mp.weixin.qq.com/s/p9II_b1oI-7iKMmFveus5g \
  清华芯片新突破登Science，获评“存算一体领域重大进展”！基于类脑架构实现片上快速AI学习  量子位  https://mp.weixin.qq.com/s/r9mza55fywxTBDQvuenC-Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/954d9a24-006d-4c8d-b477-4f7658d32b4a) \
  论文地址：https://www.science.org/doi/full/10.1126/science.ade3483
* 77、(**值得看看**)复旦 NLP 实验室联合米哈游解读大模型：AI Agents 的现状和未来  Founder Park  https://mp.weixin.qq.com/s/jArfNGEdsZ4OxvCZ8B1siw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/fc8e3ba3-093b-481c-a4df-cfa0b61639cb) \
  论文链接：https://arxiv.org/pdf/2309.07864.pdf \ 
  (**!!!重要资源**)LLM-based Agent 论文列表：https://github.com/WooooDyy/LLM-Agent-Paper-List
* 78、(**为啥淘汰向量数据库？看看，搞清楚**)AutoGPT 宣布不再使用向量数据库！向量数据库是小题大作的方案？  infoQ  https://mp.weixin.qq.com/s/mlUg1N7jQ5f6HVKKOvKOjA \

# 10.12 周四
* 79、类脑智能：基于脑启发的智能研究新范式  脑机接口社区  https://mp.weixin.qq.com/s/oE7VmRHUiwF7bwIb69mi4Q \
* 80、(**可以看看，TP**)中科院提出“思维传播”，极大增强ChatGPT等模型复杂推理能力  AIGC开放社区  https://mp.weixin.qq.com/s/wKFHMjH4GQNilCp5Dibtbw \
  思维传播(Thought Propagation，简称“TP”)
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b40e6c3f-627a-445d-9edc-8fb6967890b5) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5357a60f-56ff-48a2-ad6e-3da0ad9194cd) \
  论文地址：https://arxiv.org/abs/2310.03965
* 81、突发！Hinton入局机器人创业，公司新获9000万投资  量子位  https://mp.weixin.qq.com/s/gBgAwznRFmFsrj9wBqXBiA \
* 82、陈丹琦团队新作：5%成本拿下SOTA，“羊驼剪毛”大法火了  量子位  https://mp.weixin.qq.com/s/DZTmfeYUceWLcRokocdFtQ \
  手把手教你剪「羊驼」，陈丹琦团队提出LLM-Shearing大模型剪枝法  机器之心  https://mp.weixin.qq.com/s/jahm_Pxm9KIDJozSXXPt5g \
  只用3%的计算量、5%的成本取得SOTA，统治了1B-3B规模的开源大模型。怎么剪枝的，研究研究 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ba4642d9-cb17-4522-975f-290fc2009513) \
  论文地址：https://arxiv.org/abs/2310.06694 \
  Hugging Face：https://huggingface.co/princeton-nlp \
  项目主页：https://xiamengzhou.github.io/sheared-llama/
* 83、“九章三号”光量子计算机问世！比超算快一亿亿倍，来自中科大潘建伟团队  \
  论文地址：https://journals.aps.org/prl/issues/131/15 \
  参考链接：[1]https://quantum.ustc.edu.cn/web/index.php/node/1140 \
           [2]https://s.weibo.com/weibo?q=%E4%B9%9D%E7%AB%A0%E4%B8%89%E5%8F%B7
* 84、OpenAI被曝“在憋大招”：构建ChatGPT应用成本暴降95%  量子位  https://mp.weixin.qq.com/s/9GfRh8uK24frOt9pdk6Z0g \
  据路透社爆料，OpenAI正计划推出一次重大更新，让开发者基于ChatGPT搭建APP的**成本一次性缩水95%**。 \
* 85、AI搞定谷歌验证码，最新多模态大模型比GPT-4V空间理解更准确 | 苹果AI/ML团队  量子位  https://mp.weixin.qq.com/s/r6I_fo9GeqpqAlSYMMKErw \
  由苹果和哥伦比亚大学研究团队带来的多模态大模型“雪貂”（Ferret） \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f38a135c-4bff-4f8d-883c-943478803eaf) \
  论文地址：https://arxiv.org/abs/2310.07704
* 86、(**重要，值得看看**)GPT-4就是AGI！谷歌斯坦福科学家揭秘大模型如何超智能  新智元  https://mp.weixin.qq.com/s/JnqXdQxfS6iBFIKsC-UkeA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/58165fb3-7ba9-40c9-b807-5b46bc80aa8c) \
  参考资料：https://www.noemamag.com/artificial-general-intelligence-is-already-here/
* 87、机器人瓦力来了！迪士尼亮出新机器人，用RL学习走路，还能进行社交互动  新智元  https://mp.weixin.qq.com/s/HeTX1Mo1j_Ym52Ma8FiM7g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e72b2bff-b7a7-4318-9bbf-dbbac8e47de6) \
* 88、国产大模型开源一哥再登场，最强双语LLM「全家桶」级开源！340亿参数超越Llama2-70B  新智元  https://mp.weixin.qq.com/s/jp90YD6LvTeQL_nAeZY1Tw \
* 89、(**有趣，研究研究，UniSim**)生成模型构建交互式现实世界模拟器，LeCun觉得非常酷  机器之心  https://mp.weixin.qq.com/s/m-agHghFmgGNLFBRuviO4g \
  Meta 首席 AI 科学家 Yann LeCun 非常看好世界模型，希望创建一个能够学习世界如何运作的内部模型。近日，UC 伯克利、谷歌 DeepMind 等机构的研究者用生成模型来构建交互式现实世界模拟器，对于世界模型具有积极意义。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f318be8c-2330-49d6-9765-8aacaa784e54) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c14ed98f-0f26-4ee3-9ade-46a10e165f61) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a58b12e0-b78e-44b2-b99b-3d7e26fd3774) \
  论文地址：https://arxiv.org/pdf/2310.06114.pdf \
  论文主页：https://universal-simulator.github.io/unisim/
  
# 10.13 周五
* 90、(**重要，研究研究，ACE**)让ChatGPT等模型学会自主思考！开创性技术“自主认知”框架  AIGC开放社区  https://mp.weixin.qq.com/s/4qHof1eSlI3gddr4uXVL2A \
  克莱姆森大学AI实验室提出了自主认知技术框(Autonomous Cognitive Entity，简称“ACE”) \
  ACE主要由道德、全局战略、代理模型、执行、认知控制和任务执行6大层组成 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/08716b75-74ef-460a-a353-1b65171423c2) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/13bd854c-7d3b-4631-a548-348405a77204) \
  论文地址：https://arxiv.org/abs/2310.06775
* 91、(**有趣，值得看看**)东大华人博士让GPT-4用「心智理论」玩德扑！完胜传统算法，碾压人类新手  新智元  https://mp.weixin.qq.com/s/Mp0rqPD29_zdp0HD-mmLdw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4beaf828-17b2-4853-a81d-fc93a86e6dca) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/339b268b-acdd-4d03-89c0-ab421c3b4270) \
  论文：https://arxiv.org/abs/2309.17277 
* 92、(**面经，找工作必备**)LLM-面试八股  小红书  https://www.xiaohongshu.com/explore/6526d676000000001e00c870?secondshare=weixin&share_from_user_hidden=true&appuid=603b996b0000000001008468&apptime=1697191774&wechatWid=c8bca3cae5d5cc9174b900b21f52cb0d&wechatOrigin=menu \
* 93、(**值得看看，Mistra-7b**)“最强7B模型”论文发布，揭秘如何超越13B版Llama 2  量子位  https://mp.weixin.qq.com/s/KE7S1eNXqkgU6VPk1LJE5g \
  Mistral不仅全面战胜了13B Llama2，在数学、代码和推理方面，34B的Llama1也不是Mistral的对手。 \
  在推理任务上，Mistral的表现更是直逼10倍参数量的Llama2-70B。 \
  但Mistral消耗的资源却很少，只需要6GB显存，MacBook就能流畅运行。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e2f5e91d-d226-4972-a359-e31172e094ac) \
  论文地址：https://arxiv.org/abs/2310.06825 \
  微调教程：https://wandb.ai/byyoung3/ml-news/reports/Fine-Tuning-Mistral7B-on-Python-Code-With-A-Single-GPU---Vmlldzo1NTg0NzY5

# 10.14 周六
* 94、(**可以看看**)用暂停token重新训练大模型，AI学会三思而后行  量子位  https://mp.weixin.qq.com/s/WAAVTs_svZao35XQfaZuig \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/bfb4a4c1-8c94-41db-9887-ae945d9e3f39) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9cd45250-a99c-4599-b42e-6367a839f618) \
  论文地址：https://arxiv.org/abs/2310.02226 \
  参考链接：https://twitter.com/arankomatsuzaki/status/1709372124891070915
* 95、(**有趣，值得看看 T4D、FaR**)谷歌让大模型更具“心智”，GPT-4任务准确率大增  量子位  https://mp.weixin.qq.com/s/-WMZ5o0JRbz7gNoya8En7A \
  Thinking for Doing（T4D）-根据推理给出行动建议，Foresee and Reflect（FaR）提示策略 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/380dfd3c-10af-43fd-9401-9af3058b70ef) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/18a92c3f-cd65-4360-b222-329a40ab9090) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/653bb39c-7054-4cec-899c-0728769ab603) \
  论文地址：http://arxiv.org/abs/2310.03051
* 96、(**看看FlashAttention的原理**)别再「浪费」GPU了，FlashAttention重磅升级，实现长文本推理速度8倍提升  机器之心  https://mp.weixin.qq.com/s/dV72_ban9JHAoOV6W93G7g \
  **FlashAttention** 作者 Tri Dao 等人提出的「**Flash-Decoding**」通过充分利用 GPU，可以将大模型的长上下文推理速度提高至 8 倍。 \
  参考链接：https://princeton-nlp.github.io/flash-decoding/ 
* 97、(**值得看看HtT**)DeepMind让大模型学会归纳和演绎，GPT-4准确率提升13.7%  机器之心  https://mp.weixin.qq.com/s/OXT8ilDpn2xDPdinswlGdQ \
  让大模型真正学会1+1=2！谷歌教会模型自动学习推理规则，大模型的幻觉有救了  夕小瑶科技说  https://mp.weixin.qq.com/s/b1rgKoMSvDwegU9oTh5wSQ \
  HtT（Hypotheses-to-Theories）假设到理论, 没看明白，先从问题答案对中找到推理规则（归纳），在利用这些规则进行推理（演绎） \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/58d2709a-1a8d-4ef7-a096-8e4d4343c79c) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/48e7d7d5-485b-4f45-a713-d042fdc143c8) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c4a50f5b-e5e8-4140-a8c7-d5ec7cf9f97d) \
  论文地址：https://arxiv.org/abs/2310.07064
* 98、ICCV 2023 | 实现实时六自由度物体跟踪，深度主动轮廓模型DeepAC来了  机器之心  https://mp.weixin.qq.com/s/Tgyy7EjDjPzlzm5Dr4tFbA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4302c46a-eccd-4018-9dea-1fb16e004df2) \
  论文地址：https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Active_Contours_for_Real-time_6-DoF_Object_Tracking_ICCV_2023_paper.pdf \
  项目主页：https://zju3dv.github.io/deep_ac/

# 10.15 周日
* 99、(**李航大佬的总结，值得看看**)字节跳动李航：对语言大模型的若干观察和思考  机器之心  https://mp.weixin.qq.com/s/0I-y1dGM08n8KF1Kwv2diw \
* 100、CityDreamer：一键生成无边界的3D城市  机器之心  https://mp.weixin.qq.com/s/wCkAhuBGqZTEAWjN9NpEEA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/560e3202-e3da-4edf-a7fa-49cae069ade9) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8aafca2f-474b-44b0-abf5-cd283b3b1c04) \
  论文地址：https://arxiv.org/abs/2009.00610 \
  项目地址：https://haozhexie.com/project/city-dreamer \
  代码地址：https://github.com/hzxie/city-dreamer
* 101、大模型如何实时更新？悉尼科大等最新《 大型语言模型如何捕捉不断变化的世界知识?》最新进展综述  机器学习研究组订阅  https://mp.weixin.qq.com/s/6nO7L6wAEUFJQsLL9cROwQ \
  本文提供了对最近在不从头开始重新训练的情况下，将LLMs与不断变化的世界知识对齐的进展的全面回顾。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0c2f3b53-5b22-453b-94e5-16da360bce8b) \
* 102、“大大震惊”一位CTO：GPT-4V自动驾驶五连测  量子位  https://mp.weixin.qq.com/s/3SYc2-7HLWMBrB-fEpPVhQ \
  LLM未来在自动驾驶领域的应用大有前途 \
  参考链接：https://zhuanlan.zhihu.com/p/660940512

# 10.16 周一
* 103、轻量级MobileSAM：比FastSAM快4倍，处理一张图像仅需10ms（附源代码）  计算机视觉研究院  https://mp.weixin.qq.com/s/g-UHNQGOqCfg7uhEAF6KmQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7be80005-59b8-4426-9019-4877074d1b0a) \
  论文地址：https://arxiv.org/pdf/2306.14289.pdf \
  代码地址：https://github.com/ChaoningZhang/MobileSAM
* 104、大语言模型击败扩散模型！视频图像生成双SOTA，谷歌CMU最新研究，一作北大校友  量子位  https://mp.weixin.qq.com/s/VjGTXQx4Ao02GZ7Ha59Xbw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b3df5e8c-ef51-48d4-a708-ab371afc99f4) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9f27e1e1-c2cb-4bb3-b8be-02fa9f7a89c0) \
  论文链接： \
  https://arxiv.org/abs/2310.05737 \
  https://magvit.cs.cmu.edu/v2/
* 105、(**值得听听**)OpenAI科学家最新大语言模型演讲火了，洞见LLM成功的关键  机器之心  https://mp.weixin.qq.com/s/Kwkn7H82QV7KaFma0r7SlQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ab0797d1-cfa9-404e-a601-291a7e8ae3e2) \
  视频地址：https://www.youtube.com/watch?v=dbo3kNKPaUA \
* 106、(**有趣，值得看看**)语言、机器人破壁，MIT等用GPT-4自动生成模拟任务，并迁移到真实世界  机器之心  https://mp.weixin.qq.com/s/tEl920V0MsEfdaOS1h6vqQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6b8d7a9e-c0f8-4e4e-958f-b6f461308a6e) \
  论文地址：https://arxiv.org/pdf/2310.01361.pdf
* 107、(**有趣，可以看看**)ReCon框架帮助AI大模型识破谎言，来看智能体如何在阿瓦隆游戏中应对欺骗  机器之心  https://mp.weixin.qq.com/s/TglUikgaQe17XTP29cF9Uw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/3d566322-5eef-4294-a75a-c240ea8f860b) \
  Arxiv 链接：https://arxiv.org/abs/2310.01320
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c91c0ef2-7437-4251-aecd-c238ae743f64)
* 108、(**重要且有趣，值得看看**)英伟达爆火智能体研究：AI逼真还原人类情感！会饿会孤独，会跑步会发火  新智元  https://mp.weixin.qq.com/s/aPjhHMVHsKV1icUalSZv_w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6018b49a-74a1-4a9d-bc8e-ccde35ed026c) \
  论文地址：https://arxiv.org/abs/2310.05418 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7300021e-ae22-4c33-a32d-0b7e2203aaf5)
* 109、GPT-4肆虐「谁是卧底」桌游！交谈逼真，类人属性仍有发展空间  新智元  https://mp.weixin.qq.com/s/cR8IOCnufiUq9V7aRmsFyw
* 110、(**重要，试试能不能把PaLI-3玩起来**)谷歌重磅发布 PaLI-3，四两拨千斤！  夕小瑶科技说  https://mp.weixin.qq.com/s/lcDaJSTx60e_Ankq9iAdng \
  谷歌视觉语言模型PaLI-3问世，参数仅5B，更小、更快、更强  机器之心  https://mp.weixin.qq.com/s/u3v86z0DKbvbaLTT7YLjCg \
  论文题目:PALI-3 Vision Language Models: Smaller, Faster, Stronger \
  论文链接:https://arxiv.org/abs/2310.09199 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5499fa68-b8ef-4d43-a308-2d85d7a36ce9) 
* 111、(**可以看看**)上海交大 | 提出Meta-CoT思维链，增强 LLMs 在「混合任务场景」中的推理能力  AINLPer  https://mp.weixin.qq.com/s/NcK1K3IifMHn5IbkP1Zx4A \
  性能强劲又通用！Meta-CoT: 混合问题场景下的自适应思维链推理  paperweekly  https://mp.weixin.qq.com/s/bOc5y8gmsV9FaKYQGiMgRw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d8449f8e-9d78-4c98-ad9f-3338530b2566) \
  Paper：https://arxiv.org/pdf/2310.06692.pdf \
  Code：https://github.com/Anni-Zou/Meta-CoT

# 10.17 周二
* 112、(**可以试玩一下**)全面超越AutoGPT，面壁智能联合清华NLP实验室开源大模型「超级英雄」XAgent  机器之心  https://mp.weixin.qq.com/s/vW5HDUuRHve4KwOljLhqoQ \
  清华版「AutoGPT」登GitHub热榜！复杂任务轻松搞定，还能自己训练模型  量子位  https://mp.weixin.qq.com/s/d4fCz1KPrF7W6M5AFD355g \
  现已在 GitHub 正式开源，地址 https://github.com/OpenBMB/XAgent \
  案例展示地址：https://x-agent.net/ \
  博客地址：https://blog.x-agent.net
* 113、(**研究研究，试玩一下**)MiniGPT-4升级到MiniGPT-v2了，不用GPT-4照样完成多模态任务  机器之心  https://mp.weixin.qq.com/s/Lt11fr50uHr8TB50wXbo_w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9567a984-b0d2-43b4-9dfc-c78d2387a855) \
  论文地址：https://arxiv.org/pdf/2310.09478.pdf \
  论文主页：https://minigpt-v2.github.io/ \
  Demo: https://minigpt-v2.github.io/
* 114、GPT-4V多模态能力惊人！公式截图直出代码，「龙与魔法世界」瞬间生成，OpenAI总裁激动转发  新智元  https://mp.weixin.qq.com/s/gWvbB_zTGt8mr6b0Ok-wUw \
* 115、(**可以看看**)PyTorch官方认可！斯坦福博士新作：长上下文LLM推理速度提8倍  量子位  https://mp.weixin.qq.com/s/rMVCqtmlxPGd6R_1mnTcpQ \
  官方博客：https://princeton-nlp.github.io/flash-decoding/ \
  参考链接：https://twitter.com/tri_dao/status/1712904220519944411?s=20
* 116、(**可以看看，基于博弈论的生成结果优化方法**)7B羊驼战胜540B“谷歌版GPT”，MIT用博弈论调教大模型，无需训练就能完成  量子位  https://mp.weixin.qq.com/s/-wMRtvYvRt5SejLX3xUVGw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0ad64926-a57f-41b5-a9e3-5a94704763b4) \
  论文地址：http://arxiv.org/abs/2310.09139

# 10.18 周三
* 117、(**大模型微调基本概念，可以看看**)拓展技术边界，掌握AI大语言模型微调（LLaMA）方法 【赠算力】  AINLPer  https://mp.weixin.qq.com/s/Hy1exaTDsDoi4tqK1yqDVA \
* 118、(**大模型调参经验，可以看看**)谷歌大脑深度学习调参（炼丹）指南出炉，Hinton点赞，一天收获1500星  计算机视觉研究院  https://mp.weixin.qq.com/s/GPQUYgI2Ns3bkZl60PfncA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/18b6ce11-aa8f-4dfb-867d-84aba2c52ffe) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/3dffb7d0-2ab7-427a-850e-7c4d168bf12f) \
  论文地址：https://arxiv.org/pdf/2201.04620v1.pdf \
  项目地址：https://github.com/google-research/tuning_playbook
* 119、(**利用操作系统虚拟内存的概念扩展LLM的上下文，值得看看**)把LLM视作操作系统，它就拥有了无限「虚拟」上下文，伯克利新作已揽1.7k star  机器之心  https://mp.weixin.qq.com/s/qtm52JKXoX0bGNE10a4deQ \
  在本文中，研究者探究了如何在继续使用固定上下文模型的同时，提供无限上下文的幻觉（illusion）。他们的方法借鉴了虚拟内存分页的思路，使得应用程序能够处理远超出可用内存的数据集。基于该思路，研究者利用 LLM 智能体函数调用能力的最新进展，设计出了一个受 OS 启发、用于虚拟上下文管理的 LLM 系统 ——MemGPT。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/475ac0ea-ab8e-4b9b-a97b-e424720e2ff2) \
  论文主页：https://memgpt.ai/ \
  arXiv 地址：https://arxiv.org/pdf/2310.08560.pdf
* 120、未来大模型顶会？陈丹琦等人组织首届COLM，为语言建模研究提供新平台  机器之心  https://mp.weixin.qq.com/s/XoY2mZ7Sgm83may967JkqA \
  新成立的会议，COLM（Conference on Language Modeling）,专注于语言建模研究
* 121、端侧AI推理，高效部署PyTorch模型：官方新工具开源，Meta已经用上了  机器之心  https://mp.weixin.qq.com/s/ot6sbEpSYt2jL-2Is801fw \
  在边缘和移动设备上实现 AI 推理的解决方案：ExecuTorch，开源的 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ab26e1db-1391-4fc5-9a0e-c0e6e2b16e7d) \
* 122、超低训练成本文生图模型PixArt来了，效果媲美MJ，只需SD 10%训练时间  机器之心  https://mp.weixin.qq.com/s/7dg6O5jmBwZ-1_LoiMvTlw
* 123、精确率提升7.8%！首个多模态开放世界检测大模型MQ-Det登NeurIPS 2023  新智元  https://mp.weixin.qq.com/s/lI7_1r9KyqzgfLACm4jKcw \
  MQ-Det在已有基于文本查询的检测大模型基础上，加入了视觉示例查询功能，同时保留了高泛化性能和细粒度多模态查询 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/3e4df985-1d4c-477a-a960-cb9430679b73) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/bb6a461c-4281-46fe-a1ce-230e105d30fb) \
  论文链接：https://arxiv.org/abs/2305.18980 \
  代码地址：https://github.com/YifanXu74/MQ-Det
* 124、马斯克一觉醒来，纯视觉NOA已在中国开跑：上海闹市一镜到底0接管，高速城区全都不用自己开  量子位  https://mp.weixin.qq.com/s/yZz71P488bDg7QXdXgBZIw
* 125、(**有趣，可以玩玩**)零基础最详细的部署ChatGPT 微信机器人教程(附源码)  新机器视觉  https://mp.weixin.qq.com/s/LTL_S5hXhQPWc2FMdq7UYQ

# 10.19 周四
* 126、开源智能体来啦！港大团队发布OpenAgents，可以搞数据分析、聊天、支持200+插件  夕小瑶科技说  https://mp.weixin.qq.com/s/lL8J9hiwavIK-v5WNllAqQ \
  港大的研究团队最近发布了一个新的开源 Agent 框架，名为 OpenAgents. 它可以用于实际用户场景，特别是在使用自然语言执行复杂任务的情况下。先前的语言智能体框架主要关注概念验证或者供开发人员使用，而 OpenAgents 则更注重非专家用户的使用体验和应用设计。它提供了一个开放的平台，让更多人可以在日常生活中使用和部署语言智能体。这个平台包括数据智能体、插件智能体和 Web 智能体，用户可以通过一个优化的 Web 界面与智能体进行交互。 \
  论文题目:OpenAgents: An Open Platform For Languageagents In The Wild \
  论文链接:https://arxiv.org/abs/2310.10634 \
  项目地址:https://github.com/xlang-ai/OpenAgents \
  Demo 地址:https://chat.xlang.ai/
* 127、超火迷你GPT-4视觉能力暴涨，GitHub两万星，华人团队出品  夕小瑶科技说  https://mp.weixin.qq.com/s/RH4f9UUnBcnOpRY_GJq-4Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4a94c188-1479-41df-9d22-0f47df0d6810)
* 128、大模型总弄错「事实」怎么办？这有一份汇聚了300多篇文献的综述  机器之心  https://mp.weixin.qq.com/s/VvXNS6HBrmS99Z-tNohjrg \
* 129、(**有趣，可以看看**)狂揽4k star，AI通过强化学习玩宝可梦，两万场后成功拿下  机器之心  https://mp.weixin.qq.com/s/hV_BBQCMMt36Y6Jo2-Qs6w \
  项目地址：https://github.com/PWhiddy/PokemonRedExperiments \
  视频地址：https://www.youtube.com/watch?v=DcYLT37ImBY
* 130、OpenAI新模型研发遇挫，稀疏性是大模型降本的钥匙吗？  机器之心  https://mp.weixin.qq.com/s/d17EiFvst3BJVZkb3pH_7Q \
* 131、(**fuyu-8b可以试试**)Transformer一作来卷多模态！学术图表也能看懂，100毫秒极速响应｜免费试玩  量子位  https://mp.weixin.qq.com/s/VA0QptFJV7LNynZHWV4vtg \
  Demo试玩：https://huggingface.co/spaces/adept/fuyu-8b-demo \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2ac103c6-a7f8-447c-9cd2-f4e0643fcc80)
* 132、AI实时解读大脑信号，7倍速还原图像关键视觉特征，LeCun转发  量子位  https://mp.weixin.qq.com/s/X5aJ_vdVFMUPYD9fzPgKGA \
  AI读脑成真，延迟仅0.25秒！Meta里程碑新研究：MEG实时解码大脑图像，LeCun转赞  新智元  https://mp.weixin.qq.com/s/s9aOjj3TPr5MwD1B57FUWw \
  AI实时解读大脑信号，7倍速还原图像关键视觉特征，LeCun转发  脑机接口社区  https://mp.weixin.qq.com/s/4HFlcLYDKYFGAa5S2R2Jzg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ad9c3697-844a-41f2-9a5a-70d883707f68) \
  论文地址：https://ai.meta.com/static-resource/image-decoding
* 133、人手一个编程助手！北大最强代码大模型CodeShell-7B开源，性能霸榜，IDE插件全开源  新智元  https://mp.weixin.qq.com/s/lLKGDdslHgWhf6Skb-wldg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7452efb3-f803-456c-96be-37aa5b3deff9) \
  CodeShell代码：https://github.com/WisdomShell/codeshell \
  CodeShell基座模型：https://huggingface.co/WisdomShell/CodeShell-7B \
  代码助手VSCode插件：https://github.com/WisdomShell/codeshell-vscode

# 10.20 周五
* 134、ChatGPT可以使用DALL·E 3啦！OpenAI还开放了论文  AIGC开放社区  https://mp.weixin.qq.com/s/RKXEjoc5en7e21XsGsjrrA \
  OpenAI终于Open一回：DALL-E 3论文公布、上线ChatGPT，作者一半是华人  机器之心  https://mp.weixin.qq.com/s/xLvJXe2FDL8YdByZLHjGMQ \
  DALL·E 3关键技术公开！19页论文揭秘如何对提示词“唯命是从”  量子位  https://mp.weixin.qq.com/s/dn1DwlOXtMM7GBa41lyGIw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8eb6e0ac-2df9-4ae0-adae-1e6be5e2229e) \
  DALL·E 3论文地址：https://cdn.openai.com/papers/dall-e-3.pdf \
  DALL·E 3系统卡：https://openai.com/research/dall-e-3-system-card
* 135、在RTX 4090被限制的时代下，让大模型使用RLHF更高效的方法来了  机器之心  https://mp.weixin.qq.com/s/3I0kOE1FprOeXSEERVVBIQ \
  该论文介绍了一种名为 ReMax 的新算法，专为基于人类反馈的强化学习（RLHF）而设计。ReMax 在计算效率（约减少 50% 的 GPU 内存和 2 倍的训练速度提升）和实现简易性（6 行代码）上超越了最常用的算法 PPO，且性能没有损失。\
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9a506942-e421-4f10-9a5f-8debd1691108) \
  论文链接：https://arxiv.org/abs/2310.10505 \
  开源代码：https://github.com/liziniu/ReMax
* 136、提示工程夭折？MIT斯坦福让大模型主动提问，自己搞明白你想要什么  量子位  https://mp.weixin.qq.com/s/mx9DnFVT5Wio9anBk5PVSw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1813f5c2-51f6-4efd-8d20-02ccb2e839e1) \
  论文地址：https://arxiv.org/abs/2310.11589
* 137、(**具身智能，可以看看**)ICCV 2023 | 面向视觉-语言导航的实体-标志物对齐自适应预训练方法  paperweekly  https://mp.weixin.qq.com/s/t1sbE_lhIiWULacRQB8Lzg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4d45eea0-451d-4b2a-9d29-6a1059859d92) \
  论文地址：https://arxiv.org/abs/2308.12587 \
  代码地址：https://github.com/csir1996/vln-gela
* 138、(**重要，务必看看**)MIT惊人再证大语言模型是世界模型！LLM能分清真理和谎言，还能被人类洗脑  新智元  https://mp.weixin.qq.com/s/AqPWbzk9lD6vFPZLbutpIw \
  MIT等学者的「世界模型」第二弹来了！这次，他们证明了LLM能够分清真话和假话，而通过「脑神经手术」，人类甚至还能给LLM打上思想钢印，改变它的信念。\
  MIT惊人再证大语言模型是世界模型！LLM能分清真理和谎言，还能被人类洗脑  机器学习研究组订阅  https://mp.weixin.qq.com/s/EH2dWmrWTm-WYx9CeCpQeA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/41a8a80e-8e35-4234-b442-b37f8723f043) \ 
  论文地址：https://arxiv.org/abs/2310.06824
  
# 10.21 周六
* 139、(**机器人相关，可以看看**)有了GPT-4之后，机器人把转笔、盘核桃都学会了  机器之心  https://mp.weixin.qq.com/s/Ohhkdbcd8Y_CK6EV7TyTSA \
  ChatGPT自动训练实体机器人动作指令！代码水平达到人类专家级  AIGC开放社区  https://mp.weixin.qq.com/s/mPq_gVloZCEKAAmlOC9JwA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b034066b-e465-4ed8-b1d0-7effe32a6f9b) \
  论文链接：https://arxiv.org/pdf/2310.12931.pdf \
  项目链接：https://eureka-research.github.io/ \
  代码链接：https://github.com/eureka-research/Eureka
* 140、(**怎么做到的，可以看看**)LLaMA2上下文长度暴涨至100万tokens，只需调整1个超参数｜复旦邱锡鹏团队出品  量子位  https://mp.weixin.qq.com/s/572q79xv90KdBOpgB3Bl-g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0cc183a8-c853-466b-9ee2-e74ba9432451) \
  论文地址：https://arxiv.org/abs/2310.05209 \
  Github仓库：https://github.com/OpenLMLab/scaling-rope \
  论文解析博客：https://zhuanlan.zhihu.com/p/660073229
* 141、推特爆火！超越ChatGPT和Llama2，新一代检索增强方法Self-RAG来了  夕小瑶科技说  https://mp.weixin.qq.com/s/kRY5o_KJnNfPhmw_attaIg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/bccbb55d-374b-4cfe-ac45-b97cd8c67899) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/46206f99-28cf-4c80-9def-18f5df608983) \
  论文链接：https://arxiv.org/abs/2310.11511 \
  项目主页：https://selfrag.github.io/
* 142、(**可以玩一玩**)AgentLM：能打的 Agent 模型来了！7B，13B，70B 全开源  GLM大模型  https://mp.weixin.qq.com/s/CMyY39qbbMNPww610dWlkA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a1b11a3b-8fc9-49af-8139-be196dbb2889) 
* 143、如何做出顶级AI研究？OpenAI科学家Jason Wei《AI研究思考》演讲，讲述杰出与普通研究之差别  专知  https://mp.weixin.qq.com/s/DAxXsvDUvgtCZRLTqQ0GEw 

# 10.22 周日
* 144、特定任务上下文解耦用于目标检测（Chat-GPT协助完成）  计算机视觉研究院  https://mp.weixin.qq.com/s/sXmeIY8ybAaGyQdXOrx0LA 
* 145、无需标注海量数据，目标检测新范式OVD让多模态AGI又前进一步  计算机视觉研究院  https://mp.weixin.qq.com/s/6Ixs65uG6_GPIV2F8LFnbA
* 146、(**可以看看，Eureka**)ChatGPT自动训练实体机器人动作指令！代码水平达到人类专家级  AIGC开放社区  https://mp.weixin.qq.com/s/mPq_gVloZCEKAAmlOC9JwA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/debb8cc5-592a-46a7-bc4b-62d0560404d3)
  开源地址：https://github.com/eureka-research/Eureka \
  论文：https://arxiv.org/abs/2310.12931
* 147、(**重要，值得看看**)MIT又有新发现！大型语言模型(LLMs)竟然可被「洗脑」，GPT-4 并不能理解真实世界  AINLPer  https://mp.weixin.qq.com/s/vgadcRvqCFZRnSEyx_svpA \
  MIT等学者的「世界模型」第二弹来了！这次，他们证明了LLM能够分清真话和假话，而通过「脑神经手术」，人类甚至还能给LLM打上思想钢印，改变它的信念。\
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/99aa3f38-d969-4b54-8651-d851e46d8f67) \
  论文地址：https://arxiv.org/abs/2310.06824

# 10.23 周一
* 148、(**重要，值得看看SoM**)在视觉提示中加入「标记」，微软等让GPT-4V看的更准、分的更细  机器之心  https://mp.weixin.qq.com/s/cypVddu28iApKZ9YOEiyxQ \
  GPT-4V (ision) 由于出色的多模态感知和推理能力得到了大家格外的关注。然而，尽管 GPT-4V 具有前所未有的视觉语言理解能力，但其细粒度 visual grounding（输入是图片和对应的物体描述，输出是描述物体的 box）能力相对较弱，或者尚未发挥出来。\
  来自微软、香港科技大学等机构的研究者提出了一种新的视觉 prompt 方法 Set-of-Mark（SoM），来解决 GPT-4V 在细粒度视觉任务上的问题。\
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/63bb2306-d8bb-4a5b-b5b4-897fbf2b9200) \
  论文地址：https://arxiv.org/pdf/2310.11441.pdf \
  论文主页：https://som-gpt4v.github.io/
* 149、(**重要，值得实践，AgentTuning**)大幅提升大模型的通用智能体能力！清华最新研究，让Llama2直逼GPT-4？  夕小瑶科技说  https://mp.weixin.qq.com/s/tTioa55oMZXyk7e6QilYWA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6b17a6c2-e837-46df-89c9-20a56893c1b7) \
  论文题目:AgentTuning: Enabling Generalized Agent Abilities for LLMs \
  论文链接:https://arxiv.org/abs/2310.12823 \
  GitHub 地址:https://github.com/THUDM/AgentTuning \
  AgentLM 链接:https://huggingface.co/THUDM/agentlm-70b
* 150、(**Habitat 3.0，了解了解**)LeCun墙裂推荐！Meta发布最新AI智能体，贾维斯是你来了吗！  夕小瑶科技说  https://mp.weixin.qq.com/s/7htqyec53YBXGDHaoLIRug \
  Meta发布了Habitat 3.0，这是一款最高质量的模拟器，其允许在类似家庭等环境中进行人机协作。\
  Habitat 3.0引入了具有感知能力、可以与环境互动的AI智能体，这些智能体可以与人类合作，并在共享环境中安全地协同工作。研究人员表示，这只是他们宏远计划的第一步，他们的最终目标是开发全天佩戴的增强现实（AR）眼镜，可在日常生活中为人类提供协助。\
  官方博客：https://ai.meta.com/blog/habitat-3-socially-intelligent-robots-siro/?continueFlag=af62ed3ae2b36a11b0e8f501867a4e83
* 151、(**比较重要，研究一下**)Meta普林斯顿提出LLM上下文终极解决方案！让模型化身自主智能体，自行读取上下文节点树  新智元  https://mp.weixin.qq.com/s/1NVYtTgyijr2hiQ73KdXLQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c00a4c78-78ab-4e9c-8b46-ff0b3e9b0b0c) \
  论文地址：https://arxiv.org/abs/2310.05029

# 10.24 周二
* 152、科学能解释自由意志吗？  集智俱乐部  https://mp.weixin.qq.com/s/-pEYqxhLhfZWKagFkrD2Vg
* 153、(**重要，值得看看**)LeCun和xAI联创对呛，GPT-4重大推理缺陷无解？网友：人类也是「随机鹦鹉」  新智元  https://mp.weixin.qq.com/s/XVgs_lJfHL83gmDKQJRJxw \
  LeCun又双叒唱衰自回归LLM：GPT-4的推理能力非常有限，有两篇论文为证  机器之心  https://mp.weixin.qq.com/s/osHH3wkPvSw2eZvNQO8Pzg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/40dc5f0e-73bf-486e-8473-2e4368a7e304) \
  也许在不久的将来，我们将能看到xAI抓住LLM推理能力弱的「痛点」，穷追猛打，打造出一个「强推理」的大模型，弥补了像ChatGPT等市面上一干大模型产品的最大缺陷。 \
  LeCun：说多少次了，LLM就是不行！  LLM怎么就不行了？？？ 在很多能力上号称达到和超越人类水平的LLM，在推理和规划能力上有重大缺陷 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a80453c4-e0ff-46b0-96a2-004edbfc6f64)
  论文地址：https://arxiv.org/pdf/2310.12397.pdf \
  论文地址：https://arxiv.org/abs/2310.08118

# 10.25 周三
* 154、(****)

# 10.23 周一
# 10.24 周二
# 10.25 周三
# 10.26 周四
# 10.27 周五
# 10.28 周六
# 10.29 周日
# 10.30 周一
# 10.31 周二
