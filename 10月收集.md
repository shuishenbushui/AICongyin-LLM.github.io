# 10.1 周日
* 1、(**值得看看**)走向最小统一意识模型  图灵人工智能  https://mp.weixin.qq.com/s/RexTiOr7F-w45uQZCNlG8g \
  走向最小统一意识模型的步骤：基于自由能原理的意识模型的整合 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/86042724-e5ba-49e4-8bdc-292ce6d470f5) \
* 2、《深度模型融合》综述   专知  https://mp.weixin.qq.com/s/2-ZOAi2qzpWcAjktgaPJOw\
  深度模型融合/合并是一种新兴的技术，它将多个深度学习模型的参数或预测合并成一个。它结合了不同模型的能力，以补偿单一模型的偏差和错误，以实现更好的性能。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/beee0a0d-0c2a-4978-a8ac-7074dcbd9f52) \
* 3、接入大模型的眼睛：一文纵览多模态指令  专知  https://mp.weixin.qq.com/s/99pcSgcOjue9C5pGvj7Taw \
  当前的多模态大模型往往通过给大模型添加一个视觉模块，再通过多模态指令微调来进行两个模型的对齐。这之中，多模态指令微调至关重要。本文将从相关论文出发，梳理当前用于指令微调的多模态指令集，从收集方法，复杂度与指令侧重点来介绍它们。
* 4、Transformer+强化学习，谷歌DeepMind让大模型成为机器人感知世界的大脑  脑机接口社区  https://mp.weixin.qq.com/s/h8Aj5Ua7piSIMY1ar64efw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4de1108a-1884-480e-8067-1c5e3ffeef02) \
  论文：https://q-transformer.github.io/assets/q-transformer.pdf \
  项目：https://q-transformer.github.io/ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/575898a1-c2eb-4b83-898f-32a17032a81e)
* 5、ICLR 2023 | 神经规范场: 渲染引导空间规范变换  CVHub  https://mp.weixin.qq.com/s/Z31wFDdULBOcoACfQxsVKA \
  近期，神经场（Neural Fields）领域的巨大进展，已经显著推动了神经场景表示和神经渲染的发展。为了提高3D场景的计算效率和渲染质量，一个常见的范式是将3D坐标系统映射到另一种测量系统，例如2D流形和哈希表，以建模神经场。 \
  论文：https://arxiv.org/abs/2305.03462 \
  源码：https://github.com/fnzhan/Neural-Gauge-Fields \
  项目：https://fnzhan.com/Neural-Gauge-Fields/
* 6、（**值得看看**）别用GPT-4直出文本摘要！MIT、哥大等发布全新「密度链」提示：实体密度是摘要质量的关键  新智元  https://mp.weixin.qq.com/s/SklBTf_jegeYfRuCNc04YA \
  CoD（Chain of Dense）密度链 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7934fe34-2561-452e-b6d8-fcc841b7f62a) \
  论文链接：https://arxiv.org/pdf/2309.04269.pdf \
  开源数据：https://huggingface.co/datasets/griffin/chain_of_density
* 7、(**可以玩一玩**)以3D视角洞悉矩阵乘法，这就是AI思考的样子  机器之心  https://mp.weixin.qq.com/s/HRcjGjj83o3eVO6-AeGb2w \
  工具地址：https://bhosmer.github.io/mm/ref.html \
  博客原文：https://pytorch.org/blog/inside-the-matrix \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e2af8c80-64a1-488b-9e16-26a1f6a33fdc) \
* 8、(**重要，值得看看**)语言模型有重大缺陷，知识推演竟然是老大难  机器之心  https://mp.weixin.qq.com/s/ZV1_N5w0E2W07zPmCMW5yw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e331c636-6f7b-4578-9f77-9957446c203a) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/63ff7dea-1d96-4006-be27-3bd7f92c4e7f) \
  论文地址：https://arxiv.org/abs/2309.14402
* 9、不装电池也能「自动驾驶」，这个机器人还能无限续航 | 华盛顿大学  量子位  https://mp.weixin.qq.com/s/NXfo2C-60luLdR0EopB7-Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2158af17-e681-45f9-ab7b-c01e3cd1aa05) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b2da28dd-d715-44f5-900c-0a1d979f8b29) \
  参考链接： \
  [1]https://www.washington.edu/news/2023/09/27/millimobile-battery-free-autonomous-self-driving-robot-solar/ \
  [2]论文地址：https://homes.cs.washington.edu/~vsiyer/Papers/millimobile-compressed.pdf \
* 10、选用哪个GPT？华中科大等最新《大型GPT模型》综述，37页pdf详述关于语言、多模态及科学GPT模型  专知  https://mp.weixin.qq.com/s/333ph-SgSVN8qci05TS9Iw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d37ecdd2-a600-4706-a729-998b8dceee38)
* 11、什么是涌现？人工智能给你答案  集智俱乐部  https://mp.weixin.qq.com/s/PmLu2gqDL9Udrf0DCobxjw

# 10.2 周一
* 12、(**重要，看看**)吴恩达力赞！哈佛、MIT学者用下棋证明：大型语言模型确实「理解」了世界  脑机接口社区  https://mp.weixin.qq.com/s/T1g-1bNxvaiURiZLvcetMw \
  吴恩达相信LLM能够构建出足够复杂的世界模型，理解了这个世界 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a01279c8-ccb2-42ed-9b9f-59786c9c70a5) \
  论文链接：https://arxiv.org/pdf/2210.13382.pdf \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0976bb1d-ed67-4885-99d5-166db10430f2) \
  博客链接：https://www.deeplearning.ai/the-batch/does-ai-understand-the-world/ \
* 13、（**值得看看**）Chinchilla之死：只要训练足够长时间，小模型也能超过大模型  机器之心  https://mp.weixin.qq.com/s/Rx-6odhz1ap1fNEZJw8o_w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/630d3c74-babe-4125-95db-f9da10d88fd8) \
* 14、(**值得看看**)20多种意识理论哪个才是主导？五年了，还没有赢家  机器之心  https://mp.weixin.qq.com/s/ktm93pDX9xCG2WkKAKmi1Q \
* 15、如何评估大语言模型是否可信？这里总结了七大维度  机器之心  https://mp.weixin.qq.com/s/HTbr7aOVuJoeqbYCpY-kTA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/10abbacd-fa90-41a8-a3bd-5633ba3f61db) \
  论文地址：https://arxiv.org/abs/2308.05374 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/65037a94-60b3-4454-ba67-4fa46671e89f) 

# 10.3 周二
* 16、IBM量子计算最新进展：量子计算的chatGPT时刻即将来临？  图灵人工智能  https://mp.weixin.qq.com/s/GnwHw1fzMh0_Zp5gWXDG1Q
* 17、（**miniGPT-4值得研究**）MiniGPT-4：使用先进的大型语言模型提升 AI 视觉语言理解能力  专知  https://mp.weixin.qq.com/s/EY84dwiTCkO2M8DmSJs2xA
* 18、（**GPT-4V**）试过GPT-4V后，微软写了个166页的测评报告，业内人士：高级用户必读  机器之心  https://mp.weixin.qq.com/s/8FtR6JcEFVcRLWCaANXQ6g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4223f388-4421-4a82-bdd6-24cbc3f8d849) \
  报告地址：https://arxiv.org/pdf/2309.17421.pdf 
* 19、从观察、思考到行动，深度强化学习大牛Pieter Abbeel谈如何驯服机器人  机器之心  https://mp.weixin.qq.com/s/vEZAkF_TtbZIoulEBxStNQ
* 20、将LLaMA2上下文扩展至100k，MIT、港中文有了LongLoRA方法  机器之心  https://mp.weixin.qq.com/s/NeAPOblAOhzURy3XDVFV1Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ca456f3f-2a48-47d0-b4a6-d4b802bc9838) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1311f057-4f02-444e-89ee-1a45a534b144) \
  论文地址：https://arxiv.org/pdf/2309.12307.pdf \
  项目地址：https://github.com/dvlab-research/LongLoRA
* 21、(**看看怎么回事儿**)清华、微软等淘汰提示工程师？LLM与进化算法结合，创造超强提示优化器  机器学习研究组订阅  https://mp.weixin.qq.com/s/fCp856ON1YerIp4yhSEHDg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1a402a69-0ffa-4075-ae54-fecc800fdb42) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/38b8cd87-4c51-4036-affa-bb09e6d8c726) \
  论文地址：https://arxiv.org/pdf/2309.08532
* 22、DeepMind创始人：生成式AI只是过渡，AI未来将获得自由，交互式AI将改变人类  新智元  https://mp.weixin.qq.com/s/ICspZRixQ6nG5teJzPgdzQ \
  现阶段的生成式AI只是一个技术阶段，接下来会进入交互式AI的时代：AI将会成为能够根据每个用户的不同任务需求去调用其他软件和人来完成工作的机器人。
* 23、NeurIPS 2023 Spotlight｜高质量多视角图像生成，完美复刻场景材质！SFU等提出MVDiffusion  新智元  https://mp.weixin.qq.com/s/6fFfvKvAA9_zrxZIrYuerA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7454fa49-5a06-479b-8e33-a6371fafe885) \
  论文链接：https://arxiv.org/abs/2307.01097 \
  项目网站：https://mvdiffusion.github.io/ \
  Demo: https://huggingface.co/spaces/tangshitao/MVDiffusion \
  代码：https://github.com/Tangshitao/MVDiffusion \
  发表会议：NeurIPS（spotlight）
* 24、(**值得研究**)纽大具身智能新进展：靠视觉反馈学会开罐头，任务成功率提高135%，LeCun点赞  量子位  https://mp.weixin.qq.com/s/mPWanq2QrNNcCglkGj-leA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ede66bc9-5c68-4561-b498-0a62c6b7eeaa) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/533588bc-9273-4e0f-afe0-6e93710f1c5f) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/169c2169-c213-4bc6-a7fd-33375f1d6a49) \
  论文地址：https://arxiv.org/abs/2309.12300 \
  GitHub项目页：https://github.com/irmakguzey/see-to-touch \
* 25、大脑不对称性的起源：任务复杂性打破神经网络镜像对称性  集智俱乐部  https://mp.weixin.qq.com/s/8BVt61NgiJA1hhwRXP8j8Q \
  动物大脑的神经网络在一定程度上是镜像对称的，不对称性被认为在认知能力更强的物种中更为常见。这个假设源于一个长期存在的理论，即神经任务不断增加的复杂性，可以将镜像对称的神经回路转化为仅存在于大脑一侧的回路。
* 26、(**值得研究**)通院机器人实验室研究成果发表在IJCV 2022，构建机器人场景感知与任务规划的桥梁  北京通用人工智能研究院  https://mp.weixin.qq.com/s/kMw7iFZd6qt7LaAQSFw8Mw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8002754e-253b-43fe-ab80-8f88e05d2403) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ed1ab5b8-2ab1-45d9-ab42-f60935546633) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0ad1a054-857e-402b-a88e-cf0a51e00c8e) \
  论文链接：https://link.springer.com/article/10.1007/s11263-022-01670-0 \
  代码：https://github.com/hmz-15/Interactive-Scene-Reconstruction
* 27、通院机器人实验室IROS 2022研究成果介绍：利用物理常识驱动机器人使用工具  北京通用人工智能研究院  https://mp.weixin.qq.com/s/XF16lWZkplJ_yZ7V7ox3JQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6cfafdb5-e5d8-43c8-9d66-28acad502d61) \
  论文链接：https://ieeexplore.ieee.org/document/9832465 
* 28、(**可以看看**)朱松纯团队研究成果登上Science头条！为机器立“心”、实现通用AI迈出重要一步  北京通用人工智能研究院  https://mp.weixin.qq.com/s/0ZvpcHt8NRBjVw5KWfyMDA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9511bace-67df-4ba9-99cf-af2ec97717e5) \
  论文地址：https://www.science.org/doi/10.1126/scirobotics.abm4183

# 10.4 周三
* 29、(**可以看看怎么回事儿**)词表的选择如何影响语言模型训练？这可能是目前见过最好的词表选择研究  机器之心  https://mp.weixin.qq.com/s/EeD_sk2fSX-_YKsHVa_4Lg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d6693cfb-b8df-42c7-bca0-c8f1d9ba1aad)
* 30、数学家孜孜以求的数学证明本质是一种社会契约，为什么这么说？  机器之心  https://mp.weixin.qq.com/s/oJ3UNUtycg0-vfsa7I94kA
* 31、(**非常重要，仔细研究**)机器人研究迎来ImageNet时刻：一个数据集，让DeepMind具身智能大模型突飞猛进  机器之心  https://mp.weixin.qq.com/s/k3iXMZtdtzoP8ZuA5_Htww \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/73951d37-d56c-407e-9230-2d351a2939f4) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6c81c3ee-8e9d-4b56-b0bb-d7f2d2746082) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b4e26402-a3c4-4e25-b629-08da2f00dcba) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5d97aa00-16c1-42d2-9d03-37027d3b8875) \
  参考链接：https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types \
  论文链接：https://robotics-transformer-x.github.io/paper.pdf \
  项目链接：https://robotics-transformer-x.github.io/
* 32、(**重要，研究研究**)背诵不等于理解，深度解析大模型背后的知识储存与提取  机器之心  https://mp.weixin.qq.com/s/iYuykb8HnqhmUe9ZRm2H-g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c4c048bc-6de7-43ae-958e-9248f901f5da) \
  论文地址：https://arxiv.org/pdf/2309.14316.pdf
* 33、（**不错的教程，值得收藏**）llm-action：让天下没有难学的大模型  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/u6StD4IaJ7KuwTsNUaprMA \
  吃果冻不吐果冻皮：今年陆陆续续也写了不少关于大模型的文章，为了方便查看，均梳理了并放置在Github上面: https://github.com/liguodongiot/llm-action \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a0f75c39-3cfa-4963-bad6-3a823e703221)
* 34、【2023新书】决策智能手册：在复杂世界中基于证据做出决策的实用步骤, 270页pdf  专知  https://mp.weixin.qq.com/s/8StCl0zXIumzGoUrFc4DUQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2cb7cad4-2676-44fd-8d77-1175718bb2d9) \
* 35、(**获奖论文值得看看，学习一下**)ICCV2023奖项出炉！斯坦福ControlNet和多伦多大学分别获得最佳论文！Segment Anything最佳提名  专知  https://mp.weixin.qq.com/s/4ayiCpL3nSYTilURfrDwCg \
  Adding Conditional Control to Text-to-Image Diffusion Models \
  tracking everything everywhere all at once \
  segment anything \
* 36、400万token，大模型推理飙升22倍！清华校友爆火一作，GitHub狂揽1.8k星  新智元  https://mp.weixin.qq.com/s/Xjvg_ifh5lPkoQ2gkhY2BQ \
  Meta、MIT、CMU的研究者最近刚刚发表了一篇论文，提出了一种被称为是「高效流式语言模型」（Efficient Streaming Language Models，ESLM）的方法，可以让有限上下文能力的语言模型能够支持几乎无限的上下文窗口。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b54620af-b7dd-4dd1-af20-75dd18176ad6) \
  https://arxiv.org/pdf/2309.17453.pdf

# 10.5 周四
# 10.6 周五
# 10.7 周六
# 10.8 周日
# 10.9 周一
# 10.10 周二
# 10.11 周三
# 10.12 周四
# 10.13 周五
# 10.14 周六
# 10.15 周日
# 10.16 周一
# 10.17 周二
# 10.18 周三
# 10.19 周四
# 10.20 周五
# 10.21 周六
# 10.22 周日
# 10.23 周一
# 10.24 周二
# 10.25 周三
# 10.26 周四
# 10.27 周五
# 10.28 周六
# 10.29 周日
# 10.30 周一
# 10.31 周二
