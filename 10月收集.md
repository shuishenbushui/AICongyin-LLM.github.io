# 10.1 周日
* 1、(**值得看看**)走向最小统一意识模型  图灵人工智能  https://mp.weixin.qq.com/s/RexTiOr7F-w45uQZCNlG8g \
  走向最小统一意识模型的步骤：基于自由能原理的意识模型的整合 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/86042724-e5ba-49e4-8bdc-292ce6d470f5) \
* 2、《深度模型融合》综述   专知  https://mp.weixin.qq.com/s/2-ZOAi2qzpWcAjktgaPJOw\
  深度模型融合/合并是一种新兴的技术，它将多个深度学习模型的参数或预测合并成一个。它结合了不同模型的能力，以补偿单一模型的偏差和错误，以实现更好的性能。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/beee0a0d-0c2a-4978-a8ac-7074dcbd9f52) \
* 3、接入大模型的眼睛：一文纵览多模态指令  专知  https://mp.weixin.qq.com/s/99pcSgcOjue9C5pGvj7Taw \
  当前的多模态大模型往往通过给大模型添加一个视觉模块，再通过多模态指令微调来进行两个模型的对齐。这之中，多模态指令微调至关重要。本文将从相关论文出发，梳理当前用于指令微调的多模态指令集，从收集方法，复杂度与指令侧重点来介绍它们。
* 4、Transformer+强化学习，谷歌DeepMind让大模型成为机器人感知世界的大脑  脑机接口社区  https://mp.weixin.qq.com/s/h8Aj5Ua7piSIMY1ar64efw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4de1108a-1884-480e-8067-1c5e3ffeef02) \
  论文：https://q-transformer.github.io/assets/q-transformer.pdf \
  项目：https://q-transformer.github.io/ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/575898a1-c2eb-4b83-898f-32a17032a81e)
* 5、ICLR 2023 | 神经规范场: 渲染引导空间规范变换  CVHub  https://mp.weixin.qq.com/s/Z31wFDdULBOcoACfQxsVKA \
  近期，神经场（Neural Fields）领域的巨大进展，已经显著推动了神经场景表示和神经渲染的发展。为了提高3D场景的计算效率和渲染质量，一个常见的范式是将3D坐标系统映射到另一种测量系统，例如2D流形和哈希表，以建模神经场。 \
  论文：https://arxiv.org/abs/2305.03462 \
  源码：https://github.com/fnzhan/Neural-Gauge-Fields \
  项目：https://fnzhan.com/Neural-Gauge-Fields/
* 6、（**值得看看**）别用GPT-4直出文本摘要！MIT、哥大等发布全新「密度链」提示：实体密度是摘要质量的关键  新智元  https://mp.weixin.qq.com/s/SklBTf_jegeYfRuCNc04YA \
  CoD（Chain of Dense）密度链 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7934fe34-2561-452e-b6d8-fcc841b7f62a) \
  论文链接：https://arxiv.org/pdf/2309.04269.pdf \
  开源数据：https://huggingface.co/datasets/griffin/chain_of_density
* 7、(**可以玩一玩**)以3D视角洞悉矩阵乘法，这就是AI思考的样子  机器之心  https://mp.weixin.qq.com/s/HRcjGjj83o3eVO6-AeGb2w \
  工具地址：https://bhosmer.github.io/mm/ref.html \
  博客原文：https://pytorch.org/blog/inside-the-matrix \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e2af8c80-64a1-488b-9e16-26a1f6a33fdc) \
* 8、(**重要，值得看看**)语言模型有重大缺陷，知识推演竟然是老大难  机器之心  https://mp.weixin.qq.com/s/ZV1_N5w0E2W07zPmCMW5yw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e331c636-6f7b-4578-9f77-9957446c203a) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/63ff7dea-1d96-4006-be27-3bd7f92c4e7f) \
  论文地址：https://arxiv.org/abs/2309.14402
* 9、不装电池也能「自动驾驶」，这个机器人还能无限续航 | 华盛顿大学  量子位  https://mp.weixin.qq.com/s/NXfo2C-60luLdR0EopB7-Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2158af17-e681-45f9-ab7b-c01e3cd1aa05) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b2da28dd-d715-44f5-900c-0a1d979f8b29) \
  参考链接： \
  [1]https://www.washington.edu/news/2023/09/27/millimobile-battery-free-autonomous-self-driving-robot-solar/ \
  [2]论文地址：https://homes.cs.washington.edu/~vsiyer/Papers/millimobile-compressed.pdf \
* 10、选用哪个？华中科大等最新《大型GPT模型》综述，37页pdf详述关于语言、多模态及科学GPT模型  专知  https://mp.weixin.qq.com/s/333ph-SgSVN8qci05TS9Iw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d37ecdd2-a600-4706-a729-998b8dceee38)
* 11、什么是涌现？人工智能给你答案  集智俱乐部  https://mp.weixin.qq.com/s/PmLu2gqDL9Udrf0DCobxjw

# 10.2 周一
* 12、(**重要，看看**)吴恩达力赞！哈佛、MIT学者用下棋证明：大型语言模型确实「理解」了世界  脑机接口社区  https://mp.weixin.qq.com/s/T1g-1bNxvaiURiZLvcetMw \
  MIT惊人证明：大语言模型就是「世界模型」？吴恩达观点再被证实，LLM竟能理解空间和时间  新智元  https://mp.weixin.qq.com/s/9OcaKA6WeniXVvopGSn22A \
  吴恩达相信LLM能够构建出足够复杂的世界模型，理解了这个世界 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a01279c8-ccb2-42ed-9b9f-59786c9c70a5) \
  论文链接：https://arxiv.org/pdf/2210.13382.pdf \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0976bb1d-ed67-4885-99d5-166db10430f2) \
  博客链接：https://www.deeplearning.ai/the-batch/does-ai-understand-the-world/ \
* 13、（**值得看看**）Chinchilla之死：只要训练足够长时间，小模型也能超过大模型  机器之心  https://mp.weixin.qq.com/s/Rx-6odhz1ap1fNEZJw8o_w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/630d3c74-babe-4125-95db-f9da10d88fd8) \
* 14、(**值得看看**)20多种意识理论哪个才是主导？五年了，还没有赢家  机器之心  https://mp.weixin.qq.com/s/ktm93pDX9xCG2WkKAKmi1Q \
* 15、如何评估大语言模型是否可信？这里总结了七大维度  机器之心  https://mp.weixin.qq.com/s/HTbr7aOVuJoeqbYCpY-kTA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/10abbacd-fa90-41a8-a3bd-5633ba3f61db) \
  论文地址：https://arxiv.org/abs/2308.05374 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/65037a94-60b3-4454-ba67-4fa46671e89f) 

# 10.3 周二
* 16、IBM量子计算最新进展：量子计算的chatGPT时刻即将来临？  图灵人工智能  https://mp.weixin.qq.com/s/GnwHw1fzMh0_Zp5gWXDG1Q
* 17、（**miniGPT-4值得研究**）MiniGPT-4：使用先进的大型语言模型提升 AI 视觉语言理解能力  专知  https://mp.weixin.qq.com/s/EY84dwiTCkO2M8DmSJs2xA
* 18、（**GPT-4V**）试过GPT-4V后，微软写了个166页的测评报告，业内人士：高级用户必读  机器之心  https://mp.weixin.qq.com/s/8FtR6JcEFVcRLWCaANXQ6g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4223f388-4421-4a82-bdd6-24cbc3f8d849) \
  报告地址：https://arxiv.org/pdf/2309.17421.pdf 
* 19、从观察、思考到行动，深度强化学习大牛Pieter Abbeel谈如何驯服机器人  机器之心  https://mp.weixin.qq.com/s/vEZAkF_TtbZIoulEBxStNQ
* 20、将LLaMA2上下文扩展至100k，MIT、港中文有了LongLoRA方法  机器之心  https://mp.weixin.qq.com/s/NeAPOblAOhzURy3XDVFV1Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ca456f3f-2a48-47d0-b4a6-d4b802bc9838) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1311f057-4f02-444e-89ee-1a45a534b144) \
  论文地址：https://arxiv.org/pdf/2309.12307.pdf \
  项目地址：https://github.com/dvlab-research/LongLoRA
* 21、(**看看怎么回事儿**)清华、微软等淘汰提示工程师？LLM与进化算法结合，创造超强提示优化器  机器学习研究组订阅  https://mp.weixin.qq.com/s/fCp856ON1YerIp4yhSEHDg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1a402a69-0ffa-4075-ae54-fecc800fdb42) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/38b8cd87-4c51-4036-affa-bb09e6d8c726) \
  论文地址：https://arxiv.org/pdf/2309.08532
* 22、DeepMind创始人：生成式AI只是过渡，AI未来将获得自由，交互式AI将改变人类  新智元  https://mp.weixin.qq.com/s/ICspZRixQ6nG5teJzPgdzQ \
  现阶段的生成式AI只是一个技术阶段，接下来会进入交互式AI的时代：AI将会成为能够根据每个用户的不同任务需求去调用其他软件和人来完成工作的机器人。
* 23、NeurIPS 2023 Spotlight｜高质量多视角图像生成，完美复刻场景材质！SFU等提出MVDiffusion  新智元  https://mp.weixin.qq.com/s/6fFfvKvAA9_zrxZIrYuerA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7454fa49-5a06-479b-8e33-a6371fafe885) \
  论文链接：https://arxiv.org/abs/2307.01097 \
  项目网站：https://mvdiffusion.github.io/ \
  Demo: https://huggingface.co/spaces/tangshitao/MVDiffusion \
  代码：https://github.com/Tangshitao/MVDiffusion \
  发表会议：NeurIPS（spotlight）
* 24、(**值得研究**)纽大具身智能新进展：靠视觉反馈学会开罐头，任务成功率提高135%，LeCun点赞  量子位  https://mp.weixin.qq.com/s/mPWanq2QrNNcCglkGj-leA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ede66bc9-5c68-4561-b498-0a62c6b7eeaa) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/533588bc-9273-4e0f-afe0-6e93710f1c5f) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/169c2169-c213-4bc6-a7fd-33375f1d6a49) \
  论文地址：https://arxiv.org/abs/2309.12300 \
  GitHub项目页：https://github.com/irmakguzey/see-to-touch \
* 25、大脑不对称性的起源：任务复杂性打破神经网络镜像对称性  集智俱乐部  https://mp.weixin.qq.com/s/8BVt61NgiJA1hhwRXP8j8Q \
  动物大脑的神经网络在一定程度上是镜像对称的，不对称性被认为在认知能力更强的物种中更为常见。这个假设源于一个长期存在的理论，即神经任务不断增加的复杂性，可以将镜像对称的神经回路转化为仅存在于大脑一侧的回路。
* 26、(**值得研究**)通院机器人实验室研究成果发表在IJCV 2022，构建机器人场景感知与任务规划的桥梁  北京通用人工智能研究院  https://mp.weixin.qq.com/s/kMw7iFZd6qt7LaAQSFw8Mw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8002754e-253b-43fe-ab80-8f88e05d2403) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ed1ab5b8-2ab1-45d9-ab42-f60935546633) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0ad1a054-857e-402b-a88e-cf0a51e00c8e) \
  论文链接：https://link.springer.com/article/10.1007/s11263-022-01670-0 \
  代码：https://github.com/hmz-15/Interactive-Scene-Reconstruction
* 27、通院机器人实验室IROS 2022研究成果介绍：利用物理常识驱动机器人使用工具  北京通用人工智能研究院  https://mp.weixin.qq.com/s/XF16lWZkplJ_yZ7V7ox3JQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6cfafdb5-e5d8-43c8-9d66-28acad502d61) \
  论文链接：https://ieeexplore.ieee.org/document/9832465 
* 28、(**可以看看**)朱松纯团队研究成果登上Science头条！为机器立“心”、实现通用AI迈出重要一步  北京通用人工智能研究院  https://mp.weixin.qq.com/s/0ZvpcHt8NRBjVw5KWfyMDA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9511bace-67df-4ba9-99cf-af2ec97717e5) \
  论文地址：https://www.science.org/doi/10.1126/scirobotics.abm4183

# 10.4 周三
* 29、(**可以看看怎么回事儿**)词表的选择如何影响语言模型训练？这可能是目前见过最好的词表选择研究  机器之心  https://mp.weixin.qq.com/s/EeD_sk2fSX-_YKsHVa_4Lg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d6693cfb-b8df-42c7-bca0-c8f1d9ba1aad)
* 30、数学家孜孜以求的数学证明本质是一种社会契约，为什么这么说？  机器之心  https://mp.weixin.qq.com/s/oJ3UNUtycg0-vfsa7I94kA
* 31、(**非常重要，仔细研究**)机器人研究迎来ImageNet时刻：一个数据集，让DeepMind具身智能大模型突飞猛进  机器之心  https://mp.weixin.qq.com/s/k3iXMZtdtzoP8ZuA5_Htww \
  DeepMind 全新 AI 项目曝光：可控制各类机器人，数据集有望开源 人机交互研究院  https://mp.weixin.qq.com/s/wl4k-mHAqWHIaH1OKKGKdQ \
  100多位作者！具身智能人进展！谷歌 DeepMind等机构推出《开放 X-实体化：机器人学习数据集与 RT-X 模型》论文  专知  https://mp.weixin.qq.com/s/RsyNU-U6SKwfkkVP50AhqA \
  RT-X、Open X-Embodiment, <Open X-Embodiment: Robotic Learning Datasets and RT-X Models> \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/73951d37-d56c-407e-9230-2d351a2939f4) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6c81c3ee-8e9d-4b56-b0bb-d7f2d2746082) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b4e26402-a3c4-4e25-b629-08da2f00dcba) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5d97aa00-16c1-42d2-9d03-37027d3b8875) \
  参考链接：https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types \
  论文链接：https://robotics-transformer-x.github.io/paper.pdf \
  项目链接：https://robotics-transformer-x.github.io/
* 32、(**重要，研究研究**)背诵不等于理解，深度解析大模型背后的知识储存与提取  机器之心  https://mp.weixin.qq.com/s/iYuykb8HnqhmUe9ZRm2H-g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c4c048bc-6de7-43ae-958e-9248f901f5da) \
  论文地址：https://arxiv.org/pdf/2309.14316.pdf
* 33、（**不错的教程，值得收藏**）llm-action：让天下没有难学的大模型  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/u6StD4IaJ7KuwTsNUaprMA \
  吃果冻不吐果冻皮：今年陆陆续续也写了不少关于大模型的文章，为了方便查看，均梳理了并放置在Github上面: https://github.com/liguodongiot/llm-action \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a0f75c39-3cfa-4963-bad6-3a823e703221)
* 34、【2023新书】决策智能手册：在复杂世界中基于证据做出决策的实用步骤, 270页pdf  专知  https://mp.weixin.qq.com/s/8StCl0zXIumzGoUrFc4DUQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2cb7cad4-2676-44fd-8d77-1175718bb2d9) \
* 35、(**获奖论文值得看看，学习一下**)ICCV2023奖项出炉！斯坦福ControlNet和多伦多大学分别获得最佳论文！Segment Anything最佳提名  专知  https://mp.weixin.qq.com/s/4ayiCpL3nSYTilURfrDwCg \
  Adding Conditional Control to Text-to-Image Diffusion Models \
  tracking everything everywhere all at once \
  segment anything \
* 36、400万token，大模型推理飙升22倍！清华校友爆火一作，GitHub狂揽1.8k星  新智元  https://mp.weixin.qq.com/s/Xjvg_ifh5lPkoQ2gkhY2BQ \
  最多400万token上下文、推理提速22倍，StreamingLLM火了，已获GitHub 2.5K星  机器之心  https://mp.weixin.qq.com/s/qIwYJAfD5bXJS6j0xtp2cw \
  Meta、MIT、CMU的研究者最近刚刚发表了一篇论文，提出了一种被称为是「高效流式语言模型」（Efficient Streaming Language Models，ESLM）的方法，可以让有限上下文能力的语言模型能够支持几乎无限的上下文窗口。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b54620af-b7dd-4dd1-af20-75dd18176ad6) \
  https://arxiv.org/pdf/2309.17453.pdf

# 10.5 周四
* 37、(**值得看看的课程，随便练习英语听力，熟悉人工智能术语**)斯坦福NLP课程XCS224U视频全部放出，干货满满，速来听讲  机器之心  https://mp.weixin.qq.com/s/KFrwkmI_lrH1E1fe7Q187g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/58265041-2eaa-4bff-9141-b7919a113b6e) \
  视频地址：https://www.youtube.com/playlist?list=PLoROMvodv4rOwvldxftJTmoR3kRcWkJBp
* 38、(**非常重要，进行研究**)谷歌推出全球最大通用大模型之一RT-X，并开放训练数据集！  AIGC开放社区  https://mp.weixin.qq.com/s/2472JCigL9RBxicWruJ5_g \
  模型和数据集地址：https://robotics-transformer-x.github.io/ \
  论文地址：https://robotics-transformer-x.github.io/paper.pdf 
* 39、(**立坤教授的演讲，非常值得看看**)Yann LeCun最新AI演讲《从机器学习到自主智能》，大模型不能规划，提出目标驱动AI，附视频与Slides  专知  https://mp.weixin.qq.com/s/I7XyftKGugfWqFF0niLW3A \
  机器如何能够像人类和动物一样高效地学习？机器如何能够学会推理和规划？机器如何能够学习感知和动作计划的多层次抽象表示，使它们能够在多个时间尺度上进行推理、预测和规划？ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/71909c49-fbae-49ac-8dd4-0da4e40c5d6c) 
* 40、(**看看讲了个啥**)【CMU博士论文】持续机器人学习:基准和模块化方法，125页pdf  专知  https://mp.weixin.qq.com/s/qZRbkX-KOAgb8zqkBFb_jQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c3e6efee-2302-4353-b472-247cc70f7bb4)

# 10.6 周五
* 41、(**重要，研究研究**)姚期智领衔提出大模型「思维」框架！逻辑推理正确率达98%，思考方式更像人类了  脑机接口社区  https://mp.weixin.qq.com/s/4AYbVFIWW96kAjcjH-0ndw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6698821d-7858-4838-8f2c-a7d8b6fa5cc6) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0fff46d6-4a0f-470a-a84e-6653d61e3e45) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ea2dc8b3-5dcf-482f-b745-f034882cd7c4) \
  论文链接：https://arxiv.org/abs/2308.04371 
* 42、(**看看怎么做到的**)如何降低视觉Transformer计算成本？时间冗余方法让人大吃一惊  机器之心  https://mp.weixin.qq.com/s/Qa_Fi7bmWWc04zz7NKoaQg \
  在为语言领域带来变革之后，Transformer 正在进军视觉领域，但其也有着高计算成本的问题。近日，威斯康星大学麦迪逊分校一个研究团队提出了 Eventful Transformer，可通过在视觉 Transformer 中利用时间冗余来节省成本。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/51fa37b2-1824-444e-b866-f90915ab3026) \
  论文地址：https://arxiv.org/pdf/2308.13494.pdf \
  项目地址：http://wisionlab.com/project/eventful-transformers
* 43、(**值得看看**)LLM成功不可或缺的基石：RLHF及其替代技术  机器之心  https://mp.weixin.qq.com/s/K0hFyK0bviFdcNrl21achQ \
* 44、(**有趣，值得看看**)在笔记本电脑上从头设计一款会走路的机器人，AI只需26秒  机器之心  https://mp.weixin.qq.com/s/SRH9iLaEttv5kWgeFdRlYQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/626cc85e-d00f-48d1-bd39-b7f562a3d581) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ab4651ed-3e5a-4329-88ae-5414cfcf5690) \
  论文链接：https://www.pnas.org/doi/epdf/10.1073/pnas.2305180120
* 45、3300万美元，谷歌开启5年脑计划！绘制小鼠大脑2-3%图谱，大约一个珠穆朗玛峰的数据量  新智元  https://mp.weixin.qq.com/s/C6xC3i4jdKCEItQIGLb8sw \
  谷歌宣布将绘制出小鼠大脑中海马体的所有连接组，这将是人类有史以来最大的生物数据集。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a694f607-cea6-4199-b767-6af887324684) \
* 46、(**有趣，重要，研究研究**)CMU华人打破大模型黑盒，Llama 2撒谎被一眼看穿！脑电波惨遭曝光，LLM矩阵全破解  新智元  https://mp.weixin.qq.com/s/0fPd86dMUaJmLAC3S_RZAw \
  大语言模型黑盒，居然被CMU等机构的学者打破了？他们发现，LLM内部有可解释的表征，如果撒谎，还能被测谎仪检测出来！ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/dd43632f-0dac-403d-8e7f-daa271102f85) \
  论文地址：https://arxiv.org/pdf/2310.01405.pdf \
  几个月前，OpenAI团队曾发表了一篇论文「语言模型可以解释语言模型中的神经元」，用AI竟然可以解释AI，震惊全网。通过调用GPT-4，能够解释GPT-2三十万个神经元。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7592ddf0-8749-492f-8360-101ba0bfcfc1) \
  论文地址：https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html#sec-intro \
  1972年，诺贝尔奖获得者P. W. Anderson在一篇「More Is Different」文章中，描述了复杂的现象如何不能简单地自下而上地进行解释。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e3596da9-c009-4319-a8a8-4632106fb0ea) \

# 10.7 周六
* 47、(**重要，研究研究**)分解大模型的神经元！Claude团队最新研究火了，网友：打开黑盒  量子位  https://mp.weixin.qq.com/s/FAz3MjN5uRFo9xVpqbgebw \
  打破大模型黑盒，彻底分解神经元！OpenAI对头Anthropic击破AI不可解释性障碍  新智元  https://mp.weixin.qq.com/s/MbjdkEoQt9USU8o_2fZKRg \
  深度学习可解释性新进展！Claude团队利用字典学习分解大模型神经元  夕小瑶科技说  https://mp.weixin.qq.com/s/U3QWO3oyHQ2r9r3Fb5JPUA \
  打破大模型黑盒，彻底分解神经元！OpenAI对头Anthropic击破AI不可解释性障碍  机器学习研究组订阅  https://mp.weixin.qq.com/s/mhaagZvZH0dp9dhWy5NW2Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/808d5dfd-ff45-4972-aed4-6f6a155e81a7) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/48fc517f-1bb3-444c-aa18-86d5b1b7309e) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/53e39f3d-166a-46b4-ab58-039caf49f56d) \
  报告题目为《迈向单义性：通过字典学习分解语言模型》（Towards Monosemanticity: Decomposing Language Models With Dictionary Learning） \
  报告链接： https://transformer-circuits.pub/2023/monosemantic-features/index.html \
  参考链接：https://twitter.com/anthropicai/status/1709986949711200722
* 48、OpenAI造芯计划曝光！拟自研AI芯片，正在评估收购目标  量子位  https://mp.weixin.qq.com/s/2QZdLDC-Z-f3RlTvwpVxVA \
  OpenAI计划研发自己的AI芯片，已有收购目标  机器之心  https://mp.weixin.qq.com/s/2yKiFlri86KXKnrWPP036w \
* 49、致敬TempleOS，有开发者创建了启动Llama 2的操作系统，网友：8G内存老电脑就能跑  机器之心  https://mp.weixin.qq.com/s/3VavBuDPDa49wEiPaGxaXw \
* 50、(**重要，研究研究，可能是LLM未来的应用路线**)7.7亿参数，超越5400亿PaLM！UW谷歌提出「分步蒸馏」，只需80%训练数据｜ACL 2023  新智元  https://mp.weixin.qq.com/s/10Gjkn7Ymed31xilmWOfog \
  LLM不实用，小模型蒸馏才是「现实」的大模型应用路线，全面领先微调技术！土豪请无视。。。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/867237bf-28fd-4d7d-949c-9d9eb7b57ea1) \
  论文链接：https://arxiv.org/abs/2305.02301
* 51、文章分享 | 人脑与人工神经网络中的知识组装  神经计算与控制实验室  https://mp.weixin.qq.com/s/h87cvPmXQ1nuKlD3kbW9UA \
* 52、《机器人语言》美陆军5年项目46页技术总结报告，2023年  专知智能防务  https://mp.weixin.qq.com/s/WVL9WCXo4b9pNemDS1U_-g \
* 53、(**值得看看**)微软发布AutoGen开源框架，简化大语言模型工作流的编排、优化和自动化  人工智能与算法学习  https://mp.weixin.qq.com/s/M7xHAA4HSH-cJG3kbvgvNg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9953ca2c-799d-4005-a522-73115c2664ce) 

# 10.8 周日
* 54、有了ModelScope-Agent，小白也能打造专属智能体，附保姆级教程  机器之心  https://mp.weixin.qq.com/s/-nP4eUlBavI6LmM9ASSi7w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7fad0d08-5632-40bb-bb74-5079b387c474) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ea3a7faa-2624-45a9-8d3d-bbd0cc7a5768) \
  论文链接：https://arxiv.org/abs/2309.00986 \
  代码链接：https://github.com/modelscope/modelscope-agent \
  ModelScope 体验地址：https://modelscope.cn/studios/damo/ModelScopeGPT/summary
* 55、(**值得看看**)正面硬刚GPT-4V！浙大校友开源多模态大模型LLaVA-1.5，130亿参数8个A100一天训完  新智元  https://mp.weixin.qq.com/s/luvuIsIBGEJYDezEbCOw5g \
  挑战GPT-4V，浙大校友推出开源版多模态大模型，获GitHub 6k+星标  量子位  https://mp.weixin.qq.com/s/EId9sFo5Qep-h4KiQewgVA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/92787ae7-f7cf-4c1c-9303-0fce8125f659) \
  ???怎么做到的，居然能看懂这种草图，难道训练数据里有吗  
* 56、(**阿尔伯塔计划，实现智能体的计划，了解了解其路线**)强化学习之父入局AGI创业！联手传奇程序员卡马克，放话不依赖大模型  量子位  https://mp.weixin.qq.com/s/YxeIJiO5CFzt8mpADGEcsg \
  Alberta Plan \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/65121437-b4b8-4f54-af12-8900888647db) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/59ebbcbe-1bc0-4127-a127-06267a1f2f05) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9f2e1815-1b84-4365-80b7-eaf2bd59b6be) \
  参考链接： \
  [1]https://www.amii.ca/latest-from-amii/john-carmack-and-rich-sutton-agi/ \
  [2]https://www.youtube.com/watch?v=uTMtGT1RjlY \
  [3]https://arxiv.org/abs/2208.11173  论文链接
* 57、对标GPT-4代码解释器！港中大让模型写代码解决数学难题，得分超越GPT-4  量子位  https://mp.weixin.qq.com/s/xUbGPXw2U9yhET9lvGFhTg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/163aba8d-1052-478b-af03-99e32a546b01) \
  论文地址：https://arxiv.org/abs/2310.03731
* 58、不可错过！斯坦福最新《大型语言模型与应用》课程，讲述LLMs技术栈和应用以及评估  专知  https://mp.weixin.qq.com/s/ygBT-y9HP6HwKb-ziHevkg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e62a8467-8ed6-4518-8a06-47c980aa4857) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/09b6f65c-b08c-49e7-a446-90251becc378) \
  https://web.stanford.edu/class/cs329t/index.html

# 10.9 周一
* 59、贾佳亚团队开源全球首个70B长文本大语言模型，读论文看小说直接ProMax  量子位  https://mp.weixin.qq.com/s/HaTqlerchNV3GmTzDJDS_A \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/3a630b03-f782-4b8b-b9bd-85fd1bd78243) \
* 60、最好的7B模型易主，笔记本轻松跑，免费开源可商用，来自“欧洲的OpenAI”  量子位  https://mp.weixin.qq.com/s/EhDRgNsFHyB3XIpfN9dQyw \
  来自法国的开源大模型Mistral-7B \
  如果你对Mistral-7B感兴趣，可以在Perplexity或HuggingChat试玩。 \
  labs.perplexity.ai \
  https://huggingface.co/chat \
  还有一个与Llama 2同台竞技的小游戏可玩。 \
  https://llmboxing.com 
* 61、迪士尼玩起强化学习，新机器人有星球大战那味了  量子位  https://mp.weixin.qq.com/s/q-V8BAAK__I_RmjKXPyEZw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c5a65c5b-ebe5-442c-b4fa-9a81d783429a)
* 62、(**值得看看，LongLoRA**)2行代码，「三体」一次读完！港中文贾佳亚团队联手MIT发布超长文本扩展技术，打破LLM遗忘魔咒  新智元  https://mp.weixin.qq.com/s/8QoKHgwjxv7fG_CCqouU8w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/dac2d276-761a-4502-ab16-777de2b27b37) \
  论文地址：https://arxiv.org/abs/2309.12307 \
  代码和Demo地址：https://github.com/dvlab-research/LongLoRA
* 63、(**有趣，了解了解**)文生3D模型大突破！MVDream重磅来袭，一句话生成超逼真三维模型  新智元  https://mp.weixin.qq.com/s/EpdblKDrb1T6xjnVRE8TCw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4eaa4a32-0439-4932-80f7-0de4b29bb6d6) \
  参考资料： \
  https://www.louisbouchard.ai/mvdream/ \
  https://arxiv.org/pdf/2308.16512.pdf 
* 64、(**MiniGPT-5，看一看，玩一玩**)统一图像和文字生成的MiniGPT-5来了：Token变Voken，模型不仅能续写，还会自动配图了 \
  野心勃勃的MiniGPT-5出现了！Token变Voken，支持图文交叉生成  夕小瑶科技说  https://mp.weixin.qq.com/s/5qKrE7bHtBEx7IB7ermWqg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4aab77b3-4376-4aa5-b736-a79eb0acd81a) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1ec9b2fc-b3be-4200-8678-93af1c5a6d7d) \
  论文地址：https://browse.arxiv.org/pdf/2310.02239v1.pdf \
  项目地址：https://github.com/eric-ai-lab/MiniGPT-5 \
* 65、500多倍！伯克利 | 提出Ring Attention，Transformer分块，最高支持100M上下文！ AINLPer  https://mp.weixin.qq.com/s/wOCpDcb7acPxioRk_6jm9g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5df91724-f2fc-4529-9d4d-68404116941a) \
  Paper：https://browse.arxiv.org/pdf/2310.01889.pdf \
  Code：coming soon~

# 10.10 周二
* 66、陶哲轩：我用GPT-4辅助证明不等式定理，论文还会上传arXiv  机器之心  https://mp.weixin.qq.com/s/Cezn03Xksu4XLiQYFE9cug \
  GPT-4野生代言人陶哲轩：搞论文学新工具没它得崩溃！11页“超简短”新作已上线  量子位  https://mp.weixin.qq.com/s/l_otQop-xFbFTmML0Bq0cQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5ca3bba9-1f69-4e27-b6b7-66f7732ae4bf)
  论文地址：https://browse.arxiv.org/pdf/2310.05328.pdf
* 67、大模型开启「长」时代，杨植麟的新公司把对话框容量做到了世界第一  机器之心  https://mp.weixin.qq.com/s/ucBkWpdG8PU5rM5OPmK5jw \
* 68、多模态大模型落地的风，最终还是刮了起来  计算机视觉研究院  计算机视觉研究院  https://mp.weixin.qq.com/s/5OgjMrYMDrTZDJZrZNgL2g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/34ec52b9-c103-47dc-9ff5-ad86d383a827) \
  LLaVA-1.5 \
  论文地址：https://browse.arxiv.org/pdf/2310.03744.pdf \
  Demo 地址：https://llava.hliu.cc/
* 69、(**试玩一下**)挑战GPT-4V！清华唐杰&智谱开源多模态14边形战士，在线可玩  量子位  https://mp.weixin.qq.com/s/sKMQUrIGBN2Kh9Nx2ifJtg \
  CogVLM \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1c3bdcbf-7277-4eab-bbd7-88836c321680) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8d273a70-5c79-44ef-9c5e-1d249ecf39a4) \
  试玩地址：http://36.103.203.44:7861 \
  开源及论文地址：https://github.com/THUDM/CogVLM

# 10.11 周三
* 70、EfficientViT：让ViT更高效部署实现实时推理（附源码）  计算机视觉研究院  https://mp.weixin.qq.com/s/-kivpJIjouIuDew2Jog3MA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/01e0aff9-67e3-4a15-a248-d1f10f4c51e3) \
  论文地址：https://arxiv.org/pdf/2305.07027.pdf \
  项目代码：https://github.com/microsoft/Cream/tree/main/EfficientViT
* 71、InternImage：探索具有可变形卷积的大规模视觉基础模型  计算机视觉研究院  https://mp.weixin.qq.com/s/ELIzsTJ5l881SyxcbF7LNg \
* 72、(**重要，听一听**)OpenAI科学家最新演讲：GPT-4即将超越拐点，1000倍性能必定涌现！  新智元  https://mp.weixin.qq.com/s/48Brr7APBBYT2X28Z724AA \
  OpenAI科学家最新演讲：GPT-4即将超越拐点，1000倍性能必定涌现！  机器学习研究组订阅  https://mp.weixin.qq.com/s/XLgKurtiXEba9TUNju760w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f127d284-593d-436b-974f-3e0eed9f0056) \
  参考资料：\
  https://twitter.com/xiaohuggg/status/1711714757802369456?s=20 \
  https://twitter.com/dotey/status/1711504620025942243 \
  https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g27b7c310230_0_496
* 73、(**值得看看**)Meta再放「长文本」杀器Llama 2-Long：70B尺寸登顶最强「32k上下文」模型，超越ChatGPT  新智元  https://mp.weixin.qq.com/s/-6thXLygj-TUaZWhPTmMcQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a8311e1f-7a89-4ad4-b1e0-4b80e84d977c) \
  论文链接：https://arxiv.org/pdf/2309.16039.pdf 
* 74、(**可以看看**)在图像、视频生成上，语言模型首次击败扩散模型，tokenizer是关键  机器之心  https://mp.weixin.qq.com/s/fHWTbv_yvqKb-GiBqDUAsA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/903f72a6-2e60-4030-83b0-74fa730ac3eb)
  论文链接：https://arxiv.org/pdf/2310.05737.pdf
* 75、MetaMath：新数学推理语言模型，训练大模型的逆向思维  机器之心  https://mp.weixin.qq.com/s/Rtao_IXfY3hXIvYZPxIBGA \
  ？？？怎么实现逆向思维的 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d871f99d-e5d5-48ef-aec4-562eef975e9a) \
  项目地址：https://meta-math.github.io/ \
  论文地址：https://arxiv.org/abs/2309.12284 \
  数据地址：https://huggingface.co/datasets/meta-math/MetaMathQA \
  模型地址：https://huggingface.co/meta-math \
  代码地址：https://github.com/meta-math/MetaMath
* 76、清华全球首颗片上学习忆阻器存算一体芯片，成果登上Science  机器之心  https://mp.weixin.qq.com/s/p9II_b1oI-7iKMmFveus5g \
  清华芯片新突破登Science，获评“存算一体领域重大进展”！基于类脑架构实现片上快速AI学习  量子位  https://mp.weixin.qq.com/s/r9mza55fywxTBDQvuenC-Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/954d9a24-006d-4c8d-b477-4f7658d32b4a) \
  论文地址：https://www.science.org/doi/full/10.1126/science.ade3483
* 77、(**值得看看**)复旦 NLP 实验室联合米哈游解读大模型：AI Agents 的现状和未来  Founder Park  https://mp.weixin.qq.com/s/jArfNGEdsZ4OxvCZ8B1siw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/fc8e3ba3-093b-481c-a4df-cfa0b61639cb) \
  论文链接：https://arxiv.org/pdf/2309.07864.pdf \ 
  (**!!!重要资源**)LLM-based Agent 论文列表：https://github.com/WooooDyy/LLM-Agent-Paper-List
* 78、(**为啥淘汰向量数据库？看看，搞清楚**)AutoGPT 宣布不再使用向量数据库！向量数据库是小题大作的方案？  infoQ  https://mp.weixin.qq.com/s/mlUg1N7jQ5f6HVKKOvKOjA \

# 10.12 周四
* 79、
* 80、
  
# 10.13 周五
# 10.14 周六
# 10.15 周日
# 10.16 周一
# 10.17 周二
# 10.18 周三
# 10.19 周四
# 10.20 周五
# 10.21 周六
# 10.22 周日
# 10.23 周一
# 10.24 周二
# 10.25 周三
# 10.26 周四
# 10.27 周五
# 10.28 周六
# 10.29 周日
# 10.30 周一
# 10.31 周二
