# 3.1 Fri
* 1.OpenAI把GPT塞进机器人大脑，具身AGI奇点迫近！英伟达微软参投26亿美金独角兽Figure  新智元  https://mp.weixin.qq.com/s/OQkJFksgBDf1YjrvOgNB7A
* 2.(**值得看看**)2024！深入了解 大语言模型（LLM）微调方法（总结）  AINLPer  https://mp.weixin.qq.com/s/Kig_vbAdiGJ1oALiPe-O_Q

# 3.2 Sat
* 3.今日Arxiv最热NLP大模型论文：Llama-2上下文扩大48倍的方法来了，港大发布，无需训练  夕小瑶科技说  https://mp.weixin.qq.com/s/0aDk8BQZPD8xGEJs4Gc7Sw \
  论文标题：Training-Free Long-Context Scaling of Large Language Models \
  论文链接：https://arxiv.org/pdf/2402.17463.pdf 
* 4.香港大学发布思维扩散DoT，让思维在时间上扩散，提效保质！  夕小瑶科技说  https://mp.weixin.qq.com/s/lD4RgRhf3z1HOtE_r0Codg \
  标题：Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models \
  论文链接:https://arxiv.org/pdf/2402.07754.pdf
* 5.(**重要学习资料**)大模型理论基础(so-large-lm)课程笔记！  Datawhale  https://mp.weixin.qq.com/s/MZiVMcDEq3Mkm9tFmaN_7A \
  https://github.com/datawhalechina/so-large-lm

# 3.3 Sun
* 6.北大发起复现Sora，框架已搭！袁粒田永鸿领衔，AnimateDiff大神响应  量子位  https://mp.weixin.qq.com/s/DRulMeZETAApD1P28EhxGw \
  Open Sora项目主页： \
  https://pku-yuangroup.github.io/Open-Sora-Plan/blog_cn.html \
  https://github.com/PKU-YuanGroup/Open-Sora-Plan
* 7.(**可以看看**)北大具身智能成果入选CVPR'24：只需一张图一个指令，就能让大模型玩转机械臂  量子位  https://mp.weixin.qq.com/s/YTvN6VDmP9aSxvI5M3YVCg \
  更多细节可查看论文原文： \
  https://arxiv.org/pdf/2312.16217.pdf \
  和项目主页： \
  https://sites.google.com/view/manipllm \
  ManipLLM: Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation
* 8.(**非常值得看看**)大视频模型是世界模型？DeepMind/UC伯克利华人一作：预测下一帧就能改变世界  新智元  https://mp.weixin.qq.com/s/pMzISIodXUO92cik8uJS7Q \
  论文地址：https://arxiv.org/abs/2402.17139 \
  Video as the New Language for Real-World Decision Making
* 9.(**非常值得看看**)给AI Agent完整的一生！港大NYU谢赛宁等最新智能体研究：虚拟即现实  新智元  https://mp.weixin.qq.com/s/YMHjCaJ0Si7u0yTHBjmPRQ \
  论文地址：https://arxiv.org/abs/2402.03310 \
  代码地址：https://github.com/VIRL-Platform/VIRL \
  V-IRL: Grounding Virtual Intelligence in Real Life
* 10.(**可以看看**)清华、哈工大把大模型压缩到了1bit，把大模型放在手机里跑的愿望就快要实现了！  机器之心  https://mp.weixin.qq.com/s/sAf-S9utl3gjUVgCOlPVPA \
  论文标题：OneBit: Towards Extremely Low-bit Large Language Models \
  论文地址：https://arxiv.org/pdf/2402.11295.pdf \
  相关论文： \
  [1] Dettmers T, Lewis M, Belkada Y, et al. Llm. int8 (): 8-bit matrix multiplication for transformers at scale [J]. arXiv preprint arXiv:2208.07339, 2022. \
  [2] Frantar E, Ashkboos S, Hoefler T, et al. GPTQ: Accurate post-training quantization for generative pre-trained transformers [J]. arXiv preprint arXiv:2210.17323, 2022. \
  [3] Wang H, Ma S, Dong L, et al. Bitnet: Scaling 1-bit transformers for large language models [J]. arXiv preprint arXiv:2310.11453, 2023.
* 11.(**Griffin\Hawk**)RNN效率媲美Transformer，谷歌新架构两连发：同等规模强于Mamba  机器之心  https://mp.weixin.qq.com/s/RtAZiEzjRWgqQw3yu3lvcg \
  再超Transformer！Google| 提出两个新模型(Griffin、Hawk)，强于Mamba，更省资源  AINLPer  https://mp.weixin.qq.com/s/R34tP32pUrRRGh-6NXlzXQ \
  论文标题：Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models \
  论文链接：https://arxiv.org/pdf/2402.19427.pdf
* 12.十年内出现AGI？下一代Gemini能感知环境？DeepMind CEO哈萨比斯畅谈AI  机器之心  https://mp.weixin.qq.com/s/MMaeLRpo37Ot_9P5mjj5wg \
* 13.(**MobileVLM V2**)端侧实时运行、3B媲美7B！美团、浙大等提出MobileVLM V2：更快、更强的端侧视觉语言模型  PaperWeekly  https://mp.weixin.qq.com/s/WPLWmxkjlc6_2sn8ToHBqg \
  论文地址：https://arxiv.org/abs/2402.03766 \
  模型地址：https://huggingface.co/mtgv \
  代码地址：https://github.com/Meituan-AutoML/MobileVLM \
  MobileVLM V2: Faster and Stronger Baseline for Vision Language Model
* 14.港中文深圳提出ALLaVA-4V：百万级别的开源多模态GPT-4V数据集  PaperWeekly  https://mp.weixin.qq.com/s/otxd8rEVy2kw2mHzb0JFBA \
  论文题目：ALLaVA: Harnessing GPT4V-synthesized Data for A Lite Vision-Language Model \
  论文链接：https://arxiv.org/abs/2402.11684 \
  数据链接：https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V \
  代码链接：https://github.com/FreedomIntelligence/ALLaVA \
  Demo链接：https://allava.freedomai.cn/#/

# 3.4 Mon
* 15.

# 3.5 Tue
# 3.6 Wed
# 3.7 Thur
# 3.8 Fri
# 3.9 Sat
# 3.10 Sun
# 3.11 Mon
# 3.12 Tue
# 3.13 Wed
# 3.14 Thur
# 3.15 Fri
# 3.16 Sat
# 3.17 Sun
# 3.18 Mon
# 3.19 Tue
# 3.20 Wed
# 3.21 Thur
# 3.22 Fri
# 3.23 Sat
# 3.24 Sun
# 3.25 Mon
# 3.26 Tue
# 3.27 Wed
# 3.28 Thur
# 3.29 Fri
# 3.30 Sat
# 3.31 Sun
