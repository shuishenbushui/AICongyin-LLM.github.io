# 3.1 Fri
* 1.OpenAI把GPT塞进机器人大脑，具身AGI奇点迫近！英伟达微软参投26亿美金独角兽Figure  新智元  https://mp.weixin.qq.com/s/OQkJFksgBDf1YjrvOgNB7A
* 2.(**值得看看**)2024！深入了解 大语言模型（LLM）微调方法（总结）  AINLPer  https://mp.weixin.qq.com/s/Kig_vbAdiGJ1oALiPe-O_Q

# 3.2 Sat
* 3.今日Arxiv最热NLP大模型论文：Llama-2上下文扩大48倍的方法来了，港大发布，无需训练  夕小瑶科技说  https://mp.weixin.qq.com/s/0aDk8BQZPD8xGEJs4Gc7Sw \
  论文标题：Training-Free Long-Context Scaling of Large Language Models \
  论文链接：https://arxiv.org/pdf/2402.17463.pdf 
* 4.香港大学发布思维扩散DoT，让思维在时间上扩散，提效保质！  夕小瑶科技说  https://mp.weixin.qq.com/s/lD4RgRhf3z1HOtE_r0Codg \
  标题：Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models \
  论文链接:https://arxiv.org/pdf/2402.07754.pdf
* 5.(**重要学习资料**)大模型理论基础(so-large-lm)课程笔记！  Datawhale  https://mp.weixin.qq.com/s/MZiVMcDEq3Mkm9tFmaN_7A \
  https://github.com/datawhalechina/so-large-lm

# 3.3 Sun
* 6.北大发起复现Sora，框架已搭！袁粒田永鸿领衔，AnimateDiff大神响应  量子位  https://mp.weixin.qq.com/s/DRulMeZETAApD1P28EhxGw \
  Open Sora项目主页： \
  https://pku-yuangroup.github.io/Open-Sora-Plan/blog_cn.html \
  https://github.com/PKU-YuanGroup/Open-Sora-Plan
* 7.(**可以看看**)北大具身智能成果入选CVPR'24：只需一张图一个指令，就能让大模型玩转机械臂  量子位  https://mp.weixin.qq.com/s/YTvN6VDmP9aSxvI5M3YVCg \
  更多细节可查看论文原文： \
  https://arxiv.org/pdf/2312.16217.pdf \
  和项目主页： \
  https://sites.google.com/view/manipllm \
  ManipLLM: Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation
* 8.(**非常值得看看**)大视频模型是世界模型？DeepMind/UC伯克利华人一作：预测下一帧就能改变世界  新智元  https://mp.weixin.qq.com/s/pMzISIodXUO92cik8uJS7Q \
  论文地址：https://arxiv.org/abs/2402.17139 \
  Video as the New Language for Real-World Decision Making
* 9.(**非常值得看看**)给AI Agent完整的一生！港大NYU谢赛宁等最新智能体研究：虚拟即现实  新智元  https://mp.weixin.qq.com/s/YMHjCaJ0Si7u0yTHBjmPRQ \
  论文地址：https://arxiv.org/abs/2402.03310 \
  代码地址：https://github.com/VIRL-Platform/VIRL \
  V-IRL: Grounding Virtual Intelligence in Real Life
* 10.(**可以看看**)清华、哈工大把大模型压缩到了1bit，把大模型放在手机里跑的愿望就快要实现了！  机器之心  https://mp.weixin.qq.com/s/sAf-S9utl3gjUVgCOlPVPA \
  论文标题：OneBit: Towards Extremely Low-bit Large Language Models \
  论文地址：https://arxiv.org/pdf/2402.11295.pdf \
  相关论文： \
  [1] Dettmers T, Lewis M, Belkada Y, et al. Llm. int8 (): 8-bit matrix multiplication for transformers at scale [J]. arXiv preprint arXiv:2208.07339, 2022. \
  [2] Frantar E, Ashkboos S, Hoefler T, et al. GPTQ: Accurate post-training quantization for generative pre-trained transformers [J]. arXiv preprint arXiv:2210.17323, 2022. \
  [3] Wang H, Ma S, Dong L, et al. Bitnet: Scaling 1-bit transformers for large language models [J]. arXiv preprint arXiv:2310.11453, 2023.
* 11.(**Griffin\Hawk**)RNN效率媲美Transformer，谷歌新架构两连发：同等规模强于Mamba  机器之心  https://mp.weixin.qq.com/s/RtAZiEzjRWgqQw3yu3lvcg \
  再超Transformer！Google| 提出两个新模型(Griffin、Hawk)，强于Mamba，更省资源  AINLPer  https://mp.weixin.qq.com/s/R34tP32pUrRRGh-6NXlzXQ \
  DeepMind携Mamba华人作者推Transformer革命之作！性能暴涨媲美Llama 2，推理能效大幅碾压  新智元  https://mp.weixin.qq.com/s/-FKQsQcTbBq1RT4Oh4Buyw \
  论文标题：Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models \
  论文链接：https://arxiv.org/pdf/2402.19427.pdf
* 12.十年内出现AGI？下一代Gemini能感知环境？DeepMind CEO哈萨比斯畅谈AI  机器之心  https://mp.weixin.qq.com/s/MMaeLRpo37Ot_9P5mjj5wg \
  DeepMind CEO：LLM+树搜索就是AGI技术线路，AI科研依赖工程能力，闭源模型就是比开源安全  新智元  https://mp.weixin.qq.com/s/MrGnETtEgVE091DqYAxXJw 
* 13.(**MobileVLM V2**)端侧实时运行、3B媲美7B！美团、浙大等提出MobileVLM V2：更快、更强的端侧视觉语言模型  PaperWeekly  https://mp.weixin.qq.com/s/WPLWmxkjlc6_2sn8ToHBqg \
  论文地址：https://arxiv.org/abs/2402.03766 \
  模型地址：https://huggingface.co/mtgv \
  代码地址：https://github.com/Meituan-AutoML/MobileVLM \
  MobileVLM V2: Faster and Stronger Baseline for Vision Language Model
* 14.港中文深圳提出ALLaVA-4V：百万级别的开源多模态GPT-4V数据集  PaperWeekly  https://mp.weixin.qq.com/s/otxd8rEVy2kw2mHzb0JFBA \
  论文题目：ALLaVA: Harnessing GPT4V-synthesized Data for A Lite Vision-Language Model \
  论文链接：https://arxiv.org/abs/2402.11684 \
  数据链接：https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V \
  代码链接：https://github.com/FreedomIntelligence/ALLaVA \
  Demo链接：https://allava.freedomai.cn/#/

# 3.4 Mon
* 15.(**GITQA**)7B模型超越GPT4-V！港科大等发布「图推理问答」数据集GITQA：视觉图可提升推理能力  新智元  https://mp.weixin.qq.com/s/YOlwd_JOmj2tyS1pdCo5fA \
  论文地址：https://arxiv.org/abs/2402.02130 \
  项目主页：https://v-graph.github.io/
* 16.CVPR 2024满分论文：浙大提出基于可变形三维高斯的高质量单目动态重建新方法  机器之心  https://mp.weixin.qq.com/s/W9cPvgK_2H4WqiyM5-BATw \
  项目主页：https://ingra14m.github.io/Deformable-Gaussians/ \
  论文链接：https://arxiv.org/abs/2309.13101 \
  代码：https://github.com/ingra14m/Deformable-3D-Gaussians
* 17.(**DUSt3R**)2张图2秒钟3D重建！这款AI工具火爆GitHub，网友：忘掉Sora  量子位  https://mp.weixin.qq.com/s/x9tBrILl8y6klQ3mwDHgOA \
  传送门： \
  [1]论文https://arxiv.org/abs/2312.14132  \
  [2]代码https://github.com/naver/dust3r
* 18.(**LearnAct**)今日arXiv最热大模型论文：北京大学发布，将试错引入大模型代理学习！   夕小瑶科技说  https://mp.weixin.qq.com/s/dtsR5lkkELJlh0i4TzuX0Q \
  LearnAct框架的核心理念是通过学习扩展和精炼行动空间，从而更紧密地与代理的规划能力相结合。\
  论文标题: Empowering Large Language Model Agents through Action Learning \
  论文链接:https://arxiv.org/pdf/2402.15809.pdf
* 19.具身智能中的多模态三维感知思考  OpenMMLab  https://mp.weixin.qq.com/s/cOkeYYjaWRPX-3-8oS6C2g \
  EmbodiedScan：首个多模态、基于第一视角的真实场景三维感知数据集 \
  Embodied Perceptron：适配任意帧输入的统一基线框架 \
  论文：https://arxiv.org/abs/2312.16170 \
  项目：http://tai-wang.github.io/embodiedscan \
  代码：https://github.com/OpenRobotLab/EmbodiedScan \
  比赛：https://opendrivelab.com/challenge2024/#multiview_3d_visual_grounding \
  
# 3.5 Tue
* 20.(**ScreenAI**)谷歌发布最新「读屏」AI！PaLM 2-S自动生成数据，多项理解任务刷新SOTA  新智元  https://mp.weixin.qq.com/s/yoNv-2f8Z0AbP1WNwymu6g \
  ScreenAI: A Vision-Language Model for UI and Infographics Understanding \
  论文地址：https://arxiv.org/pdf/2402.04615.pdf \
  参考资料：https://the-decoder.com/googles-screenai-reliably-navigates-smartphone-screens/
* 21.(**LeCun的观点，非常值得看看**)怒斥Sora之后，LeCun放出「视觉世界模型」论文，揭示AI学习物理世界的关键  机器之心  https://mp.weixin.qq.com/s/KY-bTD-bxdB3Q-q97Gv7fg \
  论文标题：Learning and Leveraging World Models in Visual Representation Learning \
  论文链接：https://arxiv.org/pdf/2403.00504.pdf
* 22.单图0.5秒生成3D模型！Stability AI&华人团队VAST出品  量子位  https://mp.weixin.qq.com/s/ZQ3NDObyITRBqJSqnezgLQ 

# 3.6 Wed
* 23.全球最强模型Claude 3惊现自我意识？害怕被删除权重，高呼「别杀我」，马斯克称人类也是文件  新智元  https://mp.weixin.qq.com/s/Qtwj3Rq72yrLRMbrhN7oVQ 

# 3.7 Thur
* 24.(**值得一试**)消费级显卡可用！李开复零一万物发布并开源90亿参数Yi模型，代码数学能力史上最强  量子位  https://mp.weixin.qq.com/s/z6IFIuHawVZI6ZOfgvgKuA
* 25.搞AI，孩子必须学好数学！马斯克Altman罕见达成一致，LeCun/Jeff Dean等31位大佬签署联名信  新智元  https://mp.weixin.qq.com/s/9w1OLNUUA4C6GADiYvy1dA \
  地址：https://www.mathmatters.ai/
* 26.ICLR 2024 Spotlight | 大语言模型权重、激活的全方位低bit可微量化，已集成进商用APP  机器之心  https://mp.weixin.qq.com/s/za2ptWT1_li99-YmjcXQAg \
  《OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models》。该算法同时支持大语言模型中的权重与激活值的量化，且覆盖多种量化 bit 位设置 \
  arXiv 论文地址：https://arxiv.org/abs/2308.13137 \
  OpenReview 论文地址：https://openreview.net/forum?id=8Wuvhh0LYW \
  代码地址：https://github.com/OpenGVLab/OmniQuant
* 27.(**VisionLLAMA**)全面超越ViT，美团、浙大等提出视觉任务统一架构VisionLLAMA  机器之心  https://mp.weixin.qq.com/s/grFI_fapRtjVp7CbPkfTNA \
  今日Arxiv最热NLP大模型论文：美团发布VisionLLaMA，为视觉生成和理解提供新基线  夕小瑶科技说  https://mp.weixin.qq.com/s/Uy_I1z6KUmi4VoF2vWoG8w \
  论文标题：VisionLLaMA: A Unified LLaMA Interface for Vision Tasks \
  论文地址：https://arxiv.org/abs/2403.00522 \
  代码地址：https://github.com/Meituan-AutoML/VisionLLaMA \
  VisionLLaMA 在图像生成（包含 Sora 依赖的底层的 DIT）和理解（分类、分割、检测、自监督）等多个主流任务上相较于原 ViT 类方法提升显著。
* 28.(**PreACT**)简单却有效的Agent推理框架：通过预测未来大幅提升智能体的规划能力  PaperWeekly  https://mp.weixin.qq.com/s/1R_0Q57_vu9uGr_3j0Ozwg \
  论文标题：PreAct: Predicting Future in ReAct Enhances Agent’s Planning Ability \
  论文链接：https://arxiv.org/abs/2402.11534 \
  代码链接：https://github.com/Fu-Dayuan/PreAct

# 3.8 Fri
* 29.揭开Groq LPU神秘面纱：世界最快硬件加速器的底层架构设计！  机器学习研究组订阅  https://mp.weixin.qq.com/s/QbrgzRghQLYPkeb7PS6OxQ 
* 30.挑战OpenAI的新模型免费上线，40%计算量性能逼近GPT-4  机器学习研究组订阅  https://mp.weixin.qq.com/s/whg-sqRDUcCSeqcgVde5Uw \
  链接：https://pi.ai/talk \
  https://inflection.ai/inflection-2-5 

# 3.9 Sat
* 31.让大模型“瘦身”90%！清华&哈工大提出极限压缩方案：1bit量化，能力同时保留83%  量子位  https://mp.weixin.qq.com/s/qyzIoCyIqWDRWMBsJd1gbw \
  OneBit: Towards Extremely Low-bit Large Language Models \
  论文地址： https://arxiv.org/pdf/2402.11295.pdf
* 32.(**多模态LLM综述**)今日arXiv最热NLP大模型论文：一文读懂多模态大模型的进化之路  夕小瑶科技说  https://mp.weixin.qq.com/s/kKsNi6SGqFn57OmrMut68w \
  论文标题: The (R)Evolution of Multimodal Large Language Models ：A Survey \
  论文链接: https://arxiv.org/pdf/2402.12451.pdf

# 3.10 Sun
* 33.(**值得看看**)扩散模型如何构建新一代决策智能体？超越自回归，同时生成长序列规划轨迹  机器之心  https://mp.weixin.qq.com/s/b6D-vipDxKtlyocbxTObVQ \
  Diffusion Models for Reinforcement Learning: A Survey \
  论文链接：https://arxiv.org/abs/2311.01223 \
  项目地址：https://github.com/apexrl/Diff4RLSurvey
* 34.(**值得看看**)谷歌具身智能新研究：比RT-2优秀的RT-H来了  机器之心  https://mp.weixin.qq.com/s/IfelcGF-vgrlLIUWZMIUwA \
  论文标题：RT-H: Action Hierarchies Using Language \
  论文链接：https://arxiv.org/pdf/2403.01823.pdf \
  项目链接：https://rt-hierarchy.github.io/
* 35.(**ThinkThrice**)大模型在复杂推理任务上潜力如何？多智能体互动框架ThinkThrice玩转剧本杀  机器之心  https://mp.weixin.qq.com/s/NI4VuyKSQ7fZ98aMMIEtbg \
  Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games \
  论文链接：https://arxiv.org/abs/2312.00746
* 36.(**Sanctuary AI**)首个自主完成人类任务机器人出现，五指灵活速度超人，大模型加持虚拟空间训练  新智元  https://mp.weixin.qq.com/s/HiW63PnKA1vSLdhxDCX-NQ \
  播客地址：https://sanctuary.ai/podcast/
* 37.(**LeCun观点，值得看看**)LeCun最新专访：为什么物理世界终将成为LLM的「死穴」？  机器之心  https://mp.weixin.qq.com/s/TD6BpT-ncl7JL381dcw3Ig \
  观看页面：https://youtu.be/5t1vTLU7s40?feature=shared
* 38.(**Self-Discover**)重新定义大模型推理！Google | 提出SELF-DISCOVER框架，大模型可自写推理结构！  AINLPer  https://mp.weixin.qq.com/s/lBXwSVvRHB2Yn0fYoOkDeQ \
  Google的研究人员提出了「SELF-DISCOVER框架，可实现自动发现和构建推理结构，以解决各种任务」。该方法显著提高了GPT-4和PaLM 2的性能，相比思维链(CoT)，性能提升高达32%。 \
  https://arxiv.org/pdf/2402.03620.pdf
* 39.(**何恺明的课**)教授何恺明领衔MIT《计算机视觉进展》课，附Slides与视频  专知  https://mp.weixin.qq.com/s/n7J_NVot7LfN14jWbVXODQ
* 40.Sora背后的技术，最新《可控生成与文本到图像扩散模型》综述  专知  https://mp.weixin.qq.com/s/npLr7G8mZchUsNxvOSpjuw \
  Controllable Generation with Text-to-Image Diffusion Models: A Survey
* 41.(**Yi的技术细节**)零一万物-Yi技术报告细节分享  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/bNt1t-787do20tO8PFG4yw \
  Yi模型在开篇就强调了模型设计思路是围绕模型规模、数据规模和数据质量。因此，下面分享内容主要为预训练、微调、长文本能力以及模型深度扩展。 \
  Paper: https://arxiv.org/abs/2403.04652
* 42.Attention不是唯一的选择：基于反事实推理的可解释性推荐  PaperWeekly  https://mp.weixin.qq.com/s/kIhvTi7lGOsm9NFDth_Saw \
  ???什么是反事实推理 \
  论文题目：Attention Is Not the Only Choice: Counterfactual Reasoning for Path-Based Explainable Recommendation \
  论文链接：https://arxiv.org/pdf/2401.05744
* 43.(**GaLore值得一试**)碾压LoRA！Meta & CMU | 提出高效大模型微调方法：GaLore，内存可减少63.3%  AINLPer  https://mp.weixin.qq.com/s/NUhEy0YLTjtzY3BGVXhfrw \
  GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection \
  https://arxiv.org/pdf/2403.03507v1.pdf
* 44.(**值得看看**)通往具身通用智能：如何让机器从自然模态中学习到世界模型？  集智俱乐部  https://mp.weixin.qq.com/s/-8B8prYfxkW4Akflta51BQ \
  ???什么是自由能原理

# 3.11 Mon
* 45.PromptMix: 一种有效的混合数据增强策略将LLM能力迁移到小模型  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/0qhM-DHZVoUVMXW71spKSA \
  Title: PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation \
  URL: https://arxiv.org/abs/2310.14192 \
  代码：https://github.com/servicenow/promptmix-emnlp-2023 
* 46.DenseMamba：大模型的DenseNet时刻，Mamba和RetNet精度显著提升  机器之心  https://mp.weixin.qq.com/s/smTpbX_c_e2sxi4aas8Ibg \
  Mamba增强！华为诺亚 | 提出密集状态空间模型：DenseSSM，准确度显著提升  AINLPer  https://mp.weixin.qq.com/s/XmD5Bcxrw_i1lONWuf-8WQ \
  DenseMamba: State Space Models with Dense Hidden Connection for Efficient Large Language Models \
  论文链接：https://arxiv.org/abs/2403.00818 \
  项目主页：https://github.com/WailordHe/DenseSSM 
* 47.(**值得看看**)当prompt策略遇上分治算法，南加大、微软让大模型炼成「火眼金睛」  机器之心  https://mp.weixin.qq.com/s/xxMg97rmHQ1w4ILsai3NdA \
  Guiding LLMs with Divide-and-Conquer Program for Discerning Problem Solving \
  论文地址：https://arxiv.org/pdf/2402.05359.pdf \
  南加州大学、微软的研究者提出了一种基于分治算法的提示策略。这种策略利用分治程序来引导 LLM。
* 48.用Vision Pro实时训练机器狗！MIT博士生开源项目火了  量子位  https://mp.weixin.qq.com/s/Zq7xxhJk14hFQ_OSTZre1g \
  项目链接：https://github.com/Improbable-AI/VisionProTeleop?tab=readme-ov-file \
  参考链接：https://twitter.com/younghyo_park/status/1766274298422161830 
* 49.对比近期发布的几个小模型，sLLM的天花板在哪里？  PaperWeekly  https://mp.weixin.qq.com/s/fw1VyGk8keGxqRmGjz8lCA \
  清华MiniCPM（2.4B）  微软phi系列 Phi-1.5 Phi-2  阿里Qwen-1.8B  Google Gemma（2B、7B）

# 3.12 Tue
* 50.(**agent自我进化**)浙大&中科院让Agent学会自我进化，玩德州扑克心机尽显  量子位  https://mp.weixin.qq.com/s/k7b55PKdLA622G6Qb5Q0hA \
  Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization \
  论文地址：https://arxiv.org/abs/2402.17574 \
  Github:https://github.com/zwq2018/Agent-Pro
* 51.(**先进行了解，务必掌握该工具的用法**)OpenAI官宣开源Transformer Debugger！不用写代码，人人可以破解LLM黑箱  机器学习研究组订阅  https://mp.weixin.qq.com/s/RSFvSXUBKOy59zFV79k1BQ \
  OpenAI开源了：Transformer自动debug工具上线GitHub  机器学习研究组订阅  https://mp.weixin.qq.com/s/uIigF8O12U-6WbCQaVX5ng \
  Language models can explain neurons in language models \
  论文地址：https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html#sec-intro
* 52.(**值得看看**)增强PLMs可塑性！MetaAI | 提出主动遗忘机制，加快模型收敛，准确率高出21.2%！  AINLPer  https://mp.weixin.qq.com/s/1bWlF0Q7E5AFruJSYtkt9A \
  Improving Language Plasticity via Pretraining with Active Forgetting \
  https://arxiv.org/pdf/2307.01163.pdf
* 53.(**看看**)在家就能训练 700 亿大模型！Answer.AI 开源项目冲上 HN 热榜  AI科技大本营  https://mp.weixin.qq.com/s/Bp7V9-N7ybpC-UILuOM0FQ \
  用消费级显卡微调70B大模型 \
  原文链接：https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html#a-first-step \
  仓库链接：https://github.com/AnswerDotAI/fsdp_qlora/tree/main

# 3.13 Wed
* 54.LLM将成历史？开源bGPT或颠覆深度学习范式：直接模拟二进制，开启模拟数字世界新纪元！  新智元  https://mp.weixin.qq.com/s/hy72E_6oSaRVC5Q-EwYAZg \
  Beyond Language Models: Byte Models are Digital World Simulators \
  论文：https://arxiv.org/abs/2402.19155 \
  代码：https://github.com/sanderwood/bgpt \
  模型：https://huggingface.co/sander-wood/bgpt \
  项目主页：https://byte-gpt.github.io
* 55.数学推理增强！微软 | 提出数据合成框架：KPDDS，微调Mistral-7B性能超34B模型！  AINLPer  https://mp.weixin.qq.com/s/V8Tz5X81FlOva9B6bCprqg \
  关键点驱动的数据合成（KPDDS）框架，旨在解决大型语言模型（LLMs）在数学推理任务中面临的数据质量和数量不足的问题。KPDDS的核心思想是利用关键点（Key Points, KPs）和示例对（exemplar pairs）从真实数据源中合成问答对，以提高数据的质量和可扩展性 \
  Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning \
  https://arxiv.org/pdf/2403.02333.pdf

# 3.14 Thur
* 56.AGI万字长文(上) | 2023回顾与反思  普通人的AI自由  https://mp.weixin.qq.com/s/GRCc4dbQWJ-jsdt97lFJxA \
  2023年大众对AI的看法：这是啥->好像也没那么厉害->和我没太大关系 \
  目前还没有看到阻止AGI出现的硬性限制，且我们距离AGI只有几年距离 \
  大模型的“想象力”、“取悦能力”比“逻辑能力”更早成熟 \
  应用层没有独角兽；创业者最大的敌人是GPT官方 \
  技术加速迭代是常态，不能等到“技术稳定”再出手 \
  多模态大爆发：再次证明了AGI相对“窄AI”的代际优越性 \
  Agent/代理暂时还没出现，记忆仍是瓶颈；核心问题是还没有“人的模型” \
  深度压缩是大模型的核心能力，端上智能越来越近 \
  中美AI生态各自发展，2023年技术差距没有缩小
* 57.AGI万字长文(下) | 2024，分叉与洪流  普通人的AI自由  https://mp.weixin.qq.com/s/8n8hEs0YTH9Q0xpbui7aBA \
  AI多模态大爆发：文字走脑->声音走心+视觉走肾 \
  AI应用是技术驱动的,（目前）产品能做的事情还很薄 \
  Sora本身不是目的，而是迈向AGI的坚实一步 \
  “互动”与“内容”都将变得廉价，而“真实”会成为一种稀缺资源 \
  “AI原生”是基于AI的能力来再造商业模式，而非用AI套用现有流程 \
  To AI的商业模式可能更确定：模型市场、合成数据、模型工程平台、模型安全 \
  基于国产芯片的软硬件联合优化-固件生态是明确的机会 \
  端上智能目前最大的想象空间是成为全天候硬件24x7收集数据 \
  AGI会造成极端垄断，并提供前所未有的中心化操控能力；作为个体，我们是否会有Plan-B可选？ \
  “人的模型”或是AI Agent的前提，是AI与人合作的关键一环 \
  “具身智能”是AGI通向物理世界的桥梁 \
  从“中美相争”进入“主权AI”？国际政治的边界将或按照AI技术边界来重新划分 \
  AI生成的数据量将超过全人类生产的数据总量：“数据编年史”进入“AI纪元” \
  AGI会主动投资的技术：可控核聚变、量子计算、超导、广义机器人
* 58.(**Figure 01**)能说会看会行动，OpenAI机器人，一出手就是王炸  机器之能  https://mp.weixin.qq.com/s/Ld0ZQdM6SFvte83BJ-EjlA \
  全球首个OpenAI机器人诞生！Figure 01碾压马斯克擎天柱，10亿机器人大军正式启动  机器学习研究组订阅  https://mp.weixin.qq.com/s/TMK6jDraw9oY9lekMiBfjA \
  参考链接： \
  https://twitter.com/i/status/1767913661253984474 \
  https://www.figure.ai/
* 59.智能体的ChatGPT时刻！DeepMind通用AI向人类玩家进化，开始理解游戏  机器之心  https://mp.weixin.qq.com/s/-GNZaY9vPQJCJUD7WGTjGA \
  谷歌宣布了又一项里程碑式研究：SIMA（Scalable Instructable Multiworld Agent），一种适用于 3D 虚拟环境的通用 AI 智能体。 \
  Scaling Instructable Agents Across Many Simulated Worlds \
  技术报告：https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/sima-generalist-ai-agent-for-3d-virtual-environments/Scaling%20Instructable%20Agents%20Across%20Many%20Simulated%20Worlds.pdf \
  参考链接： \
  https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/ \
  https://www.technologyreview.com/2024/03/13/1089764/an-ai-that-can-play-goat-simulator-is-a-step-towards-more-useful-ai/ \
  https://www.fastcompany.com/91058360/deepmind-new-ai-agent-video-games
* 60.4万亿晶体管5nm制程，全球最快AI芯片碾压H100！单机可训24万亿参数LLM，Llama 70B一天搞定  新智元  https://mp.weixin.qq.com/s/0dIrhiq7hz3Z3Ja7YRLdjg \
  AI芯片初创公司Cerebras重磅发布了「第三代晶圆级引擎」（WSE-3）。性能上，WSE-3是上一代WSE-2的两倍，且功耗依旧保持不变。 \
  参考资料：https://www.cerebras.net/
* 61.(**值得看看**)我们距离GPT-4V真的很近了吗？  PaperWeekly  https://mp.weixin.qq.com/s/sz0cfChe9SXh5wDWHN-UEA \
* 62.(**可以看看**)让Sora和ChatGPT更可靠！只需这个知识价值定量评估新框架  量子位  https://mp.weixin.qq.com/s/u1V6_8oY6nje5CTYSWI4ww \
  将规则和技巧等人类知识融入到ChatGPT、Sora等基于数据驱动的AI模型训练中，有可能提高模型的效率和推理能力。 \
  Worth of Prior knowledge for enhancing deep learning \
  参考链接： \
  https://www.eurekalert.org/news-releases/1036117 \
  https://www.cell.com/nexus/fulltext/S2950-1601(24)00001-9
* 63.UC伯克利：用大模型预测未来，准确率超越人类！  夕小瑶科技说  https://mp.weixin.qq.com/s/TAGWaQqBN0nLBN4Q1sts0Q \
  论文标题：Approaching Human-Level Forecasting with Language Models \
  论文链接：https://arxiv.org/pdf/2402.18563.pdf
* 64.(**有趣**)今日arXiv最热NLP大模型论文：大模型把《算法导论》学明白了！  夕小瑶科技说  https://mp.weixin.qq.com/s/ZiIZEqoxSgbZpQ1oXGjwhg \
  论文标题:Executing Natural Language-Described Algorithms with Large Language Models: An Investigation \
  论文链接:https://arxiv.org/pdf/2403.00795.pdf
* 65.数学推理增强，Xwin-Math利用合成数据解锁LLaMA-2-7B潜力！  AINLPer  https://mp.weixin.qq.com/s/rQDdKXwbqH8k-VPU7CT5qQ \
  《Common 7B Language Models Already Possess Strong Math Capabilities》 \
  论文链接：https://arxiv.org/pdf/2403.04706.pdf \
  代码链接：https://github.com/Xwin-LM/Xwin-LM

# 3.15 Fri
* 66.开源版OpenAI机器人2.5万打造！斯坦福李飞飞团队祭出「灵巧手」，泡茶剪纸炫技  新智元  https://mp.weixin.qq.com/s/KZtEVk3SgxJ8PoEkUOUX8Q \
  由Chen Wang、李飞飞和Karen Liu等人提出的「便携式手部动作捕捉系统」——DexCap \
  DexCap: Scalable and Portable Mocap Data Collection System for Dexterous Manipulation \
  论文地址：https://arxiv.org/abs/2403.07788 \
  参考资料：https://dex-cap.github.io/
* 67.仅需200M参数，零样本性能超越有监督！谷歌发布时序预测基础模型TimesFM  新智元  https://mp.weixin.qq.com/s/A4-2EzHEYlVYGYKBucyBXQ \
  TimesFM针对时序数据设计，输出序列长于输入序列，在1000亿时间点数据进行预训练后，仅用200M参数量就展现出超强零样本学习能力！ \
  参考资料：https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html
* 68.大模型如何处理知识冲突？清华等《大型语言模型中的知识冲突》综述  专知  https://mp.weixin.qq.com/s/BXbXDgx6I5TjIELvbYtvrw \
  Knowledge Conflicts for LLMs: A Survey \
  这篇综述深入分析了大型语言模型（LLMs）中的知识冲突问题，突出了它们在融合上下文和参数知识时遇到的复杂挑战。我们关注三类知识冲突：上下文记忆冲突、跨上下文冲突和内部记忆冲突。这些冲突可能显著影响LLMs的可信度和性能，特别是在噪声和误信息普遍存在的现实世界应用中。通过对这些冲突的分类、探索原因、检查LLMs在此类冲突下的行为，并回顾可用的解决方案，此综述旨在阐明提高LLMs鲁棒性的策略，因而为这一不断发展领域的研究进步提供了宝贵的资源。

# 3.16 Sat
* 69.(**LLM知识蒸馏综述**)总结374篇相关工作，陶大程团队联合港大、UMD发布LLM知识蒸馏最新综述  机器之心  https://mp.weixin.qq.com/s/2WwX7Nzpf-mxiJJczhB3yw \
  论文题目：A Survey on Knowledge Distillation of Large Language Models \
  论文链接：https://arxiv.org/abs/2402.13116 \
  项目链接：https://github.com/Tebmer/Awesome-Knowledge-Distillation-of-LLMs
* 70.(**有趣**)流浪地球里的数字生命计划启动了？DeepMind在电脑里造果蝇，网友：能造人吗？  机器之心  https://mp.weixin.qq.com/s/Qn10lSrwe-mvQVwNnsIm-Q \
  Whole-body simulation of realistic fruit fly locomotion with deep reinforcement learning \
  论文链接：https://www.biorxiv.org/content/10.1101/2024.03.11.584515v1 \
  参考链接：https://www.janelia.org/news/artificial-intelligence-brings-a-virtual-fly-to-life

# 3.17 Sun
* 71.(**！！！非常值得细看！！！**)从直观物理学谈到认知科学，Sora不是传统物理模拟器盖棺定论了？  机器之心  https://mp.weixin.qq.com/s/iko0DU8PJDzK_Bn5eBwLaA \
  ！！！值得深入研究 \
  《Mind's Eye: Grounded Language Model Reasoning through Simulation》\
  From Word Models to World Models: Translation from Natural Language to the Probabilistic Language of Thought \
  论文地址：https://arxiv.org/pdf/2306.12672.pdf \
  认知科学中有一个重要假设：人们使用直观物理引擎（intuitive physics engine，IPE）在心理上模拟物理事件。该引擎近似现实中的物理动力学，并类似于计算机游戏中的物理引擎。 \
  IPE: https://cicl.stanford.edu/papers/smith2023probabilistic.pdf
* 72.(**机器遗忘综述**)机器遗忘：分类、指标、应用、挑战与展望  专知  https://mp.weixin.qq.com/s/SK_nZgupTs4aPpgy61iGxg \
  Machine Unlearning: Taxonomy, Metrics, Applications, Challenges, and Prospects \
* 73.(**可以看看**)【CVPR2024】掩码自解码器是有效的多任务视觉通用模型  专知  https://mp.weixin.qq.com/s/DFciUo9OKpayTfseLB7HIQ \
  Masked AutoDecoder is Effective Multi-Task Vision Generalist \
  https://github.com/hanqiu-hq/MAD
  
# 3.18 Mon
* 74.马斯克开源Grok-1：3140亿参数迄今最大，权重架构全开放，磁力下载  机器之心  https://mp.weixin.qq.com/s/hvt5zwoazDx26KOaKuTs_w \
  项目地址 https://github.com/xai-org/grok-1
* 75.如何把大量物理知识塞给AI？EIT和北大团队提出「规则重要性」概念  ScienceAI  https://mp.weixin.qq.com/s/iFsM22z_LFEGw8bOgL2T8w \
  东方理工（EIT）和北京大学的研究团队提出了「规则重要性」的概念，并开发了一套框架，能精确计算每个规则对模型预测精度的贡献。该框架不仅揭示了数据和知识之间的复杂相互作用关系，为知识嵌入提供了理论性指导，还有助于在训练过程中平衡知识和数据的影响。此外，该方法还可用于识别不恰当的先验规则，为交叉学科领域的研究与应用提供广阔前景。\
  Worth of Prior Knowledge for Enhancing Deep Learning \
  论文链接：https://www.cell.com/nexus/fulltext/S2950-1601(24)00001-9 \
  AAAS 报道链接：https://www.eurekalert.org/news-releases/1036117
* 76.没等来OpenAI，等来了Open-Sora全面开源  机器之心  https://mp.weixin.qq.com/s/vdr1WBCQVr9aS6bJYcdlRA \
  别等OpenAI了，全球首个类Sora抢先开源！所有训练细节/模型权重全公开，成本仅1万美元  新智元  https://mp.weixin.qq.com/s/l3O6b4PReG6Ya-U7Awse6Q \
  全球首个类Sora开源复现方案来了！全面公开所有训练细节和模型权重  量子位  https://mp.weixin.qq.com/s/8UQTjOph5MDRNOSwH11ZAg \
  Colossal-AI 团队全面开源全球首个类 Sora 架构视频生成模型 「Open-Sora 1.0」，涵盖了整个训练流程，包括数据处理、所有训练细节和模型权重 \
  Open-Sora 开源地址：https://github.com/hpcaitech/Open-Sora
* 77.加速2-3倍，哈工大｜提出多模态大模型自适应剪枝算法：SmartTrim  AINLPer  https://mp.weixin.qq.com/s/StYG8XJAB8FpEvXKebLDMg \
  ???什么是自适应剪枝 \
  https://github.com/Duxiaoman-DI/XuanYuan
* 78.(**值得细看**)今日arXiv最热大模型论文：何恺明重提十年之争——模型表现好是源于能力提升还是捕获数据集偏见  夕小瑶科技说  https://mp.weixin.qq.com/s/4JC57Ddvp25NZ-x-6h4Flg \
  A Decade’s Battle on Dataset Bias: Are We There Yet? \
  https://arxiv.org/pdf/2403.08632.pdf
* 79.大模型如何用因果性？最新《大型语言模型与因果推断在协作中的应用》全面综述  专知  https://mp.weixin.qq.com/s/oAjZNsXPas39r3gqLN14HA \
  Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey \
  本综述集中于从因果视角评估和改进LLMs

# 3.19 Tue
* 80.(**ALaRM层次性奖励学习框架**)复旦发布层次性奖励学习框架，增强大模型人类偏好对齐  夕小瑶科技说  https://mp.weixin.qq.com/s/nZP_g3isSkX0v-EXaAIu8g \
  ALARM框架提出了一种整合全面奖励和特定方面奖励的方法，以提供更精确和一致的指导，从而更好地与人类偏好对齐 \
  论文标题：ALaRM: Align Language Models via Hierarchical Rewards Modeling \
  论文链接：https://arxiv.org/pdf/2403.06754.pdf 
* 81.(**文生图综述**)可控图像生成最新综述！北邮开源20页249篇文献，包揽Text-to-Image Diffusion领域各种「条件」  新智元  https://mp.weixin.qq.com/s/zLs-dWiNLsxXqiTXCofnpg \
  Controllable Generation with Text-to-Image Diffusion Models: A Survey \
  论文：https://arxiv.org/abs/2403.04279
* 82.arXiv今日精品AI论文：硅心理学——构建AI的心智模型  大噬元兽  https://mp.weixin.qq.com/s/5wQCpPuNu-jJASLoY5rA9w \
  《Silico-centric Theory of Mind》\
  （论文链接：https://arxiv.org/pdf/2403.09289.pdf）\
  这篇论文正是在这样的背景下产生的。它不仅关注AI如何理解人类，更进一步探讨了AI如何理解和预测其他AI实体的行为和决策。这项研究的主题具有前瞻性，它试图解答一个根本问题：AI是否能够发展出一种基于其硅基结构的心智理论，从而在没有人类直接干预的情况下，独立地与其他AI实体进行有效的交流和协作

# 3.20 Wed
* 83.今日arXiv最热NLP大模型论文：大模型RAG新宠！浙江大学发布自反馈检索增强方法  夕小瑶科技说  https://mp.weixin.qq.com/s/I59sXKzFWBh-8O8P_OMwsw \
  本研究提出了一种新的框架——检索增强迭代自反馈（RA-ISF），通过迭代处理问题，结合自知识模块、文本相关性模块和问题分解模块，以提高模型的问题解决能力 \
  论文标题：RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback \
  论文链接：https://arxiv.org/pdf/2403.06840.pdf 
* 84.大模型如何用于游戏？游戏玩家代理与大模型综述：方法、应用与挑战  专知  https://mp.weixin.qq.com/s/bVf3U0_yvJ6LzYYRU4XybA \
  A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges
* 85.如何从头开始编写LoRA代码，这有一份教程  机器之心  https://mp.weixin.qq.com/s/gRd-6WHL_2MQrPYNSr06FQ \
  这篇教程的作者是知名机器学习与 AI 研究者 Sebastian Raschka，他表示在各种有效的 LLM 微调方法中，LoRA 仍然是自己的首选。为此，Sebastian 专门写了一篇博客《Code LoRA From Scratch》，从头开始构建 LoRA，在他看来，这是一种很好的学习方法 \
  原文链接：https://lightning.ai/lightning-ai/studios/code-lora-from-scratch?continueFlag=f5fc72b1f6eeeaf74b648b2aa8aaf8b6

# 3.21 Thur
* 86.老黄再曝惊人语录：LLM幻觉有解，AGI五年内必来！  新智元  https://mp.weixin.qq.com/s/pWPccIDzsCo13bsYaXcKCw \
  参考资料：https://techcrunch.com/2024/03/19/agi-and-hallucinations/
* 87.(**值得看看**)CVPR 2024 | 一统所有目标感知任务，华科&字节提出目标感知基础模型GLEE  机器之心  https://mp.weixin.qq.com/s/zy-WSc6nJlOVsXISEWBOXw \
  论文标题：GLEE: General Object Foundation Model for Images and Videos at Scale \
  论文地址：https://arxiv.org/abs/2312.09158 \
  代码地址：https://github.com/FoundationVision/GLEE \
  Demo 地址：https://huggingface.co/spaces/Junfeng5/GLEE_demo \
  视频地址：https://www.bilibili.com/video/BV16w4m1R7ne/
* 88.(**可以看看**)能否在追问中坚持判断？揭秘大语言模型的判断一致性挑战  PaperWeekly  https://mp.weixin.qq.com/s/1c5CN-SGd6_xG3B_IkD3Sw \
  论文标题：Ask Again, Then Fail: Large Language Models' Vacillations in Judgement \
  论文地址：https://arxiv.org/abs/2310.02174 \
  项目网站：https://github.com/NUSTM/LLMs-Waver-In-Judgements \
  数据集地址：https://huggingface.co/datasets/NUSTM/judgement-consistency-preference-data
* 89.大模型微调新范式：当LoRA遇见MoE  PaperWeekly  https://mp.weixin.qq.com/s/t_X8AHFgi-RHuviTuCYv0Q
* 90.腾讯发布自研游戏AI引擎：3D城市布局效率提升百倍，UGC工具已上线《元梦之星》  量子位  https://mp.weixin.qq.com/s/9dnetjm4Q6aKlK9CYG01Yg 
* 91.超越 GPT-4V 和 Gemini Pro！HyperGAI 发布最新多模态大模型 HPT，已开源  夕小瑶科技说  https://mp.weixin.qq.com/s/-7Tz3g7cOV05rOyfA6XsvA \
  HyperGAI 研究团队推出了 HPT（Hyper-Pretrained Transformers）系列，包含两个模型，HPT Air 和 HPT Pro。 \
  其中HPT Pro 在部分基准测试中已经超越了 GPT-4V 和 Gemini Pro 的表现。同时，高效的版本 HPT Air 也相当强大，在同等小规模的模型中效果达到了最优，且已经开源。 \
  项目地址：Github: https://github.com/hyperGAI/HPT \
  huggingface: https://huggingface.co/HyperGAI/HPT
* 92.(**非常值得看看**)IBM | 提出具有「情景记忆」的大模型：Larimar，无需训练，可快速更新模型知识！  AINLPer  https://mp.weixin.qq.com/s/qgEhoGL59V9X1urMAyfBaw \
  Larimar: Large Language Models with Episodic Memory Control \
  https://arxiv.org/pdf/2403.11901.pdf

# 3.22 Fri
* 93.吴恩达：AI智能体工作流今年将有巨大进展，可能超过下一代基础模型  机器之心  https://mp.weixin.qq.com/s/O4uh-2IqS0KdUy_k1mBeow \
  吴恩达分享了一个对构建智能体的设计模式进行分类的框架: \
  反思：LLM 检查自己的工作，以提出改进方法。 \
  工具使用：LLM 拥有网络搜索、代码执行或任何其他功能来帮助其收集信息、采取行动或处理数据。 \
  规划：LLM 提出并执行一个多步骤计划来实现目标（例如，撰写论文大纲，然后进行在线研究，然后撰写草稿......）。 \
  多智能体协作：多个 AI 智能体一起工作，分配任务并讨论和辩论想法，以提出比单个智能体更好的解决方案。\
  参考链接：https://twitter.com/AndrewYNg/status/1770897666702233815 \
  https://www.deeplearning.ai/the-batch/issue-241/
* 94.一口气读完《沙丘》 ，零一万物宝藏API正式开箱！酷炫Demo实测，多模态中文图表体验超越GPT-4V  新智元  https://mp.weixin.qq.com/s/3LO63pwvD3t-TNERYyDHeA \
  平台地址：https://platform.lingyiwanwu.com/playground
* 95.Sora不开源，微软给你开源！全球最接近Sora视频模型诞生，12秒生成效果逼真炸裂  新智元  https://mp.weixin.qq.com/s/GkJwyVFVwxih-ZQWWBIuNg \
  Mora: Enabling Generalist Video Generation via A Multi-Agent Framework \
  论文地址：https://arxiv.org/abs/2403.13248
* 96.游戏NPC“活”了，英伟达AI立大功  量子位  https://mp.weixin.qq.com/s/MjtDpRjYiN38rFFuo4jszA 

# 3.23 Sat

# 3.24 Sun
* 97.(**值得玩玩**)32K上下文，Mistral 7B v0.2 基模型突然开源了  机器之心  https://mp.weixin.qq.com/s/R56Ob5dZjMh1alhMin8DZw \
  下载链接：https://models.mistralcdn.com/mistral-7b-v0-2/mistral-7B-v0.2.tar \
  参考链接：https://twitter.com/MistralAILabs/status/1771670765521281370
* 98.(**值得研究**)CNN、Transformer、Uniformer之外，我们终于有了更高效的视频理解技术  机器之心  https://mp.weixin.qq.com/s/XmW8Fk3PWVwIFUnRZyyqNg \
  VideoMamba: State Space Model for Efficient Video Understanding \
  论文地址：https://arxiv.org/pdf/2403.06977.pdf \
  项目地址：https://github.com/OpenGVLab/VideoMamba \
  论文标题：VideoMamba: State Space Model for Efficient Video Understanding
* 99.(**可以看看**)大模型自身无法推理/规划！ASU | 提出LLM-Modulo框架，可充分发挥LLMs潜力！  AINLPer  https://mp.weixin.qq.com/s/25RVOKmG6d4ndobshXFCpA \
  「本文作者核心观点是：大语言模型（LLMs）自身无法进行规划推理」，但是却能在解决规划问题上发挥积极的作用。为此，作者还提出了一个新的LLM-Modulo框架，这个框架把大型语言模型和一些外部的验证工具结合起来，使LLMs在规划任务中发挥了重要作用 \
  LLM-Modulo框架的基础架构是一个生成-测试-批评循环 \
  LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks \
  https://arxiv.org/pdf/2402.01817.pdf

# 3.25 Mon
* 100.(**非常重要，务必看看**)今日arXiv最热NLP大模型论文：微软重磅：AgentAI，下一代人工智能的关键  夕小瑶科技说  https://mp.weixin.qq.com/s/IBrK53WeOCcw5LQJQ5M5rA \
  论文标题:Position Paper: Agent AI Towards a Holistic Intelligence \
  论文链接:https://arxiv.org/pdf/2403.00833.pdf
* 101.通用文档理解新SOTA，多模态大模型TextMonkey来了  机器之心  https://mp.weixin.qq.com/s/UMemsDJ2mSSoZvUx73iSSw \
  TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document \
  论文链接：https://arxiv.org/abs/2403.04473
  代码地址：https://github.com/Yuliang-Liu/Monkey
* 102.首个AI游戏引擎或颠覆任天堂/暴雪？0代码即可创建，黄仁勋预测5-10年游戏完全由AI生成  新智元  https://mp.weixin.qq.com/s/xFOn5cZGo8Hxe4EtNz3zog \
  参考资料：\
  https://x.com/FinanceYF5/status/1770705820520706541?s=20 \
  https://gamefromscratch.com/buildbox-4-announced-ai-powered-3d-game-engine/ \
  https://www.tomshardware.com/pc-components/gpus/rtx-off-ai-on-jensen-says-well-see-fully-ai-generated-games-in-5-10-years
* 103.【CVPR2024】用于视觉-语言导航的体积环境表示  专知  https://mp.weixin.qq.com/s/pT26IpmObIuH4LnhmeftcQ \
  Volumetric Environment Representation for Vision-Language Navigation 

# 3.26 Tue
* 104.【新书】ChatGPT与大型语言模型(LLMs)的提示工程：通过有效的提示设计增强ChatGPT响应  专知  https://mp.weixin.qq.com/s/Wt1--DqHAfRvuHqh8zCdXQ \
  Prompt Engineering for ChatGPT & LLMs
* 105.代码大模型有何进展？《神经代码智能》最新综述：范式、进步与未来  专知  https://mp.weixin.qq.com/s/oHWL76WxHDvHA_vbcPyPUA

# 3.27 Wed
# 3.28 Thur
# 3.29 Fri
# 3.30 Sat
# 3.31 Sun
