# 3.1 Fri
* 1.OpenAI把GPT塞进机器人大脑，具身AGI奇点迫近！英伟达微软参投26亿美金独角兽Figure  新智元  https://mp.weixin.qq.com/s/OQkJFksgBDf1YjrvOgNB7A
* 2.(**值得看看**)2024！深入了解 大语言模型（LLM）微调方法（总结）  AINLPer  https://mp.weixin.qq.com/s/Kig_vbAdiGJ1oALiPe-O_Q

# 3.2 Sat
* 3.今日Arxiv最热NLP大模型论文：Llama-2上下文扩大48倍的方法来了，港大发布，无需训练  夕小瑶科技说  https://mp.weixin.qq.com/s/0aDk8BQZPD8xGEJs4Gc7Sw \
  论文标题：Training-Free Long-Context Scaling of Large Language Models \
  论文链接：https://arxiv.org/pdf/2402.17463.pdf 
* 4.香港大学发布思维扩散DoT，让思维在时间上扩散，提效保质！  夕小瑶科技说  https://mp.weixin.qq.com/s/lD4RgRhf3z1HOtE_r0Codg \
  标题：Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models \
  论文链接:https://arxiv.org/pdf/2402.07754.pdf
* 5.(**重要学习资料**)大模型理论基础(so-large-lm)课程笔记！  Datawhale  https://mp.weixin.qq.com/s/MZiVMcDEq3Mkm9tFmaN_7A \
  https://github.com/datawhalechina/so-large-lm

# 3.3 Sun
* 6.北大发起复现Sora，框架已搭！袁粒田永鸿领衔，AnimateDiff大神响应  量子位  https://mp.weixin.qq.com/s/DRulMeZETAApD1P28EhxGw \
  Open Sora项目主页： \
  https://pku-yuangroup.github.io/Open-Sora-Plan/blog_cn.html \
  https://github.com/PKU-YuanGroup/Open-Sora-Plan
* 7.(**可以看看**)北大具身智能成果入选CVPR'24：只需一张图一个指令，就能让大模型玩转机械臂  量子位  https://mp.weixin.qq.com/s/YTvN6VDmP9aSxvI5M3YVCg \
  更多细节可查看论文原文： \
  https://arxiv.org/pdf/2312.16217.pdf \
  和项目主页： \
  https://sites.google.com/view/manipllm \
  ManipLLM: Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation
* 8.(**非常值得看看**)大视频模型是世界模型？DeepMind/UC伯克利华人一作：预测下一帧就能改变世界  新智元  https://mp.weixin.qq.com/s/pMzISIodXUO92cik8uJS7Q \
  论文地址：https://arxiv.org/abs/2402.17139 \
  Video as the New Language for Real-World Decision Making
* 9.(**非常值得看看**)给AI Agent完整的一生！港大NYU谢赛宁等最新智能体研究：虚拟即现实  新智元  https://mp.weixin.qq.com/s/YMHjCaJ0Si7u0yTHBjmPRQ \
  论文地址：https://arxiv.org/abs/2402.03310 \
  代码地址：https://github.com/VIRL-Platform/VIRL \
  V-IRL: Grounding Virtual Intelligence in Real Life
* 10.(**可以看看**)清华、哈工大把大模型压缩到了1bit，把大模型放在手机里跑的愿望就快要实现了！  机器之心  https://mp.weixin.qq.com/s/sAf-S9utl3gjUVgCOlPVPA \
  论文标题：OneBit: Towards Extremely Low-bit Large Language Models \
  论文地址：https://arxiv.org/pdf/2402.11295.pdf \
  相关论文： \
  [1] Dettmers T, Lewis M, Belkada Y, et al. Llm. int8 (): 8-bit matrix multiplication for transformers at scale [J]. arXiv preprint arXiv:2208.07339, 2022. \
  [2] Frantar E, Ashkboos S, Hoefler T, et al. GPTQ: Accurate post-training quantization for generative pre-trained transformers [J]. arXiv preprint arXiv:2210.17323, 2022. \
  [3] Wang H, Ma S, Dong L, et al. Bitnet: Scaling 1-bit transformers for large language models [J]. arXiv preprint arXiv:2310.11453, 2023.
* 11.(**Griffin\Hawk**)RNN效率媲美Transformer，谷歌新架构两连发：同等规模强于Mamba  机器之心  https://mp.weixin.qq.com/s/RtAZiEzjRWgqQw3yu3lvcg \
  再超Transformer！Google| 提出两个新模型(Griffin、Hawk)，强于Mamba，更省资源  AINLPer  https://mp.weixin.qq.com/s/R34tP32pUrRRGh-6NXlzXQ \
  DeepMind携Mamba华人作者推Transformer革命之作！性能暴涨媲美Llama 2，推理能效大幅碾压  新智元  https://mp.weixin.qq.com/s/-FKQsQcTbBq1RT4Oh4Buyw \
  论文标题：Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models \
  论文链接：https://arxiv.org/pdf/2402.19427.pdf
* 12.十年内出现AGI？下一代Gemini能感知环境？DeepMind CEO哈萨比斯畅谈AI  机器之心  https://mp.weixin.qq.com/s/MMaeLRpo37Ot_9P5mjj5wg \
  DeepMind CEO：LLM+树搜索就是AGI技术线路，AI科研依赖工程能力，闭源模型就是比开源安全  新智元  https://mp.weixin.qq.com/s/MrGnETtEgVE091DqYAxXJw 
* 13.(**MobileVLM V2**)端侧实时运行、3B媲美7B！美团、浙大等提出MobileVLM V2：更快、更强的端侧视觉语言模型  PaperWeekly  https://mp.weixin.qq.com/s/WPLWmxkjlc6_2sn8ToHBqg \
  论文地址：https://arxiv.org/abs/2402.03766 \
  模型地址：https://huggingface.co/mtgv \
  代码地址：https://github.com/Meituan-AutoML/MobileVLM \
  MobileVLM V2: Faster and Stronger Baseline for Vision Language Model
* 14.港中文深圳提出ALLaVA-4V：百万级别的开源多模态GPT-4V数据集  PaperWeekly  https://mp.weixin.qq.com/s/otxd8rEVy2kw2mHzb0JFBA \
  论文题目：ALLaVA: Harnessing GPT4V-synthesized Data for A Lite Vision-Language Model \
  论文链接：https://arxiv.org/abs/2402.11684 \
  数据链接：https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V \
  代码链接：https://github.com/FreedomIntelligence/ALLaVA \
  Demo链接：https://allava.freedomai.cn/#/

# 3.4 Mon
* 15.(**GITQA**)7B模型超越GPT4-V！港科大等发布「图推理问答」数据集GITQA：视觉图可提升推理能力  新智元  https://mp.weixin.qq.com/s/YOlwd_JOmj2tyS1pdCo5fA \
  论文地址：https://arxiv.org/abs/2402.02130 \
  项目主页：https://v-graph.github.io/
* 16.CVPR 2024满分论文：浙大提出基于可变形三维高斯的高质量单目动态重建新方法  机器之心  https://mp.weixin.qq.com/s/W9cPvgK_2H4WqiyM5-BATw \
  项目主页：https://ingra14m.github.io/Deformable-Gaussians/ \
  论文链接：https://arxiv.org/abs/2309.13101 \
  代码：https://github.com/ingra14m/Deformable-3D-Gaussians
* 17.(**DUSt3R**)2张图2秒钟3D重建！这款AI工具火爆GitHub，网友：忘掉Sora  量子位  https://mp.weixin.qq.com/s/x9tBrILl8y6klQ3mwDHgOA \
  传送门： \
  [1]论文https://arxiv.org/abs/2312.14132  \
  [2]代码https://github.com/naver/dust3r
* 18.(**LearnAct**)今日arXiv最热大模型论文：北京大学发布，将试错引入大模型代理学习！   夕小瑶科技说  https://mp.weixin.qq.com/s/dtsR5lkkELJlh0i4TzuX0Q \
  LearnAct框架的核心理念是通过学习扩展和精炼行动空间，从而更紧密地与代理的规划能力相结合。\
  论文标题: Empowering Large Language Model Agents through Action Learning \
  论文链接:https://arxiv.org/pdf/2402.15809.pdf
* 19.具身智能中的多模态三维感知思考  OpenMMLab  https://mp.weixin.qq.com/s/cOkeYYjaWRPX-3-8oS6C2g \
  EmbodiedScan：首个多模态、基于第一视角的真实场景三维感知数据集 \
  Embodied Perceptron：适配任意帧输入的统一基线框架 \
  论文：https://arxiv.org/abs/2312.16170 \
  项目：http://tai-wang.github.io/embodiedscan \
  代码：https://github.com/OpenRobotLab/EmbodiedScan \
  比赛：https://opendrivelab.com/challenge2024/#multiview_3d_visual_grounding \
  
# 3.5 Tue
* 20.
* 21.
* 22.
* 23.
* 24.
* 25.
* 26.
* 27.
* 28.

# 3.6 Wed
# 3.7 Thur
# 3.8 Fri
# 3.9 Sat
# 3.10 Sun
# 3.11 Mon
# 3.12 Tue
# 3.13 Wed
# 3.14 Thur
# 3.15 Fri
# 3.16 Sat
# 3.17 Sun
# 3.18 Mon
# 3.19 Tue
# 3.20 Wed
# 3.21 Thur
# 3.22 Fri
# 3.23 Sat
# 3.24 Sun
# 3.25 Mon
# 3.26 Tue
# 3.27 Wed
# 3.28 Thur
# 3.29 Fri
# 3.30 Sat
# 3.31 Sun
