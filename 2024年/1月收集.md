# 1.1 Mon
* 1、（**值得玩玩**）Github揽获3k+星！清华开源CogAgent：基于多模态大模型的GUI Agent  PaperWeekly  https://mp.weixin.qq.com/s/ZXbEpSCFG90qz0uwHJ6cJQ \
  论文名称：CogAgent: A Visual Language Model for GUI Agents \
  论文链接：https://arxiv.org/pdf/2312.08914.pdf \
  GitHub项目地址（含开源模型、网页版Demo）: https://github.com/THUDM/CogVLM \
  CogAgent 是一个通用的视觉理解大模型，具备视觉问答、视觉定位（Grounding）、GUI Agent 等多种能力，在 9 个经典的图像理解榜单上（含 VQAv2，STVQA, DocVQA，TextVQA，MM-VET，POPE 等）取得了通用能力第一的成绩，并在涵盖电脑、手机的GUI Agent数据集上（含 Mind2Web，AITW 等），大幅超过基于 LLM 的 Agent，取得第一。为了更好地促进多模态大模型、Agent 社区的发展，我们已将 CogAgent-18B 开源至 GitHub 仓库（可商用），并提供了网页版 Demo。欢迎大家体验、使用与反馈！ \
* 2、（**务必看看**）基础模型+机器人：现在已经走到哪一步了  机器之心  https://mp.weixin.qq.com/s/n774PtQZn3XzJ7cb7WAV9Q \
  论文名称：Toward General-Purpose Robots via Foundation Models:A Survey and Meta-Analysis \
  论文地址：https://arxiv.org/pdf/2312.08782.pdf \
* 3、（**值得看看**）你没有看过的全新版本，Transformer数学原理揭秘  机器之心  https://mp.weixin.qq.com/s/i0vNZoqWejmFFPUMR4qo5w \
  揭秘 Transformer 的数学原理！  AINLPer  https://mp.weixin.qq.com/s/qVZqwpD7ngdSX-UzIj68hw \
  论文名称：A MATHEMATICAL PERSPECTIVE ON TRANSFORMERS \
  论文地址：https://arxiv.org/pdf/2312.10794.pdf
* 4、Mamba可以替代Transformer，但它们也能组合起来使用  机器之心  https://mp.weixin.qq.com/s/X4NCoSObAZTjyl0GpYUtpQ \
  论文名称：Block-State Transformers \
  论文地址：https://arxiv.org/pdf/2306.09539.pdf
* 5、通往具身通用智能：如何让机器从自然模态中学习到世界模型？  专知  https://mp.weixin.qq.com/s/9Lk77mgpvtHmqs3hd6iKqQ 

# 1.2 Tue
* 6、Hyena成下一代Transformer？StripedHyena-7B开源：最高128k输入，训练速度提升50%  新智元  https://mp.weixin.qq.com/s/dHDtfOkX1RVj6-bZVVUKlg

# 1.3 Wed
* 7、面向超长上下文，大语言模型如何优化架构，这篇综述一网打尽了  机器之心  https://mp.weixin.qq.com/s/VrV3E_SKTbpjJBfFyirvhA \
  论文链接：https://arxiv.org/pdf/2311.12351.pdf
* 8、(**牛逼，值得看看**)维基百科+大模型打败幻觉！斯坦福WikiChat性能碾压GPT-4，准确率高达97.3%   新智元  https://mp.weixin.qq.com/s/5fDBx9eLS9Q7nw3ZZiccKw \
  碾压GPT-4！斯坦福 | 发布WikiChat聊天机器人，准确率达97.3%  AINLPer  https://mp.weixin.qq.com/s/zX5bo1gvCI_nFKnjkg1Dwg \
  论文名称：WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia \
  论文地址：https://aclanthology.org/2023.findings-emnlp.157.pdf \
  项目代码：https://github.com/stanford-oval/WikiChat \
  Demo地址：https://wikichat.genie.stanford.edu/

# 1.4 Thu
* 9、斯坦福炒虾机器人爆火全网！华人团队成本22万元，能做满汉全席还会洗碗  新智元  https://mp.weixin.qq.com/s/i9VQJXxQI9uXpsrtyAlTOQ
* 10、首创pix2emb范式！NUS清华联合发布NExT-Chat：对话/检测/分割全能多模态大模型  新智元  https://mp.weixin.qq.com/s/BgDRskXV6HFBWwP9_M31Ew \
  多模态对话模型Demo：https://next-chatv.github.io/ \
  论文：https://arxiv.org/pdf/2311.04498.pdf \
  代码：https://github.com/NExT-ChatV/NExT-Chat \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b71b9937-f67f-43c7-b3e5-fe81fc23ef38)
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5d9fc943-005e-4c34-a9f6-e0424e4d3c3a)
* 11、GPT-4V开源平替！清华浙大领衔，LLaVA、CogAgent等开源视觉模型大爆发  新智元  https://mp.weixin.qq.com/s/LDVgCTvUcfnMX4Dl78gDHg
* 12、吴恩达最新推出基于大模型的《AI高级检索》课程，限时免费白嫖！  夕小瑶科技说  https://mp.weixin.qq.com/s/8GZPnm8tq2Dqgvj1iAfNAw \
  课程名是 《Advanced Retrieval for AI with Chroma》，即 《使用 Chroma 进行 AI 高级检索》 ，这里面Chroma 是一个 AI 原生开源嵌入数据库。
* 13、(**值得看看，什么叫LLM知识编辑**)如何编辑大模型中的知识？浙大等最新《大型语言模型知识编辑》全面综述  专知  https://mp.weixin.qq.com/s/vJwoQPVqNDWqfe8vpI7StA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d4b278d4-4da4-49dd-8523-ddd30b56871f)
  
# 1.5 Fri
* 14、谷歌DeepMind机器人成果三连发！两大能力全提升，数据收集系统可同时管理20个机器人  量子位  https://mp.weixin.qq.com/s/j7tviAf2DNbLxdIwC5rzWg \
  谷歌 DeepMind 机器人成果三连发，具身智能指日可待？  Founder Park  https://mp.weixin.qq.com/s/GF173SOD3HrO1Kl3Lxp6zQ \
  ![Uploading image.png…]()
  参考链接：https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/

# 1.6 Sat
* 15、《大型语言模型（LLMs）: 训练到推理》全面概述技术细节  专知 https://mp.weixin.qq.com/s/Pw_b0ndP1tFXuYc39pveOw \
  论文名称：understanding LLMs- A Comprehensive Overview from Training to Inference
* 16、模型A：幸亏有你，我才不得0分，模型B：俺也一样  机器学习研究组订阅  https://mp.weixin.qq.com/s/Q4z_dLoCeSn-d62So6TiVw \
  在大模型（LLM）爆发的当下，我们能不能像拼积木一样，把不同的模型搭建起来，而不会影响原来模型的功能，还能起到 1+1>2 的效果 \
  论文名称：LLM Augmented LLMs- Expanding Capabilities Through Composition \
  论文地址：https://arxiv.org/pdf/2401.02412.pdf \
  该研究是这样实现的，他们提出了一种新颖的 CALM（组合到增强语言模型 Composition to Augment Language Models）框架来解决模型组合设置。CALM 不是增强和 anchor LM 的浅层组合，而是在增强和 anchor 模型的中间层表示上引入了少量的可训练参数。

# 1.7 Sun
* 17、(**重要，值得看看**)万字长文再论大语言模型的位置编码及其外推性  PaperWeekly  https://mp.weixin.qq.com/s/xpvO169i8IhhgvNkcrtHow \

# 1.8 Mon
* 18、(**重要，值得看看**)以LLAMA为例，快速入门LLM的推理过程  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/5lbrqbqiHPZIARsVW6l6tA \
* 19、中科院最新工作：基于自步课程学习实现多模态大模型CLIP在多模态视觉语言理解与定位任务上的迁移研究
  论文CLIP-VG: Self-paced Curriculum Adapting of CLIP for Visual Grounding，其工作内容是基于自步课程学习实现多模态大模型CLIP在多模态视觉语言理解与定位任务上的迁移研究。\
  Arxiv：https://arxiv.org/abs/2305.08685 \
  代码：https://github.com/linhuixiao/CLIP-VG（已开源）
* 20、轻量级模型，重量级性能，TinyLlama、LiteLlama小模型火起来了  机器之心  https://mp.weixin.qq.com/s/qVFa2z9JJ6t6kTJlTubHfQ \
  论文名称：TinyLlama- An Open-Source Small Language Model \
  论文地址：https://arxiv.org/pdf/2401.02385.pdf \
  项目地址：https://github.com/jzhang38/TinyLlama/blob/main/README_zh-CN.md \
  LiteLlama:
  项目地址：https://huggingface.co/ahxt/LiteLlama-460M-1T
* 21、400万token上下文、推理再加速46%！最新开源方案升级MIT成果，推理成本再降低  量子位  https://mp.weixin.qq.com/s/fiYSESKcOgZIDe8dpLdAdQ \
  大模型无限流式输入推理飙升46%！国产开源加速「全家桶」，打破多轮对话长度限制  新智元  https://mp.weixin.qq.com/s/7aBzsiUjX-WHRzpY4IAU5A \
  开源地址：https://github.com/hpcaitech/SwiftInfer \
  Colossal-AI开源地址：https://github.com/hpcaitech/ColossalAI \
  参考链接：https://hpc-ai.com/blog/Colossal-AI-SwiftInfer \
  StreamingLLM可以在不牺牲生成效果、推理速度的前提下，实现多轮对话共400万个token，22.2倍推理速度提升。该项目在上线不到3个月时间内，GitHub项目标星达到5.7k star。不过，StreamingLLM使用原生PyTorch实现，对于多轮对话推理场景落地应用的低成本、低延迟、高吞吐等需求仍有优化空间。Colossal-AI团队开源了SwiftInfer，基于TensorRT的StreamingLLM，可以进一步提升大模型推理性能46%，有效解决如上问题
* 22、(**值得看看**)图解大模型计算加速系列：Flash Attention V1，从硬件到计算逻辑  吃果冻不吐果冻皮  https://mp.weixin.qq.com/s/J2i2MDv4us_GMwCyku0tnw
* 23、机器人又拿下一种家务：10小时学会煮咖啡，仅需观看人类演示视频  量子位  https://mp.weixin.qq.com/s/UnrKueHigPhIAthoLG2hGA

# 1.9 Tue
# 1.10 Wed
# 1.11 Thu
# 1.12 Fri
# 1.13 Sat
# 1.14 Sun

# 1.15 Mon
# 1.16 Tue
# 1.17 Wed
# 1.18 Thu
# 1.19 Fri
# 1.20 Sat
# 1.21 Sun

# 1.22 Mon
# 1.23 Tue
# 1.24 Wed
# 1.25 Thu
# 1.26 Fri
# 1.27 Sat
# 1.28 Sun

# 1.29 Mon
# 1.30 Tue
# 1.31 Wed
