# 2.1 Thu
* 1.新语言模型出现！Eagle7B：基于线性Transformer，推理成本降低10-100 倍！  AINLPer  https://mp.weixin.qq.com/s/RFC-QQ_RE8QoUSvAzlTAnw \
  基于 RWKV-v5 架构构建，该架构的推理成本较低（RWKV 是一个线性 transformer，推理成本降低 10-100 倍以上）；

# 2.2 Fri
* 2.大模型如何处理长上下文？亚马逊等最新《 大型语言模型中上下文长度扩展技术》综述  机器学习研究组订阅  https://mp.weixin.qq.com/s/PUrUOzoNUUx8P3jMx0K94w
* 3.加速知识检索：伯克利&DeepMind联合研究，RaLMSpec让语言模型服务飞速提升2-7倍！  夕小瑶科技说  https://mp.weixin.qq.com/s/N5bkQw6xlb8peAMlbXPrNA \
  论文题目:Accelerating Retrieval-Augmented Language Model Serving with Speculation \
  论文链接:https://arxiv.org/abs/2401.14021
* 4.今日arXiv最热NLP大模型论文：像人一样浏览网页执行任务，腾讯AI lab发布多模态端到端Agent  夕小瑶科技说  https://mp.weixin.qq.com/s/kFJ2BUftNQAQpSlimUAu0g \
  腾讯AI lab提出了一种新的多模态网络Agent——WebVoyager，旨在以端到端的方式在线处理网络任务，即在没有人工介入的情况下从开始到结束自主管理整个过程。\
  论文标题：WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models \
  论文链接：https://arxiv.org/pdf/2401.13919.pdf
* 5.阿里全新Agent玩转手机：刷短视频自主点赞评论，还学会了跨应用操作  量子位  https://mp.weixin.qq.com/s/bt2VNschheVL413mSV5guw \
  具体来说，Mobile-Agent基于最强多模态大模型GPT-4V实现。通过视觉感知模块，Mobile-Agent从设备的屏幕截图中准确定位视觉和文本元素文本和图标。这一过程涉及到使用OCR工具和CLIP模型来确定图标的位置。通过这些视觉信息，Mobile-Agent能够将语言模型生成的操作指令映射到具体的屏幕位置，从而执行点击等操作。\
  GitHub主页：https://github.com/X-PLUG/MobilAgent \
  论文地址：https://arxiv.org/abs/2401.16158
* 6.1元=1700000tokens！清华系发布国产Mistral仅2B，老手机都带得动，GitHub一天斩获300+星  量子位  https://mp.weixin.qq.com/s/tLjETnaLWrrvimUPDcS2yA \
  开源地址（内含技术报告）： \
  MiniCPM GitHub：https://github.com/OpenBMB/MiniCPM \
  OmniLMM GitHub：https://github.com/OpenBMB/OmniLMM
* 7.匿名论文提出奇招！增强大模型长文本能力居然还能这么做  量子位  https://mp.weixin.qq.com/s/V9C0s4HR2cQinz1Bgrjsiw \
  一提到提高大模型长文本能力，就想到长度外推或者上下文窗口扩展？ \
  不行，这些都太费硬件资源了。 \
  来看一个奇妙新解： \
  和长度外推等方法使用KV缓存的本质不同，它用模型的参数来存储大量上下文信息。 \
  具体办法就是建一个临时Lora模块，让它仅在长文本生成过程中“流式更新”，也就是用先前生成的内容不断作为输入来充当训练数据，以此保证知识被存进模型参数中。 \
  然后一旦推理完成，就丢掉它，保证不对模型参数产生长久影响。 \
  这个方法可以让我们不用扩展上下文窗口的同时，随便存储上下文信息，想存多少存多少。\
  论文： https://arxiv.org/abs/2401.11504
* 8.UCLA华人提出全新自我对弈机制！LLM自己训自己，效果碾压GPT-4专家指导  新智元  https://mp.weixin.qq.com/s/ORZCxa97y-Hn8yme97eBTA \
  论文地址：https://arxiv.org/abs/2401.01335v1
* 9.（值得看看）图灵奖Yann LeCun最新《目标驱动的人工智能：走向能够学习、推理和计划的机器》，附Slides与视频  专知  https://mp.weixin.qq.com/s/mZxUG_YoIA8hd2MibbmEAA \
  https://www.ece.uw.edu/news-events/lytle-lecture-series/

# 2.3 Sat
* 10.（值得试试）史上首个100%开源大模型重磅登场！破纪录公开代码/权重/数据集/训练全过程，AMD都能训  新智元  https://mp.weixin.qq.com/s/v-xCzo6j7sfVK5SF9iLg_A \
  AllenAI 开源了关于大模型的所有细节！数据、代码、参数、训练过程，完全复现  夕小瑶科技说  https://mp.weixin.qq.com/s/BtcVlIlEaC9Spn2wrv8tpw \
  艾伦人工智能研究所推出的这个开放大语言模型（Open Language Model，OLMo）实验和训练平台，则提供了一个完全开源的大模型，以及所有和训练开发这个模型有关的数据和技术细节 \
  论文：https://allenai.org/olmo/olmo-paper.pdf \ 
  权重：https://huggingface.co/allenai/OLMo-7B \
  代码：https://github.com/allenai/OLMo \
  数据：https://huggingface.co/datasets/allenai/dolma \
  评估：https://github.com/allenai/OLMo-Eval \
  适配：https://github.com/allenai/open-instruct
* 11.（值得看看）ICLR 2024 | LLM Agent领域第一高分论文，全网Star数最高的多智能体框架  PaperWeekly  https://mp.weixin.qq.com/s/InH6N4xZG4DriF4mLsF7zQ \
  Agent像人一样分工协作，还能“群聊”交换信息｜ICLR2024 Oral  量子位  https://mp.weixin.qq.com/s/s5teEWlbcfHCVFjy6Nb3AQ \
  MetaGPT 创新性地将 SOPs 编码为智能体的设计规范和协议，进而实现了人类领域知识的自动嵌入。这一工作为更好地理解和模拟人类工作流程提供了新的途径，为自主智能体在各种任务中的表现和适应性带来了新的可能性。 \
  论文题目：MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework \
  论文链接：https://arxiv.org/abs/2308.00352 \
  代码链接：https://github.com/geekan/MetaGPT
* 12.《大型视觉语言模型中的幻觉现象》综述  专知  https://mp.weixin.qq.com/s/pPZLySMH5WpHhFG9ytGJrg 

# 2.4 Sun

# 2.5 Mon
* 13.CMU&ETH实现突破：机器狗点满敏捷值天赋，超高速穿越障碍，速度与安全兼备！  机器之心  https://mp.weixin.qq.com/s/A8m8asq9ErAcyPQBlj9yPw \
  CMU 与 ETH Zurich 团队联合研发了一个名为 「敏捷但安全」（ABS，Agile But Safe）的新框架，为四足机器人在复杂环境中实现高速运动提供了解决方案。ABS 不仅在避免碰撞方面展现出高效能力，还在极速上达到了前所未有的 3.1 米秒 \
  论文地址: https://arxiv.org/pdf/2401.17583.pdf

# 2.6 Tue
* 14.向完全自主性更进一步，清华、港大全新跨任务自我进化策略让智能体学会「以经验为鉴」  机器之心  https://mp.weixin.qq.com/s/21NmR5ufFSnRYkS_-eXszg \
  近年来，GPT 和 LLaMA 等语言模型展示了他们在解决复杂任务时的惊人能力。然而，他们尽管可以利用工具解决具体任务，但在本质上缺乏对过去成功和失败经历的洞见与汲取。这就像一个只会完成特定任务的机器人，虽然在完成当下任务上表现出色，但面对新的挑战时，却无法调用过去的经验来提供帮助。\
  针对这一难题，近期来自清华大学、香港大学、人民大学以及面壁智能的联合团队提出了一种全新的智能体自我演化策略：探索 - 固化 - 利用（Investigate-Consolidate-Exploit，ICE）。它旨在通过跨任务的自我进化来提升 AI 智能体的适应性和灵活性。其不仅能提升智能体处理新任务时的效率和效果，还能显著降低对智能体基座模型能力的需求。\
  论文标题：Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution \
  论文链接：https://arxiv.org/abs/2401.13996

# 2.7 Wed

# 2.8 Thu
* 15.（务必进行研究）机器人领域首个开源视觉-语言操作大模型，RoboFlamingo框架激发开源VLMs更大潜能  机器之心  https://mp.weixin.qq.com/s/rJ5nuV4Og_2BWJbLncHOiw \
  项目主页：https://roboflamingo.github.io \
  代码地址：https://github.com/RoboFlamingo/RoboFlamingo \
  论文地址：https://arxiv.org/abs/2311.01378
* 16. （可以看看）斯坦福炒虾机器人帮你戴隐形，偷钱包被抓现行！联手DeepMind重磅升级，华人领衔19万元成本全开源  新智元  https://mp.weixin.qq.com/s/nr-DEPyclWkJ5OPXhKn_SQ \
  一个月前，斯坦福爆火炒菜机器人Mobile ALOHA，在今天全新升级二代ALOHA 2！ \
  论文地址：https://aloha-2.github.io/assets/aloha2.pdf

# 2.9 Fri
* 17.3B模型不输7B LLaVA！北大多模态MoE模型登GitHub热榜  量子位  https://mp.weixin.qq.com/s/NSfAdIBXNzG9WNrz9jP1eA \
  Github: https://github.com/PKU-YuanGroup/MoE-LLaVA \
  论文地址: https://arxiv.org/abs/2401.15947 \
  Demo: https://huggingface.co/spaces/LanguageBind/MoE-LLaVA

# 2.10 Sat
# 2.11 Sun

# 2.12 Mon
* 18.（非常有趣）开源AGI智能体人人可养成：AGI对齐新思路，让智能体在人类世界中接受训练  新智元  https://mp.weixin.qq.com/s/VJGGFdO3hPLKw9bzY9FBAw \
  一位网友根据Karpathy曾经构想过的一个AGI智能体构架，创建了一个开源的智能体，命名为Samantha。 \
  借助GPT-4V的能力，她可以做到： \
  -动态交流：Samantha可以根据上下文和想法的影响随时说话。与仅限于回复用户提示词的的普通LLM完全不一样，Samantha可以主动采取行动，发起聊天，完成某些具体的任务。 \
  -实时视觉能力：支持多模态信息的输入，输入视觉效果仅在上下文相关时才会被Samantha提及，并采取相应的行动，但总是会引起Samantha影响思想和行为。 \
  -外部分类内存：由Samantha动态写入和读取，它选择最相关的信息进行写入并检索到上下文。 \
  -每时每刻都在学习和演变：存储在记忆中的经历可以影响和塑造Samantha随后的行为，如性格、频率和言语风格等。 \
  项目地址：https://github.com/BRlkl/AGI-Samantha \
  参考资料：https://twitter.com/Schindler___/status/1745986132737769573
  <img width="548" alt="1708315436886" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2689ff50-b86a-4e83-aada-af01fc580b18">
* 19.三年16篇一作，前谷歌研究科学家Yi Tay官宣新模型，21B媲美Gemini Pro、GPT-3.5  机器之心  https://mp.weixin.qq.com/s/vPqv0wBR6_sv8jKQRrhbfQ \
  参考链接：https://reka.ai/reka-flash-an-efficient-and-capable-multimodal-language-model/
* 20.（可以看看）《基础模型在现实世界机器人应用》综述  专知  https://mp.weixin.qq.com/s/s39_lq9aSGnuXHRcW0zbjQ \
  Real-World Robot Application of Foundation Models: A Review

# 2.13 Tue

# 2.14 Wed
* 21.英伟达官宣AI聊天机器人，本地RTX显卡运行，这是要挑战OpenAI？  机器之心  https://mp.weixin.qq.com/s/DmRe3pa2xhEL_yxdGbxUJg \
  下载地址：https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/ \
  与 ChatGPT 等需要联网使用的聊天机器人不同，Chat with RTX 可以在本地运行，帮你检索、分析保存在电脑上的文件（支持文本、PDF、.doc、.docx 和 .xml 等格式）。比如，你可以问它「在拉斯维加斯时，我的搭档推荐了哪家餐厅？」Chat with RTX 将扫描你指向的本地文件，并提供带有上下文的答案。
* 22.ChatGPT有记忆了！OpenAI官宣记忆功能开启测试，奥特曼称GPT-5更智能  新智元  https://mp.weixin.qq.com/s/SINusNr9K6g4R7bY8Qea7g \
  参考资料：\
  https://openai.com/blog/memory-and-new-controls-for-chatgpt \
  https://twitter.com/AndrewCurran_/status/1757424866398175407
  
# 2.15 Thu
* 23.下一代Windows系统曝光：基于GPT-4V，Agent跨应用调度，代号UFO  量子位  https://mp.weixin.qq.com/s/gd_t2XI4HJ56Od2D2r3vTQ \
  参考链接： \
  [1]https://github.com/microsoft/UFO \
  [2]https://arxiv.org/abs/2402.07939 \
  [3]https://twitter.com/_akhaliq/status/1757625641724215585

# 2.16 Fri

# 2.17 Sat
* 24.(**SoRA太火了**)一锤降维！解密OpenAI超级视频模型Sora技术报告，虚拟世界涌现了  新智元  https://mp.weixin.qq.com/s/ODsebK3fEc-adRDwRVDhQA \
  真·降维打击，Sora与Runway、Pika的对比来了，震撼效果背后是物理引擎模拟现实世界  机器之心  https://mp.weixin.qq.com/s/_ckq6uZyvRgZvJJKVeZZ2w \
  OpenAI超级视频模型Sora技术报告解读，虚拟世界涌现了  夕小瑶科技说  https://mp.weixin.qq.com/s/qhr6D7LZMVo36rO0qVrOng \
  报告地址：https://openai.com/research/video-generation-models-as-world-simulators
* 25.(**值得看看**)今日Arxiv最热大模型论文：大语言模型真的理解上下文了吗？新研究揭示惊人发现  夕小瑶科技说  https://mp.weixin.qq.com/s/72bIuoVqafauVjiUOYZLxw \
  "实验结果表明，预训练的密集模型在理解更微妙的上下文特征方面存在困难，尤其是与最新的微调模型相比。其次，随着LLMs压缩在研究和实际应用中的重要性日益增加，评估了在上下文学习设置下量化模型的上下文理解能力。我们发现，3位后训练量化导致我们基准上的性能不同程度的降低。我们对这些场景进行了广泛的分析，以支持实验结果。" \
  论文标题：Can Large Language Models Understand Context? \
  论文链接：https://arxiv.org/pdf/2402.00858.pdf

# 2.18 Sun
* 26.(**值得看看**)Sora背后的32篇技术论文  一支烟一支花  https://mp.weixin.qq.com/s/LJlJXcN0nQJeslj-ynP7wQ \
* 27.(**非常值得看看**)LeCun怒斥Sora不能理解物理世界！Meta首发AI视频「世界模型」V-JEPA  新智元  https://mp.weixin.qq.com/s/s_vMMHaCRpAd-twq3eoq2A \
  "我们的目标是打造出能够像人类那样学习的先进机器智能（AMI），通过构建对周遭世界的内在模型来学习、适应和高效规划，以解决复杂的任务。" \
  接下来，LeCun更详细地解释道：虽然可以想象出的视频种类繁多，但视频生成系统只需创造出「一个」合理的样本就算成功。而对于一个真实视频，其合理的后续发展路径就相对较少，生成这些可能性中的具代表性部分，尤其是在特定动作条件下，难度大得多。此外，生成这些视频后续内容不仅成本高昂，实际上也毫无意义。更理想的做法是生成那些后续内容的「抽象表示」，去除与我们可能采取的行动无关的场景细节。这正是JEPA（联合嵌入预测架构）的核心思想，它并非生成式的，而是在表示空间中进行预测。\
  然后，他用自家的研究VICReg、I-JEPA、V-JEPA以及他人的工作证明：与重建像素的生成型架构，如变分自编码器（Variational AE）、掩码自编码器（Masked AE）、去噪自编码器（Denoising AE）等相比，「联合嵌入架构」能够产生更优秀的视觉输入表达。当使用学习到的表示作为下游任务中受监督头部的输入（无需对主干进行微调），联合嵌入架构在效果上超过了生成式架构。\
  人类对于周遭世界的认识，特别是在生命的早期，很大程度上是通过「观察」获得的。就拿牛顿的「运动第三定律」来说，即便是婴儿，或者猫，在多次把东西从桌上推下并观察结果，也能自然而然地领悟到：凡是在高处的任何物体，终将掉落。\
  这种认识，并不需要经过长时间的指导，或阅读海量的书籍就能得出。可以看出，你的内在世界模型——一种基于心智对世界的理解所建立的情景理解——能够预见这些结果，并且极其高效。Yann LeCun表示，V-JEPA正是我们向着对世界有更深刻理解迈出的关键一步，目的是让机器能够更为广泛的推理和规划。\
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/36b54566-4968-4dfb-97e8-7fa54ba5d2ba) \
  V-JEPA通过预测学习潜空间中被隐藏的时空区域来训练视觉编码器 \
  在抽象的表示空间中进行预测非常关键，因为它让模型专注于视频内容的高层概念，而不必担心通常对完成任务无关紧要的细节。\
  V-JEPA的研究表明，就可以一次性预训练模型，不依赖任何标记数据，然后将模型用于多个不同的任务，如动作分类、细粒度物体交互识别和活动定位，开辟了全新的可能。\
  少样本冻结评估：V-JEPA在标注使用效率上优于其他模型，尤其是当每个类别可用的标注样本减少时，V-JEPA与其他模型之间的性能差距更加明显。\
  在文本或视频中生成看似有趣的内容并不意味着（也不需要）它「理解」自己生成的内容。一个能够基于理解进行推理的智能体模型必须，绝对是在大模型或扩散模型之外。\
  论文地址：https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning-visual-representations-from-video/ \
  参考资料：https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/ \

# 2.19 Mon
* 28.(**非常值得看看**)揭秘Sora技术路线：核心成员来自伯克利，基础论文曾被CVPR拒稿  机器之心  https://mp.weixin.qq.com/s/_HyZTyrN95Ys6ZFJzY-mkg \
  Sora 背后的重要技术基础之一:《Scalable diffusion models with transformers》  \
  论文链接：https://arxiv.org/abs/2212.09748 \
  Sora 成功的背后，还有哪些重要技术？ \
  1、论文标题：World Models \
  作者：David Ha、Jurgen Schmidhuber \
  机构：谷歌大脑、NNAISENSE（Schmidhuber 创立的公司）、Swiss AI Lab \
  论文链接：https://arxiv.org/pdf/1803.10122.pdf \
  2、论文标题：VideoGPT: Video Generation using VQ-VAE and Transformers \
  作者：Wilson Yan、Yunzhi Zhang、Pieter Abbeel、Aravind Srinivas \
  机构：UC 伯克利 \
  论文链接：https://arxiv.org/pdf/2104.10157.pdf \
  3、论文标题：NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion \
  作者：Chenfei Wu、Jian Liang、Lei Ji、Fan Yang、Yuejian Fang、Daxin Jiang、Nan Duan \
  机构：微软亚洲研究院、北京大学 \
  论文链接：https://arxiv.org/pdf/2111.12417.pdf \
  4、论文标题：Masked autoencoders are scalable vision learners  \
  论文链接：https://arxiv.org/abs/2111.06377 \
  5、论文标题：High-resolution image synthesis with latent diffusion models \
  论文链接：https://arxiv.org/pdf/2112.10752.pdf \
  6、论文标题：Photorealistic Video Generation with Diffusion Models \
  论文链接：https://arxiv.org/pdf/2312.06662.pdf 
* 29.100万token，一次能分析1小时YouTube视频，「大世界模型」火了  机器之心  https://mp.weixin.qq.com/s/8ONe7_ejQQIT1UwqDGK-vg \
  论文标题：WORLD MODEL ON MILLION-LENGTH VIDEO AND LANGUAGE WITH RINGATTENTION \
  论文地址：https://arxiv.org/pdf/2402.08268.pdf \
  项目主页：https://github.com/LargeWorldModel/LWM?tab=readme-ov-file
* 30.Sora到底懂不懂物理世界？一场头脑风暴正在AI圈大佬间展开  机器之心  https://mp.weixin.qq.com/s/r_dSOWaV-bZbL8WanLg4rg \
  Sora不懂物理世界，翻车神图全网爆笑！LeCun马斯克DeepMind大佬激辩世界模型  新智元  https://mp.weixin.qq.com/s/mbT7O3HfVzSkGKai3pQu2Q \
  Chollet 认为，不能简单地通过拟合大量数据（如游戏引擎渲染的图像或视频）来期望得到一个能够泛化到现实世界所有可能情况的模型。这是因为现实世界的复杂性和多样性远超过任何模型能够通过有限数据学习到的。\
  有人将这种行为类比为人类做梦，认为 Sora 其实只是达到了人类做梦的水平，但是逻辑能力依然不行。\
  其他观点：Sora 被认为是「数据驱动的物理引擎」太荒谬。\
* 31.AI配音版Sora视频刷屏！绝美逼真音效打破「无声电影」，或颠覆万亿美元产业  新智元  https://mp.weixin.qq.com/s/OEaDx6UpHvE8I3oChG5odQ \
* 32.(**消除疑点，生成与嵌入任务**)大模型如何统一生成和嵌入？最新《生成式表示指令微调》论文详细解答  专知  https://mp.weixin.qq.com/s/FiWBGS2DCHGI1X409RLHLg \
  大模型如何统一生成和嵌入？最新《生成式表示指令微调》论文详细解答  机器学习研究组订阅  https://mp.weixin.qq.com/s/Uc4CohqSsQt1zd1YfcHioA \
  所有基于文本的语言问题都可以归结为生成任务或嵌入任务。 \
  大型语言模型（Large Language Models, LLMs）已成为单一多任务模型的有希望方向 \
  ???没搞明白，生成任务 与 嵌入任务 具体有啥区别 \
  论文：Generative Representational Instruction Tuning 
* 33.(**完全不懂？？？**)【阿姆斯特丹博士论文】神经网络表示中的结构约束，125页pdf  专知  https://mp.weixin.qq.com/s/UriO7eJOFUFgZ2wTMESxKQ \
  这篇论文探讨了对神经网络表示的结构性约束，作为在神经网络中编码先验知识的一种方式。神经网络已经证明具有处理感知数据的卓越能力，通过映射感知实体并预测缺失或未来信息。尽管它们在建模方面表现出色，但神经网络不编码或表示一般知识或概念，并且通常不提供对被建模对象的理解或洞察。一种可能的使用神经网络作为允许科学分析和理解的工具的方式是，探讨将先验概念知识与从数据中提取的感知信息相结合的方法。这篇论文检验了图分割、子集、离散变量和微分方程作为特定的结构性约束，对神经网络表示进行约束，以表示先验知识，目的是使神经网络更加可解释和可分析。\
* 34.Sora模型只有3B | 笔记  未尽研究  https://mp.weixin.qq.com/s/kp9RJMAEr3R8K5mKp8hYUA \
  Sora理论基础，论文作者解释原理  隐藏的AI工具箱  https://mp.weixin.qq.com/s/wQfo-N-AOSpi2EKH4OpFBA \
  Sora技术报告中最重要的一篇论文:"Scalable diffusion models with transformers."  
* 35、RNN模型挑战Transformer霸权！1%成本性能比肩Mistral-7B，支持100+种语言全球最多  机器学习研究组订阅  https://mp.weixin.qq.com/s/zkmrKm6MmZ37c3ClPod4Zw \
  近日，RWKV发布了Eagle 7B模型，基于最新的RWKV-v5架构。\
  Eagle 7B在多语言基准测试中，击败了所有的同级别模型，在单独的英语测试中，也和表现最好的模型基本打平。\
  同时，Eagle 7B用的是RNN架构，相比于同尺寸的Transformer模型，推理成本降低了10-100倍以上，可以说是世界上最环保的7B模型。\
  论文：RWKV：Reinventing RNNS for the Transformer Era \
  论文地址：https://arxiv.org/pdf/2305.13048.pdf

# 2.20 Tue
* 36.LoRA再升级！英伟达 | 提出权重分解低阶适应：DoRA，极大的增强模型学习能力  AINLPer  https://mp.weixin.qq.com/s/PYFfcvD3bMmc1m6zcYH2SA \
  本文提出了权重分解低阶适应（DoRA），增强了 LoRA 的学习能力和训练稳定性，同时避免了任何额外的推理开销，实验表明DoRA 在各种下游任务上的模型微调都要优于LoRA \
  https://arxiv.org/pdf/2402.09353.pdf
* 37.为什么说Sora是世界的模拟器？  新智元  https://mp.weixin.qq.com/s/4Vj1FAzMOxbXYnYs7JdtTA \
* 38.爆火Sora震惊威尔·史密斯，真人整活吃意面视频！OpenAI技术路线或早在1月被成功预言  新智元  https://mp.weixin.qq.com/s/HzMEVnz101Lt44htjbyRPw \
  Patch n'Pack: NaViT, A Vision Transfomrer for any Aspect Ratio and Resolution \
  论文地址：https://arxiv.org/abs/2307.06304 \
  An Image is Worth 16x16 Words Transformers for Image Recognition at Scale \
  论文地址：https://arxiv.org/abs/2010.11929
* 39.在Sora引爆视频生成时，Meta开始用Agent自动剪视频了，华人作者主导  机器学习研究组订阅  https://mp.weixin.qq.com/s/c4iog5YSyezXTm67duzBOA \
  论文标题：LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing \
  论文地址：https://arxiv.org/pdf/2402.10294.pdf
* 40.图解RoPE旋转位置编码及其特性  图解RoPE旋转位置编码及其特性  https://mp.weixin.qq.com/s/K4osgj9GDzSNTuOByTqBNg 

# 2.21 Wed
* 41.一文带你了解OpenAI Sora  腾讯技术工程  https://mp.weixin.qq.com/s/Efk-gP8iuau3crWB2wWizg
* 42.成功！马斯克官宣首个Neuralink脑机接口人类，意念操控鼠标，全民机器人时代来了？  新智元  https://mp.weixin.qq.com/s/pxDX5r7eYtNWQZHQORpKSw \
  论文地址：https://www.nature.com/articles/s41586-023-06094-5?CJEVENT=215c0ea5d05511ee81b700340a18ba72 \
  参考资料：\
  https://www.nature.com/articles/d41586-024-00481-2 \
  https://www.businessinsider.com/neuralink-elon-musk-first-human-patient-control-mouse-with-mind-2024-2
* 43.独家｜世界模拟器才是AGI终局，12态势预测！首席专家万字长文专业解读Sora里程碑  新智元  https://mp.weixin.qq.com/s/MENP7swULpDJ2ywizHjghA
* 44.逐步思考还是死记硬背？探索大语言模型多跳知识推理中潜在的事实捷径  PaperWeekly  https://mp.weixin.qq.com/s/bEA554H46BVtlVDn6wtkWg \
  论文题目: Investigating Multi-Hop Factual Shortcuts in Knowledge Editing of Large Language Models \
  论文链接：https://arxiv.org/pdf/2402.11900.pdf \
  本文分析了大语言模型推理多跳知识问题时潜在的事实捷径，这些捷径会诱导模型直接得到多跳知识的跨步答案而不进行逐步推理。我们证明了这些捷径与预训练阶段模型接受的语料高度相关，并对知识编辑后模型的推理一致性产生了灾难性的危害，我们提出了一种简单但有效的事后缓解策略，并呼吁在预训练阶段限制这些捷径的产生，要求大模型与人类的思维模式对齐。

# 2.22 Thu
* 45.(**有空可以看看**)模型融合、混合专家、更小的LLM，几篇论文看懂2024年LLM发展方向  机器之心  https://mp.weixin.qq.com/s/qImKOQXLoZqLTW-SVISKHA \
* 46.开源大模型王座易主！谷歌Gemma杀入场，笔记本可跑，可商用  机器之心  https://mp.weixin.qq.com/s/_iCYfqmXA3enKn3Hm-DwSA \
  Gemma 官方页面：https://ai.google.dev/gemma/ \
  本次发布包含两种权重规模的模型：Gemma 2B 和 Gemma 7B。每种规模都有预训练和指令微调版本。其中 70 亿参数的模型用于 GPU 和 TPU 上的高效部署和开发，20 亿参数的模型用于 CPU 和端侧应用程序。\
  技术报告链接：https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf
* 47.为什么号称模拟世界的Sora，处理不好一些简单的物理规律？  AIGC开放社区  https://mp.weixin.qq.com/s/Talo7ksQpjPD36GGNiExpg \
* 48.(**一个知识库，有一些重要资料，值得翻一翻**)通往AGI之路  WaytoAGI.com  https://waytoagi.feishu.cn/wiki/QPe5w5g7UisbEkkow8XcDmOpn8e
* 49.(**diffusion综述**)爆火Sora背后的技术，一文综述扩散模型的最新发展方向  机器学习研究组订阅  https://mp.weixin.qq.com/s/TzKvSJWQMesfTidBf6SVmw
  
# 2.23 Fri
* 50.Stable Diffusion 3深夜横空出世！模型与Sora同架构，也能「理解」物理世界  新智元  https://mp.weixin.qq.com/s/PU_VCbFU29rkfgoIm2as0g \
* 51.符尧大佬一作发文，仅改训练数据，就让LLaMa-2上下文长度扩展20倍！  夕小瑶科技说  https://mp.weixin.qq.com/s/sTxoxhyG6mAm5fI8tKdMPw \
* 52.今日arXiv最热NLP大模型论文：无需提示也能推理！Google DeepMind新研究揭示AI内在推理能力  夕小瑶科技说  https://mp.weixin.qq.com/s/E1D1_9AuJcFSeeaX3QeIAQ \
  论文标题:Chain-of-Thought Reasoning Without Prompting \
  CoT-decoding是一种新的解码方法，它能够从预训练的大语言模型（LLMs）中激发出推理能力，而无需依赖于传统的提示技术。
  
# 2.24 Sat
# 2.25 Sun
# 2.26 Mon
# 2.27 Tue
# 2.28 Wed
# 2.29 Thu
