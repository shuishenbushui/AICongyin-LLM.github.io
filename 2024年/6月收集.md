# 6.1 Sat

# 6.2 Sun
* 1.多模态大模型不够灵活，谷歌DeepMind创新架构**Zipper**：分开训练再「压缩」  机器之心  https://mp.weixin.qq.com/s/F8wstkJyYiNJCbSqYq3Pbw \
  论文标题：Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities \
  论文链接：https://arxiv.org/pdf/2405.18669

# 6.3 Mon
* 2.next-token被淘汰！Meta实测「多token」训练方法，推理提速3倍，性能大涨10%+  新智元  https://mp.weixin.qq.com/s/rUBktCIL6BgTAbdod72MrQ \
  Better & Faster Large Language Models via Multi-token Prediction \
  论文链接：https://arxiv.org/pdf/2404.19737
* 3.英伟达新研究：上下文长度虚标严重，32K性能合格的都不多  量子位  https://mp.weixin.qq.com/s/pNUT8_T5YMJXrzLbzUi9ww \
  RULER: What's the Real Context Size of Your Long-Context Language Models? \
  论文链接：https://arxiv.org/abs/2404.06654
* 4.ICML2024高分！魔改注意力，让小模型能打两倍大的模型  量子位  https://mp.weixin.qq.com/s/MdXJaurs2Yn59In4FQyVpQ \
  Improving Transformers with Dynamically Composable Multi-Head Attention \
  Arxiv 论文链接：https://arxiv.org/abs/2405.08553 \
  代码链接：https://github.com/Caiyun-AI/DCFormer 

# 6.4 Tue
* 5.再战Transformer！原作者带队的Mamba 2来了，新架构训练效率大幅提升  机器之心  https://mp.weixin.qq.com/s/31t6pJqcXrZDjT6XiJZC_g \
  论文地址：https://arxiv.org/pdf/2405.21060 \
  GitHub 地址：https://github.com/state-spaces/mamba \
  论文标题：Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality
* 6.单个4090可推理，2000亿稀疏大模型「天工MoE」开源  机器之心  https://mp.weixin.qq.com/s/h5bxuWca65t3LsQwqGq-Og 
* 7.LeCun新作：分层世界模型，数据驱动的人型机器人控制  新智元  https://mp.weixin.qq.com/s/BxhvxpM66JGtbR2KgYYtBg \
  Hierarchical World Models as Visual Whole-Body Humanoid Controllers \
  论文地址：https://arxiv.org/pdf/2405.18418 \
  项目介绍：https://nicklashansen.com/rlpuppeteer
* 8.多模态模型学会打扑克：表现超越GPT-4v，全新强化学习框架是关键  量子位  https://mp.weixin.qq.com/s/bAf-5NzOD3fdTwYzdKsELw \
  Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning \
  论文地址：https://arxiv.org/abs/2405.10292 \
  GitHub：https://github.com/RL4VLM/RL4VLM
* 9.重温被Mamba带火的SSM：线性系统和HiPPO矩阵  PaperWeekly  https://mp.weixin.qq.com/s/tIYTNqdkiXhdgcWO3OI-8A

# 6.5 Wed
* 10.李飞飞高徒 Jim Fan：具身智能的难点不是硬件，而是「Foundation Agent」  图灵人工智能  https://mp.weixin.qq.com/s/hiJKt8_FifNwqUP5163vTw
* 11.GLM-4开源版本终于来了：超越Llama3，多模态比肩GPT4V，MaaS平台也大升级  机器之心  https://mp.weixin.qq.com/s/MqxiXeYs8dg_lynsUIR0Tg \
  杀疯了！全面超越Llama3的强悍开源模型，仅9B，1000k上下文；GPT-4级别模型1年降价1万倍  夕小瑶科技说  https://mp.weixin.qq.com/s/ITSDWHCvnAY7XHUCODzbxw 
* 12.腾讯混元&北大| 发现「**浪涌现象**」，解决学习率调参难题  AINLPer  https://mp.weixin.qq.com/s/ElpyTzDgnTQRcqbyn_PUTg
* 13.绝绝子！UT| 提出新型大模型微调架构：**LOFIT**，相比LoRA，学习参数减少200倍！！  AINLPer  https://mp.weixin.qq.com/s/_3Yi0o2mhrdPmeiauxwKZA
* 14.【ETHZ博士论文】有限数据中的元学习先验：从理论到实践  专知  https://mp.weixin.qq.com/s/KSXznLnMJ1zp0WhRZTj0pw

# 6.6 Thur
* 15.首次证实白盒Transformer可扩展性！马毅教授CRATE-α：鲸吞14亿数据，性能稳步提升  新智元  https://mp.weixin.qq.com/s/0Ps_9BVHDulpEprlb-3sgg \
  Scaling White-Box Transformers for Vision \
  论文链接：https://arxiv.org/pdf/2405.20299  \
  项目链接：https://rayjryang.github.io/CRATE-alpha/
* 16.作为人工智能下一个关口的意识研究：从加扎尼加的意识学说切入  神经现实  https://mp.weixin.qq.com/s/lF30iooZSCKTk0iyg_CAhQ \
  《意识本能》

# 6.7 Fri
* 17.ACL 2024 | 让纯LLM实现类人的符号逻辑推理能力，开源框架SymbCoT来了  机器之心  https://mp.weixin.qq.com/s/qYDBKHQmJg4TKXgwIoaapQ \
  论文：Faithful Logical Reasoning via Symbolic Chain-of-Thought \
  论文地址：https://arxiv.org/pdf/2405.18357.pdf \
  代码地址：https://github.com/Aiden0526/SymbCoT
* 18.(**重要，自监督选择性搜索**)大语言模型何时需要检索？UCLA提出全新自监督选择性检索策略  PaperWeekly  https://mp.weixin.qq.com/s/1fGt0egAYYa36EMWSzRD6g 
* 19.(**值得看看**)OpenAI新作署名Ilya，提取1600万个特征看透GPT-4大脑！  新智元  https://mp.weixin.qq.com/s/nx1LkHMkQbgeO6xU3fuc2w \
  Scaling and evaluating sparse autoencoders \
  论文地址：https://cdn.openai.com/papers/sparse-autoencoders.pdf
* 20.全球开源新王Qwen2-72B诞生，碾压Llama3-70B击败国产闭源模型！AI圈大佬转疯了  新智元  https://mp.weixin.qq.com/s/H6BbNfBNhyJTWs4ML6K1CQ 

# 6.8 Sat
* 21.轻松构建聊天机器人、准确性新SOTA，RAG有了更强大的AI检索器  机器之心  https://mp.weixin.qq.com/s/Ic12BIYK13mIPnFbkxk-Ww \
  denser-retriever \
  GitHub地址：https://github.com/denser-org/denser-retriever/tree/main \
  博客地址：https://denser.ai/blog/denser-retriever/
* 22.Llama3-8B秒杀700亿巨兽？北大博士生等全新「**BoT**」框架推理暴涨70倍，24点图形推理一步成神  新智元  https://mp.weixin.qq.com/s/wdtM2o1KzLahaW-rPUr7Mg \
  思维缓冲区（Buffer of Thoughts，BoT） \
  北大、UC伯克利、斯坦福的研究人员提出了一种元缓冲区（meta-buffer）。它可以存储一系列信息丰富的高级思维，也就是所谓的「思维模板」，它是从各种任务的问题解决过程中蒸馏出来的 \
  论文地址：https://arxiv.org/abs/2406.04271
* 23.To Believe or Not to Believe？DeepMind新研究一眼看穿LLM幻觉  新智元  https://mp.weixin.qq.com/s/MurapI7vQVRqMhX8W_neeA \
  如果无法强迫LLM坚持输出真实信息，知道它什么时候在胡说八道也很重要。 \
  To Believe or Not to Believe Your LLM \
  论文地址：https://arxiv.org/abs/2406.02543

# 6.9 Sun
* 24.从LLM中完全消除矩阵乘法，效果出奇得好，10亿参数跑在FPGA上接近大脑功耗  机器之心  https://mp.weixin.qq.com/s/HUvGGug48nGBx067nCbkag \
  论文地址：https://arxiv.org/pdf/2406.02528 \
  项目地址：https://github.com/ridgerchu/matmulfreellm \
  论文标题：Scalable MatMul-free Language Modeling
* 25.可信度超越GPT-4V，清华&面壁揭秘「小钢炮」模型背后的高效对齐技术  机器之心  https://mp.weixin.qq.com/s/7otafJLrrj4jlZIltQxcjQ \
  论文：RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V Trustworthiness \
  论文地址: https://arxiv.org/abs/2405.17220 \
  项目地址：https://github.com/RLHF-V/RLAIF-V \
  DEMO：https://huggingface.co/spaces/openbmb/RLAIF-V-12B

# 6.10 Mon
* 26.Karpathy最新四小时视频教程：从零复现GPT-2，通宵运行即搞定  机器之心  https://mp.weixin.qq.com/s/BI8EdDyTEk8meL_FhX-ftw \
   GitHub 地址：https://github.com/karpathy/build-nanogpt
* 27.(**重要**)大模型在持续学习中的最新进展：综述  专知  https://mp.weixin.qq.com/s/yQcZnLG9hFeBgPV-trQOsA \
  https://arxiv.org/pdf/2405.18653
* 28.两句话，让LLM逻辑推理瞬间崩溃！最新「爱丽丝梦游仙境」曝出GPT、Claude等重大缺陷  新智元  https://mp.weixin.qq.com/s/iLGMOQOS-xHqsXLVfstguQ \
  对此，LeCun也在第一时间转评道：「再次强调，推理能力和常识不应与存储和大致检索大量事实的能力混为一谈。」\
  Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models \
  论文地址：https://arxiv.org/abs/2406.02061 \
  开源地址：https://github.com/LAION-AI/AIW 
  

# 6.11 Tue
* 29.赋予机器人思考能力！北大提出**自纠正多模态大模型**，赋能端到端机器人操作 
 PaperWeekly  https://mp.weixin.qq.com/s/tOBBV00wHaMPoqmg9y54ZQ \
  项目主页：https://sites.google.com/view/sc-mllm-web \
  Github链接：https://github.com/2644521362/SC-MLLM \
  论文链接：https://arxiv.org/pdf/2405.17418 \
  Self-Corrected Multimodal Large Language Model for End-to-End Robot Manipulation
* 30.【CMU博士论文】构建自适应性强的通用机器人，248页pdf  专知  https://mp.weixin.qq.com/s/louXBjjF3-V4FI-zjwhizg 

# 6.12 Wed
* 31.ICML 2024 哈佛大学最新研究：越强的大模型越不懂人类  夕小瑶科技说  https://mp.weixin.qq.com/s/XfoD6INP-nC3Nth9tPKuHg \
  论文题目：Do Large Language Models Perform the Way People Expect? Measuring the Human Generalization Function \
  论文链接：http://arxiv.org/abs/2406.01382
* 32.复旦字节强强联手，量身定制多模态思维链，让7B模型全面超越GPT-4V  夕小瑶科技说  https://mp.weixin.qq.com/s/Co5PV5fGS85XV7-NHWdzoA \
  论文标题：VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large Multi-Modal Models  \
  论文链接：https://arxiv.org/abs/2405.16919 \
  VoCoT 具有两个关键特征：（1）以对象为中心的推理路径，围绕跨模态共享的对象级信息展开，以及（2）以多模态交叉和对齐的方式对对象概念进行视觉上的表征，有效地弥合了 LMM 在长文本过程中的模态差异。
* 33.手机流畅运行470亿大模型：上交大发布LLM手机推理框架PowerInfer-2，提速29倍  量子位  https://mp.weixin.qq.com/s/vylZp7MG7TA3pQKOBWbYRQ
* 34.((**重要**)港大&腾讯 | 提出SELF-TUNING学习框架，让LLM自学获取新知识，表现出色！  AINLPer  https://mp.weixin.qq.com/s/-FTbJYMbCyiQXyTZ6BHjaA \
  SELF-TUNING: Instructing LLMs to Effectively Acquire New Knowledge 
 through Self-Teaching \
  https://arxiv.org/pdf/2406.06326

# 6.13 Thur
* 35.GPT-4尚未出现自我意识！这项研究用「上帝之点」解读，迈向AGI局限无法克服  新智元  https://mp.weixin.qq.com/s/dhH6CsVqo6sNFLBklLW4Gg \
  Flight Model: New Explorations into the Fundamental Principles of Intelligence and Consciousness \
  论文地址：http://dx.doi.org/10.13140/RG.2.2.24518.28484

# 6.14 Fri

# 6.15 Sat

# 6.16 Sun
* 36.(**重要**)ACL 2024论文盖棺定论：大语言模型≠世界模拟器，Yann LeCun：太对了  机器之心  https://mp.weixin.qq.com/s/FBqYb_gcBr5D204mDtmCOA \
  GPT-4不是世界模型，LeCun双手赞同！ACL力证LLM永远无法模拟世界  新智元  https://mp.weixin.qq.com/s/-YjuaZ44SnVEsooYJea0Qw \
  Can Language Models Serve as Text-Based World Simulators? \
  论文地址：https://arxiv.org/pdf/2406.06485 \
  基准测试的代码和数据: \
  https://github.com/cognitiveailab/GPT-simulator
* 37.Transformer升级之路：RoPE的底数设计原则  PaperWeekly  https://mp.weixin.qq.com/s/YhpfIz0Pi1OMLwN3V3J1mQ \
  《Base of RoPE Bounds Context Length》
* 38.(**重要**)打通智能体「自我进化」全流程！复旦推出通用智能体平台AgentGym   PaperWeekly  https://mp.weixin.qq.com/s/WyxQMJoj03FsNT3QRVD05A \
  AgentGym: Evolving Large Language Model-based Agents across Diverse Environments \
  论文链接：https://arxiv.org/abs/2406.04151 \
  代码仓库：https://github.com/WooooDyy/AgentGym
* 39.(**重要**)大语言模型的终身学习综述  专知  https://mp.weixin.qq.com/s/S7eq26JeGMphQV3PUnZ40w \
  Towards Lifelong Learning of Large Language Models: A Survey

# 6.17 Mon
* 40.(**重要**)大模型+蒙特卡洛树搜索，一招让LLaMa-3 8B奥数水平直逼GPT-4  机器之心  https://mp.weixin.qq.com/s/g2w7Rn7Q0mtz9xTPX-Q0Mw \
  AI 参与数学竞赛的主要短板是逻辑推理能力弱，证明题很难拿到完整得分点。这也是 GPT-4、LLaMA 等当前大语言模型（LLM）在需要策略和逻辑推理的任务中面临的重大挑战。\
  其中的一大障碍是输出的准确性和可信度，尤其是在需要保证精度的数学上下文中，LLM 在推理时往往容易产生幻觉。输出结果表面上看似合理，但实际上不相关或事实不正确，最终导致不合理的推理过程。\
  虽然像 Self-Refine 这样的重写技术有助于缓解这种倾向，但依然可能导致现实世界复杂的数学问题产生误导性或错误的结果。\
  因此，为了应对这些挑战，来自复旦大学、上海 AI Lab 的研究者提出了 MCT Self-Refine（MCTSr），将 LLM 与蒙特卡洛树搜索（MCTS）算法相结合，并重点提高 LLM 在复杂数学推理任务（比如奥数竞赛题）中的表现。\
  作为一种决策工具，MCTS 广泛应用于人工智能中需要战略规划的场景，通常用于游戏和复杂的问题解决环境。本文通过将 MCTS 的系统探索能力与 LLM 的 Self-Refine 和 Self-Evaluation 能力相结合， 旨在创建一个更强大的框架来应对当前 LLM 难以解决的复杂推理任务。\
  Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B: A Technical Report \
  论文地址：https://arxiv.org/pdf/2406.07394 \
  项目地址：https://github.com/trotsky1997/MathBlackBox
* 41.3D 版 SORA 来了！DreamTech 推出全球首个原生 3D-DiT 大模型 Direct3D  机器之心  https://mp.weixin.qq.com/s/y2uVCgy0ywSlsF860Byt3g 
* 42.LLM最全「怪癖」首曝光！马里兰OpenAI等30+学者祭出75页提示报告  新智元  https://mp.weixin.qq.com/s/iKB9j1Nr4bDLA4rVv6jHWA \
  论文地址：https://arxiv.org/abs/2406.06608
* 43.树莓派上部署RAG！微软Phi-3技术报告揭示「小而美」模型如何诞生  新智元  https://mp.weixin.qq.com/s/pF9SvSzcakkdssfZYFQP9Q 
* 44.大模型「幻觉」全无？图神经网络成破解核心，精准预测因果消除「幻觉」  新智元  https://mp.weixin.qq.com/s/mmWi2RPXBcU2KtVUoVOH6Q 
* 45.(**重要**)拯救Transformer推理能力！DeepMind新研究TransNAR：给模型嵌入「算法推理大脑」  新智元  https://mp.weixin.qq.com/s/YPICpkYHAC7zTLC_0M_XkQ \
  将Transformers的语言理解能力与基于图神经网络（GNN）的神经算法推理器（NAR）的稳健性结合起来，提升其算法推理能力
* 46.机器遗忘综述：技术与新出现的隐私风险  专知  https://mp.weixin.qq.com/s/g2VD6KKt4PW74PXjVI0nCw

# 6.18 Tue
* 47.全球首个开源类Sora猛升级，16秒720p画质电影感拉满！代码权重全开源  新智元  https://mp.weixin.qq.com/s/3upT7Kl9vr-b4k4d-SE35w
* 48.黄仁勋提到的机器人世界，还需要AI数据来“调教” | CVPR 2024  量子位  https://mp.weixin.qq.com/s/l4GQLBurZt0dkbqzVu8YGA

# 6.19 Wed
* 49.低层视觉中的扩散模型：综述  机器学习研究组订阅  https://mp.weixin.qq.com/s/4aW0wNUQ4wVfKPLUR-fC2g

# 6.20 Thur
* 50.通用人工智能：是什么？如何测试？如何实现？  集智俱乐部  https://mp.weixin.qq.com/s/EncRoqcTacbxPTa9jC6RjA
* 51.吵翻了：意识是如何产生的？科学家能否达成一致？  集智俱乐部  https://mp.weixin.qq.com/s/t-yfhhlff3Rx-nSPAmWw6A
* 52.北大推出全新机器人多模态大模型！面向通用和机器人场景的高效推理和操作  机器之心  https://mp.weixin.qq.com/s/ED2bnE6NDT83zlF9QXHg6Q \
  北大 | 推出全新机器人多模态大模型！（视觉编码+Mamba）  AINLPer  https://mp.weixin.qq.com/s/TxV93_zApwUxo4hDiBnoBw \
  论文：RoboMamba: Multimodal State Space Model for Efficient Robot Reasoning and Manipulation \
  论文链接：https://arxiv.org/abs/2406.04339 \
  项目主页：https://sites.google.com/view/robomamba-web \
  Github：https://github.com/lmzpai/roboMamba

# 6.21 Fri

# 6.22 Sat
* 53.GPT-5一年半后拥有「博士级智能」，Claude 3.5首超人类博士！全知全能ASI将成人类「新神」？ 
 新智元  https://mp.weixin.qq.com/s/GdosKK2J0h0zESrWsTuXrQ \
  ASI as the New God: Technocratic Theocracy \
  论文地址：https://arxiv.org/pdf/2406.08492
* 54.
* 55.
* 56.
* 57.
* 58.
* 59.
