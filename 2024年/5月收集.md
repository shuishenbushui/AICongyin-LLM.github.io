# 5.1 Wed
* 1.(**非常厉害 OctopusV3**)参数量不到10亿的OctopusV3，如何媲美GPT-4V和GPT-4？  机器之心  https://mp.weixin.qq.com/s/mUpX-nvo221WVii-gnjUmQ \
  论文标题：Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent \
  论文链接：https://arxiv.org/pdf/2404.11459.pdf \
  模型权重和推理代码：https://www.nexa4ai.com/apply
* 2.(**自我奖励模型**)「用 AI 训 AI」这事靠谱吗？  机器之心  https://mp.weixin.qq.com/s/bLLoYDTpq8q7ExfwyDekOQ \
  Meta 等提出的**自我奖励模型**具备双重角色：一方面，它遵循模型的指令来生成给定提示的响应；另一方面，它也能够根据示例生成和评估新的指令，进而将其添加到训练集中。该模型建立在假设之上，即利用基础的预训练语言模型和少量的人工注释数据，可以创建一个同时具备指令遵循和自指令创建能力的模型 \
* 3.Llama 3细节公布！AI产品总监站台讲解：Llama系列超庞大生态系统  新智元  https://mp.weixin.qq.com/s/iDAlop_LNv9evZtfPMPyUg \
  **目前发布的其实是Llama 3的非常早期版本**，团队原本打算将这些模型称为预发布或预览版本，因为模型并不具有计划中包含的全部功能
* 4.(**LLM幻觉综述**)《多模态大型语言模型的幻觉现象》综述  专知  https://mp.weixin.qq.com/s/O89fDn8UtgPF-QKYeeF3-g \
  Hallucination of Multimodal Large Language Models: A Survey

# 5.2 Thur
* 5.(**KAN**)MLP一夜被干掉！MIT加州理工等革命性KAN破记录，发现数学定理碾压DeepMind  新智元  https://mp.weixin.qq.com/s/vqhTFPbcUQaCsQnARZrn0g \
  全新神经网络架构KAN一夜爆火！200参数顶30万，MIT华人一作，轻松复现Nature封面AI数学研究  量子位  https://mp.weixin.qq.com/s/5WFJMPJvtaofeGDxFQ9aDw \
  无需怀念MLP，新网络KAN基于柯尔莫哥洛夫-阿诺德定理，带着更少的参数、更强的性能、更好的可解释性来了，深度学习架构革新进入新时代！ \
  KAN: Kolmogorov-Arnold Networks \
  论文地址：https://arxiv.org/pdf/2404.19756 \
  项目链接：https://kindxiaoming.github.io/pykan/
* 6.Meta 联合纽约大学和华盛顿大学提出MetaCLIP，带你揭开CLIP的高质量数据之谜  机器之心  https://mp.weixin.qq.com/s/bEhDOBWcGeUZGMGA6lHoCA \
  原文链接：https://arxiv.org/abs/2309.16671 \
  项目链接：https://github.com/facebookresearch/MetaCLIP \
  论文标题：Demystifying CLIP Data
* 7.GitHub 8.9K Star，伯克利大学开源LLM记忆管理框架MemGPT  AI科技大本营  https://mp.weixin.qq.com/s/holcsXlfNQ9ZYBX5xEECNw \
  开源链接：https://github.com/cpacker/MemGPT

# 5.3 Fri
* 8.终于有人调查了小模型过拟合：三分之二都有数据污染，微软Phi-3、Mixtral 8x22B被点名  机器之心  https://mp.weixin.qq.com/s/YRYaCSsaegjBtwevpwlLHQ \
  论文标题：A Careful Examination of Large Language Model Performance on Grade School Arithmetic \
  论文链接：https://arxiv.org/pdf/2405.00332
* 9.小模型性能饱和、表现不佳，根源是因为Softmax?  机器之心  https://mp.weixin.qq.com/s/bvv-frM8bKhkZiqOa9nqDA \
  Why do small language models underperform? Studying LM Saturation via the Softmax Bottleneck \
  论文链接：https://arxiv.org/pdf/2404.07647.pdf
* 10.CVPR 2024 Highlight | 基于单曝光压缩成像，不依赖生成模型也能从单张图像中重建三维场景  机器之心  https://mp.weixin.qq.com/s/8F6Wij7kOkEEFzAHo00j8g \
  原文链接：https://arxiv.org/abs/2403.20018 \
  项目链接：https://github.com/WU-CVGL/SCINeRF \
  论文标题：SCINeRF: Neural Radiance Fields from a Snapshot Compressive Image
* 11.(**meta一次预测多token**)一次预测多个token，Meta新模型推理加速3倍，编程任务提高17%  量子位  https://mp.weixin.qq.com/s/GuIqBdj4MteR9eBlTesdBA \
  对于背后原理，团队认为多token预测缓解了训练时Teacher Forcing和推理时自回归生成之间的分布差异。\
  也就是说，在训练的时候，模型看到的都是标准答案，生成的时候却得靠自己。好比人类在家做练习册时有答案，考试时却啥也没有，就会不适应。\
  而多token预测相当于训练时就逼着模型多想几步，这样到了考场上，才能应对自如。\
  从信息论的角度，团队还给出了一个更精确的论证。\
  传统的下一个Token预测，目标是最小化当前位置的信息熵。而2-Token预测实际上最小化的是当前和下一位置的信息熵之和。\
  数学推导表明，后者其实隐含了更大的互信息权重，也就是更看重当前Token和未来Token的相关性。这就是为什么多Token预测更”有远见”。\
  论文地址：https://arxiv.org/abs/2404.19737 \
  Better & Faster Large Language Models via Multi-token Prediction
* 12.(**多任务学习MTL综述**)释放多任务学习的力量：涵盖传统、深度和预训练基础模型时代的综述  专知  https://mp.weixin.qq.com/s/LjkpH4daIzpSF9FAC6V8-A \
  Unleashing the Power of Multi-Task Learning- A Comprehensive Survey Spanning Traditional, Deep, and Pretrained Foundation Model Eras \
  https://github.com/junfish/AwesomeMultitask-Learning

# 5.4 Sat
* 13.(**Multimodal Pathway**)CVPR‘24：与任务无关的多模态数据也能提升Transformer性能｜港中文&腾讯  量子位  https://mp.weixin.qq.com/s/Y4LV07qNzRa5MA_lygBiaw \
  Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities \
  论文地址：https://arxiv.org/abs/2401.14405 \
  项目网页：https://ailab-cvc.github.io/M2PT/ \
  开源代码：https://github.com/AILab-CVC/M2PT \
  讲解视频：https://www.bilibili.com/video/BV1Sm41127eW/
* 14.AI教母李飞飞首次创业！成立“空间智能”公司，已完成种子轮  量子位  https://mp.weixin.qq.com/s/RPhN_TR3lW990epLE7izmA \
  公司方向定为“空间智能”——旨在让AI能像人类一样对视觉信息进行高级推理。消息人士表示，这将是该技术的一次飞跃 \
  演讲中，李飞飞对“空间智能”的描述是从物体之间的关系中获得预测和洞察力的能力。\
  她表示，AI对空间智能理解的进步，正在催化机器人学习，使我们更接近让AI能与世界互动的目标。

# 5.5 Sun
* 15.(**非常值得看看**)LeCun哈佛演讲PPT放出：唱衰自回归LLM，指明下一代AI方向  机器之心  https://mp.weixin.qq.com/s/-dlh8e7ZLxj8c77iWCEO_g \
  PPT 链接：https://drive.google.com/file/d/1Ymx_LCVzy7vZXalrVHPXjX9qbpd9k_bo/view?pli=1 \
  视频地址 https://www.youtube.com/watch?v=MiqLoAZFRSE \
  LeCun 强调 AI 系统应该朝着能够学习、记忆、推理、规划、有常识、可操纵且安全的方向发展。 \
  LeCun 花了大量篇幅介绍 JEPA 相关技术，最后他给出了简单的总结：放弃生成模型，支持联合嵌入架构；放弃概率模型，支持基于能量的模型（EBM）；放弃对比方法，支持正则化方法；放弃强化学习，支持模型 - 预测控制；仅当规划无法产生结果时才使用强化学习来调整世界模型。\
  高级机器智能（Advanced Machine Intelligence，AMI）:\
  1.从感官输入中学习世界模型的 AI 系统；\
  2.具有持久记忆的系统；\
  3.具有规划行动的系统；\
  4.可控和安全的系统；\
  5.目标驱动的 AI 架构（LeCun 重点强调了这一条）。\
* 16.(**六边形战士JAT**)告别偏科，能玩转多模态、多任务、多领域的强化智能体终于来了  机器之心  https://mp.weixin.qq.com/s/2GBB-w7hBf6equtqD8V0Lg \
  论文名称：《Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent》 \
  论文链接：https://huggingface.co/papers/2402.09844 \
  代码链接：https://github.com/huggingface/jat \
  项目链接：https://huggingface.co/jat-project/jat \
  数据集：https://huggingface.co/datasets/jat-project/jat-dataset \
  要达到全能型智能体，主要需要解决以下问题：（1）如何设计一个能够处理多种数据类型和模态的统一模型结构？（2）如何有效地平衡不同任务的学习进度和优先级？（3）如何确保智能体制定合适的学习目标，以避免不同任务之间的干扰和负向迁移？
* 17.FixAgent：一款自动化debug的多Agent应用，有效提升模型20% debug能力  大语言模型论文追踪  https://mp.weixin.qq.com/s/LZhHg27ce5dWQVzwLQihRg \
  论文原文: https://arxiv.org/abs/2404.17153 \
  https://github.com/HuggingAGI/HuggingArxiv!

# 5.6 Mon
* 18.大骂“深度学习是垃圾”的自由能到底是什么？有什么效果？  CreateAMind  https://mp.weixin.qq.com/s/Jjw1BA1ociiCbAxKmjvU6A 
* 19.强化学习新书-《自适应行为及认知机器人概述》pdf分享  深度学习与NLP  https://mp.weixin.qq.com/s/UFDGNKjlhS9W5DCagjIimA \
  Behavioral and CognitiveRobotics An Adaptive Perspective \
  Stefano Nolfi
* 20.特斯拉Optimus人形机器人进厂打工，娴熟分装电池、自我矫正，还能走更远了  机器之心  https://mp.weixin.qq.com/s/P5pJFKGxxvi-jBuPCmk-RQ \
  Optimus 在机器人的 FSD 计算机上实时运行，而仅仅依靠 2D 摄像头、手部触觉和力传感器。 \
* 21.(**值得试试**)仅用250美元，Hugging Face技术主管手把手教你微调Llama 3  机器之心  https://mp.weixin.qq.com/s/PR4fCky5a6geBdCbxsOURg \
  Efficiently fine-tune Llama 3 with PyTorch FSDP and O-Lora
* 22.今日arXiv最热大模型论文：首个面向AI的python编程框架，提升大模型编程能力新思路  夕小瑶科技说  https://mp.weixin.qq.com/s/PBRfaD3d1PoQG2zt9vBn9g \
  论文标题：AI Coders Are Among Us: Rethinking Programming Language Grammar Towards Efficient Code Generation \
  论文链接：https://arxiv.org/pdf/2404.16333 \
  作者提出并实现了一个面向AI的Python语法，称为Simple Python（SimPy）作为概念验证
* 23.上海AI Lab开源首个可替代GPT-4V的多模态大模型  夕小瑶科技说  https://mp.weixin.qq.com/s/6Y_eFZgBGyIicdgs2zx0FA \
  与开源和闭源模型相比，InternVL 1.5 在 OCR、多模态、数学和多轮对话等 18 个基准测试中的 8 个中取得了最先进的结果。\
  https://arxiv.org/abs/2312.14238 \
  https://github.com/OpenGVLab/InternVL \
  https://internvl.opengvlab.com \
  https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5 
* 24.58行代码把Llama 3扩展到100万上下文，任何微调版都适用  量子位  https://mp.weixin.qq.com/s/gG6qTLIpOcURt5s8GFy96w \
  ???不清楚如何做到的，LLM的上下文长度是怎么定的??? \
  524k版本LoRA：https://huggingface.co/cognitivecomputations/Llama-3-70B-Gradient-524k-adapter \
  1048k版本LoRA：https://huggingface.co/cognitivecomputations/Llama-3-70B-Gradient-1048k-adapter \
  合并代码:https://gist.github.com/ehartford/731e3f7079db234fa1b79a01e09859ac \
  参考链接：https://twitter.com/erhartford/status/1786887884211138784
* 25.(**PhysDreamer**)硬核解决Sora的物理bug！美国四所顶尖高校联合发布：给视频生成器装个物理引擎  新智元  https://mp.weixin.qq.com/s/YZXFVWTi7zJw-eqyJJMVNA \
  PhysDreamer: Physics-Based Interation with 3D Objects via Video Generation \
  论文链接：https://arxiv.org/pdf/2404.13026.pdf
  项目主页：https://physdreamer.github.io/
* 26.(**phi-3**)手机可跑，3.8B参数量超越GPT-3.5！微软发布Phi-3技术报告：秘密武器是洗干净数据  新智元  https://mp.weixin.qq.com/s/_t0jgnqk_WcvEQ37mr5R-A \
  Phi-3 Technical Report:A Highly Capable Language Model Locally on Your Phone \
  论文链接：https://arxiv.org/pdf/2404.14219.pdf \
  模型的训练遵循「Textbooks Are All You Need」的工作序列，利用高质量的训练数据来提升小型语言模型的性能，同时突破了标准的规模法则（scaling-laws）：phi-3-mini仅用3.8B的总参数量，就能达到GPT-3.5或Mixtral等高性能模型的水平（Mixtral的总参数量为45B）\
  在大型语言模型的能力方面，phi-3-mini虽然在语言理解力和推理能力上与更大型的模型旗鼓相当，但由于其规模的限制，在处理某些特定任务时仍然存在一些固有的局限性
* 27.AIXI, FEP-AI, 世界模型:走向智能和意识的统一理解  CreateAMind  https://mp.weixin.qq.com/s/JXwpUUcBJmbdbKBJITgO9A \
  太深奥，看不懂，但是很重要

# 5.7 Tue
* 28.
* 29.
* 30.

# 5.8 Wed
# 5.9 Thur
# 5.10 Fri
# 5.11 Sat
# 5.12 Sun

# 5.13 Mon
# 5.14 Tue
# 5.15 Wed
# 5.16 Thur
# 5.17 Fri
# 5.18 Sat
# 5.19 Sun

# 5.20 Mon
# 5.21 Tue
# 5.22 Wed
# 5.23 Thur
# 5.24 Fri
# 5.25 Sat
# 5.26 Sun

# 5.27 Mon
# 5.28 Tue
# 5.29 Wed
# 5.30 Thur
# 5.31 Fri
