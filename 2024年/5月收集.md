# 5.1 Wed
* 1.(**非常厉害 OctopusV3**)参数量不到10亿的OctopusV3，如何媲美GPT-4V和GPT-4？  机器之心  https://mp.weixin.qq.com/s/mUpX-nvo221WVii-gnjUmQ \
  论文标题：Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent \
  论文链接：https://arxiv.org/pdf/2404.11459.pdf \
  模型权重和推理代码：https://www.nexa4ai.com/apply
* 2.(**自我奖励模型**)「用 AI 训 AI」这事靠谱吗？  机器之心  https://mp.weixin.qq.com/s/bLLoYDTpq8q7ExfwyDekOQ \
  Meta 等提出的**自我奖励模型**具备双重角色：一方面，它遵循模型的指令来生成给定提示的响应；另一方面，它也能够根据示例生成和评估新的指令，进而将其添加到训练集中。该模型建立在假设之上，即利用基础的预训练语言模型和少量的人工注释数据，可以创建一个同时具备指令遵循和自指令创建能力的模型 \
* 3.Llama 3细节公布！AI产品总监站台讲解：Llama系列超庞大生态系统  新智元  https://mp.weixin.qq.com/s/iDAlop_LNv9evZtfPMPyUg \
  **目前发布的其实是Llama 3的非常早期版本**，团队原本打算将这些模型称为预发布或预览版本，因为模型并不具有计划中包含的全部功能
* 4.(**LLM幻觉综述**)《多模态大型语言模型的幻觉现象》综述  专知  https://mp.weixin.qq.com/s/O89fDn8UtgPF-QKYeeF3-g \
  Hallucination of Multimodal Large Language Models: A Survey

# 5.2 Thur
* 5.(**KAN**)MLP一夜被干掉！MIT加州理工等革命性KAN破记录，发现数学定理碾压DeepMind  新智元  https://mp.weixin.qq.com/s/vqhTFPbcUQaCsQnARZrn0g \
  全新神经网络架构KAN一夜爆火！200参数顶30万，MIT华人一作，轻松复现Nature封面AI数学研究  量子位  https://mp.weixin.qq.com/s/5WFJMPJvtaofeGDxFQ9aDw \
  无需怀念MLP，新网络KAN基于柯尔莫哥洛夫-阿诺德定理，带着更少的参数、更强的性能、更好的可解释性来了，深度学习架构革新进入新时代！ \
  KAN: Kolmogorov-Arnold Networks \
  论文地址：https://arxiv.org/pdf/2404.19756 \
  项目链接：https://kindxiaoming.github.io/pykan/
* 6.Meta 联合纽约大学和华盛顿大学提出MetaCLIP，带你揭开CLIP的高质量数据之谜  机器之心  https://mp.weixin.qq.com/s/bEhDOBWcGeUZGMGA6lHoCA \
  原文链接：https://arxiv.org/abs/2309.16671 \
  项目链接：https://github.com/facebookresearch/MetaCLIP \
  论文标题：Demystifying CLIP Data
* 7.GitHub 8.9K Star，伯克利大学开源LLM记忆管理框架MemGPT  AI科技大本营  https://mp.weixin.qq.com/s/holcsXlfNQ9ZYBX5xEECNw \
  开源链接：https://github.com/cpacker/MemGPT

# 5.3 Fri
* 8.终于有人调查了小模型过拟合：三分之二都有数据污染，微软Phi-3、Mixtral 8x22B被点名  机器之心  https://mp.weixin.qq.com/s/YRYaCSsaegjBtwevpwlLHQ \
  论文标题：A Careful Examination of Large Language Model Performance on Grade School Arithmetic \
  论文链接：https://arxiv.org/pdf/2405.00332
* 9.小模型性能饱和、表现不佳，根源是因为Softmax?  机器之心  https://mp.weixin.qq.com/s/bvv-frM8bKhkZiqOa9nqDA \
  Why do small language models underperform? Studying LM Saturation via the Softmax Bottleneck \
  论文链接：https://arxiv.org/pdf/2404.07647.pdf
* 10.CVPR 2024 Highlight | 基于单曝光压缩成像，不依赖生成模型也能从单张图像中重建三维场景  机器之心  https://mp.weixin.qq.com/s/8F6Wij7kOkEEFzAHo00j8g \
  原文链接：https://arxiv.org/abs/2403.20018 \
  项目链接：https://github.com/WU-CVGL/SCINeRF \
  论文标题：SCINeRF: Neural Radiance Fields from a Snapshot Compressive Image
* 11.(**meta一次预测多token**)一次预测多个token，Meta新模型推理加速3倍，编程任务提高17%  量子位  https://mp.weixin.qq.com/s/GuIqBdj4MteR9eBlTesdBA \
  对于背后原理，团队认为多token预测缓解了训练时Teacher Forcing和推理时自回归生成之间的分布差异。\
  也就是说，在训练的时候，模型看到的都是标准答案，生成的时候却得靠自己。好比人类在家做练习册时有答案，考试时却啥也没有，就会不适应。\
  而多token预测相当于训练时就逼着模型多想几步，这样到了考场上，才能应对自如。\
  从信息论的角度，团队还给出了一个更精确的论证。\
  传统的下一个Token预测，目标是最小化当前位置的信息熵。而2-Token预测实际上最小化的是当前和下一位置的信息熵之和。\
  数学推导表明，后者其实隐含了更大的互信息权重，也就是更看重当前Token和未来Token的相关性。这就是为什么多Token预测更”有远见”。\
  论文地址：https://arxiv.org/abs/2404.19737 \
  Better & Faster Large Language Models via Multi-token Prediction
* 12.(**多任务学习MTL综述**)释放多任务学习的力量：涵盖传统、深度和预训练基础模型时代的综述  专知  https://mp.weixin.qq.com/s/LjkpH4daIzpSF9FAC6V8-A \
  Unleashing the Power of Multi-Task Learning- A Comprehensive Survey Spanning Traditional, Deep, and Pretrained Foundation Model Eras \
  https://github.com/junfish/AwesomeMultitask-Learning

# 5.4 Sat
* 13.(**Multimodal Pathway**)CVPR‘24：与任务无关的多模态数据也能提升Transformer性能｜港中文&腾讯  量子位  https://mp.weixin.qq.com/s/Y4LV07qNzRa5MA_lygBiaw \
  Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities \
  论文地址：https://arxiv.org/abs/2401.14405 \
  项目网页：https://ailab-cvc.github.io/M2PT/ \
  开源代码：https://github.com/AILab-CVC/M2PT \
  讲解视频：https://www.bilibili.com/video/BV1Sm41127eW/
* 14.AI教母李飞飞首次创业！成立“空间智能”公司，已完成种子轮  量子位  https://mp.weixin.qq.com/s/RPhN_TR3lW990epLE7izmA \
  公司方向定为“空间智能”——旨在让AI能像人类一样对视觉信息进行高级推理。消息人士表示，这将是该技术的一次飞跃 \
  演讲中，李飞飞对“空间智能”的描述是从物体之间的关系中获得预测和洞察力的能力。\
  她表示，AI对空间智能理解的进步，正在催化机器人学习，使我们更接近让AI能与世界互动的目标。

# 5.5 Sun
* 15.(**非常值得看看**)LeCun哈佛演讲PPT放出：唱衰自回归LLM，指明下一代AI方向  机器之心  https://mp.weixin.qq.com/s/-dlh8e7ZLxj8c77iWCEO_g \
  PPT 链接：https://drive.google.com/file/d/1Ymx_LCVzy7vZXalrVHPXjX9qbpd9k_bo/view?pli=1 \
  视频地址 https://www.youtube.com/watch?v=MiqLoAZFRSE \
  LeCun 强调 AI 系统应该朝着能够学习、记忆、推理、规划、有常识、可操纵且安全的方向发展。 \
  LeCun 花了大量篇幅介绍 JEPA 相关技术，最后他给出了简单的总结：放弃生成模型，支持联合嵌入架构；放弃概率模型，支持基于能量的模型（EBM）；放弃对比方法，支持正则化方法；放弃强化学习，支持模型 - 预测控制；仅当规划无法产生结果时才使用强化学习来调整世界模型。\
  高级机器智能（Advanced Machine Intelligence，AMI）:\
  1.从感官输入中学习世界模型的 AI 系统；\
  2.具有持久记忆的系统；\
  3.具有规划行动的系统；\
  4.可控和安全的系统；\
  5.目标驱动的 AI 架构（LeCun 重点强调了这一条）。\
* 16.(**六边形战士JAT**)告别偏科，能玩转多模态、多任务、多领域的强化智能体终于来了  机器之心  https://mp.weixin.qq.com/s/2GBB-w7hBf6equtqD8V0Lg \
  论文名称：《Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent》 \
  论文链接：https://huggingface.co/papers/2402.09844 \
  代码链接：https://github.com/huggingface/jat \
  项目链接：https://huggingface.co/jat-project/jat \
  数据集：https://huggingface.co/datasets/jat-project/jat-dataset \
  要达到全能型智能体，主要需要解决以下问题：（1）如何设计一个能够处理多种数据类型和模态的统一模型结构？（2）如何有效地平衡不同任务的学习进度和优先级？（3）如何确保智能体制定合适的学习目标，以避免不同任务之间的干扰和负向迁移？
* 17.FixAgent：一款自动化debug的多Agent应用，有效提升模型20% debug能力  大语言模型论文追踪  https://mp.weixin.qq.com/s/LZhHg27ce5dWQVzwLQihRg \
  论文原文: https://arxiv.org/abs/2404.17153 \
  https://github.com/HuggingAGI/HuggingArxiv!

# 5.6 Mon
* 18.大骂“深度学习是垃圾”的自由能到底是什么？有什么效果？  CreateAMind  https://mp.weixin.qq.com/s/Jjw1BA1ociiCbAxKmjvU6A 
* 19.强化学习新书-《自适应行为及认知机器人概述》pdf分享  深度学习与NLP  https://mp.weixin.qq.com/s/UFDGNKjlhS9W5DCagjIimA \
  Behavioral and CognitiveRobotics An Adaptive Perspective \
  Stefano Nolfi
* 20.特斯拉Optimus人形机器人进厂打工，娴熟分装电池、自我矫正，还能走更远了  机器之心  https://mp.weixin.qq.com/s/P5pJFKGxxvi-jBuPCmk-RQ \
  Optimus 在机器人的 FSD 计算机上实时运行，而仅仅依靠 2D 摄像头、手部触觉和力传感器。 \
* 21.(**值得试试**)仅用250美元，Hugging Face技术主管手把手教你微调Llama 3  机器之心  https://mp.weixin.qq.com/s/PR4fCky5a6geBdCbxsOURg \
  Efficiently fine-tune Llama 3 with PyTorch FSDP and O-Lora
* 22.今日arXiv最热大模型论文：首个面向AI的python编程框架，提升大模型编程能力新思路  夕小瑶科技说  https://mp.weixin.qq.com/s/PBRfaD3d1PoQG2zt9vBn9g \
  论文标题：AI Coders Are Among Us: Rethinking Programming Language Grammar Towards Efficient Code Generation \
  论文链接：https://arxiv.org/pdf/2404.16333 \
  作者提出并实现了一个面向AI的Python语法，称为Simple Python（SimPy）作为概念验证
* 23.上海AI Lab开源首个可替代GPT-4V的多模态大模型  夕小瑶科技说  https://mp.weixin.qq.com/s/6Y_eFZgBGyIicdgs2zx0FA \
  与开源和闭源模型相比，InternVL 1.5 在 OCR、多模态、数学和多轮对话等 18 个基准测试中的 8 个中取得了最先进的结果。\
  https://arxiv.org/abs/2312.14238 \
  https://github.com/OpenGVLab/InternVL \
  https://internvl.opengvlab.com \
  https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5 
* 24.58行代码把Llama 3扩展到100万上下文，任何微调版都适用  量子位  https://mp.weixin.qq.com/s/gG6qTLIpOcURt5s8GFy96w \
  ???不清楚如何做到的，LLM的上下文长度是怎么定的??? \
  524k版本LoRA：https://huggingface.co/cognitivecomputations/Llama-3-70B-Gradient-524k-adapter \
  1048k版本LoRA：https://huggingface.co/cognitivecomputations/Llama-3-70B-Gradient-1048k-adapter \
  合并代码:https://gist.github.com/ehartford/731e3f7079db234fa1b79a01e09859ac \
  参考链接：https://twitter.com/erhartford/status/1786887884211138784
* 25.(**PhysDreamer**)硬核解决Sora的物理bug！美国四所顶尖高校联合发布：给视频生成器装个物理引擎  新智元  https://mp.weixin.qq.com/s/YZXFVWTi7zJw-eqyJJMVNA \
  PhysDreamer: Physics-Based Interation with 3D Objects via Video Generation \
  论文链接：https://arxiv.org/pdf/2404.13026.pdf
  项目主页：https://physdreamer.github.io/
* 26.(**phi-3**)手机可跑，3.8B参数量超越GPT-3.5！微软发布Phi-3技术报告：秘密武器是洗干净数据  新智元  https://mp.weixin.qq.com/s/_t0jgnqk_WcvEQ37mr5R-A \
  Phi-3 Technical Report:A Highly Capable Language Model Locally on Your Phone \
  论文链接：https://arxiv.org/pdf/2404.14219.pdf \
  模型的训练遵循「Textbooks Are All You Need」的工作序列，利用高质量的训练数据来提升小型语言模型的性能，同时突破了标准的规模法则（scaling-laws）：phi-3-mini仅用3.8B的总参数量，就能达到GPT-3.5或Mixtral等高性能模型的水平（Mixtral的总参数量为45B）\
  在大型语言模型的能力方面，phi-3-mini虽然在语言理解力和推理能力上与更大型的模型旗鼓相当，但由于其规模的限制，在处理某些特定任务时仍然存在一些固有的局限性
* 27.AIXI, FEP-AI, 世界模型:走向智能和意识的统一理解  CreateAMind  https://mp.weixin.qq.com/s/JXwpUUcBJmbdbKBJITgO9A \
  太深奥，看不懂，但是很重要

# 5.7 Tue
* 28.意识的整合世界建模理论：FEP-AI + IIT + GNWT = IWMT  CreateAMind  https://mp.weixin.qq.com/s/rcZzMUyX5Y25L-WWnk49NA
  整合世界模型理论（IWMT）的实现思路  CreateAMind 
 https://mp.weixin.qq.com/s/PlsLVfNZ9Afg9fvrHlgVUw \
  系统工程理论-综合世界建模理论（IWMT）扩展：对意识和人工智能理论的启示  CreatAMind  https://mp.weixin.qq.com/s/tUtDxi8cWfFM7NkJzdaU4A
* 29.斯坦福20亿参数端测多模态AI Agent模型大升级，手机汽车机器人都能用  量子位  https://mp.weixin.qq.com/s/c4Cl4FD16-i6HjwdpmyRgA \
  Octopus v3 \
  论文地址：https://arxiv.org/abs/2404.11459
* 30.LeCun转发，AI让失语者重新说话！纽约大学发布全新「神经-语音」解码器｜Nature子刊  新智元  https://mp.weixin.qq.com/s/IJBebE0CHb-W1fuAp_xpAw \

# 5.8 Wed

# 5.9 Thur
* 31.基础模型视频理解综述  专知  https://mp.weixin.qq.com/s/FZ_qsK_zC0A0oW5NIW6hsQ \
* 32.HuggingFace烧钱做了一大批实验，揭示多模态大模型哪些trick真正有效  夕小瑶科技说  https://mp.weixin.qq.com/s/JnXU8wuyGyWgf7jjMtnFuw  \
  试玩地址: https://huggingface.co/spaces/HuggingFaceM4/idefics2_playground \
  论文标题: What matters when building vision-language models? \
  论文链接：https://arxiv.org/pdf/2405.02246 \
  本文通过详尽的实验，深入探讨了构建多模态大模型时文献中常见trick的有效性，并得出了一系列有价值的结论。不仅如此，作者还亲身实践了这些有用的技巧，成功构建了一个性能卓越的8B参数视觉语言模型——**Idefics2**。在同等规模的模型中，Idefics2展现出了最先进的性能，并具备更高的推理效率，为多模态大模型的研究提供了重要参考
* 33.今日arXiv最热大模型论文：浙江大学：如何减轻视觉大模型中的幻觉问题  夕小瑶科技说  https://mp.weixin.qq.com/s/ptJSDjM80uCZ4hewcyQs9g 
* 34.闭源赶超GPT-4 Turbo、开源击败Llama-3-70B，歪果仁：这中国大模型真香  机器之心  https://mp.weixin.qq.com/s/lwv7OTirD7IoTN8RNWCc5A \
  QWEN1.5
* 35.网传Ilya Sutskever的推荐清单火了，掌握当前AI 90%  机器之心  https://mp.weixin.qq.com/s/AFZoWX8kbk0uWklJwl4M_g \
  推荐清单：https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE
* 36.中山&港大| 提出DQ-LoRe框架，自动选择上下文示例，为LLMs复杂推理开辟新道路！  AINLPer  https://mp.weixin.qq.com/s/Kzh4ZAFwfjBlWzJaXcXflQ \
  DQ-LoRe \
  https://arxiv.org/pdf/2310.02954

# 5.10 Fri
* 37.Sora是世界模拟器吗? 世界模型及其以后的综述  专知  https://mp.weixin.qq.com/s/u9VsQxFEgrwCGSlBqQ3SPQ 
* 38.最详细人脑3D地图登Science！GPT-4参数只相当于人类0.2%  量子位  https://mp.weixin.qq.com/s/-BRNHTHIibMDtGYKJzNe7g 
* 39.14 项任务测下来，GPT4V、Gemini等多模态大模型竟都没什么视觉感知能力？ 
  机器之心  https://mp.weixin.qq.com/s/_-mgdLLJd4ck1UMJmfWTpg \
  **BLINK**将激励社区帮助多模态LLMs达到与人类同等级别的视觉感知能力 \
  BLINK 是一个针对多模态语言模型（Multimodal LLMs）的新基准测试，专注于评估其核心视觉感知能力，这些能力在其他评估中并未涉及。 \
  论文链接：https://zeyofu.github.io/blink
* 40.3倍生成速度还降内存成本，超越Medusa2的高效解码框架终于来了  机器之心  https://mp.weixin.qq.com/s/Aw_bjXIQFdOJvN22UvW9UA \
  抛弃自回归，连接一致性Diffusion和LLM！UCSD上交新作热度紧追AF 3  新智元  https://mp.weixin.qq.com/s/jOmh6g8X67WjXL0iLitD9Q \
  高效解码n -token序列，CLLMs+Jacobi解码框架。\
传统上，大型语言模型（LLMs）被认为是顺序解码器，逐个解码每个token。\
  来自上海交通大学、加利福尼亚大学的研究团队展示了预训练的LLMs可以轻松地被教导成为高效的并行解码器，并介绍了一种新的并行解码器族，称为一致性大语言模型（CLLMs），能够通过在每个推断步骤中高效地解码一个n -token序列来降低推断延迟。\
  在此篇论文中，研究表明：「模仿人类在头脑中形成完整句子后逐字表达的认知过程，可以通过简单地微调预训练的LLMs来有效地学习。」\
  具体而言，CLLMs通过将任何随机初始化的n -token序列映射到尽可能少的步骤中，产生与自回归（AR）解码相同结果，来进行并行解码的训练。\
  论文名称：《CLLMs：Consistency Large Language Models》\
  论文链接：https://arxiv.org/pdf/2403.00835
  
# 5.11 Sat
* 41.30%参数达到92%的表现，大模型稀疏化方法显神通  夕小瑶科技说  https://mp.weixin.qq.com/s/U53JtPQSpxQvHLJ7VLfWxA \
  论文标题: Enabling High-Sparsity Foundational Llama Models With Efficient  Pretraining and Deployment \
  论文链接: https://arxiv.org/pdf/2405.03594.pdf
* 42.微软打破Decoder-Only架构！大幅降低GPU内存需求，网友：把Llama3 70B弄20GB GPU上运行  量子位  https://mp.weixin.qq.com/s/aEi-GAmv_kzct1Pv9fjXMg \
  微软&清华最新研究，打破GPT系列开创的Decoder-Only架构—— \
  提出Decoder-Decoder新型架构，名为YOCO（You Only Cache Once）。\
  **YOCO**仅缓存一次键值对，可大幅降低GPU内存需求，且保留全局注意力能力。\
  论文链接：https://arxiv.org/abs/2405.05254
* 43.人类偏好就是尺！SPPO对齐技术让大语言模型左右互搏、**自我博弈**  机器之心  https://mp.weixin.qq.com/s/ulVGoBkCtFyV_mwSBdzgQg \
  论文标题：Self-Play Preference Optimization for Language Model Alignment \
  论文链接：https://arxiv.org/pdf/2405.00675.pdf

# 5.12 Sun
* 44.(**值得研究**)DiT架构大一统：一个框架集成图像、视频、音频和3D生成，可编辑、能试玩  机器之心  https://mp.weixin.qq.com/s/NwwbaeRujh-02V6LRs5zMg \
  基于 **Diffusion Transformer**（DiT）又迎来一大力作「**Flag-DiT**」，这次要将图像、视频、音频和 3D「一网打尽」\
  **Lumina-T2X** 系列中最大的模型包括具有 70 亿参数的 Flag-DiT 和一个多模态大语言模型 **SPHINX**。SPHINX 是一个文本编码器，它具有 130 亿参数，能够处理 128K tokens。\
  论文地址：https://arxiv.org/pdf/2405.05945 \
  GitHub 地址：https://github.com/Alpha-VLLM/Lumina-T2X \
  模型下载地址：https://huggingface.co/Alpha-VLLM/Lumina-T2I/tree/main \
  论文标题：Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers 

# 5.13 Mon
* 45.美国教授用2岁女儿训AI模型登Science！人类幼崽头戴相机训练全新AI  新智元  https://mp.weixin.qq.com/s/v6xvH1uPq8W5osws_yUzWg 
* 46.大神Karpathy强推，分词领域必读：自动钓鱼让大模型“发疯”的token，来自Transformer作者创业公司  量子位  https://mp.weixin.qq.com/s/UpkgRhZkK45gAPWOOmEwYQ \
  自动检测大模型中那些会导致“故障”的token。
* 47.网友缝合Llama3 120B竟意外能打，轻松击败GPT2-chatbot和GPT-4  量子位  https://mp.weixin.qq.com/s/3LtAKK3E6qC57OWIPAhNuw
* 48.Google和普林斯顿大学联合发表CoRL论文：寻求帮助的机器人-大型语言模型规划者的不确定性对齐   CAAI认知系统与信息处理专委会  https://mp.weixin.qq.com/s/aNeabrcdslgWurqUGL9D0A\
  文章介绍了一种名为KnowNo 的框架，用于测量和对齐基于大型语言模型（LLM）的规划器的不确定性，这样他们就知道什么时候它们不知道，并在需要的时候寻求帮助 \
  Robots That Ask For Help: Uncertainty Alignment for Large Language Model Robots Planners
* 49.(**RAG综述**)一文看懂RAG的各种套路 | 综述：当RAG遇到大语言模型  HuggingAGI 大语言模型论文跟踪  https://mp.weixin.qq.com/s/h8z4eXsemPMeL2oI_8VnvQ \
  A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models
* 50.(**Occupancy感知综述**)最新最全总结！自动驾驶Occupancy感知综述：信息融合视角  3D视觉工坊  https://mp.weixin.qq.com/s/muLuIA00jp1ovFVQBLsfoA

# 5.14 Tue
* 51.OpenAI颠覆世界：GPT-4o完全免费，实时语音视频交互震撼全场，直接进入科幻时代  机器之心  https://mp.weixin.qq.com/s/PfWnlhXh3n3VDfZaMI-ifQ
* 52.微软让MoE长出多个头，大幅提升专家激活率  机器之心  https://mp.weixin.qq.com/s/ZCRyb63M2DL4hOQh7uxxaw \
  多头混合专家  MH-MoE \
  论文标题：Multi-Head Mixture-of-Experts \ 
  论文地址：https://arxiv.org/pdf/2404.15045 \
  代码地址：https://github.com/yushuiwx/MH-MoE
* 53.沉浸式线性代数教材，不懂哪里点哪里，网友：天花板级别  量子位  https://mp.weixin.qq.com/s/g7VDc12v8wG5dTQp4nB0tw \
  传送门：https://immersivemath.com/ila/
* 54.(**值得看看**)思维链不存在了？纽约大学最新研究：推理步骤可「省略」  新智元  https://mp.weixin.qq.com/s/w_Ogu7DhtgdQXMRWrFhvxA \
  思维链技术，可能要被推翻了！来自纽约大学的最新研究表明：大模型并没有利用思维链的推理能力，它只是偷偷加了计算！ \
  研究人员发现，把思维链（Chain-of-Thought，CoT）推理中的具体步骤，替换成毫无意义的「...」，产生的推理结果也大差不差 \
  Let's Think Dot by Dot: Hidden Computation in Transformer Language Models \
  论文地址：https://arxiv.org/pdf/2404.15758
* 55.牛皮吹破？大模型长输入能力不能拿来做上下文学习  夕小瑶科技说  https://mp.weixin.qq.com/s/NI4juWbm9jOjhK2hCM8KQA \
  论文标题: Long-context LLMs Struggle with Long In-context Learning \
  论文链接：https://arxiv.org/pdf/2404.02060.pdf
* 56.【伯克利博士论文】零样本机器人感知的视觉-语言表示，74页pdf  专知  https://mp.weixin.qq.com/s/Ze5x3x4GnQCZExk8jJl1Dg \
  Vision-Language Representations for Zero-Shot Robotic Perception
* 57.RAG 与 LLMs 的结合 - 迈向检索增强的大型语言模型**综述**  专知  https://mp.weixin.qq.com/s/p_sPNF54y1mAoayzWRkBaA \
  
# 5.15 Wed
* 58.博弈论如何让大语言模型更聪明？ | 智能渐近线   追问nextquestion  https://mp.weixin.qq.com/s/kCmkm8litbmAttZwMkHA_A \
  The consensus game: Language model generation via equilibrium search

# 5.16 Thur
* 59.GPT-4o手写板书以假乱真惊呆网友！杀死谷歌翻译，代码建模无所不能  新智元  https://mp.weixin.qq.com/s/mpSSSDqL6qYSvXdtPJbm1A \
* 60.李飞飞解读创业方向「**空间智能**」，让AI真正理解世界  机器之心  https://mp.weixin.qq.com/s/okhjWPp0is0ks3e_RvJO4g \
  李飞飞 TED 演讲链接: https://www.ted.com/talks/fei_fei_li_with_spatial_intelligence_ai_will_understand_the_real_world/transcript \
* 61.无位置编码 (NoPE) 也有长度泛化问题？首个针对NoPE的长度外推方法 
 PaperWeekly  https://mp.weixin.qq.com/s/8Gq2paZSWmzqXRVMRRB-lw \
  论文标题：Length Generalization of Causal Transformers without Position Encoding \
  论文链接：https://arxiv.org/pdf/2404.12224.pdf \
  代码链接：https://github.com/AntNLP/nope_head_scale

# 5.17 Fri
* 62.走向最小统一意识模型  CreateAMind  https://mp.weixin.qq.com/s/MJB1nb9wmwZliJR0HGDSxw \
  意识研究的黄金测试标准，**米田引理**的应用  CreateAMind  https://mp.weixin.qq.com/s/hwfzY0t_cKaP68q9Iofy_A \
  将胡塞尔现象学映射到主动推理  CreateAMind  https://mp.weixin.qq.com/s/Fg-qEKDDdgUxZX0326feCg

# 5.18 Sat
* 63.Transformer是推断还是记忆？初始化大小很重要  PaperWeekly  https://mp.weixin.qq.com/s/hmAUN5GM8AQIxVHFUkip-A \
  通过这项研究，我们发现，Transformer 模型的初始化大小决定了它是像福尔摩斯一样通过推理解谜，还是像我奶奶一样通过记忆菜谱来做饭。小初始化让模型像侦探一样，只需要记住几个关键的线索（运算规则），就能推理出所有结果。而大初始化则像孙悟空，把所有知识吃下去的方式记下来。
* 64.(**可以看看**)我们离AGI有多远？UIUC最新120页论文阐述AGI定义、目标和发展轨迹  专知  https://mp.weixin.qq.com/s/1jXGdt4PjAQBfwy40LvlIA \
  How Far Are We From AGI 
* 65.GPT-4通过图灵测试，胜率高达54%！UCSD新作：人类无法认出GPT-4  新智元  https://mp.weixin.qq.com/s/0_49it464APmy7uwvHH3KQ \
  论文地址：https://arxiv.org/pdf/2405.08007
* 66.(**知道了解**)缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA  PaperWeekly  https://mp.weixin.qq.com/s/yCczYU0po0PvPTa-eh2pfg 
* 67.

# 5.19 Sun

# 5.20 Mon
# 5.21 Tue
# 5.22 Wed
# 5.23 Thur
# 5.24 Fri
# 5.25 Sat
# 5.26 Sun

# 5.27 Mon
# 5.28 Tue
# 5.29 Wed
# 5.30 Thur
# 5.31 Fri
