# 4.1 Mon
* 1.国产黑马一年肝出万亿参数MoE！霸榜多模态，剑指AGI  新智元  https://mp.weixin.qq.com/s/JDGDUe26bdjlpkFjgZyx3A \
  阶跃星辰，一口气带来了Step-1千亿参数语言大模型、Step-1V千亿参数多模态大模型，以及Step-2万亿参数MoE语言大模型的预览版，公司命名灵感来自scaling laws \
  Scaling Laws for Neural Language Models \
  论文地址：https://arxiv.org/pdf/2001.08361.pdf \
  参考资料：\
  https://stepchat.cn/chats/new \
  https://stepchat.cn/textposter \
  https://maopaoya.com/chat 
* 2.ChatGPT实体化了！手机变身ChatGPT实体机器人，只需一个配件，能说话还会做梦，真的牛！  夕小瑶科技说  https://mp.weixin.qq.com/s/WL3pTa49ZuOT9fQwasriAw \
  LOOI 
* 3.(**了解**)今日arXiv最热NLP大模型论文：Github万星！北航发布零代码大模型微调平台LlamaFactory  夕小瑶科技说  https://mp.weixin.qq.com/s/jJ5hItGNz91TiaDrdfYwUg \
  LLAMA FACTORY是一个旨在普及LLMs微调的框架。它通过可扩展的模块统一了多种高效微调方法，使得数百种语言模型能够在资源有限的情况下进行高吞吐量的微调。此外，该框架还简化了常用的训练方法，如生成式预训练、监督式微调、基于人类反馈的强化学习以及直接偏好优化等。用户可以通过命令行或Web界面，以最小或无需编码的方式自定义和微调他们的语言模型 \
  LLAMAFACTORY: Unified Efficient Fine-Tuning of 100+ Language Models \
  https://arxiv.org/pdf/2403.13372.pdf \
  https://github.com/hiyouga/LLaMA-Factory
* 4.(**值得一试**)比LoRA还快50%的微调方法来了！一张3090性能超越全参调优，UIUC联合LMFlow团队提出LISA  机器之心  https://mp.weixin.qq.com/s/7s8NNGYlq4JWeln0TkOKmQ \
  LoRA 技术仍存在一定的挑战。一是 LoRA 技术在很多任务上还没有超过正常的全参数微调 [2][3][4]，二是 LoRA 的理论性质分析比较困难，给其进一步的研究带来了阻碍。\
  UIUC 联合 LMFlow 团队成员对 LoRA 的实验性质进行了分析，意外发现 LoRA 非常侧重 LLM 的底层和顶层的权重。利用这一特性，LMFlow 团队提出一个极其简洁的算法：Layerwise Importance Sampled AdamW（LISA） \
  论文链接：https://arxiv.org/abs/2403.17919 \
  开源地址：https://github.com/OptimalScale/LMFlow
* 5.ICLR 2024 | 鸡生蛋蛋生鸡？再论生成数据能否帮助模型训练  机器之心  https://mp.weixin.qq.com/s/MSSzIl3KnvRzgWVN0ZyW6A \
  论文题目：Do Generated Data Always Help Contrastive Learning？ \
  论文地址：https://arxiv.org/abs/2403.12448 \
  代码地址：https://github.com/PKU-ML/adainf
* 6.MemGPT, 教会LLM管理自身的记忆  大语言模型  https://mp.weixin.qq.com/s/K1zE-HpOtK-jOrwkM4YS1Q \
  地址：https://github.com/cpacker/MemGPT
* 7.(**值得看看**)CVPR 2024 | 多模态大模型幻觉原因找到了！  PaperWeekly  https://mp.weixin.qq.com/s/qAYImdyACrhd4ipMNh39XA \
  summary token 与幻觉产生的原因有关 \
  论文题目：OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation \
  论文地址：https://arxiv.org/abs/2311.17911 \
  代码地址：https://github.com/shikiw/OPERA

# 4.2 Tue
* 8.阿里7B多模态文档理解大模型拿下新SOTA｜开源  量子位  https://mp.weixin.qq.com/s/vtymW1k93ZLSOqj0iWwe6A \
  mPLUG团队的DocOwl \
  GitHub链接：https://github.com/X-PLUG/mPLUG-DocOwl \
  论文链接：https://arxiv.org/abs/2403.12895
* 9.(**多模态位置编码，非常值得看看!!!**)Transformer升级之路：多模态编码位置的简单思考  PaperWeekly  https://mp.weixin.qq.com/s/2Qt4yKf0wJ_Thqf-JUBijQ \
* 10.《大模型决策制定中的幻觉检测》综述  专知  https://mp.weixin.qq.com/s/ZthlpSAfMvVQ_iZk18wfTQ \
  Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art 

# 4.3 Wed
* 11.(**有趣，值得看看，SWE-agent**)普林斯顿首个「开源」AI程序员登场！爆改GPT-4，93秒修bug  新智元  https://mp.weixin.qq.com/s/Mr4yv6t3-k7K5H5or5aGNg \
  GPT-4加Agent轻松追平Devin！普林斯顿造，开源首日斩获1.6k星  量子位  https://mp.weixin.qq.com/s/gUdh3uwKCY-4eI_RihgiNA \
  世界首个AI程序员Devin诞生不足一个月，普林斯顿就推出了全新的「开源版本」——SWE-agent！在GPT-4的加持下，debug只需93秒，准确率几乎不相上下 \
  参考资料： \
  https://swe-agent.com/ \
  https://github.com/princeton-nlp/SWE-agent \
  https://news.opensauced.pizza/open-source-projects-that-are-gaining-steam-that-you-havent-heard-of/
* 12.(**高效提示方法综述**)大型语言模型的高效提示方法综述  专知  https://mp.weixin.qq.com/s/dJn2H56glWk-zHC6WR5t2g \
  Efficient Prompting Methods for Large Language Models: A Survey
* 13.超干货！如何设计基于Agent的AI应用系统  唐霜  https://mp.weixin.qq.com/s/tQdaLvARta47gQDJqPh1Vw
* 14.(**分布式训练，预训练**)从啥也不会到DeepSpeed————一篇大模型分布式训练的学习过程总结  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/L4FBUYEvZoTJyl8ZcUBS2A \
* 15.澳门大学 | 提出神经元级高效微调方法：NeFT，秒杀LoRA，性能超全参微调（FPFT）！  AINLPer  https://mp.weixin.qq.com/s/vVjAol05HCagWsR8scNcvg \
  神经元级高效微调方法：NeFT \
  https://arxiv.org/pdf/2403.11621.pdf

# 4.4 Thur
* 16.ICLR2024 | 语言模型知识编辑的鲁棒性研究  ZJUKG  https://mp.weixin.qq.com/s/jKSZeFN1tV8rX7U6nwUO3A 
* 17.弱智吧竟成最佳中文AI训练数据？！中科院等：8项测试第一，远超知乎豆瓣小红书  量子位  https://mp.weixin.qq.com/s/iq5lGyh9Y5P7NXLUS3-giA \
  Ruozhiba 
* 18.首个开源世界模型！百万级上下文，长视频理解吊打GPT-4，UC伯克利华人一作  新智元  https://mp.weixin.qq.com/s/HtTRrIVYqmdUb_h6P9lFtA \
  LWM采用了一个包含各种视频和书籍的大型数据集，利用RingAttention技术对长序列进行可扩展的训练，最终将上下文长度增加到1M token \
  World Model on Million-Length Video And Language With RingAttention \ 
  论文地址：https://arxiv.org/pdf/2402.08268.pdf \
  代码地址：https://github.com/LargeWorldModel/LWM
* 19.基于大型语言模型的游戏智能体综述  专知  https://mp.weixin.qq.com/s/3Cr5N7bGuSBwzSQ8DF7T8Q \
  A Survey on Large Language Model-Based Game Agents 

# 4.5 Fri
* 20.OpenAI发布全新微调API ：ChatGPT支持更详细可视化微调啦！  AIGC开放社区  https://mp.weixin.qq.com/s/0-3TptRmDJbsdR_ESlTR5g \
  基于Epoch的检查点创建、Playground新功能、第三方集成、全面验证指标、超参数配置和更详细的微调仪表板改进。 \
  新的微调API功能适用于GPT-4/Turbo、GPT-3.5等系列模型。 \
  详细微调API教程：https://platform.opEnai.com/docs/guidEs/finE-tuning
* 21.李飞飞主讲，斯坦福2024 CS231n开课，依旧座无虚席  机器之心  https://mp.weixin.qq.com/s/ZVuM_lGyJegXzxxAjD-ESg \
  课程主页：https://cs231n.stanford.edu/
* 22.值得你花时间看的扩散模型教程，来自普渡大学  机器之心  https://mp.weixin.qq.com/s/s-d_VK1ln7ysKL8QIftxNA \
  Tutorial on Diffusion Models for Imaging and Vision \
  文章链接：https://arxiv.org/abs/2403.18103 \
  参考链接：https://engineering.purdue.edu/ChanGroup/stanleychan.html
* 23.(**值得看看EgoExoLearn**)让智能体像孩子一样观察别人学习动作，跨视角技能学习数据集EgoExoLearn来了  机器之心  https://mp.weixin.qq.com/s/HfprU44_ttbpthCJplXnCQ \
  EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World \
  论文链接：https://arxiv.org/abs/2403.16182 \
  代码与数据集链接：https://github.com/OpenGVLab/EgoExoLearn
* 24.(**JetMoE值得试试**)10万美元训出Llama-2级大模型！全华人打造新型MoE，贾扬清SD前CEO围观  量子位   https://mp.weixin.qq.com/s/98TmAe_c4H64RTZXIG5yfg \
  JetMoE，来自MIT、普林斯顿等研究机构。性能妥妥超过同等规模的Llama-2 \
  传送门：https://github.com/myshell-ai/JetMoE \
  参考链接：https://twitter.com/jiayq/status/1775935845205463292
* 25.(**MoD**)谷歌更新Transformer架构，更节省计算资源！50%性能提升  量子位  https://mp.weixin.qq.com/s/Xqnv2L9X4KRkfpTaw7B0SA \
  Mixture-of-Depths（MoD）\
  结果显示，在等效计算量和训练时间上，MoD每次向前传播所需的计算量更小，而且后训练采样过程中步进速度提高50% \
  论文地址：https://arxiv.org/abs/2404.02258
* 26.(**非常重要，值得看看**)《大型语言模型增强强化学习》综述  专知  https://mp.weixin.qq.com/s/TPinksRNrFrn_xdHFdwLMg \
  在这篇综述中，我们提供了一个关于LLM增强RL现有文献的全面回顾，并总结了与传统RL方法相比的特点，旨在明确研究范围和未来研究的方向 \
  利用经典的智能体-环境交互范式，我们提出了一个结构化的分类法，以系统地分类LLMs在RL中的功能，包括四个角色：信息处理器、奖励设计师、决策者和生成器 \
  Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods \
  https://arxiv.org/abs/2404.00282

# 4.6 Sat
* 27.

# 4.7 Sun

# 4.8 Mon

# 4.9 Tue

# 4.10 Wed

# 4.11 Thur

# 4.12 Fri

# 4.13 Sat

# 4.14 Sun

# 4.15 Mon

# 4.16 Tue

# 4.17 Wed

# 4.18 Thur

# 4.19 Fri

# 4.20 Sat

# 4.21 Sun

# 4.22 Mon

# 4.23 Tue

# 4.24 Wed

# 4.25 Thur

# 4.26 Fri

# 4.27 Sat

# 4.28 Sun

# 4.29 Mon

# 4.30 Tue
