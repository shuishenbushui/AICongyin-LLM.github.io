# 4.1 Mon
* 1.国产黑马一年肝出万亿参数MoE！霸榜多模态，剑指AGI  新智元  https://mp.weixin.qq.com/s/JDGDUe26bdjlpkFjgZyx3A \
  阶跃星辰，一口气带来了Step-1千亿参数语言大模型、Step-1V千亿参数多模态大模型，以及Step-2万亿参数MoE语言大模型的预览版，公司命名灵感来自scaling laws \
  Scaling Laws for Neural Language Models \
  论文地址：https://arxiv.org/pdf/2001.08361.pdf \
  参考资料：\
  https://stepchat.cn/chats/new \
  https://stepchat.cn/textposter \
  https://maopaoya.com/chat 
* 2.ChatGPT实体化了！手机变身ChatGPT实体机器人，只需一个配件，能说话还会做梦，真的牛！  夕小瑶科技说  https://mp.weixin.qq.com/s/WL3pTa49ZuOT9fQwasriAw \
  LOOI 
* 3.(**了解**)今日arXiv最热NLP大模型论文：Github万星！北航发布零代码大模型微调平台LlamaFactory  夕小瑶科技说  https://mp.weixin.qq.com/s/jJ5hItGNz91TiaDrdfYwUg \
  LLAMA FACTORY是一个旨在普及LLMs微调的框架。它通过可扩展的模块统一了多种高效微调方法，使得数百种语言模型能够在资源有限的情况下进行高吞吐量的微调。此外，该框架还简化了常用的训练方法，如生成式预训练、监督式微调、基于人类反馈的强化学习以及直接偏好优化等。用户可以通过命令行或Web界面，以最小或无需编码的方式自定义和微调他们的语言模型 \
  LLAMAFACTORY: Unified Efficient Fine-Tuning of 100+ Language Models \
  https://arxiv.org/pdf/2403.13372.pdf \
  https://github.com/hiyouga/LLaMA-Factory
* 4.(**值得一试**)比LoRA还快50%的微调方法来了！一张3090性能超越全参调优，UIUC联合LMFlow团队提出LISA  机器之心  https://mp.weixin.qq.com/s/7s8NNGYlq4JWeln0TkOKmQ \
  LoRA 技术仍存在一定的挑战。一是 LoRA 技术在很多任务上还没有超过正常的全参数微调 [2][3][4]，二是 LoRA 的理论性质分析比较困难，给其进一步的研究带来了阻碍。\
  UIUC 联合 LMFlow 团队成员对 LoRA 的实验性质进行了分析，意外发现 LoRA 非常侧重 LLM 的底层和顶层的权重。利用这一特性，LMFlow 团队提出一个极其简洁的算法：Layerwise Importance Sampled AdamW（LISA） \
  论文链接：https://arxiv.org/abs/2403.17919 \
  开源地址：https://github.com/OptimalScale/LMFlow
* 5.ICLR 2024 | 鸡生蛋蛋生鸡？再论生成数据能否帮助模型训练  机器之心  https://mp.weixin.qq.com/s/MSSzIl3KnvRzgWVN0ZyW6A \
  论文题目：Do Generated Data Always Help Contrastive Learning？ \
  论文地址：https://arxiv.org/abs/2403.12448 \
  代码地址：https://github.com/PKU-ML/adainf
* 6.MemGPT, 教会LLM管理自身的记忆  大语言模型  https://mp.weixin.qq.com/s/K1zE-HpOtK-jOrwkM4YS1Q \
  地址：https://github.com/cpacker/MemGPT
* 7.(**值得看看**)CVPR 2024 | 多模态大模型幻觉原因找到了！  PaperWeekly  https://mp.weixin.qq.com/s/qAYImdyACrhd4ipMNh39XA \
  summary token 与幻觉产生的原因有关 \
  论文题目：OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation \
  论文地址：https://arxiv.org/abs/2311.17911 \
  代码地址：https://github.com/shikiw/OPERA

# 4.2 Tue
* 8.阿里7B多模态文档理解大模型拿下新SOTA｜开源  量子位  https://mp.weixin.qq.com/s/vtymW1k93ZLSOqj0iWwe6A \
  mPLUG团队的DocOwl \
  GitHub链接：https://github.com/X-PLUG/mPLUG-DocOwl \
  论文链接：https://arxiv.org/abs/2403.12895
* 9.(**多模态位置编码，非常值得看看!!!**)Transformer升级之路：多模态编码位置的简单思考  PaperWeekly  https://mp.weixin.qq.com/s/2Qt4yKf0wJ_Thqf-JUBijQ \
* 10.《大模型决策制定中的幻觉检测》综述  专知  https://mp.weixin.qq.com/s/ZthlpSAfMvVQ_iZk18wfTQ \
  Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art 

# 4.3 Wed
* 11.(**有趣，值得看看，SWE-agent**)普林斯顿首个「开源」AI程序员登场！爆改GPT-4，93秒修bug  新智元  https://mp.weixin.qq.com/s/Mr4yv6t3-k7K5H5or5aGNg \
  GPT-4加Agent轻松追平Devin！普林斯顿造，开源首日斩获1.6k星  量子位  https://mp.weixin.qq.com/s/gUdh3uwKCY-4eI_RihgiNA \
  世界首个AI程序员Devin诞生不足一个月，普林斯顿就推出了全新的「开源版本」——SWE-agent！在GPT-4的加持下，debug只需93秒，准确率几乎不相上下 \
  参考资料： \
  https://swe-agent.com/ \
  https://github.com/princeton-nlp/SWE-agent \
  https://news.opensauced.pizza/open-source-projects-that-are-gaining-steam-that-you-havent-heard-of/
* 12.(**高效提示方法综述**)大型语言模型的高效提示方法综述  专知  https://mp.weixin.qq.com/s/dJn2H56glWk-zHC6WR5t2g \
  Efficient Prompting Methods for Large Language Models: A Survey
* 13.超干货！如何设计基于Agent的AI应用系统  唐霜  https://mp.weixin.qq.com/s/tQdaLvARta47gQDJqPh1Vw
* 14.(**分布式训练，预训练**)从啥也不会到DeepSpeed————一篇大模型分布式训练的学习过程总结  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/L4FBUYEvZoTJyl8ZcUBS2A \
* 15.澳门大学 | 提出神经元级高效微调方法：NeFT，秒杀LoRA，性能超全参微调（FPFT）！  AINLPer  https://mp.weixin.qq.com/s/vVjAol05HCagWsR8scNcvg \
  神经元级高效微调方法：NeFT \
  https://arxiv.org/pdf/2403.11621.pdf

# 4.4 Thur
* 16.ICLR2024 | 语言模型知识编辑的鲁棒性研究  ZJUKG  https://mp.weixin.qq.com/s/jKSZeFN1tV8rX7U6nwUO3A 
* 17.弱智吧竟成最佳中文AI训练数据？！中科院等：8项测试第一，远超知乎豆瓣小红书  量子位  https://mp.weixin.qq.com/s/iq5lGyh9Y5P7NXLUS3-giA \
  Ruozhiba 
* 18.首个开源世界模型！百万级上下文，长视频理解吊打GPT-4，UC伯克利华人一作  新智元  https://mp.weixin.qq.com/s/HtTRrIVYqmdUb_h6P9lFtA \
  LWM采用了一个包含各种视频和书籍的大型数据集，利用RingAttention技术对长序列进行可扩展的训练，最终将上下文长度增加到1M token \
  World Model on Million-Length Video And Language With RingAttention \ 
  论文地址：https://arxiv.org/pdf/2402.08268.pdf \
  代码地址：https://github.com/LargeWorldModel/LWM
* 19.基于大型语言模型的游戏智能体综述  专知  https://mp.weixin.qq.com/s/3Cr5N7bGuSBwzSQ8DF7T8Q \
  A Survey on Large Language Model-Based Game Agents 

# 4.5 Fri
* 20.OpenAI发布全新微调API ：ChatGPT支持更详细可视化微调啦！  AIGC开放社区  https://mp.weixin.qq.com/s/0-3TptRmDJbsdR_ESlTR5g \
  基于Epoch的检查点创建、Playground新功能、第三方集成、全面验证指标、超参数配置和更详细的微调仪表板改进。 \
  新的微调API功能适用于GPT-4/Turbo、GPT-3.5等系列模型。 \
  详细微调API教程：https://platform.opEnai.com/docs/guidEs/finE-tuning
* 21.李飞飞主讲，斯坦福2024 CS231n开课，依旧座无虚席  机器之心  https://mp.weixin.qq.com/s/ZVuM_lGyJegXzxxAjD-ESg \
  课程主页：https://cs231n.stanford.edu/
* 22.值得你花时间看的扩散模型教程，来自普渡大学  机器之心  https://mp.weixin.qq.com/s/s-d_VK1ln7ysKL8QIftxNA \
  Tutorial on Diffusion Models for Imaging and Vision \
  文章链接：https://arxiv.org/abs/2403.18103 \
  参考链接：https://engineering.purdue.edu/ChanGroup/stanleychan.html
* 23.(**值得看看EgoExoLearn**)让智能体像孩子一样观察别人学习动作，跨视角技能学习数据集EgoExoLearn来了  机器之心  https://mp.weixin.qq.com/s/HfprU44_ttbpthCJplXnCQ \
  EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World \
  论文链接：https://arxiv.org/abs/2403.16182 \
  代码与数据集链接：https://github.com/OpenGVLab/EgoExoLearn
* 24.(**JetMoE值得试试**)10万美元训出Llama-2级大模型！全华人打造新型MoE，贾扬清SD前CEO围观  量子位   https://mp.weixin.qq.com/s/98TmAe_c4H64RTZXIG5yfg \
  JetMoE，来自MIT、普林斯顿等研究机构。性能妥妥超过同等规模的Llama-2 \
  传送门：https://github.com/myshell-ai/JetMoE \
  参考链接：https://twitter.com/jiayq/status/1775935845205463292
* 25.(**MoD**)谷歌更新Transformer架构，更节省计算资源！50%性能提升  量子位  https://mp.weixin.qq.com/s/Xqnv2L9X4KRkfpTaw7B0SA \
  Mixture-of-Depths（MoD）\
  结果显示，在等效计算量和训练时间上，MoD每次向前传播所需的计算量更小，而且后训练采样过程中步进速度提高50% \
  论文地址：https://arxiv.org/abs/2404.02258
* 26.(**非常重要，值得看看**)《大型语言模型增强强化学习》综述  专知  https://mp.weixin.qq.com/s/TPinksRNrFrn_xdHFdwLMg \
  在这篇综述中，我们提供了一个关于LLM增强RL现有文献的全面回顾，并总结了与传统RL方法相比的特点，旨在明确研究范围和未来研究的方向 \
  利用经典的智能体-环境交互范式，我们提出了一个结构化的分类法，以系统地分类LLMs在RL中的功能，包括四个角色：信息处理器、奖励设计师、决策者和生成器 \
  Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods \
  https://arxiv.org/abs/2404.00282

# 4.6 Sat
* 27.AI视频理解天花板，全新MiniGPT4-Video刷爆SOTA！宝格丽宣传片配文一绝  新智元  https://mp.weixin.qq.com/s/Y8w6CqTvm7zVQMOmTuxePA \
  MiniGPT4-video不仅考虑了视觉内容，还纳入了文本对话，使该模型能够有效地回答涉及视觉和文本内容的查询。 \
  MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens \
  论文地址：https://arxiv.org/pdf/2404.03413.pdf
* 28.AI下一个重大飞跃是理解情感！第一个具有情商的对话型AI来了  新智元  https://mp.weixin.qq.com/s/IOFaPdB_6gtWC-gckWJ3Yw \
  https://venturebeat.com/ai/is-ais-next-big-leap-understanding-emotion-50m-for-hume-says-yes/
* 29.(**ReadAgent**)「有效上下文」提升20倍！DeepMind发布ReadAgent框架  新智元  https://mp.weixin.qq.com/s/xXJqJeqf8mzP9VW9kLIdgQ \
  A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts \
  论文链接：https://arxiv.org/abs/2402.09727
* 30.中科大等意外发现：大模型不看图也能正确回答视觉问题！  量子位  https://mp.weixin.qq.com/s/mmNxJ-YOZx4Hpu8zSkfDGw \
  我们评估多模态模型的方法正确吗？ \
  论文链接：https://arxiv.org/pdf/2403.20330.pdf
* 31.(**MoD**)Google | 提出深度混合Transformer，实现计算资源动态分配，比最优基线快66%  AINLPer  https://mp.weixin.qq.com/s/9eAoR2_1WiB5cQFOv4E6Tw \
  该模型能够动态地分配计算资源到输入序列的特定位置，而不是像传统模型那样均匀地分配计算资源。通过动态计算分配方式，可以在保持性能的同时显著提高模型速度 \
  Mixture-of-Depths: Dynamically allocating compute in transformer-based langugae models \
  https://arxiv.org/pdf/2404.02258.pdf

# 4.7 Sun
* 32.超越GPT-4，斯坦福团队手机可跑的大模型火了，一夜下载量超2k  新智元  https://mp.weixin.qq.com/s/qnFZOPLpdRxW42_cLUcImA \
  论文：Octopus v2: On-device language model for super agent \
  论文地址：https://arxiv.org/abs/2404.01744 \
  模型主页：https://huggingface.co/NexaAIDev/Octopus-v2
* 33.谷歌DeepMind发布Gecko：专攻检索，与大7倍模型相抗衡  机器之心  https://mp.weixin.qq.com/s/5e_Py_Xm0RsmP1YMcikpaQ \
  论文地址：https://arxiv.org/pdf/2403.20327.pdf \
  论文标题：Gecko: Versatile Text Embeddings Distilled from Large Language Models
* 34.(**太厉害了，实时语言纠正，YAY**)斯坦福团队新作：喊话就能指导机器人，任务成功率暴增，网友：特斯拉搞快点  量子位  https://mp.weixin.qq.com/s/F4BQKdkX8QG4ExHOmxzU4A \
  斯坦福的ALOHA家务机器人团队，项目名为Yell At Your Robot（简称YAY），有了它，机器人的“翻车”动作，只要喊句话就能纠正了 \
  而且机器人可以随着人类的喊话动态提升动作水平、即时调整策略，并根据反馈持续自我改进。 \
  YAY系统引入了实时的语言纠正机制，人类的口头命令优先级最高——经识别后，直接传递给低级策略用于执行。\
  Yell At Your Robot: Improving On-the-Fly from Language Corrections \
  论文地址：https://arxiv.org/abs/2403.12910
* 35.(**抱抱脸复现RLHF，值得研究**)抱抱脸Open了OpenAI的秘密武器，网易参与复现  量子位  https://mp.weixin.qq.com/s/g0DoFNH8JD70DW7CEiZ-GQ \
  来自Hugging Face、加拿大蒙特利尔Mila研究所、网易伏羲AI Lab的研究人员从零开始复现了OpenAI的RLHF pipeline，罗列了25个关键实施细节。\
  The N+ Implementation Details of RLHF with PPO: A Case Study on TL; DR Summarization \
  Learning to summarize from human feedback (openai摘要任务)\
  Training Language models to follow instructions with human feedback (gpt-3过渡chatgpt工作)\
* 36.刚刚！阿里 | 开源Qwen1.5-32B大模型，Qwen1.5系列又添新成员！（可在线体验）  AINLPer  https://mp.weixin.qq.com/s/AlpE3mQTjs-4f6hpa823pg \
  Paper：https://qwenlm.github.io/zh/blog/qwen1.5-32b/ \
  Demo：https://huggingface.co/spaces/Qwen/Qwen1.5-32B-Chat-demo

# 4.8 Mon
* 37.(**有趣**)大模型融合！最新「进化算法」全自动组合开源模型，刷榜多项基准测试  新智元  https://mp.weixin.qq.com/s/xQ73ceVsuPB2PM6cuMcGgA \
  目前，Hugging Face拥有50多万个模型，涵盖数十种不同的模态，原则上就可以组合成具有新能力的新模型。 \
  Sakana AI把这个想法转成了现实。他们研究出一种进化模型合并的方法，这是一种使用进化技术来有效地发现不同开源模型的最佳组合方式的通用方法。\
  Evolutionary Optimization of Model Merging Recipes \
  论文地址：https://arxiv.org/abs/2403.13187
* 38.揭秘AI幻觉！GPT-4V存在视觉编码漏洞，清华联合NUS提出LLaVA-UHD  PaperWeekly  https://mp.weixin.qq.com/s/Rh33sCnBeeGYVa9IT8QwFQ \
  在微软一篇长达 166 页的技术报告《The Dawn of LMMs:Preliminary Explorations with GPT-4V (ision)》中，作者发现，对于一个不太复杂的图像中的苹果数量，GPT-4V 竟然怎么数也数不对。 \
  然而，学术界和工业界尚不清楚导致这些问题的底层原因。\
  这个问题在清华大学、新加坡国立大学和中国科学院大学的一篇题为《LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images》的论文中得到了解释。\
  论文地址：https://arxiv.org/pdf/2403.11703.pdf
  代码地址：https://github.com/thunlp/LLaVA-UHD

# 4.9 Tue
* 39.(**LLM逆转诅咒**)破解36年前魔咒！Meta推出反向训练大法消除大模型「逆转诅咒」  新智元  https://mp.weixin.qq.com/s/7IDIGD03-zTmHe9mB-HJ7w \
  The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A" \
  论文地址：https://arxiv.org/pdf/2309.12288v1.pdf
* 40.(**结构性自注意力StructSA**)【CVPR2024】学习视觉Transformer的相关结构  专知  https://mp.weixin.qq.com/s/1ef1-Di8GwWMwdwGL2Us8Q \
  Learning Correlation Structures for Vision Transformers \
  结构性自注意力（StructSA） \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/cd355b84-f495-4e33-aa2e-e78bedd0dfa6) 
* 41.(**digital forgetting & unlearning**)大型语言模型中的数字遗忘：遗忘方法的综述  专知  https://mp.weixin.qq.com/s/ATOgNFfKTwz0VHCZc2SYow \
  为什么叫数字遗忘？和数字有啥关系？\
  Digital Forgetting in Large Language Models: Survey of Unlearning Methods 

# 4.10 Wed
* 42.(**有趣，量化大模型中的知识容量**)Llama架构比不上GPT2？神奇token提升10倍记忆？  机器之心  https://mp.weixin.qq.com/s/TMkn6yMTUrrGhxCQnd7_2g \
  作者采用了他们《语言模型物理学》系列论文的核心思路，即制造人工合成数据，通过控制数据中知识的数量和类型，来严格调控数据中的知识比特数 (bits)。同时，作者使用不同大小和架构的 LLM 在人工合成数据上进行训练，并给出数学定理，来精确计算训练好的模型从数据中学到了多少比特的知识。\
  GPT2 模型能比 LlaMA/Mistral 存储超过 30% 的知识，这意味着几年前的模型在某些方面超越了今天的模型。 \
  低质量数据是否会影响 LLM 对高质量知识的吸收呢？结果令人惊讶，即使对高质量数据的训练时间保持一致，低质量数据的「存在本身」，可能会让模型对高质量知识的存储量下降 20 倍！即便将高质量数据的训练时间延长 3 倍，知识储量仍会降低 3 倍。这就像是将金子丢进沙子里，高质量数据被严重浪费了。 \
  有什么办法修复呢？作者提出了一个简单但极其有效的策略，只需给所有的 (预) 训练数据加上自己的网站域名 token 即可。例如，将 Wiki 百科数据统统加上 wikipedia.org。模型不需要任何先验知识来识别哪些网站上的知识是「金子」，而可以在预训练过程中，自动发现高质量知识的网站，并自动为这些高质量数据腾出存储空间。\
  作者提出了一个简单的实验来验证：如果高质量数据都加上一个特殊 token（任何特殊 token 都行，模型不需要提前知道是哪个 token），那么模型的知识存储量可以立即回升 10 倍，是不是很神奇？所以说对预训练数据增加域名 token，是一个极其重要的数据制备操作。\
  论文地址：https://arxiv.org/pdf/2404.05405.pdf \
  论文标题：Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws
* 43.刚刚，Mistral AI最新磁力链放出！8x22B MoE模型，281GB解禁  新智元  https://mp.weixin.qq.com/s/p_jkVrCLoSA-FoEkQ0m2iQ \
* 44.(**偏好树、偏好学习**)提升开源LLMs推理能力！清华 | 构建高质量对齐数据集，公布「 Eurus」系列模型  AINLPer  https://mp.weixin.qq.com/s/2hCWISSftMD5chdDksuZ3w \
  开源LLMs推理性能和专有大模型的差距主要归因于两大原因：一是缺乏高质量的对齐数据（High-quality alignment data），二是对改进模型复杂推理能力的偏好学习技术（Preference learning techniques）的探索不足。\
  大规模、高质量数据集（ULTRAINTERACT），用于大模型的监督微调和偏好学习 \
  ULTRAINTERACT数据集其主要有以下三个特点：「多样高质量数据」 「多轮交互」 「偏好学习」 \
  「偏好学习」 为每个指令收集了一个偏好树，其中每个节点代表一个行动（action），而树的根是初始指令（instruction）。从根到叶的路径（trajectory）代表了一系列行动的序列，这些行动是模型在尝试解决问题的过程中生成的。在每个偏好树中，所有正确行动的节点和所有以正确行动结束的轨迹都可以用于监督式微调（SFT），而成对的正确和错误的节点或轨迹则用于偏好学习。 \
  Advancing LLM Reasoning Generalists with Preference Trees \
  https://arxiv.org/pdf/2404.02078v1.pdf

# 4.11 Thur
* 45.大模型做时序预测也很强！华人团队激活LLM新能力，超越一众传统模型实现SOTA  量子位  https://mp.weixin.qq.com/s/UL_Kl0PzgfYHOnq7d3vM8Q \
  Time-LLM: Time Series Forecasting by Reprogramming LLMs \
  论文链接 https://arxiv.org/abs/2310.01728
* 46.(**LLM无限长上下文,无限注意力机制,非常值得研究**)Google | 提出Infini-Transformer架构，可让LLMs处理无限长上下文，内存节约114倍！  AINLPer  https://mp.weixin.qq.com/s/factToEEJdWcs5WJG1Ljfg \
  Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention \
  https://arxiv.org/pdf/2404.07143.pdf

# 4.12 Fri
* 47.MIT等首次深度研究「集成LLM」预测能力：可媲美人类群体准确率  新智元  https://mp.weixin.qq.com/s/eGRMP_CgtNM5GgiCprNgYA \
  Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Rival Human Crowd Accuracy \
  论文链接：https://arxiv.org/pdf/2402.19379.pdf
* 48.魔改RNN挑战Transformer，RWKV上新：推出2种新架构模型  量子位  https://mp.weixin.qq.com/s/afbreOaP3dUc25y7phuYIw \
  不走Transformer寻常路，魔改RNN的国产新架构RWKV，有了新进展：提出了两种新的RWKV架构，即Eagle (RWKV-5) 和Finch（RWKV-6)。\
  《Eagle and Finch：RWKV with Matrix-Valued States and Dynamic Recurrence》 \
  论文链接：https://arxiv.org/pdf/2404.05892.pdf
* 49.(**选择性语言建模SLM**)微软&清华 | 提出模型训练新方法：SLM，选择优质Token进行训练，提升训练效率！  AINLPer  https://mp.weixin.qq.com/s/QcMgIHB0_VYRrd3Z3EUIrg \
  RHO-1: Not All Tokens Are What You Need \
  https://arxiv.org/pdf/2404.07965.pdf

# 4.13 Sat
* 50.(**VAR GPT式视觉生成**)GPT超越扩散、视觉生成Scaling Law时刻！北大&字节提出VAR范式  机器之心  https://mp.weixin.qq.com/s/KOEdTgJX4Gga5zRbl57Yow \
  新一代视觉生成范式「VAR: Visual Auto Regressive」视觉自回归来了！使 GPT 风格的自回归模型在图像生成首次超越扩散模型，并观察到与大语言模型相似的 Scaling Laws 缩放定律、Zero-shot Task Generalization 泛化能力 \
  VAR 方法核心：模仿人类视觉，重新定义图像自回归顺序 \
  人类在感知图像或进行绘画时，往往先概览全局、再深入细节。这种由粗到细、从把握整体到精调局部的思想非常自然 \
  Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction \
  体验网站：https://var.vision/ \
  论文链接：https://arxiv.org/abs/2404.02905 \
  开源代码：https://github.com/FoundationVision/VAR \
  开源模型：https://huggingface.co/FoundationVision/var \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/268c618f-f66d-431a-a848-1056f0474c90)
* 51.今日arXiv最热大模型论文：清华大学发布，ChatGML又添新功能，集成“自我批评”，提升数学能力  夕小瑶科技说  https://mp.weixin.qq.com/s/oyvz3gPlGjOhlSJkMvuDww \
  论文标题：ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline \
  论文链接：https://arxiv.org/pdf/2404.02893.pdf \
  自我批判管道(Self-Critique Pipeline)包括两个主要阶段：\
  1. 拒绝性微调（Rejective Fine-tuning, RFT）：在此阶段，采用拒绝采样技术，即淘汰不符合Math-Critique标准的响应，而将其余响应进一步微调。这一阶段的目标是提高模型在数学回答方面的准确性和一致性，同时确保所选答案的多样性。\
  2. 直接偏好优化（Direct Preference Optimization, DPO）：在RFT的基础上，通过直接从正确和错误答案对中学习，进一步提炼通过Math-Critique的答案，重点解决上一阶段中最具挑战性的问题。
* 52.(**太有趣了**)Science Robotics封面！DeepMind强化学习打造超一流机器人球员  新智元  https://mp.weixin.qq.com/s/ocCeve1opQB2i0POsea0gA \
  论文地址：https://www.science.org/doi/10.1126/scirobotics.adi8022 \
  <img width="336" alt="1714113682491" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/829337cd-e64d-4c1c-945a-578761359c36">
* 53.《视觉语言模型》前沿：当前方法和未来方向的综述  专知  https://mp.weixin.qq.com/s/E_v-blLuJssDsqNQyPPQiA \
  Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions \

# 4.14 Sun
* 54.马斯克的首款多模态大模型来了，GPT-4V又被超越了一次  机器之心  https://mp.weixin.qq.com/s/2GDjZS6ctayAF8e8eFb3CQ \
  Grok-1.5  https://x.ai/blog/grok-1.5v
* 55.Claude 3说服力堪比人类！Anthropic最新研究揭秘LLM惊人能力  新智元  https://mp.weixin.qq.com/s/SXGjeFzzhn6RvVJDSplqIQ \
  近日，Claude的东家Anthropic发表博文，称他们开发了一种测量模型说服力的基本方法，并且在Claude系列上进行了实验，相关数据也进行了开源。
* 56.(**一条通过视频生成来实现AGI的路线**)模拟一切实现AGI？OpenAI Sora核心成员最新演讲+专访来了  新智元  https://mp.weixin.qq.com/s/bcuW7NCPs8NKlr4vdYw7xA \
  OpenAI Sora团队核心成员Tim Brooks和Bill Peebles对通用人工智能的实现分享了一些他们的看法，作为Sora研究负责人，他们表示：「视频生成技术将通过模拟一切来实现AGI」。
* 57.(**适合初学者的TRM教程**)万字长文震撼来袭！揭秘Transformer——吐血解读自注意力机制的革命性突破  图灵人工智能  https://mp.weixin.qq.com/s/Fw1hYuBfb851eEIHE6ztAA 
* 58.Nature子刊评论：大脑对算法的独特理解，我们是否能够理解神经算法到底是什么？  脑机接口社区  https://mp.weixin.qq.com/s/9i7x60fGz4i2uCb0sh_HIw \
  《The brain’s unique take on algorithms》 论文链接：https://www.nature.com/articles/s41467-023-40535-z
* 59.(**LVM**)CVPR 2024 | 视觉新突破！首个无自然语言的纯视觉大模型！  小白学视觉  https://mp.weixin.qq.com/s/ieYz5jCm2xRwZfCEbk6cHg \
  Sequential Modeling Enables Scalable Learning for Large Vision Models \
  论文地址：https://arxiv.org/abs/2312.00785 \
  项目主页：https://yutongbai.com/lvm.html

# 4.15 Mon
* 60.(**自由能原理，值得了解**)大语言模型无法实现具身智能：5万字自我模型  CreateAMind  https://mp.weixin.qq.com/s/2HSkeOZtDqmtfZvrJEbq6g \
  The radically embodied conscious cybernetic bayesian brain: from free  energy to free will and back again
* 61.九次架构改进具身机器人，模拟镜像神经元  CreateAMind  https://mp.weixin.qq.com/s/ssx7yhQln2CVQiZJNGbzag
* 62.大语言模型无法实现具身认知  CreateAMind  https://mp.weixin.qq.com/s/O6G9YEn1eNjNTl5z7vmwng \
  大语言模型无法实现具身智能的根本原因  CreateAMind  https://mp.weixin.qq.com/s/brSGlBFfDXIhmHtXydK3hQ \
  Generating meaning: active inference and the scope and limits of passive AI \
  总而言之，我们对语言符号含义的掌握并非源于我们处理自然语言的能力，而是源于我们通过采样和互动而积累的对生活世界的更基础的理解
* 63.解决深度学习4大缺陷  CreateAMind  https://mp.weixin.qq.com/s/dV8RwbewEIkgkT4J6h_v9g \
  A Review of Neuroscience-Inspired Machine Learning https://arxiv.org/abs/2403.18929
  深度学习网络相对于生物神经网络的缺点 
* 64.刷爆多模态任务榜单！贾佳亚团队Mini-Gemini登热榜，代码、模型、数据全部开源  机器之心  https://mp.weixin.qq.com/s/j5CGuJ_-Sf0Pqi_-dDjABA \
  Github 地址：https://github.com/dvlab-research/MiniGemini \
  Demo 地址: http://103.170.5.190:7860/ \
  论文地址：https://arxiv.org/pdf/2403.18814.pdf \
  模型地址：https://huggingface.co/collections/YanweiLi/mini-gemini-6603c50b9b43d044171d0854 \
  数据地址：https://huggingface.co/collections/YanweiLi/mini-gemini-data-660463ea895a01d8f367624e
* 65.(**AI for Math学习清单**)陶哲轩力荐、亲自把关：AI for Math照这个清单学就对了  机器之心  https://mp.weixin.qq.com/s/eBBf51puJVIGrPmwefo6Kg \
  陶哲轩力荐！史上最全「数学AI资源」清单出炉  新智元  https://mp.weixin.qq.com/s/a-0g65mfRe3i9_anj3SB7Q \
  网址：https://docs.google.com/document/d/1kD7H4E28656ua8jOGZ934nbH2HcBLyxcRgFDduH5iQ0/edit
* 66.【博士论文】理解大型语言模型：使用探针分类器和自合理化实现严格和有针对性的可解释性，109页pdf  专知  https://mp.weixin.qq.com/s/Nqpuc8XwQK5YEYTED-5jwQ \
  ??? 什么是探针分类器和自合理器，如何解决可解释性的
* 67.扩散模型最新有何进展？普林斯顿伯克利最新「扩散模型」综述：应用、引导生成、统计率和优化  专知  https://mp.weixin.qq.com/s/qOOyiGkNf_3DHQ-9dRlzEA
* 68.(**FEP自由能原理,完全不懂**)意识的内屏模型：意识的必要条件  CreateAMind  https://mp.weixin.qq.com/s/L-Pp7D96VGFkrmIisu1dpA \
  ??? 什么是内屏模型 ??? \
  The inner screen model of consciousness: applying the free energy principle directly to the study of conscious experience
* 69.(**SFT想LLM注入知识**)微软 | 利用监督式微调（SFT），向大模型注入新知识，无需检索增强生成(RAG)！  AINLPer  https://mp.weixin.qq.com/s/OiDEVct8wnpFWlF-i71t3w \
  Injecting New Knowledge into LLMs via SFT \
  https://arxiv.org/pdf/2404.00213.pdf

# 4.16 Tue
* 70.(**MoD和MoDE**)DeepMind升级Transformer，前向通过FLOPs最多可降一半  机器之心  https://mp.weixin.qq.com/s/nvhXCywpZaOhxWAQWY7PPw \
  论文标题：Mixture-of-Depths: Dynamically allocating compute in transformer-based language models \
  论文地址：https://arxiv.org/pdf/2404.02258.pdf \
  混合深度与专家（MoDE）:MoD 技术可以自然地与 MoE 模型整合起来，组成所谓的 MoDE 模型
* 71.极长序列、极快速度：面向新一代高效大语言模型的LASP序列并行  机器之心  https://mp.weixin.qq.com/s/wPJsmgSAYgh3Si2eZ0_HzA \
  论文标题：Linear Attention Sequence Parallelism \
  论文地址：https://arxiv.org/abs/2404.02882 \
  LASP代码地址：https://github.com/OpenNLPLab/LASP
* 72.多尺度合成生物集体智能概述：5万字  CreateAMind  https://mp.weixin.qq.com/s/BCxmlmmIKRrEuCUdbY5fcw \
  Technological Approach to Mind Everywhere: An Experimentally-Grounded Framework for Understanding Diverse Bodies and Minds 2022
* 73.今日arXiv最热NLP大模型论文：一文读懂大模型的prompt技术  夕小瑶科技说  https://mp.weixin.qq.com/s/QsRWCs8V4Y_jQjYGqVdgyw \
  论文标题:Efficient Prompting Methods for Large Language Models: A Survey \
  论文链接:https://arxiv.org/pdf/2404.01077.pdf
* 74.重磅！《大语言模型》新书出炉，人大出版，391页pdf  专知  https://mp.weixin.qq.com/s/Jn-k95-IAa0N-utA4r3_Sg \
  中文书项目链接：https://llmbook-zh.github.io/ \
  A Survey of Large Language Models 
* 75.空间交替任务和海马-前额叶回路的分层主动推理模型  CreateAMind  https://mp.weixin.qq.com/s/tssU4kX06iJRX3muRPnemQ \
  Bridging Cognitive Maps: a Hierarchical Active Inference Model of Spatial Alternation Tasks and the Hippocampal-Prefrontal Circuit  https://arxiv.org/abs/2308.11463

# 4.17 Wed
* 76.(**meta的Megalodon无限长上下文**)革命新架构掀翻Transformer！无限上下文处理，2万亿token碾压Llama 2  新智元  https://mp.weixin.qq.com/s/xgP9P51gjqJ93FYSWfPeaA \
  Megalodon: Efficient LLM Pretraining and Inference with Unlimited Length \
  论文地址：https://arxiv.org/abs/2404.08801
* 77.(**GeRM**)用MoE横扫99个子任务！浙大等提出全新通用机器人策略GeRM  新智元  https://mp.weixin.qq.com/s/K7Lr1t1rXaR3LwrjbGnweQ \
  GeRM: A Generalist Robotic Model with Mixture-of-experts for Quadruped Robot \
  论文地址：https://arxiv.org/abs/2403.13358 \
  项目地址：https://songwxuan.github.io/GeRM/
* 78.(**具身数据集OpenEQA**)离世界模型更近一步！Meta开源OpenEQA，评估AI Agent情景理解能力  夕小瑶科技说  https://mp.weixin.qq.com/s/rsM4jtt_RdELxanobceqkQ \
  从文字模型到世界模型！Meta新研究让AI Agent理解物理世界  新智元  https://mp.weixin.qq.com/s/Qeuq8v5-ruKGNlcw884RXg \
  Meta 刚刚推出的 OpenEQA，是第一个支持情景记忆和主动探索用例的开放词汇基准数据集，用来衡量 AI 代理对其环境的理解 \
  https://open-eqa.github.io/assets/pdfs/paper.pdf \
  https://open-eqa.github.io/ \
  https://github.com/facebookresearch/open-eqa
* 79.脑电合成自然语音！LeCun转发Nature子刊新成果，代码开源  量子位  https://mp.weixin.qq.com/s/BcV3-3glmdsVF--fpPRU2g \
* 80.让玩家全程掌控游戏：自然语言指令驱动的游戏引擎到来了  机器之心  https://mp.weixin.qq.com/s/YPPm1lcOo_Ql41Pz9TlWkA \
  论文：https://arxiv.org/abs/2404.00276 \
  代码：https://github.com/gingasan/idge \
  Demo：https://www.bilibili.com/video/BV1dA4m1w7xr/?vd_source=e0570b35759018455d30551c1e16a676 \
  论文标题：Instruction-Driven Game Engines on Large Language Models
* 81.导航任意抽象空间：强大的智能不变量  CreateAMind  https://mp.weixin.qq.com/s/Vk5G10-Ll508KdoOJtE4lw \
  Competency in navigating arbitrary spaces as an invariant for analyzing cognition in diverse embodiments

# 4.18 Thur
* 82.最全的损失函数汇总  新机器视觉  https://mp.weixin.qq.com/s/ey8U0mF6nmuYG4FLILhGWQ \
  链接：https://blog.csdn.net/shanglianlm/article/details/85019768
* 83.你好，电动Atlas！波士顿动力机器人复活，180度诡异动作吓坏马斯克  新智元  https://mp.weixin.qq.com/s/f3PXBAVIGXXZV7JbK4ybIw 
* 84.改变LoRA的初始化方式，北大新方法PiSSA显著提升微调效果  PaperWeekly  https://mp.weixin.qq.com/s/DueyyNeiXUDXZFqFUCDSxg 

# 4.19 Fri
* 85.(**最全自由能原理资料**)从机器人到AGI，从具身到可解释，从入门到应用实现的**最全自由能原理资料**  CreateAMind  https://mp.weixin.qq.com/s/yXonEwNWg2ui5vqEiqiYbg
* 86.开源大模型Llama 3王者归来！最大底牌4000亿参数，性能直逼GPT-4  机器之心  https://mp.weixin.qq.com/s/KCyL8WTzXutPQ_k0Vl9Vwg \
  下载链接：https://llama.meta.com/llama-downloads/ \
  Github：https://github.com/meta-llama/
* 87.Loss 才是涌现的关键，而非模型参数  GLM大模型  https://mp.weixin.qq.com/s/OVgI3HMpEYdhiWIxNXufqQ \
  Understanding Emergent Abilities of Language Models from the Loss Perspective \
  论文链接：https://arxiv.org/abs/2403.15796
* 88.(**自动Loss无监督**)自动Loss无监督，仅600标记样本就达到96.6%准确率  CreateAMind  https://mp.weixin.qq.com/s/985NNHKjBmzJKqwCwiMfOg \
  Unsupervised End-to-End Training with a Self-Defined Bio-Inspired Target \
  https://arxiv.org/pdf/2403.12116 \
  https://github.com/neurophysics-cnrsthales/unsupervised-target
* 89.《大型语言模型中基于检索的文本生成》综述  专知  https://mp.weixin.qq.com/s/slHksXsbqTDzY3XwGF4nrA \
  A Survey on Retrieval-Augmented Text Generation for Large Language Models 

# 4.20 Sat
* 90.【全网首发】Llama3 微调项目实践与教程（XTuner 版）  InternLM  https://mp.weixin.qq.com/s/sKet1R4k_Xwmfo6D_x17Rw \
  XTuner：http://github.com/InternLM/XTuner \
  Llama3-XTuner-CN：https://github.com/SmartFlowAI/Llama3-XTuner-CN/
* 91.(**不确定性感知**)今日arXiv最热NLP大模型论文：面向不确定性感知的Language Agent  夕小瑶科技说  https://mp.weixin.qq.com/s/dMCg8RlPuUE_Cs4fvjTbjQ \
  论文标题：Towards Uncertainty-Aware Language Agent \
  论文主页：https://uala-agent.github.io/ \
  论文链接：https://arxiv.org/pdf/2401.14016.pdf
* 92.(**有趣，LLM研究**)Transformer本可以深谋远虑，但就是不做  机器之心  https://mp.weixin.qq.com/s/1kolCWSsFAp4e9MGG089vQ \
  论文标题：Do Language Models Plan for Future Tokens? \
  论文地址：https://arxiv.org/pdf/2404.00859.pdf  
* 93.(**有趣，LLM研究**)大模型一定就比小模型好？谷歌的这项研究说不一定  机器之心  https://mp.weixin.qq.com/s/qmVEhCRlpwC6EnALGuGAhA \
  论文标题：Bigger is not Always Better: Scaling Properties of Latent Diffusion Models \
  论文地址：https://arxiv.org/pdf/2404.01367.pdf  
* 94.MLLM真能看懂数学吗？**MathVerse**来了次摸底测评，放出当天登热榜  PaperWeekly  https://mp.weixin.qq.com/s/uZm3ipgn4FcyIepUcf4iVw \
  论文题目： MATHVERSE: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems? \
  论文链接： https://arxiv.org/pdf/2403.14624.pdf
* 95.(**意识心智相关**)丹尼特的灵魂科学：一位哲学家对心智构成的毕生探索  神经实现  https://mp.weixin.qq.com/s/MadgXUPHRtpH7x_W9atWSA \
  再见丹尼特，探索心智奥秘的一生  集智俱乐部  https://mp.weixin.qq.com/s/HF3TsFJI_pRRESbk5axxeA \
  再见，AI意识先驱：Daniel Dennett  量子位  https://mp.weixin.qq.com/s/q_NHqYVQeap93k2JQ5d-lg 

# 4.21 Sun
* 96.
* 97.
* 98.
* 99.
* 100.

# 4.22 Mon

# 4.23 Tue

# 4.24 Wed

# 4.25 Thur

# 4.26 Fri

# 4.27 Sat

# 4.28 Sun

# 4.29 Mon

# 4.30 Tue
