# 4.1 Mon
* 1.国产黑马一年肝出万亿参数MoE！霸榜多模态，剑指AGI  新智元  https://mp.weixin.qq.com/s/JDGDUe26bdjlpkFjgZyx3A \
  阶跃星辰，一口气带来了Step-1千亿参数语言大模型、Step-1V千亿参数多模态大模型，以及Step-2万亿参数MoE语言大模型的预览版，公司命名灵感来自scaling laws \
  Scaling Laws for Neural Language Models \
  论文地址：https://arxiv.org/pdf/2001.08361.pdf \
  参考资料：\
  https://stepchat.cn/chats/new \
  https://stepchat.cn/textposter \
  https://maopaoya.com/chat 
* 2.ChatGPT实体化了！手机变身ChatGPT实体机器人，只需一个配件，能说话还会做梦，真的牛！  夕小瑶科技说  https://mp.weixin.qq.com/s/WL3pTa49ZuOT9fQwasriAw \
  LOOI 
* 3.(**了解**)今日arXiv最热NLP大模型论文：Github万星！北航发布零代码大模型微调平台LlamaFactory  夕小瑶科技说  https://mp.weixin.qq.com/s/jJ5hItGNz91TiaDrdfYwUg \
  LLAMA FACTORY是一个旨在普及LLMs微调的框架。它通过可扩展的模块统一了多种高效微调方法，使得数百种语言模型能够在资源有限的情况下进行高吞吐量的微调。此外，该框架还简化了常用的训练方法，如生成式预训练、监督式微调、基于人类反馈的强化学习以及直接偏好优化等。用户可以通过命令行或Web界面，以最小或无需编码的方式自定义和微调他们的语言模型 \
  LLAMAFACTORY: Unified Efficient Fine-Tuning of 100+ Language Models \
  https://arxiv.org/pdf/2403.13372.pdf \
  https://github.com/hiyouga/LLaMA-Factory
* 4.(**值得一试**)比LoRA还快50%的微调方法来了！一张3090性能超越全参调优，UIUC联合LMFlow团队提出LISA  机器之心  https://mp.weixin.qq.com/s/7s8NNGYlq4JWeln0TkOKmQ \
  LoRA 技术仍存在一定的挑战。一是 LoRA 技术在很多任务上还没有超过正常的全参数微调 [2][3][4]，二是 LoRA 的理论性质分析比较困难，给其进一步的研究带来了阻碍。\
  UIUC 联合 LMFlow 团队成员对 LoRA 的实验性质进行了分析，意外发现 LoRA 非常侧重 LLM 的底层和顶层的权重。利用这一特性，LMFlow 团队提出一个极其简洁的算法：Layerwise Importance Sampled AdamW（LISA） \
  论文链接：https://arxiv.org/abs/2403.17919 \
  开源地址：https://github.com/OptimalScale/LMFlow
* 5.ICLR 2024 | 鸡生蛋蛋生鸡？再论生成数据能否帮助模型训练  机器之心  https://mp.weixin.qq.com/s/MSSzIl3KnvRzgWVN0ZyW6A \
  论文题目：Do Generated Data Always Help Contrastive Learning？ \
  论文地址：https://arxiv.org/abs/2403.12448 \
  代码地址：https://github.com/PKU-ML/adainf
* 6.MemGPT, 教会LLM管理自身的记忆  大语言模型  https://mp.weixin.qq.com/s/K1zE-HpOtK-jOrwkM4YS1Q \
  地址：https://github.com/cpacker/MemGPT
* 7.(**值得看看**)CVPR 2024 | 多模态大模型幻觉原因找到了！  PaperWeekly  https://mp.weixin.qq.com/s/qAYImdyACrhd4ipMNh39XA \
  summary token 与幻觉产生的原因有关 \
  论文题目：OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation \
  论文地址：https://arxiv.org/abs/2311.17911 \
  代码地址：https://github.com/shikiw/OPERA

# 4.2 Tue
* 8.阿里7B多模态文档理解大模型拿下新SOTA｜开源  量子位  https://mp.weixin.qq.com/s/vtymW1k93ZLSOqj0iWwe6A \
  mPLUG团队的DocOwl \
  GitHub链接：https://github.com/X-PLUG/mPLUG-DocOwl \
  论文链接：https://arxiv.org/abs/2403.12895
* 9.(**多模态位置编码，非常值得看看!!!**)Transformer升级之路：多模态编码位置的简单思考  PaperWeekly  https://mp.weixin.qq.com/s/2Qt4yKf0wJ_Thqf-JUBijQ \
* 10.《大模型决策制定中的幻觉检测》综述  专知  https://mp.weixin.qq.com/s/ZthlpSAfMvVQ_iZk18wfTQ \
  Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art 

# 4.3 Wed
* 11.(**有趣，值得看看，SWE-agent**)普林斯顿首个「开源」AI程序员登场！爆改GPT-4，93秒修bug  新智元  https://mp.weixin.qq.com/s/Mr4yv6t3-k7K5H5or5aGNg \
  GPT-4加Agent轻松追平Devin！普林斯顿造，开源首日斩获1.6k星  量子位  https://mp.weixin.qq.com/s/gUdh3uwKCY-4eI_RihgiNA \
  世界首个AI程序员Devin诞生不足一个月，普林斯顿就推出了全新的「开源版本」——SWE-agent！在GPT-4的加持下，debug只需93秒，准确率几乎不相上下 \
  参考资料： \
  https://swe-agent.com/ \
  https://github.com/princeton-nlp/SWE-agent \
  https://news.opensauced.pizza/open-source-projects-that-are-gaining-steam-that-you-havent-heard-of/
* 12.(**高效提示方法综述**)大型语言模型的高效提示方法综述  专知  https://mp.weixin.qq.com/s/dJn2H56glWk-zHC6WR5t2g \
  Efficient Prompting Methods for Large Language Models: A Survey
* 13.超干货！如何设计基于Agent的AI应用系统  唐霜  https://mp.weixin.qq.com/s/tQdaLvARta47gQDJqPh1Vw
* 14.(**分布式训练，预训练**)从啥也不会到DeepSpeed————一篇大模型分布式训练的学习过程总结  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/L4FBUYEvZoTJyl8ZcUBS2A \
* 15.澳门大学 | 提出神经元级高效微调方法：NeFT，秒杀LoRA，性能超全参微调（FPFT）！  AINLPer  https://mp.weixin.qq.com/s/vVjAol05HCagWsR8scNcvg \
  神经元级高效微调方法：NeFT \
  https://arxiv.org/pdf/2403.11621.pdf

# 4.4 Thur
* 16.ICLR2024 | 语言模型知识编辑的鲁棒性研究  ZJUKG  https://mp.weixin.qq.com/s/jKSZeFN1tV8rX7U6nwUO3A 
* 17.弱智吧竟成最佳中文AI训练数据？！中科院等：8项测试第一，远超知乎豆瓣小红书  量子位  https://mp.weixin.qq.com/s/iq5lGyh9Y5P7NXLUS3-giA \
  Ruozhiba 
* 18.首个开源世界模型！百万级上下文，长视频理解吊打GPT-4，UC伯克利华人一作  新智元  https://mp.weixin.qq.com/s/HtTRrIVYqmdUb_h6P9lFtA \
  LWM采用了一个包含各种视频和书籍的大型数据集，利用RingAttention技术对长序列进行可扩展的训练，最终将上下文长度增加到1M token \
  World Model on Million-Length Video And Language With RingAttention \ 
  论文地址：https://arxiv.org/pdf/2402.08268.pdf \
  代码地址：https://github.com/LargeWorldModel/LWM
* 19.基于大型语言模型的游戏智能体综述  专知  https://mp.weixin.qq.com/s/3Cr5N7bGuSBwzSQ8DF7T8Q \
  A Survey on Large Language Model-Based Game Agents 

# 4.5 Fri
* 20.OpenAI发布全新微调API ：ChatGPT支持更详细可视化微调啦！  AIGC开放社区  https://mp.weixin.qq.com/s/0-3TptRmDJbsdR_ESlTR5g \
  基于Epoch的检查点创建、Playground新功能、第三方集成、全面验证指标、超参数配置和更详细的微调仪表板改进。 \
  新的微调API功能适用于GPT-4/Turbo、GPT-3.5等系列模型。 \
  详细微调API教程：https://platform.opEnai.com/docs/guidEs/finE-tuning
* 21.李飞飞主讲，斯坦福2024 CS231n开课，依旧座无虚席  机器之心  https://mp.weixin.qq.com/s/ZVuM_lGyJegXzxxAjD-ESg \
  课程主页：https://cs231n.stanford.edu/
* 22.值得你花时间看的扩散模型教程，来自普渡大学  机器之心  https://mp.weixin.qq.com/s/s-d_VK1ln7ysKL8QIftxNA \
  Tutorial on Diffusion Models for Imaging and Vision \
  文章链接：https://arxiv.org/abs/2403.18103 \
  参考链接：https://engineering.purdue.edu/ChanGroup/stanleychan.html
* 23.(**值得看看EgoExoLearn**)让智能体像孩子一样观察别人学习动作，跨视角技能学习数据集EgoExoLearn来了  机器之心  https://mp.weixin.qq.com/s/HfprU44_ttbpthCJplXnCQ \
  EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World \
  论文链接：https://arxiv.org/abs/2403.16182 \
  代码与数据集链接：https://github.com/OpenGVLab/EgoExoLearn
* 24.(**JetMoE值得试试**)10万美元训出Llama-2级大模型！全华人打造新型MoE，贾扬清SD前CEO围观  量子位   https://mp.weixin.qq.com/s/98TmAe_c4H64RTZXIG5yfg \
  JetMoE，来自MIT、普林斯顿等研究机构。性能妥妥超过同等规模的Llama-2 \
  传送门：https://github.com/myshell-ai/JetMoE \
  参考链接：https://twitter.com/jiayq/status/1775935845205463292
* 25.(**MoD**)谷歌更新Transformer架构，更节省计算资源！50%性能提升  量子位  https://mp.weixin.qq.com/s/Xqnv2L9X4KRkfpTaw7B0SA \
  Mixture-of-Depths（MoD）\
  结果显示，在等效计算量和训练时间上，MoD每次向前传播所需的计算量更小，而且后训练采样过程中步进速度提高50% \
  论文地址：https://arxiv.org/abs/2404.02258
* 26.(**非常重要，值得看看**)《大型语言模型增强强化学习》综述  专知  https://mp.weixin.qq.com/s/TPinksRNrFrn_xdHFdwLMg \
  在这篇综述中，我们提供了一个关于LLM增强RL现有文献的全面回顾，并总结了与传统RL方法相比的特点，旨在明确研究范围和未来研究的方向 \
  利用经典的智能体-环境交互范式，我们提出了一个结构化的分类法，以系统地分类LLMs在RL中的功能，包括四个角色：信息处理器、奖励设计师、决策者和生成器 \
  Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods \
  https://arxiv.org/abs/2404.00282

# 4.6 Sat
* 27.AI视频理解天花板，全新MiniGPT4-Video刷爆SOTA！宝格丽宣传片配文一绝  新智元  https://mp.weixin.qq.com/s/Y8w6CqTvm7zVQMOmTuxePA \
  MiniGPT4-video不仅考虑了视觉内容，还纳入了文本对话，使该模型能够有效地回答涉及视觉和文本内容的查询。 \
  MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens \
  论文地址：https://arxiv.org/pdf/2404.03413.pdf
* 28.AI下一个重大飞跃是理解情感！第一个具有情商的对话型AI来了  新智元  https://mp.weixin.qq.com/s/IOFaPdB_6gtWC-gckWJ3Yw \
  https://venturebeat.com/ai/is-ais-next-big-leap-understanding-emotion-50m-for-hume-says-yes/
* 29.(**ReadAgent**)「有效上下文」提升20倍！DeepMind发布ReadAgent框架  新智元  https://mp.weixin.qq.com/s/xXJqJeqf8mzP9VW9kLIdgQ \
  A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts \
  论文链接：https://arxiv.org/abs/2402.09727
* 30.中科大等意外发现：大模型不看图也能正确回答视觉问题！  量子位  https://mp.weixin.qq.com/s/mmNxJ-YOZx4Hpu8zSkfDGw \
  我们评估多模态模型的方法正确吗？ \
  论文链接：https://arxiv.org/pdf/2403.20330.pdf
* 31.(**MoD**)Google | 提出深度混合Transformer，实现计算资源动态分配，比最优基线快66%  AINLPer  https://mp.weixin.qq.com/s/9eAoR2_1WiB5cQFOv4E6Tw \
  该模型能够动态地分配计算资源到输入序列的特定位置，而不是像传统模型那样均匀地分配计算资源。通过动态计算分配方式，可以在保持性能的同时显著提高模型速度 \
  Mixture-of-Depths: Dynamically allocating compute in transformer-based langugae models \
  https://arxiv.org/pdf/2404.02258.pdf

# 4.7 Sun
* 32.超越GPT-4，斯坦福团队手机可跑的大模型火了，一夜下载量超2k  新智元  https://mp.weixin.qq.com/s/qnFZOPLpdRxW42_cLUcImA \
  论文：Octopus v2: On-device language model for super agent \
  论文地址：https://arxiv.org/abs/2404.01744 \
  模型主页：https://huggingface.co/NexaAIDev/Octopus-v2
* 33.谷歌DeepMind发布Gecko：专攻检索，与大7倍模型相抗衡  机器之心  https://mp.weixin.qq.com/s/5e_Py_Xm0RsmP1YMcikpaQ \
  论文地址：https://arxiv.org/pdf/2403.20327.pdf \
  论文标题：Gecko: Versatile Text Embeddings Distilled from Large Language Models
* 34.(**太厉害了，实时语言纠正，YAY**)斯坦福团队新作：喊话就能指导机器人，任务成功率暴增，网友：特斯拉搞快点  量子位  https://mp.weixin.qq.com/s/F4BQKdkX8QG4ExHOmxzU4A \
  斯坦福的ALOHA家务机器人团队，项目名为Yell At Your Robot（简称YAY），有了它，机器人的“翻车”动作，只要喊句话就能纠正了 \
  而且机器人可以随着人类的喊话动态提升动作水平、即时调整策略，并根据反馈持续自我改进。 \
  YAY系统引入了实时的语言纠正机制，人类的口头命令优先级最高——经识别后，直接传递给低级策略用于执行。\
  Yell At Your Robot: Improving On-the-Fly from Language Corrections \
  论文地址：https://arxiv.org/abs/2403.12910
* 35.(**抱抱脸复现RLHF，值得研究**)抱抱脸Open了OpenAI的秘密武器，网易参与复现  量子位  https://mp.weixin.qq.com/s/g0DoFNH8JD70DW7CEiZ-GQ \
  来自Hugging Face、加拿大蒙特利尔Mila研究所、网易伏羲AI Lab的研究人员从零开始复现了OpenAI的RLHF pipeline，罗列了25个关键实施细节。\
  The N+ Implementation Details of RLHF with PPO: A Case Study on TL; DR Summarization \
  Learning to summarize from human feedback (openai摘要任务)\
  Training Language models to follow instructions with human feedback (gpt-3过渡chatgpt工作)\
* 36.刚刚！阿里 | 开源Qwen1.5-32B大模型，Qwen1.5系列又添新成员！（可在线体验）  AINLPer  https://mp.weixin.qq.com/s/AlpE3mQTjs-4f6hpa823pg \
  Paper：https://qwenlm.github.io/zh/blog/qwen1.5-32b/ \
  Demo：https://huggingface.co/spaces/Qwen/Qwen1.5-32B-Chat-demo

# 4.8 Mon
* 37.(**有趣**)大模型融合！最新「进化算法」全自动组合开源模型，刷榜多项基准测试  新智元  https://mp.weixin.qq.com/s/xQ73ceVsuPB2PM6cuMcGgA \
  目前，Hugging Face拥有50多万个模型，涵盖数十种不同的模态，原则上就可以组合成具有新能力的新模型。 \
  Sakana AI把这个想法转成了现实。他们研究出一种进化模型合并的方法，这是一种使用进化技术来有效地发现不同开源模型的最佳组合方式的通用方法。\
  Evolutionary Optimization of Model Merging Recipes \
  论文地址：https://arxiv.org/abs/2403.13187
* 38.揭秘AI幻觉！GPT-4V存在视觉编码漏洞，清华联合NUS提出LLaVA-UHD  PaperWeekly  https://mp.weixin.qq.com/s/Rh33sCnBeeGYVa9IT8QwFQ \
  在微软一篇长达 166 页的技术报告《The Dawn of LMMs:Preliminary Explorations with GPT-4V (ision)》中，作者发现，对于一个不太复杂的图像中的苹果数量，GPT-4V 竟然怎么数也数不对。 \
  然而，学术界和工业界尚不清楚导致这些问题的底层原因。\
  这个问题在清华大学、新加坡国立大学和中国科学院大学的一篇题为《LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images》的论文中得到了解释。\
  论文地址：https://arxiv.org/pdf/2403.11703.pdf
  代码地址：https://github.com/thunlp/LLaVA-UHD

# 4.9 Tue
* 39.(**LLM逆转诅咒**)破解36年前魔咒！Meta推出反向训练大法消除大模型「逆转诅咒」  新智元  https://mp.weixin.qq.com/s/7IDIGD03-zTmHe9mB-HJ7w \
  The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A" \
  论文地址：https://arxiv.org/pdf/2309.12288v1.pdf
* 40.(**结构性自注意力StructSA**)【CVPR2024】学习视觉Transformer的相关结构  专知  https://mp.weixin.qq.com/s/1ef1-Di8GwWMwdwGL2Us8Q \
  Learning Correlation Structures for Vision Transformers \
  结构性自注意力（StructSA） \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/cd355b84-f495-4e33-aa2e-e78bedd0dfa6) 
* 41.(**digital forgetting & unlearning**)大型语言模型中的数字遗忘：遗忘方法的综述  专知  https://mp.weixin.qq.com/s/ATOgNFfKTwz0VHCZc2SYow \
  为什么叫数字遗忘？和数字有啥关系？\
  Digital Forgetting in Large Language Models: Survey of Unlearning Methods 

# 4.10 Wed
* 42.(**有趣，量化大模型中的知识容量**)Llama架构比不上GPT2？神奇token提升10倍记忆？  机器之心  https://mp.weixin.qq.com/s/TMkn6yMTUrrGhxCQnd7_2g \
  作者采用了他们《语言模型物理学》系列论文的核心思路，即制造人工合成数据，通过控制数据中知识的数量和类型，来严格调控数据中的知识比特数 (bits)。同时，作者使用不同大小和架构的 LLM 在人工合成数据上进行训练，并给出数学定理，来精确计算训练好的模型从数据中学到了多少比特的知识。\
  GPT2 模型能比 LlaMA/Mistral 存储超过 30% 的知识，这意味着几年前的模型在某些方面超越了今天的模型。 \
  低质量数据是否会影响 LLM 对高质量知识的吸收呢？结果令人惊讶，即使对高质量数据的训练时间保持一致，低质量数据的「存在本身」，可能会让模型对高质量知识的存储量下降 20 倍！即便将高质量数据的训练时间延长 3 倍，知识储量仍会降低 3 倍。这就像是将金子丢进沙子里，高质量数据被严重浪费了。 \
  有什么办法修复呢？作者提出了一个简单但极其有效的策略，只需给所有的 (预) 训练数据加上自己的网站域名 token 即可。例如，将 Wiki 百科数据统统加上 wikipedia.org。模型不需要任何先验知识来识别哪些网站上的知识是「金子」，而可以在预训练过程中，自动发现高质量知识的网站，并自动为这些高质量数据腾出存储空间。\
  作者提出了一个简单的实验来验证：如果高质量数据都加上一个特殊 token（任何特殊 token 都行，模型不需要提前知道是哪个 token），那么模型的知识存储量可以立即回升 10 倍，是不是很神奇？所以说对预训练数据增加域名 token，是一个极其重要的数据制备操作。\
  论文地址：https://arxiv.org/pdf/2404.05405.pdf \
  论文标题：Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws
* 43.刚刚，Mistral AI最新磁力链放出！8x22B MoE模型，281GB解禁  新智元  https://mp.weixin.qq.com/s/p_jkVrCLoSA-FoEkQ0m2iQ \
* 44.(**偏好树、偏好学习**)提升开源LLMs推理能力！清华 | 构建高质量对齐数据集，公布「 Eurus」系列模型  AINLPer  https://mp.weixin.qq.com/s/2hCWISSftMD5chdDksuZ3w \
  开源LLMs推理性能和专有大模型的差距主要归因于两大原因：一是缺乏高质量的对齐数据（High-quality alignment data），二是对改进模型复杂推理能力的偏好学习技术（Preference learning techniques）的探索不足。\
  大规模、高质量数据集（ULTRAINTERACT），用于大模型的监督微调和偏好学习 \
  ULTRAINTERACT数据集其主要有以下三个特点：「多样高质量数据」 「多轮交互」 「偏好学习」 \
  「偏好学习」 为每个指令收集了一个偏好树，其中每个节点代表一个行动（action），而树的根是初始指令（instruction）。从根到叶的路径（trajectory）代表了一系列行动的序列，这些行动是模型在尝试解决问题的过程中生成的。在每个偏好树中，所有正确行动的节点和所有以正确行动结束的轨迹都可以用于监督式微调（SFT），而成对的正确和错误的节点或轨迹则用于偏好学习。 \
  Advancing LLM Reasoning Generalists with Preference Trees \
  https://arxiv.org/pdf/2404.02078v1.pdf

# 4.11 Thur
* 45.大模型做时序预测也很强！华人团队激活LLM新能力，超越一众传统模型实现SOTA  量子位  https://mp.weixin.qq.com/s/UL_Kl0PzgfYHOnq7d3vM8Q \
  Time-LLM: Time Series Forecasting by Reprogramming LLMs \
  论文链接 https://arxiv.org/abs/2310.01728
* 46.(**LLM无限长上下文,无限注意力机制,非常值得研究**)Google | 提出Infini-Transformer架构，可让LLMs处理无限长上下文，内存节约114倍！  AINLPer  https://mp.weixin.qq.com/s/factToEEJdWcs5WJG1Ljfg \
  Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention \
  https://arxiv.org/pdf/2404.07143.pdf

# 4.12 Fri
* 47.MIT等首次深度研究「集成LLM」预测能力：可媲美人类群体准确率  新智元  https://mp.weixin.qq.com/s/eGRMP_CgtNM5GgiCprNgYA \
  Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Rival Human Crowd Accuracy \
  论文链接：https://arxiv.org/pdf/2402.19379.pdf
* 48.魔改RNN挑战Transformer，RWKV上新：推出2种新架构模型  量子位  https://mp.weixin.qq.com/s/afbreOaP3dUc25y7phuYIw \
  不走Transformer寻常路，魔改RNN的国产新架构RWKV，有了新进展：提出了两种新的RWKV架构，即Eagle (RWKV-5) 和Finch（RWKV-6)。\
  《Eagle and Finch：RWKV with Matrix-Valued States and Dynamic Recurrence》 \
  论文链接：https://arxiv.org/pdf/2404.05892.pdf
* 49.(**选择性语言建模SLM**)微软&清华 | 提出模型训练新方法：SLM，选择优质Token进行训练，提升训练效率！  AINLPer  https://mp.weixin.qq.com/s/QcMgIHB0_VYRrd3Z3EUIrg \
  RHO-1: Not All Tokens Are What You Need \
  https://arxiv.org/pdf/2404.07965.pdf

# 4.13 Sat
* 50.(**VAR GPT式视觉生成**)GPT超越扩散、视觉生成Scaling Law时刻！北大&字节提出VAR范式  机器之心  https://mp.weixin.qq.com/s/KOEdTgJX4Gga5zRbl57Yow \
  新一代视觉生成范式「VAR: Visual Auto Regressive」视觉自回归来了！使 GPT 风格的自回归模型在图像生成首次超越扩散模型，并观察到与大语言模型相似的 Scaling Laws 缩放定律、Zero-shot Task Generalization 泛化能力 \
  VAR 方法核心：模仿人类视觉，重新定义图像自回归顺序 \
  人类在感知图像或进行绘画时，往往先概览全局、再深入细节。这种由粗到细、从把握整体到精调局部的思想非常自然 \
  Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction \
  体验网站：https://var.vision/ \
  论文链接：https://arxiv.org/abs/2404.02905 \
  开源代码：https://github.com/FoundationVision/VAR \
  开源模型：https://huggingface.co/FoundationVision/var \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/268c618f-f66d-431a-a848-1056f0474c90)
* 51.今日arXiv最热大模型论文：清华大学发布，ChatGML又添新功能，集成“自我批评”，提升数学能力  夕小瑶科技说  https://mp.weixin.qq.com/s/oyvz3gPlGjOhlSJkMvuDww \
  论文标题：ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline \
  论文链接：https://arxiv.org/pdf/2404.02893.pdf \
  自我批判管道(Self-Critique Pipeline)包括两个主要阶段：\
  1. 拒绝性微调（Rejective Fine-tuning, RFT）：在此阶段，采用拒绝采样技术，即淘汰不符合Math-Critique标准的响应，而将其余响应进一步微调。这一阶段的目标是提高模型在数学回答方面的准确性和一致性，同时确保所选答案的多样性。\
  2. 直接偏好优化（Direct Preference Optimization, DPO）：在RFT的基础上，通过直接从正确和错误答案对中学习，进一步提炼通过Math-Critique的答案，重点解决上一阶段中最具挑战性的问题。
* 52.(**太有趣了**)Science Robotics封面！DeepMind强化学习打造超一流机器人球员  新智元  https://mp.weixin.qq.com/s/ocCeve1opQB2i0POsea0gA \
  论文地址：https://www.science.org/doi/10.1126/scirobotics.adi8022 \
  <img width="336" alt="1714113682491" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/829337cd-e64d-4c1c-945a-578761359c36">
* 53.《视觉语言模型》前沿：当前方法和未来方向的综述  专知  https://mp.weixin.qq.com/s/E_v-blLuJssDsqNQyPPQiA \
  Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions \

# 4.14 Sun
* 54.马斯克的首款多模态大模型来了，GPT-4V又被超越了一次  机器之心  https://mp.weixin.qq.com/s/2GDjZS6ctayAF8e8eFb3CQ \
  Grok-1.5  https://x.ai/blog/grok-1.5v
* 55.Claude 3说服力堪比人类！Anthropic最新研究揭秘LLM惊人能力  新智元  https://mp.weixin.qq.com/s/SXGjeFzzhn6RvVJDSplqIQ \
  近日，Claude的东家Anthropic发表博文，称他们开发了一种测量模型说服力的基本方法，并且在Claude系列上进行了实验，相关数据也进行了开源。
* 56.(**一条通过视频生成来实现AGI的路线**)模拟一切实现AGI？OpenAI Sora核心成员最新演讲+专访来了  新智元  https://mp.weixin.qq.com/s/bcuW7NCPs8NKlr4vdYw7xA \
  OpenAI Sora团队核心成员Tim Brooks和Bill Peebles对通用人工智能的实现分享了一些他们的看法，作为Sora研究负责人，他们表示：「视频生成技术将通过模拟一切来实现AGI」。
* 57.(**适合初学者的TRM教程**)万字长文震撼来袭！揭秘Transformer——吐血解读自注意力机制的革命性突破  图灵人工智能  https://mp.weixin.qq.com/s/Fw1hYuBfb851eEIHE6ztAA 
* 58.Nature子刊评论：大脑对算法的独特理解，我们是否能够理解神经算法到底是什么？  脑机接口社区  https://mp.weixin.qq.com/s/9i7x60fGz4i2uCb0sh_HIw \
  《The brain’s unique take on algorithms》 论文链接：https://www.nature.com/articles/s41467-023-40535-z
* 59.(**LVM**)CVPR 2024 | 视觉新突破！首个无自然语言的纯视觉大模型！  小白学视觉  https://mp.weixin.qq.com/s/ieYz5jCm2xRwZfCEbk6cHg \
  Sequential Modeling Enables Scalable Learning for Large Vision Models \
  论文地址：https://arxiv.org/abs/2312.00785 \
  项目主页：https://yutongbai.com/lvm.html

# 4.15 Mon
* 60.(**自由能原理，值得了解**)大语言模型无法实现具身智能：5万字自我模型  CreateAMind  https://mp.weixin.qq.com/s/2HSkeOZtDqmtfZvrJEbq6g \
  The radically embodied conscious cybernetic bayesian brain: from free  energy to free will and back again
* 61.九次架构改进具身机器人，模拟镜像神经元  CreateAMind  https://mp.weixin.qq.com/s/ssx7yhQln2CVQiZJNGbzag
* 62.大语言模型无法实现具身认知  CreateAMind  https://mp.weixin.qq.com/s/O6G9YEn1eNjNTl5z7vmwng \
  大语言模型无法实现具身智能的根本原因  CreateAMind  https://mp.weixin.qq.com/s/brSGlBFfDXIhmHtXydK3hQ \
  Generating meaning: active inference and the scope and limits of passive AI \
  总而言之，我们对语言符号含义的掌握并非源于我们处理自然语言的能力，而是源于我们通过采样和互动而积累的对生活世界的更基础的理解
* 63.解决深度学习4大缺陷  CreateAMind  https://mp.weixin.qq.com/s/dV8RwbewEIkgkT4J6h_v9g \
  A Review of Neuroscience-Inspired Machine Learning https://arxiv.org/abs/2403.18929
  深度学习网络相对于生物神经网络的缺点 
* 64.刷爆多模态任务榜单！贾佳亚团队Mini-Gemini登热榜，代码、模型、数据全部开源  机器之心  https://mp.weixin.qq.com/s/j5CGuJ_-Sf0Pqi_-dDjABA \
  Github 地址：https://github.com/dvlab-research/MiniGemini \
  Demo 地址: http://103.170.5.190:7860/ \
  论文地址：https://arxiv.org/pdf/2403.18814.pdf \
  模型地址：https://huggingface.co/collections/YanweiLi/mini-gemini-6603c50b9b43d044171d0854 \
  数据地址：https://huggingface.co/collections/YanweiLi/mini-gemini-data-660463ea895a01d8f367624e
* 65.(**AI for Math学习清单**)陶哲轩力荐、亲自把关：AI for Math照这个清单学就对了  机器之心  https://mp.weixin.qq.com/s/eBBf51puJVIGrPmwefo6Kg \
  陶哲轩力荐！史上最全「数学AI资源」清单出炉  新智元  https://mp.weixin.qq.com/s/a-0g65mfRe3i9_anj3SB7Q \
  网址：https://docs.google.com/document/d/1kD7H4E28656ua8jOGZ934nbH2HcBLyxcRgFDduH5iQ0/edit
* 66.【博士论文】理解大型语言模型：使用探针分类器和自合理化实现严格和有针对性的可解释性，109页pdf  专知  https://mp.weixin.qq.com/s/Nqpuc8XwQK5YEYTED-5jwQ \
  ??? 什么是探针分类器和自合理器，如何解决可解释性的
* 67.扩散模型最新有何进展？普林斯顿伯克利最新「扩散模型」综述：应用、引导生成、统计率和优化  专知  https://mp.weixin.qq.com/s/qOOyiGkNf_3DHQ-9dRlzEA
* 68.(**FEP自由能原理,完全不懂**)意识的内屏模型：意识的必要条件  CreateAMind  https://mp.weixin.qq.com/s/L-Pp7D96VGFkrmIisu1dpA \
  ??? 什么是内屏模型 ??? \
  The inner screen model of consciousness: applying the free energy principle directly to the study of conscious experience
* 69.(**SFT想LLM注入知识**)微软 | 利用监督式微调（SFT），向大模型注入新知识，无需检索增强生成(RAG)！  AINLPer  https://mp.weixin.qq.com/s/OiDEVct8wnpFWlF-i71t3w \
  Injecting New Knowledge into LLMs via SFT \
  https://arxiv.org/pdf/2404.00213.pdf

# 4.16 Tue
* 70.(**MoD和MoDE**)DeepMind升级Transformer，前向通过FLOPs最多可降一半  机器之心  https://mp.weixin.qq.com/s/nvhXCywpZaOhxWAQWY7PPw \
  论文标题：Mixture-of-Depths: Dynamically allocating compute in transformer-based language models \
  论文地址：https://arxiv.org/pdf/2404.02258.pdf \
  混合深度与专家（MoDE）:MoD 技术可以自然地与 MoE 模型整合起来，组成所谓的 MoDE 模型
* 71.极长序列、极快速度：面向新一代高效大语言模型的LASP序列并行  机器之心  https://mp.weixin.qq.com/s/wPJsmgSAYgh3Si2eZ0_HzA \
  论文标题：Linear Attention Sequence Parallelism \
  论文地址：https://arxiv.org/abs/2404.02882 \
  LASP代码地址：https://github.com/OpenNLPLab/LASP
* 72.多尺度合成生物集体智能概述：5万字  CreateAMind  https://mp.weixin.qq.com/s/BCxmlmmIKRrEuCUdbY5fcw \
  Technological Approach to Mind Everywhere: An Experimentally-Grounded Framework for Understanding Diverse Bodies and Minds 2022
* 73.今日arXiv最热NLP大模型论文：一文读懂大模型的prompt技术  夕小瑶科技说  https://mp.weixin.qq.com/s/QsRWCs8V4Y_jQjYGqVdgyw \
  论文标题:Efficient Prompting Methods for Large Language Models: A Survey \
  论文链接:https://arxiv.org/pdf/2404.01077.pdf
* 74.重磅！《大语言模型》新书出炉，人大出版，391页pdf  专知  https://mp.weixin.qq.com/s/Jn-k95-IAa0N-utA4r3_Sg \
  中文书项目链接：https://llmbook-zh.github.io/ \
  A Survey of Large Language Models 
* 75.空间交替任务和海马-前额叶回路的分层主动推理模型  CreateAMind  https://mp.weixin.qq.com/s/tssU4kX06iJRX3muRPnemQ \
  Bridging Cognitive Maps: a Hierarchical Active Inference Model of Spatial Alternation Tasks and the Hippocampal-Prefrontal Circuit  https://arxiv.org/abs/2308.11463

# 4.17 Wed
* 76.(**meta的Megalodon无限长上下文**)革命新架构掀翻Transformer！无限上下文处理，2万亿token碾压Llama 2  新智元  https://mp.weixin.qq.com/s/xgP9P51gjqJ93FYSWfPeaA \
  Megalodon: Efficient LLM Pretraining and Inference with Unlimited Length \
  论文地址：https://arxiv.org/abs/2404.08801
* 77.(**GeRM**)用MoE横扫99个子任务！浙大等提出全新通用机器人策略GeRM  新智元  https://mp.weixin.qq.com/s/K7Lr1t1rXaR3LwrjbGnweQ \
  GeRM: A Generalist Robotic Model with Mixture-of-experts for Quadruped Robot \
  论文地址：https://arxiv.org/abs/2403.13358 \
  项目地址：https://songwxuan.github.io/GeRM/
* 78.(**具身数据集OpenEQA**)离世界模型更近一步！Meta开源OpenEQA，评估AI Agent情景理解能力  夕小瑶科技说  https://mp.weixin.qq.com/s/rsM4jtt_RdELxanobceqkQ \
  从文字模型到世界模型！Meta新研究让AI Agent理解物理世界  新智元  https://mp.weixin.qq.com/s/Qeuq8v5-ruKGNlcw884RXg \
  Meta 刚刚推出的 OpenEQA，是第一个支持情景记忆和主动探索用例的开放词汇基准数据集，用来衡量 AI 代理对其环境的理解 \
  https://open-eqa.github.io/assets/pdfs/paper.pdf \
  https://open-eqa.github.io/ \
  https://github.com/facebookresearch/open-eqa
* 79.脑电合成自然语音！LeCun转发Nature子刊新成果，代码开源  量子位  https://mp.weixin.qq.com/s/BcV3-3glmdsVF--fpPRU2g \
* 80.让玩家全程掌控游戏：自然语言指令驱动的游戏引擎到来了  机器之心  https://mp.weixin.qq.com/s/YPPm1lcOo_Ql41Pz9TlWkA \
  论文：https://arxiv.org/abs/2404.00276 \
  代码：https://github.com/gingasan/idge \
  Demo：https://www.bilibili.com/video/BV1dA4m1w7xr/?vd_source=e0570b35759018455d30551c1e16a676 \
  论文标题：Instruction-Driven Game Engines on Large Language Models
* 81.导航任意抽象空间：强大的智能不变量  CreateAMind  https://mp.weixin.qq.com/s/Vk5G10-Ll508KdoOJtE4lw \
  Competency in navigating arbitrary spaces as an invariant for analyzing cognition in diverse embodiments

# 4.18 Thur
* 82.最全的损失函数汇总  新机器视觉  https://mp.weixin.qq.com/s/ey8U0mF6nmuYG4FLILhGWQ \
  链接：https://blog.csdn.net/shanglianlm/article/details/85019768
* 83.你好，电动Atlas！波士顿动力机器人复活，180度诡异动作吓坏马斯克  新智元  https://mp.weixin.qq.com/s/f3PXBAVIGXXZV7JbK4ybIw 
* 84.改变LoRA的初始化方式，北大新方法PiSSA显著提升微调效果  PaperWeekly  https://mp.weixin.qq.com/s/DueyyNeiXUDXZFqFUCDSxg 

# 4.19 Fri
* 85.(**最全自由能原理资料**)从机器人到AGI，从具身到可解释，从入门到应用实现的**最全自由能原理资料**  CreateAMind  https://mp.weixin.qq.com/s/yXonEwNWg2ui5vqEiqiYbg
* 86.开源大模型Llama 3王者归来！最大底牌4000亿参数，性能直逼GPT-4  机器之心  https://mp.weixin.qq.com/s/KCyL8WTzXutPQ_k0Vl9Vwg \
  下载链接：https://llama.meta.com/llama-downloads/ \
  Github：https://github.com/meta-llama/
* 87.Loss 才是涌现的关键，而非模型参数  GLM大模型  https://mp.weixin.qq.com/s/OVgI3HMpEYdhiWIxNXufqQ \
  Understanding Emergent Abilities of Language Models from the Loss Perspective \
  论文链接：https://arxiv.org/abs/2403.15796
* 88.(**自动Loss无监督**)自动Loss无监督，仅600标记样本就达到96.6%准确率  CreateAMind  https://mp.weixin.qq.com/s/985NNHKjBmzJKqwCwiMfOg \
  Unsupervised End-to-End Training with a Self-Defined Bio-Inspired Target \
  https://arxiv.org/pdf/2403.12116 \
  https://github.com/neurophysics-cnrsthales/unsupervised-target
* 89.《大型语言模型中基于检索的文本生成》综述  专知  https://mp.weixin.qq.com/s/slHksXsbqTDzY3XwGF4nrA \
  A Survey on Retrieval-Augmented Text Generation for Large Language Models 

# 4.20 Sat
* 90.【全网首发】Llama3 微调项目实践与教程（XTuner 版）  InternLM  https://mp.weixin.qq.com/s/sKet1R4k_Xwmfo6D_x17Rw \
  XTuner：http://github.com/InternLM/XTuner \
  Llama3-XTuner-CN：https://github.com/SmartFlowAI/Llama3-XTuner-CN/
* 91.(**不确定性感知**)今日arXiv最热NLP大模型论文：面向不确定性感知的Language Agent  夕小瑶科技说  https://mp.weixin.qq.com/s/dMCg8RlPuUE_Cs4fvjTbjQ \
  论文标题：Towards Uncertainty-Aware Language Agent \
  论文主页：https://uala-agent.github.io/ \
  论文链接：https://arxiv.org/pdf/2401.14016.pdf
* 92.(**有趣，LLM研究**)Transformer本可以深谋远虑，但就是不做  机器之心  https://mp.weixin.qq.com/s/1kolCWSsFAp4e9MGG089vQ \
  论文标题：Do Language Models Plan for Future Tokens? \
  论文地址：https://arxiv.org/pdf/2404.00859.pdf  
* 93.(**有趣，LLM研究**)大模型一定就比小模型好？谷歌的这项研究说不一定  机器之心  https://mp.weixin.qq.com/s/qmVEhCRlpwC6EnALGuGAhA \
  论文标题：Bigger is not Always Better: Scaling Properties of Latent Diffusion Models \
  论文地址：https://arxiv.org/pdf/2404.01367.pdf  
* 94.MLLM真能看懂数学吗？**MathVerse**来了次摸底测评，放出当天登热榜  PaperWeekly  https://mp.weixin.qq.com/s/uZm3ipgn4FcyIepUcf4iVw \
  论文题目： MATHVERSE: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems? \
  论文链接： https://arxiv.org/pdf/2403.14624.pdf
* 95.(**意识心智相关**)丹尼特的灵魂科学：一位哲学家对心智构成的毕生探索  神经实现  https://mp.weixin.qq.com/s/MadgXUPHRtpH7x_W9atWSA \
  再见丹尼特，探索心智奥秘的一生  集智俱乐部  https://mp.weixin.qq.com/s/HF3TsFJI_pRRESbk5axxeA \
  再见，AI意识先驱：Daniel Dennett  量子位  https://mp.weixin.qq.com/s/q_NHqYVQeap93k2JQ5d-lg \
  丹尼特：哲学是认知科学的一部分  神经实现  https://mp.weixin.qq.com/s/ucUNl-72H2RrXZT6WrCAtw 

# 4.21 Sun
* 96.【伯克利博士论文】理解、构建和评估上下文感知条件自然语言生成模型  专知  https://mp.weixin.qq.com/s/-YgEJqIVcNqFby-OweGpIw \
  Understanding, Building, and Evaluating Models for Context Aware Conditional Natural Language Generation \
  情境感知条件自然语言生成（CNLG）
* 97.(**分层生成，多级规划**)自主机器人的分层生成建模 （intel lab）  CreateAMind  https://mp.weixin.qq.com/s/QwmaKGEl3r-ijfeHD2CLLA \
  Hierarchical generative modelling for autonomous robots \
  https://arxiv.org/pdf/2308.07775.pdf  \
  https://github.com/Yunaik/hgm4robots
* 98.五光十色的多模态大模型：浅探视觉-语言大模型的关键模块设计  PaperWeekly  https://mp.weixin.qq.com/s/RpyF_X_n0e_0OiSEpEsGUQ \
  论文题目：Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models \
  论文链接：https://arxiv.org/abs/2402.07865 \
  项目主页：https://github.com/TRI-ML/prismatic-vlms

# 4.22 Mon
* 99.(**值得看看**)Sora之后，OpenAI Lilian Weng亲自撰文教你从头设计视频生成扩散模型  机器之心  https://mp.weixin.qq.com/s/C8JoiTHwW7T-g66EBPcfDg \
  《What are Diffusion Models?》链接：https://lilianweng.github.io/posts/2021-07-11-diffusion-models/ \
  https://lilianweng.github.io/posts/2024-04-12-diffusion-video/
* 100.(**基于Mamba的MLLM,Cobra**)首个基于Mamba的MLLM来了！模型权重、训练代码等已全部开源  机器之心  https://mp.weixin.qq.com/s/KuuNTL_jBRsyhub5_6aXpQ \
  将VLM中的LLM替换位Mamba \
  原文链接：https://arxiv.org/pdf/2403.14520v2.pdf \
  项目链接：https://sites.google.com/view/cobravlm/ \
  论文标题：Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f613ba25-f7b2-43b7-8812-32c09089b197)
* 101.今日arXiv最热NLP大模型论文：浙江大学：蒸一蒸，多Agent变成单一模型，效果更好  夕小瑶科技说  https://mp.weixin.qq.com/s/e-RsPlaEdeJHgwNa_vFobQ \
  论文标题:Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model \
  论文链接：https://arxiv.org/pdf/2404.04619.pdf 
* 102.【独家】万字长文带你梳理Llama开源家族：从Llama-1到Llama-3  Datawhale  https://mp.weixin.qq.com/s/5_VnzP3JmOB0D5geV5HRFg 
* 103.新测试基准发布，最强开源Llama 3尴尬了  量子位  https://mp.weixin.qq.com/s/-lZKrLWICRdnabzvoqvGKw \
  大模型竞技场背后组织LMSYS推出下一代基准测试Arena-Hard
* 104.Disentangling：学习物体对象表示的主动推理模型  CreateAMind  https://mp.weixin.qq.com/s/ktUzDT2TUpqVMa9orJGwew \
  《解离形状和姿态的物体中心深度主动推理模型》https://arxiv.org/pdf/2209.09097

# 4.23 Tue
* 105.(**具身定位**)如何在2D地图上通过视觉进行重定位？  3D视觉工坊  https://mp.weixin.qq.com/s/f6Ql1OAn7tRUbsszAc0whA \
  论文：LaLaLoc: Latent Layout Localisation in Dynamic, Unvisited Environments（ICCV 2021） \
  LaLaLoc++: Global Floor Plan Comprehension for Layout Localisation in Unvisited Environments (ECCV 2022) \
  项目地址：https://github.com/ActiveVisionLab/LaLaLoc
* 106.加州理工华人用AI颠覆数学证明！提速5倍震惊陶哲轩，80%数学步骤全自动化  新智元  https://mp.weixin.qq.com/s/XErFod3ax-yvf6iKTPP3TQ
* 107.(**解决LLM可解释性问题**)开箱黑盒LLM！谷歌大一统框架Patchscopes实战教程来了  新智元  https://mp.weixin.qq.com/s/9-P92MN0Sw3QMZPJm6pB5w \
  Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models \
  论文链接：https://arxiv.org/pdf/2401.06102.pdf
* 108.《决策成本：解读决策中记忆、强化学习和神经连接的相互作用》166页博士论文  专知  https://mp.weixin.qq.com/s/XIH2-Z5Gekp8JvdpLBSjjQ 
* 109.视觉逻辑数据集V-LoL : A Diagnostic Dataset forVisual Logic  CreateAMind  https://mp.weixin.qq.com/s/TWenl9gYg6pexQkpvukofw \
* 110.微软发布Phi-3，性能超Llama-3，可手机端运行  机器之心  https://mp.weixin.qq.com/s/kb_gfaYkXiW_cR22K2bX9g \
  Phi-3 技术报告：https://arxiv.org/abs/2404.14219
* 111.CVPR 2024 | 基于MoE的通用图像融合模型，添加2.8%参数完成多项任务  机器之心  https://mp.weixin.qq.com/s/dltdnUd_pdfXv0NfXORYzA \
  Task-Customized Mixture of Adapters for General Image Fusion \
  论文链接：https://arxiv.org/abs/2403.12494 \
  代码链接：https://github.com/YangSun22/TC-MoA
* 112.(**BAdam**)24GB单卡全量微调Llama 3-8B，仅需添加一行代码  机器之心  https://mp.weixin.qq.com/s/4MPC-ztzDmyZTjC3wCym1w \
  论文链接：https://arxiv.org/abs/2404.02827 \
  代码链接：https://github.com/Ledzy/BAdam
* 113.(**语言模型就是Q函数,DPO大佬的论文,非常值得看看**)这就是OpenAI神秘的Q*？斯坦福：**语言模型就是Q函数**  机器之心  https://mp.weixin.qq.com/s/Mz_k5ensgiuXu-3cFQ1Dkw \
  论文标题：From r to Q∗: Your Language Model is Secretly a Q-Function \
  论文地址：https://arxiv.org/pdf/2404.12358.pdf

# 4.24 Wed
* 114.COLING2024 | 面向编程的自然语言处理综述  专知  https://mp.weixin.qq.com/s/IsTtnMnw9zNN1v3bjdThig \
  论文名称：A Survey on Natural Language Processing for Programming \
  论文链接：https://arxiv.org/pdf/2212.05773.pdf
* 115.大型语言模型高效推理综述  专知  https://mp.weixin.qq.com/s/rTZHOzTfAhtHg0Lfuk8jDw \
  A Survey on Efficient Inference for Large Language Models
* 116.Agent四大范式 | CRITIC：吴恩达力推Agent设计范式  大语言模型论文追踪  https://mp.weixin.qq.com/s/RhjmsehDXOj5KRY2gQ4wzw \
  Arxiv: https://arxiv.org/abs/2305.11738
* 117.首批中文版Llama3模型来了，解释成语、答弱智吧问题  机器之心  https://mp.weixin.qq.com/s/ny0gBOxf4-tJiwjgp3o9HQ \
  项目链接：https://github.com/CrazyBoyM/llama3-Chinese-chat \
  项目链接：https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat?continueFlag=5a1e5d88eed977ffb39d9b451be2a81d
* 118.(**MOLE,组合多个LoRA权重**)微软 & 清华 | 提出LoRAs专家混合方法：MOLE，可动态、高效地组合多个LoRA！  AINLPer  https://mp.weixin.qq.com/s/W5Js774sYqi6LW3_d70PEw \
  ???好奇是怎么做到的 \
  Mixture of LoRA Experts \
  https://arxiv.org/pdf/2404.13628.pdf

# 4.25 Thur
* 119.(**Vitron**)颜水成挂帅，奠定「通用视觉多模态大模型」终极形态！一统理解/生成/分割/编辑  新智元  https://mp.weixin.qq.com/s/ef3GMQavH_K9iarSdwoxog \
  Vitron: A Unified Pixel-level Vision LLM for Understanding, Generation, Segmenting, Editing \
  项目主页&Demo：https://vitron-llm.github.io/ \
  论文链接：https://is.gd/aGu0VV \
  开源代码：https://github.com/SkyworkAI/Vitron
* 120.(**厉害，Snowflake的Arctic，怎么进行稀疏的？**)全球最大开源模型再刷爆纪录！4800亿参数MoE击败Llama 3、Mixtral  新智元  https://mp.weixin.qq.com/s/Wbs30QvvtWtYB6mp47Z8NA \
  Snowflake的Arctic，以128位专家和4800亿参数，成为迄今最大的开源模型。它的特点，是又大又稀疏，因此计算资源只用了不到Llama 3 8B的一半，就达到了相同的性能指标。 \
  Arctic的的两个特点，一个是大，另一个就是非常稀疏。 \
  !!!???怎么做到又大又稀疏的，值得研究 \
  为了实现如此高的训练效率，Arctic采用了独特的Dense-MoE Hybrid transformer架构。\
  该架构将一个10B规模的稠密Transformer模型与一个128×3.66B规模的残差MoE MLP相结合，虽然总参数量达到480B，但通过top-2 gating的方式只选择了其中17B个参数保持活跃。\
  项目地址：https://github.com/Snowflake-Labs/snowflake-arctic \
  Cookbook：https://medium.com/snowflake/snowflake-arctic-cookbook-series-exploring-mixture-of-experts-moe-c7d6b8f14d16 \
  https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/
* 121.GPT-4现场被端侧小模型“暴打”，商汤日日新5.0：全面对标GPT-4 Turbo  量子位  https://mp.weixin.qq.com/s/oiP4LPjVWo-9FLJXiGrz5A 
* 122.(**终身学习**)【CMU博士论文】高效的深度神经网络终身学习：架构、训练和数据的优化  专知  https://mp.weixin.qq.com/s/XnzyLOMUnOJBMeNK4VMMdg \
  Efficient Lifelong Learning in Deep Neural Networks: Optimizing Architecture, Training, and Data 

# 4.26 Fri
* 123.(**PEFT综述**)让大模型不再「巨无霸」，这是一份最新的大模型参数高效微调综述  机器学习研究组订阅  https://mp.weixin.qq.com/s/-CfgMlz_-qLYXvKsze6EkQ \
  Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey \
  论文链接：https://arxiv.org/pdf/2403.14608.pdf
* 124.(**大脑信息处理**)大脑如何分解信息？信息分解帮助理解生物和人工认知系统  图灵人工智能  https://mp.weixin.qq.com/s/TEiEpXXna72vhEJq6LHjsg \
  论文题目：Information decomposition and the informational architecture of the brain \
  论文地址：https://www.sciencedirect.com/science/article/pii/S136466132300284X
* 125.数学的本质与万物的关联  图灵人工智能  https://mp.weixin.qq.com/s/JJJMX04SndTaQjesJSaJQg
* 126.CVPR 2024 | 擅长处理复杂场景和语言表达，清华&博世提出全新实例分割网络架构MagNet  机器之心 
 https://mp.weixin.qq.com/s/GXNMUNtXtHmHPRCWD3fm1g \
  指代分割 (Referring Image Segmentation，RIS) 是一项极具挑战性的多模态任务，要求算法能够同时理解精细的人类语言和视觉图像信息，并将图像中句子所指代的物体进行像素级别的分割 \
  论文标题：Mask Grounding for Referring Image Segmentation \
  论文地址：https://arxiv.org/abs/2312.12198
* 127.(**多智能体协作,非常有趣**)吴恩达：多智能体协作是新关键，软件开发等任务将更高效  机器之心  https://mp.weixin.qq.com/s/yBrELZ5-oC7-vPxuzLGsJw \
  原文链接：https://www.deeplearning.ai/the-batch/issue-245/ \
  论文标题：Communicative Agents for Software Development（ChatDEV） \
  论文链接：https://arxiv.org/pdf/2307.07924.pdf \
  论文标题：AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation \
  论文链接：https://arxiv.org/pdf/2308.08155.pdf \
  论文标题：METAGPT: META PROGRAMMING FOR A MULTI-AGENT COLLABORATIVE FRAMEWORK \
  论文链接：https://arxiv.org/pdf/2308.00352.pdf
* 128.会颠勺的国产机器人来了：大模型加持，家务能力满分  机器之心  https://mp.weixin.qq.com/s/wby5URTINNlLj1j2LoHGzg \
  来自星尘智能公司的自研 AI 机器人 Astribot S1，在同规格机器人中展现了「最强操作性能」
* 129.(**Chain-of-X综述，值得看看**)大模型思维链推理及文档理解的2个问题：大模型COT链式推理变体及文档理解的阅读顺序方案  老刘说NLP  https://mp.weixin.qq.com/s/u9CnnE8gDj6JpYqlc-zejw \
  Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs \
  https://arxiv.org/pdf/2404.15676 \
  与RAG结合，那么就会演变成coa(chain of augmentation) \
  与反馈机制进行结合，则会变成cof(chain of feedback)，但就反馈而言，其包括内部的修成self-refine，也包括外部的反馈 \
  与模型结合，则会变成com(chain of model)，这个实际上包括模型之间的讨论或者多个lora进行结合，如chain of lora
* 130.奥特曼斯坦福演讲全场爆满！GPT-5强到发指，Scaling Law依然有效  新智元  https://mp.weixin.qq.com/s/8Te-dTENLFGogme3Z2RnPQ \
* 131.(**SceneScript**)Transformer解码真实场景！Meta推出70M参数SceneScript模型  新智元  https://mp.weixin.qq.com/s/2RxgPPkdmaIgR_u-Zdsjfw \
  来自Meta的研究人员推出了SceneScript，只需要**70M**参数，仅采用编码器解码器架构，就能将真实世界的场景转化为几何表示 \
  SceneScript- Reconstructing Scenes With An Autoregressive Structured Language Model \
  论文地址：https://arxiv.org/pdf/2403.13064.pdf \
  参考资料：https://www.projectaria.com/scenescript/

# 4.27 Sat
* 132.《大型语言模型持续学习》综述  专知  https://mp.weixin.qq.com/s/oBPEwUB0y_qCBZyJ1B23Iw \
  Continual Learning of Large Language Models: AComprehensive Survey \
  在这项综述中检查的完整论文列表可在https://github.com/Wang-ML-Lab/llm-continual-learning-survey找到

# 4.28 Sun
* 133.代码：⾃扩展神经⽹络 Self-Expanding  CreateAMind  https://mp.weixin.qq.com/s/cl5bN5ODZ0ZDqA81pvv3Og \
  Self-Expanding Neural Networks \
  https://github.com/ml-research/self-expanding-neural-networks \
  https://arxiv.org/pdf/2307.04526.pdf 
* 134.视频生成、理解与流媒体的生成式人工智能和大型语言模型综述  专知  https://mp.weixin.qq.com/s/b_Lv7ubQ1Dtns4wBG-uv4A \
  A Survey on Genrative AI and LLM for Video Generation, Understanding, and Streaming 
* 135.CVPR 2024 | LORS算法：低秩残差结构用于参数高效网络堆叠，参数少、成本低、内存小  我爱计算机视觉  https://mp.weixin.qq.com/s/mNzyY45mB6A6JDE-XLhGTw \
  LORS: Low-rank Residual Structure for Parameter-Efficient Network Stacking \
  论文链接：https://arxiv.org/abs/2403.04303 \
  源码链接：https://github.com/li-jl16/LORS

# 4.29 Mon
* 136.(**Awaker1.0 VDT**)全球首个自主进化多模态MoE震撼登场！写真视频击败Sora，人大系团队自研底座VDT  新智元  https://mp.weixin.qq.com/s/uEJzoGGV_-gf3DXhPnY6OA \
  人大系初创公司智子引擎发布的全新多模态大模型Awaker 1.0 \
  在理解侧，Awaker 1.0与数字世界和现实世界进行交互，在执行任务的过程中将场景行为数据反哺给模型，以实现持续更新与训练；在生成侧，Awaker 1.0可以生成高质量的多模态内容，对现实世界进行模拟，为理解侧模型提供更多的训练数据。\
  具备「真正」的自主更新能力 \
  Awaker 1.0的生成侧，是智子引擎自主研发的类Sora视频生成底座VDT，可以用作现实世界的模拟器
* 137.(**LongRoPE**)LLM上下文窗口突破200万！无需架构变化+复杂微调，轻松扩展8倍  新智元  https://mp.weixin.qq.com/s/8V4yGzXBsFfGwCZ4VJDE1g \
  LongRoPE方法首次将LLM的窗口扩展到了2048k个token，只是简单微调的情况下，就能实现与短上下文窗口相近的性能 \
  LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens \
  论文链接：https://arxiv.org/abs/2402.13753 \
  代码链接：https: //github.com/microsoft/LongRoPE
* 138.「专业智能体指导」让小模型学会数学推理！微调Mistral-7B实现86.81%准确率  新智元  https://mp.weixin.qq.com/s/dr-Ab0G9hizCDgLNZ_o6_Q \
  Orca-Math: Unlocking the potential of SLMs in Grade School Math \
  论文链接：https://arxiv.org/abs/2402.14830
* 139.突破摩尔定律极限！前谷歌量子计算团队首创「热力学计算机」，英伟达GPU「退役」？  新智元  https://mp.weixin.qq.com/s/0p27p92t0FZzZ05IfB7LSw \
  https://www.extropic.ai/future

# 4.30 Tue
* 140.(**AgentGroupChat**)小红书让智能体们吵起来了！联合复旦推出大模型专属群聊工具  量子位  https://mp.weixin.qq.com/s/xqcpu78avAPigLzw9M2wlw \
  该平台简直是大模型的cosplay胜地，它们进行角色扮演，成为各种各样的Agent。 \
  然后，Agents通过语言交流参与社会动态，展现了个体间的互动如何涌现成群体的宏观行为。 \
  众所周知，人类群体的进化，正来源于一次次涌现行为的发生，如社会规范的建立、冲突的解决和领导力的执行。 \
  AgentGroupChat: An Interactive Group Chat Simulacra For Better Eliciting Emergent Behavior \
  论文链接：https://arxiv.org/abs/2403.13433 \
  代码链接：https://github.com/MikeGu721/AgentGroup
* 141.神秘大模型一夜刷屏，能力太强被疑GPT-4.5，奥特曼避而不答打哑谜  量子位  https://mp.weixin.qq.com/s/SuX3BPvdlbOLeqlcGKSr-Q \
  gpt2-chatbot
* 142.IEEE RAL 2024 | Safe-VLN：针对连续环境中视觉语言导航任务的避障框架  PaperWeekly  https://mp.weixin.qq.com/s/uk-vxX1Fwa0hRfb1HwD1dQ \
  Safe-VLN: Collision Avoidance for Vision-and-Language Navigation of Autonomous Robots Operating in Continuous Environments \
  论文链接： \
  https://ieeexplore.ieee.org/abstract/document/10496163 \
  https://arxiv.org/pdf/2311.02817.pdfo
* 143.在12个视频理解任务中，Mamba先打败了Transformer  机器之心  https://mp.weixin.qq.com/s/Y1gAtLoAlm7Zzt-Fl8rMYw \
  论文标题：Video Mamba Suite: State Space Model as a Versatile  Alternative for Video Understanding \
  论文链接：https://arxiv.org/abs/2403.09626 \
  代码链接：https://github.com/OpenGVLab/video-mamba-suite
* 144.COA：全参Finetune模型可以提高Agent应用工具调用能力  HuggingAGI  https://mp.weixin.qq.com/s/CrRACtFPha_DOP_QwtYTpw \
  作者提出了 COA（Chain-of-Abstraction，抽象链）框架，旨在提高 LLMs 在使用工具进行多步骤推理时的鲁棒性和效率，规划具有领域专业工具意识的通用思维链推理。
* 145.大模型如何迭代？北大等《大型语言模型自我进化》综述  专知  https://mp.weixin.qq.com/s/F1X_plq3EhJqRqceUUFu3w \
  A Survey on Self-Evolution of Large Language Models 
