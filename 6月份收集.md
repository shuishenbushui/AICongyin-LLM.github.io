# 6.1 周4
* 1、LLM推理提速2.8倍，CMU提出投机式推理引擎，小模型撬动大模型高效推理 https://mp.weixin.qq.com/s/kCJUJI1QMIcUQLAleQGosA \
近日，来自卡耐基梅隆大学（CMU）的 Catalyst Group 团队发布了一款「投机式推理」引擎 SpecInfer，可以借助轻量化的小模型来帮助大模型，在完全不影响生成内容准确度的情况下，实现两到三倍的推理加速。\
论文链接：https://arxiv.org/abs/2305.09781 \
项目链接：https://github.com/flexflow/FlexFlow/tree/inference \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/37932cd8-70a3-4e83-8141-542bd14c2461)
* 2、ChatGPT/GPT-4做知识图谱构建推理怎么样？浙大等最新《大语言模型在知识图谱构建与推理》论文，量化评估LLM在KG表现 https://mp.weixin.qq.com/s/MFi2cKh347SnLzl7zmBTWQ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/585da197-5929-4096-a617-790aba46c570)
* 3、思维链如何释放语言模型的隐藏能力？最新理论研究揭示其背后奥秘 https://mp.weixin.qq.com/s/CoLFFQTF9QqL8lSbtaY-_Q \
本文中，北大的几位研究者证明了CoT在实现大语言模型（LLM）推理中是不可或缺的，并从理论和实验角度揭示了CoT如何释放LLM的巨大潜力。
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a3327a90-a8b0-4381-b51c-7925538651e6) \
论文链接：https://arxiv.org/abs/2305.15408
* 4、GPT-4 过程监督 提高解决数学问题的能力 \
https://mp.weixin.qq.com/s/PiVLFHRBLFD5Xj_mzCDsLg https://mp.weixin.qq.com/s/rzm5jdwgc4mMzTZhirHOxQ \
* 5、张俊林趣谈：GPT4是否已具备类人智慧，为何GPT通过Next Token Prediction可以产生智能 https://mp.weixin.qq.com/s/eSGZvJKl3WPgrAwp4Zxopg

# 6.2 周5
* 1、刘知远：大模型值得探索的十个研究方向 https://mp.weixin.qq.com/s/YD1skOQmsW8U_Xfw_Km7Tw
* 2、吴恩达的3门课程 https://mp.weixin.qq.com/s/rn_6vKEHZUKo5gb5-xtXEA \
用ChatGPT API搭建系统 \
通过LangChain使用LLM开发应用 \
扩散模型如何工作 
* 3、斯坦福大学李飞飞团队新作：孪生掩码自编码器SiamMAE，刷榜视觉自监督方法 \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5f4ed679-c0b9-46ef-b8dd-ba0eb3a725d4)
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/934303ba-c397-4d7f-b4b7-027efc027e70)
论文链接：https://siam-mae-video.github.io/resources/paper.pdf
* 4、全面了解多模态大语言模型 Multimodal Large Language Models，首个跟踪 MLLM 进展的论文集合 https://mp.weixin.qq.com/s/BuBr5OgflKLIYbjLFLGPEA \
论文集合链接地址：https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models \
大语言模型 Large Language Models（LLM）强大的泛化和推理能力给计算机视觉领域带来了很多灵感和启发，从而开辟出多模态大语言模型 Multimodal Large Language Models（MLLM）这一全新的前沿热点方向。该项目汇集了该方向近期的论文，包括：\
Multimodal Instruction Tuning \
Multimodal In-Context Learning \
Multimodal Chain-of-Thought \
LLM-Aided Visual Reasoning \
Fundation Models \
others \
这 6 个子方向以及相应的新开放的数据集，该链接将保持实时更新，便于研究人员跟进。
* 5、率先开放语音、视频等多模态对话能力，这家中国公司又比OpenAI走快了一步  国产 AI 模型「元乘象 ChatImg」  https://mp.weixin.qq.com/s/XWxxFvLESqIn-5emNp5ZxA \
进行了将模型部署到机器人上的尝试，详见视频 \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7a668c12-1373-43a1-8151-b5993b712549)
* 6、模仿Jeff Dean神总结，前谷歌工程师分享「LLM开发秘籍」：每个开发者都应知道的数字！ https://mp.weixin.qq.com/s/vrPRHdsFzHZQQkrixnWS2Q
* 7、透彻！驯服大型语言模型（LLMs）的五种方法，及具体方法选择思路 https://mp.weixin.qq.com/s/93xk_x7LBFLOZlmnM96IMw


# 6.3 周6
* 1、SelFee，一个迭代自修改的大语言模型。  SelFee: Iterative Self-Revising LLM Empowered by Self-Feedback Generation \
详细介绍：kaistai.github.io/SelFee/
韩国顶尖公立大学KAIST（韩国科学技术院）根据LLaMA模型，推出了具备自我反馈、迭代能力的类ChatGPT开源模型SelFee（70亿、130亿两种参数）。SelFee的自我反馈、迭代能力相当新奇，无需借助外力可自我评估并生成。无论是在开源界、还是各大科技公司推出的产品中都很罕见。\
开源地址：https://github.com/kaistAI/SelFee \
在线体验：https://kaistai.github.io/SelFee/demo \
该模型同样是在LLaMA基础上用chatgpt的数据做的微调。你问它一个问题，它回答后会自己问自己这个答案需要求改吗，如果自己觉得需要修改就再生成一个新答案，然后继续问自己这个回答是否需要修改，直到最终自己觉得不需要修改为止。

# 6.4 周7
* 1、当量子计算遇到语言模型：量子互文性助力生成模型 | 量子世界地图 https://mp.weixin.qq.com/s/PfGjcU3k8NKX7W2Eht-ngg
* 2、PandaGPT：一个跨模态语言模型，支持6种模态指令，支持在线Demo体验！ https://mp.weixin.qq.com/s/y2gk8nsjE25FDvFPayEGWQ \
通过结合 ImageBind 的模态对齐能力和 Vicuna 的生成能力，同时实现了六种模态下的指令理解与跟随能力。虽然 PandaGPT 的效果尚有提升空间，但展示了跨模态 AGI 智能的发展潜力。\
项目主页: https://panda-gpt.github.io/ \
代码: https://github.com/yxuansu/PandaGPT \
论文: http://arxiv.org/abs/2305.16355 \
线上 Demo 展示: https://huggingface.co/spaces/GMFTBY/PandaGPT
* 3、全面测评！大模型复杂推理能力，华人科学团队推出「思维链集」 https://mp.weixin.qq.com/s/vbyRsTu1zHuYyBfw9z4FpA \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/330bca5c-6893-453c-97d4-dacbdb6fe2f4)
论文地址：https://arxiv.org/pdf/2305.17306.pdf

# 6.5 周1
* 1、思想克隆！前OpenAI研究员让AI模仿人类思维，现实版「机械姬」降临 https://mp.weixin.qq.com/s/_gqfwc9bJvI7Hb4gmuibiA \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6ad75602-24ad-4cf7-b6d9-785f0cf7e9cb)
论文地址：https://arxiv.org/pdf/2306.00323.pdf
* 2、首个模拟人类认知的思维框架OlaGPT：六大模块增强语言模型，推理能力最高提升85% https://mp.weixin.qq.com/s/pb8aIkda9IMAKeE36qgpEQ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/48bb5f2c-55b0-4a97-8d04-5c254361548e)
论文链接：https://arxiv.org/abs/2305.16334 \
代码链接：https://github.com/oladata-team/OlaGPT
* 3、神经推理如何问答？ CMU-Haitian Sun博士论文《神经推理问答》，151页pdf全面阐述QA推理任务 https://mp.weixin.qq.com/s/fdgL63dQsAuQG3IXCb2E2g
* 4、近乎完美！最强算术语言模型: Goar-7B，干翻GPT-4，怒越PaLM-540B！24G可训练 https://mp.weixin.qq.com/s/_haINkHNV4bMszm9F41yXA \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a2a259a5-5ef7-4570-86c9-4af187a9456c)
Paper：https://arxiv.org/pdf/2305.14201.pdf \
Code：https://github.com/liutiedong/goat
* 5、Amazon | 深入研究LLMs与AutoGPT的结合：揭示出GPT-4惊人的人类决策能力！ https://mp.weixin.qq.com/s/Gbz7ZVVdeTq64mj1-__aQA \
心理学研究过人们当面对不同意见时的处理方式。当人们往往比较侧重于具有权威的意见，从而忽略忽略极少数的个别意见;并且人们还会比较侧重于自己而忽略其他人的意见。今天给大家分享的这篇文章，作者针对决策任务，对Auto-GPT代理进行了全面的基准研究，探索了大型语言模型（LLM）在决策任务中的应用。「实验结果表明GPT4有了类似于人类的能力，可以从不同的意见中提取有用信息，进行思考和批判然后提高自己的结果」。\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/25b9b9fb-68d2-41d8-a515-5f8b7e649bf8)
Paper：https://arxiv.org/pdf/2306.02224.pdf \
Code：https://github.com/younghuman/LLMAgent

# 6.6 周2
* 1、GPT充当大脑，指挥多个模型协作完成各类任务，通用系统AutoML-GPT来了 https://mp.weixin.qq.com/s/Ji7vF9BAkIVfqvkCrMqSSg
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a4ad6f22-e925-4812-ba5e-0a97c3ea0336) \
论文地址：https://papers.labml.ai/paper/35151be0eb2011edb95839eec3084ddd
* 2、效果达OpenAI同规模模型96%，发布即开源！国内团队新发大模型，CEO上阵写代码  https://mp.weixin.qq.com/s/mj8cWkYNQPAobA1ybUzWYg \
国内自研大模型迎来新面孔，而且发布即开源！最新消息，多模态大语言模型TigerBot正式亮相，包含70亿参数和1800亿参数两个版本，均对外开源。\

# 6.7 周3
* 1、Awesome-Graph-LLM：图相关大型语言模型(LLM)相关资源列表: github.com/XiaoxinHe/Awesome-Graph-LLM \
* 2、参数高效微调（PEFT）技术  ???缺少资料来源\
在面对特定的下游任务时，如果进行Full FineTuning（即对预训练模型中的所有参数都进行微调），太过低效；而如果采用固定预训练模型的某些层，只微调接近下游任务的那几层参数，又难以达到较好的效果。\
PEFT技术旨在通过最小化微调参数的数量和计算复杂度，来提高预训练模型在新任务上的性能，从而缓解大型预训练模型的训练成本。这样一来，即使计算资源受限，也可以利用预训练模型的知识来迅速适应新任务，实现高效的迁移学习。因此，PEFT技术可以在提高模型效果的同时，大大缩短模型训练时间和计算成本，让更多人能够参与到深度学习研究中来。\
Prefix Tuning：与full fine-tuning更新所有参数的方式不同，该方法是在输入token之前构造一段任务相关的virtual tokens作为Prefix，然后训练的时候只更新Prefix部分的参数，而Transformer中的其他部分参数固定。该方法其实和构造Prompt类似，只是Prompt是人为构造的“显式”的提示,并且无法更新参数，而Prefix则是可以学习的“隐式”的提示。 同时，为了防止直接更新Prefix的参数导致训练不稳定的情况，他们在Prefix层前面加了MLP结构(相当于将Prefix分解为更小维度的Input与MLP的组合后输出的结果)，训练完成后，只保留Prefix的参数。\
Prompt Tuning：该方法可以看作是Prefix Tuning的简化版本，只在输入层加入prompt tokens，并不需要加入MLP进行调整来解决难训练的问题。随着预训练模型参数量的增加，Prompt Tuning的方法会逼近fine-tuning的结果。\
P-Tuning：该方法的提出主要是为了解决这样一个问题：大模型的Prompt构造方式严重影响下游任务的效果。P-Tuning将Prompt转换为可以学习的Embedding层，并用MLP+LSTM的方式来对prompt embedding进行一层处理。\
P-Tuning v2：让Prompt Tuning能够在不同参数规模的预训练模型、针对不同下游任务的结果上都达到匹敌Fine-tuning的结果。相比Prompt Tuning和P-tuning的方法，P-Tuning v2方法在多层加入了Prompts tokens作为输入，带来两个方面的好处：
带来更多可学习的参数（从P-tuning和Prompt Tuning的0.1%增加到0.1%-3%），同时也足够参数高效。加入到更深层结构中的Prompt能给模型预测带来更直接的影响。\
Adapter Tuning：该方法设计了Adapter结构（首先是一个down-project层将高维度特征映射到低维特征，然后过一个非线形层之后，再用一个up-project结构将低维特征映射回原来的高维特征；同时也设计了skip-connection结构，确保了在最差的情况下能够退化为identity），并将其嵌入Transformer的结构里面，在训练时，固定住原来预训练模型的参数不变，只对新增的Adapter结构进行微调。同时为了保证训练的高效性（也就是尽可能少的引入更多参数）。\
LoRA：在涉及到矩阵相乘的模块，引入A、B这样两个低秩矩阵模块去模拟full fine-tuning的过程，相当于只对语言模型中起关键作用的低秩本质维度进行更新。\
典型应用：\
ChatGLM-Tuning ：一种平价的chatgpt实现方案，基于清华的 ChatGLM-6B + LoRA 进行finetune。\
Alpaca-Lora：使用低秩自适应（LoRA）复现斯坦福羊驼的结果。Stanford Alpaca 是在 LLaMA 整个模型上微调，而 Alpaca-Lora 则是利用 Lora 技术，在冻结原模型 LLaMA 参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。由于这些新增参数数量较少，这样不仅微调的成本显著下降，还能获得和全模型微调类似的效果。\
BLOOM-LORA：由于LLaMA的限制，我们尝试使用Alpaca-Lora重新实现BLOOM-LoRA。\
PEFT实现：\
PEFT：Huggingface推出的PEFT库。\
unify-parameter-efficient-tuning：一个参数高效迁移学习的统一框架。\
经验与教训\
经验：\
对于同一模型，选择不同的训练框架，对于资源的消耗情况可能存在显著差异（比如使用Huggingface Transformers和DeepSpeed训练OPT-30相对于使用Alpa对于资源的消耗会低不少）。\
进行大模型模型训练时，先使用小规模模型（如：OPT-125m/2.7b）进行尝试，然后再进行大规模模型（如：OPT-13b/30b...）的尝试，便于出现问题时进行排查。\
• ChatGLM-6B 微调：• https://github.com/hiyouga/ChatGLM-Efficient-Tuning \
• LLaMA, BLOOM 微调：• https://github.com/hiyouga/LLaMA-Efficient-Tuning \
支持的方法 \
• 全参数微调 \
• Freeze部分参数微调 \
• P-Tuning v2微调（仅ChatGLM） \
• LoRA微调 \
• QLoRA微调 

# 6.8 周4
* 1、谷歌发布了9节关于《生成式AI》的课程，可免费学习。\
分别是：\
Intro to Generative AI \
Intro to Large Language Models \
Intro to Responsible AI \
Intro to Image Generation \
Encoder-Decoder \
Attention Mechanism \
Transformers and BERT Models \
Create Image Captioning Models \
Intro to Gen AI Studio \
地址：www.cloudskillsboost.google/paths/118
* 2、M⁶Doc Dataset：用于文档版面分析研究的M⁶Doc数据集: github.com/HCIILAB/M6Doc
* 3、轩辕：千亿级中文金融对话模型，针对中文金融领域优化的千亿级开源对话大模型，在BLOOM-176B的基础上针对中文通用领域和金融领域进行了针对性的预训练与微调: github.com/Duxiaoman-DI/XuanYuan
* 4、SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL
* 5、利用Llama Index、 GPT-4和 Streamlit 实现的财经新闻分析: github.com/hackingthemarkets/financial-news-llama-index \
* 6、![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/91235554-4dca-4c63-b4ce-cdca0bf96c70) \
涉及到一些模式挖掘，以及引入知识图谱作文本增强，来解决知识图谱补全问题 \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8b055444-c847-4318-8bcd-af94bad5f713)
* 7、GPT的应用流程详解和应用实例，来源https://karpathy.ai/stateofgpt.pdf \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d1535694-4b51-4f14-aa5a-5cb3638b212a)
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/32d57b59-c065-4b5a-b9e7-7e9ff5cd03ee)
* 8、Macaw-LLM，一个试验性的开源的多模态语言模型 \
地址：github.com/lyuchenyang/Macaw-LLM \
基于多个已有的开源项目，包括：\
CLIP：负责编码图像和视频帧。\
Whisper：负责编码音频数据。\
LLM（LLaMA/Vicuna/Bloom）：负责编码指令和生成响应的语言模型。
* 9、LeCun力挺，马毅教授五年集大成之作：完全数学可解释的白盒Transformer，性能不输ViT https://mp.weixin.qq.com/s/pUU5j1DEuViK9WblcQ6YHg \
马毅教授领导的研究团队开发了CRATE模型，推动了神经网络可解释研究！ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7229714f-e2c9-4adb-825f-dada3d464916)
代码链接：https://github.com/Ma-Lab-Berkeley/CRATE \
论文链接：https://arxiv.org/abs/2306.01129
* 10、多模态可控图片生成统一模型来了，模型参数、推理代码全部开源 https://mp.weixin.qq.com/s/T5G9r1nrJ8Z5WSIe-zbp3Q \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/10520e96-f6a1-4250-9fd5-6c9be66d223b)
论文地址：https://arxiv.org/abs/2305.11147 \
代码地址：https://github.com/salesforce/UniControl \
项目主页：https://shorturl.at/lmMX6 
* 11、NLP对话系统及实战项目分享【含源码】  https://mp.weixin.qq.com/s/e0450cK_bMPgx1l50v__cA \
* 对话系统核心理论与一个完整的订餐机器人实战项目

# 6.9 周5
* 1、将330亿参数大模型「塞进」单个消费级GPU，加速15%、性能不减 https://mp.weixin.qq.com/s/iOv3VYw6-OYYAaPFYRfZqQ  个人终端设备跑大模型成为现实了。 \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/64f69814-cfce-4f95-a8cd-a93888667fab)
论文地址：https://arxiv.org/pdf/2306.03078.pdf \
项目地址：https://github.com/Vahe1994/SpQR
* 2、深度学习三巨头之一 Yann LeCun：大语言模型带不来 AGI https://mp.weixin.qq.com/s/HFqPxE4rhLOJmcFybYuiSA   自监督学习与世界模型
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8abe2f22-1873-4ff8-bece-a2f2af55ca23)
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/250af903-8c2e-43b8-b5ba-2c8235a38bda)
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4857ac8f-50a0-4c3e-ab82-2a8aa4eb829d) \
相关视频：图灵奖得主、深度学习巨头 Yann LeCun 教授于2022 年 2 月 23在百度的讲座 《A Path Towards Autonomous AI。。。  \
https://www.bilibili.com/video/BV1H44y1n7Vn/?spm_id_from=333.337.search-card.all.click&vd_source=f5aceb5f4e7793d3e5cabca8dcfa32ed \
LeCun教授的理论值得深入研究，对未来的AGI系统的设计会有很深入的启发。

# 6.9之后
* 1、医药领域微调指令数据：Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models\
GitHub: github.com/zjunlp/Mol-Instructions
* 2、关于模型评测，鲁棒性评测：PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts\
GitHub: github.com/microsoft/promptbench
* 3、斯坦福发布LLM排行榜AlpacaEval，微软WizardLM登顶开源模型第一\
最近，来自斯坦福大学的研究人员发布了全新的大语言模型排行榜 AlpacaEval，它是一种基于 LLM 的全自动评估基准，且更加快速、廉价和可靠。\
https://mp.weixin.qq.com/s/7X8pRaexWJ4c0kVswawU1A
* 4、WebGLM: Towards An Efficient Web-enhanced Question Answering System with Human Preferences
https://github.com/THUDM/WebGLM \
https://arxiv.org/pdf/2306.07906.pdf \
* 5、GPT 0613版本新增的函数调用文档 https://platform.openai.com/docs/guides/gpt/function-calling 
* 6、数据，工具和模型，很全的资料\
https://github.com/DSXiangLi/DecryptPrompt\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/513270da-91f3-44c1-9cff-1fad1dbb0187)
* 7、一款零代码AI应用与LLM工作流构建神器，Flowisee\
https://flowiseai.com/ \
https://github.com/FlowiseAl/Flowise
* 8、一个关于多模态大语言模型资料收集的项目：github.com/BradyFU/Awesome-Multimodal-Large-Language-Models \
* 9、AugGPT: Leveraging ChatGPT for Text Data Augmentation，基于ChatGPT进行数据增强\
https://arxiv.org/pdf/2302.13007.pdf
* 10、面向年报和研报的金融生成式大模型的落地应用 - 星辰大海与推进的文章 - 知乎 https://zhuanlan.zhihu.com/p/635839810
* 11、Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models https://arxiv.org/abs/2305.18703.pdf
* 12、悟道·天鹰Aquila语言大模型系列已经集成在 FlagAI大模型算法开源项目中，GitHub 地址：https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila
* 13、大脑如何在社会中“导航”？Nature子刊揭示社会层级结构的网格表征 https://zhuanlan.zhihu.com/p/437285683?utm_id=0&utm_source=wechat_session&utm_medium=social&s_r=0
* 14、未来生命研究所创始人Max Tegmark：人工智能更接近生命3.0 https://mp.weixin.qq.com/s/AjcxbhjZeE8RyVGEpKEAKg\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/dc76cc6d-bff6-4ed8-9b36-4700a09aef29)
* 15、21种Transformers目标检测方法！德国人工智能研究中心等最新《Transformers 2D目标检测》综述 https://mp.weixin.qq.com/s/mmyVhaJ1nMyo1wQMiGTH-A
* 16、首个模拟人类认知的思维框架OlaGPT：六大模块增强语言模型，推理能力最高提升85% \
![1dee0be3ab6e993c7af82f2ff86f9ac2](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/dd2ff739-af01-4a4b-a539-e8fa4b7e402d)
https://mp.weixin.qq.com/s/jKegqeTgsPlPtIpYljqvDA \
论文链接：https://arxiv.org/abs/2305.16334 \
代码链接：https://github.com/oladata-team/OlaGPT
* 17、随时随地，追踪每个像素，连遮挡都不怕的「追踪一切」视频算法来了\
https://mp.weixin.qq.com/s/IqcvtfTekSKELLIjX7qRCQ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a0cb3bc5-8320-452b-87f8-18d91da4febf)
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/3bda3572-6e91-45f0-b156-f53864d6a80a)
论文地址：https://arxiv.org/abs/2306.05422 \
项目主页：https://omnimotion.github.io/
* 18、再看知识图谱与大模型在KBQA场景中的结合：增强语言模型框架KAPING代表工作解读与机理分析 https://mp.weixin.qq.com/s/0IKj0LZSMMfMKC26aomAxA
* 19、13条咒语挖掘GPT-4最大潜力，Github万星AI导师火了，网友：隔行再也不隔山了 https://mp.weixin.qq.com/s/BJpGQE4SWPBC8Ncha8XaIA \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/54fc2d25-e078-4987-bdfa-c47394f9fac0)
* 20、280万条多模态指令-响应对，八种语言通用，首个涵盖视频内容的指令数据集MIMIC-IT来了 https://mp.weixin.qq.com/s/IzmfVE2uFrlQi_PX-HECzQ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/eaf946ea-51b9-483e-a7e3-9a3061c9825d)
研究者在 MIMIC-IT 上训练了基于 OpenFlamingo 的多模态模型「Otter」。通过 ChatGPT、人类两个方面的评估，Otter 的多模态能力超越了近期的其他视觉 - 语言模型。\
MIMIC-IT 数据集包括 280 万个多模态指令 - 响应对，涵盖了基本能力：感知、推理和计划。每个指令都伴随着多模态的对话背景，使在 MIMIC-IT 上训练的 VLM 能够在交互式指令中表现出很好的熟练度，并能进行零样本的概括。\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/28a397cc-8569-4e5d-86dd-cbcd8fa10ca3)
* 21、阿里达摩院开源Video-LLaMA，帮大语言模型加上“眼睛”、“耳朵”  https://mp.weixin.qq.com/s/EDixQL5CFmrgX2hxi0aCAw \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/113ef04e-d66e-4a45-8192-2977873136a3)
论文链接：https://arxiv.org/abs/2306.02858
代码地址：https://github.com/DAMO-NLP-SG/Video-LLaMA
Demo 地址：
Modelscope: https://modelscope.cn/studios/damo/video-llama/summary
Huggingface: https://huggingface.co/spaces/DAMO-NLP-SG/Video-LLaMA
样例输入文件地址：
https://github.com/DAMO-NLP-SG/Video-LLaMA/tree/main/examples
* 22、如何更好地使用老刘说NLP技术社区：从大模型、知识图谱、事件图谱、事理图谱、面试、入门路线细分方向的索引说起 https://mp.weixin.qq.com/s/TKDl0rN1TWkBzV0ipr29AA
* 23、Hinton、吴恩达和LeCun的对话与发言，值得看看视频
吴恩达、Hinton最新对话！AI不是随机鹦鹉，共识胜过一切，LeCun双手赞成 https://mp.weixin.qq.com/s/qfoc3-HiGmMuPcDUCpuHjg \
75岁Hinton中国大会最新演讲「通往智能的两种道路」，最后感慨：我已经老了，未来交给年轻人 https://mp.weixin.qq.com/s/iA5E70VJiLFxSsAFF2Jyww\
图灵奖得主Hinton：我已经老了，如何控制比人类更聪明的AI交给你们了 https://mp.weixin.qq.com/s/3vdd0zqbmYANK0CBrObLCg \
Hinton - 在智源大会上，他以《通往智能的两条路线》为主题，讨论了“知识蒸馏”和“权重共享”两种智能路线，以及如何让AI变得更智能，以及自己对于超级智能出现的看法。\
卷积神经网络之父的强人工智能路线图：自监督，推理，规划 https://mp.weixin.qq.com/s/3CQvn3GDq7TpF0IHqJURTg \
Hinton：我对“青蛙”创造出“人”这件事的后果很紧张丨全文整理+视频 Hinton提出了非永生计算的概念 https://mp.weixin.qq.com/s/LDTpMoDaIf3tTATxWeaSgg \
* 24、GPT总设计师：大型语言模型的未来 https://mp.weixin.qq.com/s/AiikCD3LHAJWDDEHdln5fw
* 25、Nature Machine Intelligence 最新研究：结合大语言模型Chatgpt设计了机器人的番茄采摘末端 https://mp.weixin.qq.com/s/hMJvoXuLxqCPjzlb5bVxCg
* 26、小模型的意见也有用！GPT-4+AutoGPT在线决策：买东西再也不用纠结了 https://mp.weixin.qq.com/s/6ngftL32NS7y-rk1j3rzSw\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/0bca49b4-bfa7-4651-9be4-2548657b46ca)
作者比较了多种流行的LLM（包括GPT-4，GPT-3.5，Claude和Vicuna）在Auto-GPT决策任务中的表现，并引入了一种名为「额外意见」的新算法，该算法可以将小的专家模型融入到Auto-GPT方案中，从而提高了任务性能。
* 27、GPT-4最全攻略来袭！OpenAI官方发布，六个月攒下来的使用经验都在里面了 https://mp.weixin.qq.com/s/XPRfYxVq0GJs_NIst8Bhxw \
* 28、潜力发掘！INSTRUCTEVAL：一个专用于的大型语言模型(LLMs)的全面评估方法 https://mp.weixin.qq.com/s/E6hq0AUy_hItA5HGo2tCAQ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9ff480c2-0519-4a66-8559-2f2e8b888cfc) \
Paper：https://arxiv.org/abs/2306.04757 \
Code：https://github.com/declare-lab/instruct-eval
* 29、GPT-4是如何工作的？哈佛教授亲自讲授 https://mp.weixin.qq.com/s/OqtkRs-KdmtH2tM505qBXQ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/01710949-9b86-4621-9f3d-5fb80aab41d5)
参考链接：\
https://twitter.com/dotey/status/1655081670234501120 \
https://www.edx.org/course/introduction-computer-science-harvardx-cs50x \
https://www.youtube.com/watch?v=vw-KWfKwvTQ&t=1799s \
https://www.youtube.com/watch?v=vw-KWfKwvTQ
* 30、LeCun世界模型首项研究来了：自监督视觉，像人一样学习和推理，已开源 https://mp.weixin.qq.com/s/md84LwT2M_e3-QmAx0H9Kg \
LeCun世界模型出场！Meta震撼发布首个「类人」模型，理解世界后补全半张图，自监督学习众望所归 https://mp.weixin.qq.com/s/cQaYnjbcVC81_39RGZd4SQ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7234072b-53d4-4718-978a-2c597f47b3cd)
论文地址：https://arxiv.org/pdf/2301.08243.pdf \
GitHub 地址：https://t.co/DgS9XiwnMz
* 31、怒超 GPT-4！LONGMEM：提升大语言模型（LLMs）长文本处理能力，最高可达64k https://mp.weixin.qq.com/s/LiWN7iONxgEOIPnJXjYgQw \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/fa92fff8-4443-43cb-a823-4975f56320c1)
Paper：https://arxiv.org/pdf/2306.07174v1.pdf \
Code：https://github.com/Victorwz/LongMem
* 32、LLM+模仿学习，解决真实世界中的复杂任务：AI2提出SwiftSage https://mp.weixin.qq.com/s/Jb5MfELAyZPwP1XkVA-JsQ \
GPT-4 等大型语言模型（LLM）在许多推理任务上表现出色，然而，大部分现有研究仅关注静态环境下的任务，如回答问题或解数学题。那么，LLM 能否在真实世界中完成复杂的交互式任务呢？例如，如果我们想制作一个智能体（agent），让它在物理世界里完成一些实验，比如测试一个物体是否导电，我们可以使用 LLM 吗？这类复杂交互式任务（complex interactive tasks）具有很大的挑战性，因为它要求 LLM 不仅能理解动态变化的真实场景，还需要具备诸如长期规划（long-horion planning）、任务分解（task 的 composition）、记忆储存（memorization）、常识推理（commonsense reasoning）、异常处理（exception handling）等高阶认知和推理能力。\
面对这种情况，如何充分发挥 LLM 的规划和推理能力，同时降低计算成本呢？认知心理学名著《思考，快与慢》（Thinking, Fast and Slow）中介绍的双过程理论（dual propcess theory）带来了很多启示。该理论认为，人类认知过程需要两个密不可分的系统，其中 System 1 负责快速直觉式思考，而 System 2 则负责慢速分析式思考。\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/fb6ab388-e98a-4a45-afee-2d6fde561c67)
论文链接：https://arxiv.org/abs/2305.17390 \
项目网站：https://yuchenlin.xyz/swiftsage/ \
基于此，AI2 (Allen Institute for AI) 的研究人员提出了 SwiftSage 智能体框架。他们通过模仿学习得到一个小型模型，然后将其与 LLM 进行融合。这样，便可以利用大量数据对小型模型进行微调，使其具备环境和任务相关的知识，并仅在需要时调用大型模型进行高阶推理。在 30 个任务上的评估中，SwiftSage 的表现超过了之前的 SayCan、ReAct 和 Relfexion 等方法近 2 倍，并且大幅降低了 LLM 部分的计算成本。
* 33、量子计算新里程碑登Nature封面！100+量子比特无需纠错，超越经典计算 https://mp.weixin.qq.com/s/IQFR1hmjonUFTeVZ4_lSZg \
* 34、LeCun高徒超详笔记曝光，Meta世界模型首揭秘！首个「类人」模型怎么来的？ https://mp.weixin.qq.com/s/we1pIQfq9tHXR8UNoYw1DQ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ea9ec535-6f09-4a6a-9d33-3c27fd661e54)
论文地址：https://arxiv.org/abs/2306.02572 \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/cb2488d1-f565-4614-9f62-8ee82b610da0)
* 35、英伟达最新开源 | FasterViT: 面相硬件优化的高效神经网络架构 https://mp.weixin.qq.com/s/WPuG-q_ne3RcW2C-hAQRxg \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/3a978111-375b-49fe-aa8a-f9bb509f3769)
Title: FasterViT: Fast Vision Transformers with Hierarchical Attention \
Paper: https://arxiv.org/pdf/2306.06189.pdf \
Code: https://github.com/NVlabs/FasterViT
* 36、紫东太初全模态大模型来了，一个模型打通感知、认知、决策交互屏障 https://mp.weixin.qq.com/s/cBvkAKsGrTrKt9Pm0O9MMw \
紫东太初2.0 全模态大模型
* 37、如何利用LLM做多模态任务？ https://mp.weixin.qq.com/s/UmcMqk2Kv-TjLEG1x1u85g \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/25e0f16b-2c9e-48b7-b5ec-805080cc15d3)
* 38、语音领域的GPT时刻：Meta 发布「突破性」生成式语音系统，一个通用模型解决多项任务 https://mp.weixin.qq.com/s/xrLfu4qf05NlENOe6xpvkg \
今日，Meta 介绍了一种「突破性」的生成式语音系统，它可以合成六种语言的语音，执行噪声消除、内容编辑、转换音频风格等。Meta 称之为最通用的语音生成 AI。 \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/36fe44d2-499b-44fa-9ace-cbfbe4d4b213)
论文：https://research.facebook.com/publications/voicebox-text-guided-multilingual-universal-speech-generation-at-scale/
* 39、Nature封面：量子计算机离实际应用还有两年 https://mp.weixin.qq.com/s/4dr0ZwycbVoQvdvRpdIhcg
* 40、领域微调大模型入局的自我和解：领域微调大模型若一定要做，则务必想的若干个前提条件 https://mp.weixin.qq.com/s/pXcaYoNfqm1QAR21aguU2g
* 41、190页清华大学：AIGC发展研究报告1.0版（可下载） https://mp.weixin.qq.com/s/CoW0dtuP9lSS8WfuJHiJxg
* 42、大模型与人类的未来 | 基于认知神经科学的大模型论坛精彩回顾 https://mp.weixin.qq.com/s/4-Z1x0LydTih8Iz8-OScSQ
* 43、大语言模型的涌现能力（Emergent）｜OpenBMB论文速读第 8 期 https://mp.weixin.qq.com/s/tuhQ3mDh2279jxLDYfzhUQ
* 44、后GPT时代，多模态是最大的机会 https://mp.weixin.qq.com/s/x-dD0NTkc5S7V6PiJ035nA
* 45、如何构建CV中的AGI？华为最新《计算机视觉中的人工通用智能：从GPT和大型语言模型中学到的经验教训》 https://mp.weixin.qq.com/s/VrIsq6LUr4GOM1uXDgU3Cw\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2d1a4457-2ef9-4110-93c9-b6414317a238)
* 46、首个感知决策一体化自动驾驶通用大模型！商汤联合团队获CVPR 2023最佳论文 https://mp.weixin.qq.com/s/TBCiRQUGPafg_cb0Btjzxw \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1cf96bf4-7a3e-4dc6-9844-f629a02413b7)
论文题目：Planning-oriented Autonomous Driving \
论文地址：https://arxiv.org/abs/2212.10156
* 47、LeCun力挺，马毅教授五年集大成之作：完全数学可解释的白盒Transformer，性能不输ViT https://mp.weixin.qq.com/s/NBK0XNSiPTtkPFCawrceaA \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d63cf02b-60f8-46cd-bea7-f751a34e68d3)
代码链接：https://github.com/Ma-Lab-Berkeley/CRATE \
论文链接：https://arxiv.org/abs/2306.01129
* 48、EmbodiedGPT｜具身智能或将成为实现AGI的最后一公里 https://mp.weixin.qq.com/s/pwDcsvAxHm5any--1fY6qA \
论文链接：https://arxiv.org/abs/2305.15021 \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/411153f0-558f-4e73-b727-0bc0cba64b32)
* 49、我把GPT 的学习轨迹可视化了！竟和人类十分类似 ｜ACL2023 https://mp.weixin.qq.com/s/3kNqhdfZz6FEFvWey1lPIQ \
论文题目：Language acquisition: do children and language models follow similar \
论文链接：https://arxiv.org/pdf/2306.03586.pdf
* 50、比HuggingFace快24倍！伯克利神级LLM推理系统开源，碾压SOTA，让GPU砍半 https://mp.weixin.qq.com/s/3hBwSIKgiPcSXlFopNpYvw
* 51、GPT-4参数最新爆料！1.76万亿参数，8个2200亿MoE模型，PyTorch创始人深信不疑 https://mp.weixin.qq.com/s/MOsJ_vqLJvftTaTYNpBqAg
* 52、视觉大模型有何进展？微软CVPR2023最新《视觉基础模型进展》教程，附260页ppt https://mp.weixin.qq.com/s/CNmj6H2eolbiVmX4KBd6-g
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8c846359-b1fb-48db-aa95-9b23df3248c5)
https://vlp-tutorial.github.io/ \
在本教程中，我们将介绍学习和应用视觉基础模型的前沿的最新方法和原则，包括(1) 视觉和视觉语言预训练；(2) 通用视觉接口；(3) 文本到图像生成的对齐；(4)大型多模态模型；和(5) 多模态智能体。
* 53、IJCAI2023|PowerBEV：一个强大且轻量的环视图像BEV实例预测框架 https://mp.weixin.qq.com/s/tGlPhS9cNtMxKLhNtGZ1NQ \
PowerBEV，一个新颖而优雅的基于视觉的端到端框架，它只由2D卷积层组成，用于在BEV中执行多个对象的感知和预测。
论文：PowerBEV: A Powerful Yet Lightweight Framework for Instance Prediction in Bird’s-Eye View \
论文地址：https://arxiv.org/abs/2306.10761 \
代码地址：https://github.com/EdwardLeeLPZ/PowerBEV
* 54、谷歌展示全球首个多任务RoboCat：仅需100次训练，可自我优化！ https://mp.weixin.qq.com/s/H6E8odjkFnDcKIQfVTkraA \
6月21日，谷歌旗下的DeepMind展示了可自我进化的，多任务AI机器人——RoboCat。（论文：https://arxiv.org/abs/2306.11706）\
据悉，RoboCat的学习速度比目前最先进的模型还要快，仅需要最少100次演示就能完成训练，可通过自我生成的数据进行优化、改进。\
DeepMind表示，RoboCat对于工业、汽车业、制造业、互联网以及其他多任务领域非常有用，仅需很短的时间就能完成动作训练投入到实际业务中，可大幅度提升生产效率。\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/bc19a211-0398-46bf-8b4e-4221c5453525)
* 55、走向计算机视觉的通用人工智能：从GPT和大型语言模型中汲取的经验教训 (上) https://mp.weixin.qq.com/s/IJQHVrheNgtb0d0f7sexEQ \
走向计算机视觉的通用人工智能：从GPT和大型语言模型中汲取的经验教训 (下) https://mp.weixin.qq.com/s/aef_eoRHxX51d-oM-u3lYg
* 56、言简意赅 | 旷视最新研究 ChatSpot: 让多模态大语言模型“更懂你的心”！ https://mp.weixin.qq.com/s/LKdi5qk3Vle6LnyJyVyRNw
* 57、中科院自动化所发布FastSAM | 精度相当，速度提升50倍！！！ https://mp.weixin.qq.com/s/9uvfp_FUjVTlpsAnXJOocQ
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b3dbf2cc-75ab-4c80-a9d9-908eed5ebd9a)
Title: Fast Segment Anything \
PDF: https://arxiv.org/pdf/2306.12156v1.pdf \
Code: https://github.com/casia-iva-lab/fastsam
* 58、视觉与多模态大模型前沿进展 | 2023智源大会精彩回顾 https://mp.weixin.qq.com/s/7W_HF2ijZEUqVbrOjx8iXw
* 59、也看支持32K上下文的ChatGLM2-6B模型：优化点简读及现有开源模型主流训练优化点概述 https://mp.weixin.qq.com/s/Y9jnHBkWRTMXQPMCCIMfTw
* 60、斯坦福训练Transformer替代模型：1.7亿参数，能除偏、可控可解释性强 https://mp.weixin.qq.com/s/ZKBuIikH6afepM--4Cs6gw \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/37ce74d9-9e6d-4a18-abfa-1fd441ea5e12)
论文地址：https://arxiv.org/abs/2305.16765 \
项目地址：https://backpackmodels.science 
* 61、All Things ViTs：在视觉中理解和解释注意力 https://mp.weixin.qq.com/s/ii4vLxHOY_7JEndi3fRJvg\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e128326f-5fbe-49d9-b08c-7cc92296da9d)
地址：https://github.com/all-things-vits/code-samples
* 62、大模型不是未来？你需要学习下图灵奖得主Yann LeCun选择的「世界模型」 又是一篇详细介绍世界模型的文章 https://mp.weixin.qq.com/s/LFlm-PaGyFKC_02NRLe0WQ
* 63、也看面向知识图谱构建的垂直微调大模型：KnowLM、TechGPT看指令数据生成方式及开放信息抽取数据集 https://mp.weixin.qq.com/s/Ub22ksWgOUia1dGVzDw1tg
* 64、基于LangChain+GLM搭建知识本地库 https://mp.weixin.qq.com/s/Ry-nnJ2kRL71hm_I8lSEQg
* 65、清华第二代60亿参数ChatGLM2开源！中文榜居首，碾压GPT-4，推理提速42% https://mp.weixin.qq.com/s/ib0Kp35MUNDGxUuXFR0aLA
* 66、基于信息论的校准技术，CML让多模态机器学习更可靠 https://mp.weixin.qq.com/s/0cDvlmOnc9WJt2ilF6qttA\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9ea60baa-b692-4dd6-8333-1e69bc69592e)
论文 Arxiv：https://arxiv.org/abs/2306.01265 \
代码 GitHub：https://github.com/QingyangZhang/CML \
当前的多模态分类方法存在不可靠的置信度，即当部分模态被移除时，模型可能产生更高的置信度，违反了信息论中 「信息是消除的不确定性」这一基本原理。针对此问题，本文提出校准多模态学习（Calibrating Multimodal Learning）方法。该方法可以部署到不同的多模态学习范式中，提升多模态学习模型的合理性和可信性。
* 67、中科大腾讯最新《多模态大型语言模型》综述，详述多模态指令微调、上下文学习、思维链和辅助视觉推理技术 https://mp.weixin.qq.com/s/G9x_RO08VVhsS8YTi55oHQ\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/244310da-1458-4d16-904d-f93797b7498d)
* 68、微软 & 麻省理工 | 实验结果表明：代码自修复能力仅存在GPT-4！GPT-3.5不具备该能力 https://mp.weixin.qq.com/s/MXKIMXzIkTKLMXYgSNWYBw \
代码自修复流程，其主要分为四个步骤：代码生成、代码执行、反馈生成、代码自修复等。
* 69、微软发布「升级版」多模态大模型 Kosmos-2！新增局部理解能力，解锁实体级交互 https://mp.weixin.qq.com/s/wcItIWImWLwsYic4PvHwcQ\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d10aecc0-75d9-44c5-afb4-0cf45c0c03a6)
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4b26a3fe-1cab-4dbb-9ce5-aa2bc1a9a947)
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c77e8c7b-22ae-4fbe-9f6f-77ced2b5b4a5)
* 70、也谈langchain大模型外挂知识库问答系统核心部件：如何更好地解析、分割复杂非结构化文本 https://mp.weixin.qq.com/s/rOWfCQuUPohatMF_dU2nIA \
* 71、陶哲轩预言成真！MIT加州理工让ChatGPT证明数学公式，数学成见证AI重大突破首个学科 https://mp.weixin.qq.com/s/paGPCdA97kryDmcsGmwyFg \
大模型帮陶哲轩解题、证明数学定理：数学真要成为首个借助AI实现突破的学科了？ https://mp.weixin.qq.com/s/DOiT3WXIYUsagkVEa68B-w \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2a4061f3-851e-4848-aeea-408be639a2b2)
项目地址：https://leandojo.org/
* 72、斯坦福 & 微软 | 决策预训练 Transformer，可解决一系列上下文强化学习（RL）问题 https://mp.weixin.qq.com/s/cTocXQsvTN78-8-kj4ktTQ \
啥叫上下文决策？
* 73、多模态大语言模型综述来啦！一文带你理清多模态关键技术 https://mp.weixin.qq.com/s/ZUIOt8G4sgOwouBkrv_Giw \
论文题目:A Survey on Multimodal Large Language Models \
论文链接:https://arxiv.org/abs/2306.13549 \
Github 地址:https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models
* 74、视觉中怎么用提示？南洋理工CVPR2023《视觉提示》教程，附290页ppt https://mp.weixin.qq.com/s/IdtKmI5iOklPIa78MD6waw










 





