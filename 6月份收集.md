# 6.1 周4
* 1、LLM推理提速2.8倍，CMU提出投机式推理引擎，小模型撬动大模型高效推理 https://mp.weixin.qq.com/s/kCJUJI1QMIcUQLAleQGosA \
近日，来自卡耐基梅隆大学（CMU）的 Catalyst Group 团队发布了一款「投机式推理」引擎 SpecInfer，可以借助轻量化的小模型来帮助大模型，在完全不影响生成内容准确度的情况下，实现两到三倍的推理加速。\
论文链接：https://arxiv.org/abs/2305.09781 \
项目链接：https://github.com/flexflow/FlexFlow/tree/inference \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/37932cd8-70a3-4e83-8141-542bd14c2461)
* 2、ChatGPT/GPT-4做知识图谱构建推理怎么样？浙大等最新《大语言模型在知识图谱构建与推理》论文，量化评估LLM在KG表现 https://mp.weixin.qq.com/s/MFi2cKh347SnLzl7zmBTWQ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/585da197-5929-4096-a617-790aba46c570)
* 3、思维链如何释放语言模型的隐藏能力？最新理论研究揭示其背后奥秘 https://mp.weixin.qq.com/s/CoLFFQTF9QqL8lSbtaY-_Q \
本文中，北大的几位研究者证明了CoT在实现大语言模型（LLM）推理中是不可或缺的，并从理论和实验角度揭示了CoT如何释放LLM的巨大潜力。
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a3327a90-a8b0-4381-b51c-7925538651e6) \
论文链接：https://arxiv.org/abs/2305.15408
* 4、GPT-4 过程监督 提高解决数学问题的能力 \
https://mp.weixin.qq.com/s/PiVLFHRBLFD5Xj_mzCDsLg https://mp.weixin.qq.com/s/rzm5jdwgc4mMzTZhirHOxQ \
* 5、张俊林趣谈：GPT4是否已具备类人智慧，为何GPT通过Next Token Prediction可以产生智能 https://mp.weixin.qq.com/s/eSGZvJKl3WPgrAwp4Zxopg

# 6.2 周5
* 1、刘知远：大模型值得探索的十个研究方向 https://mp.weixin.qq.com/s/YD1skOQmsW8U_Xfw_Km7Tw
* 2、吴恩达的3门课程 https://mp.weixin.qq.com/s/rn_6vKEHZUKo5gb5-xtXEA \
用ChatGPT API搭建系统 \
通过LangChain使用LLM开发应用 \
扩散模型如何工作 
* 3、斯坦福大学李飞飞团队新作：孪生掩码自编码器SiamMAE，刷榜视觉自监督方法 \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5f4ed679-c0b9-46ef-b8dd-ba0eb3a725d4)
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/934303ba-c397-4d7f-b4b7-027efc027e70)
论文链接：https://siam-mae-video.github.io/resources/paper.pdf
* 4、全面了解多模态大语言模型 Multimodal Large Language Models，首个跟踪 MLLM 进展的论文集合 https://mp.weixin.qq.com/s/BuBr5OgflKLIYbjLFLGPEA \
论文集合链接地址：https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models \
大语言模型 Large Language Models（LLM）强大的泛化和推理能力给计算机视觉领域带来了很多灵感和启发，从而开辟出多模态大语言模型 Multimodal Large Language Models（MLLM）这一全新的前沿热点方向。该项目汇集了该方向近期的论文，包括：\
Multimodal Instruction Tuning \
Multimodal In-Context Learning \
Multimodal Chain-of-Thought \
LLM-Aided Visual Reasoning \
Fundation Models \
others \
这 6 个子方向以及相应的新开放的数据集，该链接将保持实时更新，便于研究人员跟进。
* 5、率先开放语音、视频等多模态对话能力，这家中国公司又比OpenAI走快了一步  国产 AI 模型「元乘象 ChatImg」  https://mp.weixin.qq.com/s/XWxxFvLESqIn-5emNp5ZxA \
进行了将模型部署到机器人上的尝试，详见视频 \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7a668c12-1373-43a1-8151-b5993b712549)
* 6、模仿Jeff Dean神总结，前谷歌工程师分享「LLM开发秘籍」：每个开发者都应知道的数字！ https://mp.weixin.qq.com/s/vrPRHdsFzHZQQkrixnWS2Q
* 7、透彻！驯服大型语言模型（LLMs）的五种方法，及具体方法选择思路 https://mp.weixin.qq.com/s/93xk_x7LBFLOZlmnM96IMw


# 6.3 周6
* 1、SelFee，一个迭代自修改的大语言模型。  SelFee: Iterative Self-Revising LLM Empowered by Self-Feedback Generation \
详细介绍：kaistai.github.io/SelFee/
韩国顶尖公立大学KAIST（韩国科学技术院）根据LLaMA模型，推出了具备自我反馈、迭代能力的类ChatGPT开源模型SelFee（70亿、130亿两种参数）。SelFee的自我反馈、迭代能力相当新奇，无需借助外力可自我评估并生成。无论是在开源界、还是各大科技公司推出的产品中都很罕见。\
开源地址：https://github.com/kaistAI/SelFee \
在线体验：https://kaistai.github.io/SelFee/demo \
该模型同样是在LLaMA基础上用chatgpt的数据做的微调。你问它一个问题，它回答后会自己问自己这个答案需要求改吗，如果自己觉得需要修改就再生成一个新答案，然后继续问自己这个回答是否需要修改，直到最终自己觉得不需要修改为止。

# 6.4 周7
* 1、当量子计算遇到语言模型：量子互文性助力生成模型 | 量子世界地图 https://mp.weixin.qq.com/s/PfGjcU3k8NKX7W2Eht-ngg
* 2、PandaGPT：一个跨模态语言模型，支持6种模态指令，支持在线Demo体验！ https://mp.weixin.qq.com/s/y2gk8nsjE25FDvFPayEGWQ \
通过结合 ImageBind 的模态对齐能力和 Vicuna 的生成能力，同时实现了六种模态下的指令理解与跟随能力。虽然 PandaGPT 的效果尚有提升空间，但展示了跨模态 AGI 智能的发展潜力。\
项目主页: https://panda-gpt.github.io/ \
代码: https://github.com/yxuansu/PandaGPT \
论文: http://arxiv.org/abs/2305.16355 \
线上 Demo 展示: https://huggingface.co/spaces/GMFTBY/PandaGPT
* 3、全面测评！大模型复杂推理能力，华人科学团队推出「思维链集」 https://mp.weixin.qq.com/s/vbyRsTu1zHuYyBfw9z4FpA \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/330bca5c-6893-453c-97d4-dacbdb6fe2f4)
论文地址：https://arxiv.org/pdf/2305.17306.pdf

# 6.5 周1
* 1、思想克隆！前OpenAI研究员让AI模仿人类思维，现实版「机械姬」降临 https://mp.weixin.qq.com/s/_gqfwc9bJvI7Hb4gmuibiA \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6ad75602-24ad-4cf7-b6d9-785f0cf7e9cb)
论文地址：https://arxiv.org/pdf/2306.00323.pdf
* 2、首个模拟人类认知的思维框架OlaGPT：六大模块增强语言模型，推理能力最高提升85% https://mp.weixin.qq.com/s/pb8aIkda9IMAKeE36qgpEQ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/48bb5f2c-55b0-4a97-8d04-5c254361548e)
论文链接：https://arxiv.org/abs/2305.16334 \
代码链接：https://github.com/oladata-team/OlaGPT
* 3、神经推理如何问答？ CMU-Haitian Sun博士论文《神经推理问答》，151页pdf全面阐述QA推理任务 https://mp.weixin.qq.com/s/fdgL63dQsAuQG3IXCb2E2g
* 4、近乎完美！最强算术语言模型: Goar-7B，干翻GPT-4，怒越PaLM-540B！24G可训练 https://mp.weixin.qq.com/s/_haINkHNV4bMszm9F41yXA \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a2a259a5-5ef7-4570-86c9-4af187a9456c)
Paper：https://arxiv.org/pdf/2305.14201.pdf \
Code：https://github.com/liutiedong/goat
* 5、Amazon | 深入研究LLMs与AutoGPT的结合：揭示出GPT-4惊人的人类决策能力！ https://mp.weixin.qq.com/s/Gbz7ZVVdeTq64mj1-__aQA \
心理学研究过人们当面对不同意见时的处理方式。当人们往往比较侧重于具有权威的意见，从而忽略忽略极少数的个别意见;并且人们还会比较侧重于自己而忽略其他人的意见。今天给大家分享的这篇文章，作者针对决策任务，对Auto-GPT代理进行了全面的基准研究，探索了大型语言模型（LLM）在决策任务中的应用。「实验结果表明GPT4有了类似于人类的能力，可以从不同的意见中提取有用信息，进行思考和批判然后提高自己的结果」。\
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/25b9b9fb-68d2-41d8-a515-5f8b7e649bf8)
Paper：https://arxiv.org/pdf/2306.02224.pdf \
Code：https://github.com/younghuman/LLMAgent

# 6.6 周2
* 1、GPT充当大脑，指挥多个模型协作完成各类任务，通用系统AutoML-GPT来了 https://mp.weixin.qq.com/s/Ji7vF9BAkIVfqvkCrMqSSg
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a4ad6f22-e925-4812-ba5e-0a97c3ea0336) \
论文地址：https://papers.labml.ai/paper/35151be0eb2011edb95839eec3084ddd
* 2、效果达OpenAI同规模模型96%，发布即开源！国内团队新发大模型，CEO上阵写代码  https://mp.weixin.qq.com/s/mj8cWkYNQPAobA1ybUzWYg \
国内自研大模型迎来新面孔，而且发布即开源！最新消息，多模态大语言模型TigerBot正式亮相，包含70亿参数和1800亿参数两个版本，均对外开源。\

# 6.7 周3
* 1、Awesome-Graph-LLM：图相关大型语言模型(LLM)相关资源列表: github.com/XiaoxinHe/Awesome-Graph-LLM \
* 2、参数高效微调（PEFT）技术  ???缺少资料来源\
在面对特定的下游任务时，如果进行Full FineTuning（即对预训练模型中的所有参数都进行微调），太过低效；而如果采用固定预训练模型的某些层，只微调接近下游任务的那几层参数，又难以达到较好的效果。\
PEFT技术旨在通过最小化微调参数的数量和计算复杂度，来提高预训练模型在新任务上的性能，从而缓解大型预训练模型的训练成本。这样一来，即使计算资源受限，也可以利用预训练模型的知识来迅速适应新任务，实现高效的迁移学习。因此，PEFT技术可以在提高模型效果的同时，大大缩短模型训练时间和计算成本，让更多人能够参与到深度学习研究中来。\
Prefix Tuning：与full fine-tuning更新所有参数的方式不同，该方法是在输入token之前构造一段任务相关的virtual tokens作为Prefix，然后训练的时候只更新Prefix部分的参数，而Transformer中的其他部分参数固定。该方法其实和构造Prompt类似，只是Prompt是人为构造的“显式”的提示,并且无法更新参数，而Prefix则是可以学习的“隐式”的提示。 同时，为了防止直接更新Prefix的参数导致训练不稳定的情况，他们在Prefix层前面加了MLP结构(相当于将Prefix分解为更小维度的Input与MLP的组合后输出的结果)，训练完成后，只保留Prefix的参数。\
Prompt Tuning：该方法可以看作是Prefix Tuning的简化版本，只在输入层加入prompt tokens，并不需要加入MLP进行调整来解决难训练的问题。随着预训练模型参数量的增加，Prompt Tuning的方法会逼近fine-tuning的结果。\
P-Tuning：该方法的提出主要是为了解决这样一个问题：大模型的Prompt构造方式严重影响下游任务的效果。P-Tuning将Prompt转换为可以学习的Embedding层，并用MLP+LSTM的方式来对prompt embedding进行一层处理。\
P-Tuning v2：让Prompt Tuning能够在不同参数规模的预训练模型、针对不同下游任务的结果上都达到匹敌Fine-tuning的结果。相比Prompt Tuning和P-tuning的方法，P-Tuning v2方法在多层加入了Prompts tokens作为输入，带来两个方面的好处：
带来更多可学习的参数（从P-tuning和Prompt Tuning的0.1%增加到0.1%-3%），同时也足够参数高效。加入到更深层结构中的Prompt能给模型预测带来更直接的影响。\
Adapter Tuning：该方法设计了Adapter结构（首先是一个down-project层将高维度特征映射到低维特征，然后过一个非线形层之后，再用一个up-project结构将低维特征映射回原来的高维特征；同时也设计了skip-connection结构，确保了在最差的情况下能够退化为identity），并将其嵌入Transformer的结构里面，在训练时，固定住原来预训练模型的参数不变，只对新增的Adapter结构进行微调。同时为了保证训练的高效性（也就是尽可能少的引入更多参数）。\
LoRA：在涉及到矩阵相乘的模块，引入A、B这样两个低秩矩阵模块去模拟full fine-tuning的过程，相当于只对语言模型中起关键作用的低秩本质维度进行更新。\
典型应用：\
ChatGLM-Tuning ：一种平价的chatgpt实现方案，基于清华的 ChatGLM-6B + LoRA 进行finetune。\
Alpaca-Lora：使用低秩自适应（LoRA）复现斯坦福羊驼的结果。Stanford Alpaca 是在 LLaMA 整个模型上微调，而 Alpaca-Lora 则是利用 Lora 技术，在冻结原模型 LLaMA 参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。由于这些新增参数数量较少，这样不仅微调的成本显著下降，还能获得和全模型微调类似的效果。\
BLOOM-LORA：由于LLaMA的限制，我们尝试使用Alpaca-Lora重新实现BLOOM-LoRA。\
PEFT实现：\
PEFT：Huggingface推出的PEFT库。\
unify-parameter-efficient-tuning：一个参数高效迁移学习的统一框架。\
经验与教训\
经验：\
对于同一模型，选择不同的训练框架，对于资源的消耗情况可能存在显著差异（比如使用Huggingface Transformers和DeepSpeed训练OPT-30相对于使用Alpa对于资源的消耗会低不少）。\
进行大模型模型训练时，先使用小规模模型（如：OPT-125m/2.7b）进行尝试，然后再进行大规模模型（如：OPT-13b/30b...）的尝试，便于出现问题时进行排查。\
• ChatGLM-6B 微调：• https://github.com/hiyouga/ChatGLM-Efficient-Tuning \
• LLaMA, BLOOM 微调：• https://github.com/hiyouga/LLaMA-Efficient-Tuning \
支持的方法 \
• 全参数微调 \
• Freeze部分参数微调 \
• P-Tuning v2微调（仅ChatGLM） \
• LoRA微调 \
• QLoRA微调 

# 6.8 周4
* 1、谷歌发布了9节关于《生成式AI》的课程，可免费学习。\
分别是：\
Intro to Generative AI \
Intro to Large Language Models \
Intro to Responsible AI \
Intro to Image Generation \
Encoder-Decoder \
Attention Mechanism \
Transformers and BERT Models \
Create Image Captioning Models \
Intro to Gen AI Studio \
地址：www.cloudskillsboost.google/paths/118
* 2、M⁶Doc Dataset：用于文档版面分析研究的M⁶Doc数据集: github.com/HCIILAB/M6Doc
* 3、轩辕：千亿级中文金融对话模型，针对中文金融领域优化的千亿级开源对话大模型，在BLOOM-176B的基础上针对中文通用领域和金融领域进行了针对性的预训练与微调: github.com/Duxiaoman-DI/XuanYuan
* 4、SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL
* 5、利用Llama Index、 GPT-4和 Streamlit 实现的财经新闻分析: github.com/hackingthemarkets/financial-news-llama-index \
* 6、![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/91235554-4dca-4c63-b4ce-cdca0bf96c70) \
涉及到一些模式挖掘，以及引入知识图谱作文本增强，来解决知识图谱补全问题 \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8b055444-c847-4318-8bcd-af94bad5f713)
* 7、GPT的应用流程详解和应用实例，来源https://karpathy.ai/stateofgpt.pdf \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d1535694-4b51-4f14-aa5a-5cb3638b212a)
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/32d57b59-c065-4b5a-b9e7-7e9ff5cd03ee)
* 8、Macaw-LLM，一个试验性的开源的多模态语言模型 \
地址：github.com/lyuchenyang/Macaw-LLM \
基于多个已有的开源项目，包括：\
CLIP：负责编码图像和视频帧。\
Whisper：负责编码音频数据。\
LLM（LLaMA/Vicuna/Bloom）：负责编码指令和生成响应的语言模型。
* 9、LeCun力挺，马毅教授五年集大成之作：完全数学可解释的白盒Transformer，性能不输ViT https://mp.weixin.qq.com/s/pUU5j1DEuViK9WblcQ6YHg \
马毅教授领导的研究团队开发了CRATE模型，推动了神经网络可解释研究！ \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7229714f-e2c9-4adb-825f-dada3d464916)
代码链接：https://github.com/Ma-Lab-Berkeley/CRATE \
论文链接：https://arxiv.org/abs/2306.01129
* 10、多模态可控图片生成统一模型来了，模型参数、推理代码全部开源 https://mp.weixin.qq.com/s/T5G9r1nrJ8Z5WSIe-zbp3Q \
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/10520e96-f6a1-4250-9fd5-6c9be66d223b)
论文地址：https://arxiv.org/abs/2305.11147 \
代码地址：https://github.com/salesforce/UniControl \
项目主页：https://shorturl.at/lmMX6 
* 11、NLP对话系统及实战项目分享【含源码】  https://mp.weixin.qq.com/s/e0450cK_bMPgx1l50v__cA \
* 对话系统核心理论与一个完整的订餐机器人实战项目

# 6.9 周5
* 1、将330亿参数大模型「塞进」单个消费级GPU，加速15%、性能不减 https://mp.weixin.qq.com/s/iOv3VYw6-OYYAaPFYRfZqQ  个人终端设备跑大模型成为现实了。 \
* ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/64f69814-cfce-4f95-a8cd-a93888667fab)
* 论文地址：https://arxiv.org/pdf/2306.03078.pdf
* 项目地址：https://github.com/Vahe1994/SpQR
* 2、深度学习三巨头之一 Yann LeCun：大语言模型带不来 AGI https://mp.weixin.qq.com/s/HFqPxE4rhLOJmcFybYuiSA   自监督学习与世界模型
* ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/8abe2f22-1873-4ff8-bece-a2f2af55ca23)
* ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/250af903-8c2e-43b8-b5ba-2c8235a38bda)
* ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4857ac8f-50a0-4c3e-ab82-2a8aa4eb829d)
* 相关视频：图灵奖得主、深度学习巨头 Yann LeCun 教授于2022 年 2 月 23在百度的讲座 《A Path Towards Autonomous AI。。。  
* https://www.bilibili.com/video/BV1H44y1n7Vn/?spm_id_from=333.337.search-card.all.click&vd_source=f5aceb5f4e7793d3e5cabca8dcfa32ed







