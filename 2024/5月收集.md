# 5.1 Wed
* 1.(**非常厉害 OctopusV3**)参数量不到10亿的OctopusV3，如何媲美GPT-4V和GPT-4？  机器之心  https://mp.weixin.qq.com/s/mUpX-nvo221WVii-gnjUmQ \
  论文标题：Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent \
  论文链接：https://arxiv.org/pdf/2404.11459.pdf \
  模型权重和推理代码：https://www.nexa4ai.com/apply
* 2.(**自我奖励模型**)「用 AI 训 AI」这事靠谱吗？  机器之心  https://mp.weixin.qq.com/s/bLLoYDTpq8q7ExfwyDekOQ \
  Meta 等提出的**自我奖励模型**具备双重角色：一方面，它遵循模型的指令来生成给定提示的响应；另一方面，它也能够根据示例生成和评估新的指令，进而将其添加到训练集中。该模型建立在假设之上，即利用基础的预训练语言模型和少量的人工注释数据，可以创建一个同时具备指令遵循和自指令创建能力的模型 \
* 3.Llama 3细节公布！AI产品总监站台讲解：Llama系列超庞大生态系统  新智元  https://mp.weixin.qq.com/s/iDAlop_LNv9evZtfPMPyUg \
  **目前发布的其实是Llama 3的非常早期版本**，团队原本打算将这些模型称为预发布或预览版本，因为模型并不具有计划中包含的全部功能
* 4.(**LLM幻觉综述**)《多模态大型语言模型的幻觉现象》综述  专知  https://mp.weixin.qq.com/s/O89fDn8UtgPF-QKYeeF3-g \
  Hallucination of Multimodal Large Language Models: A Survey

# 5.2 Thur
* 5.(**KAN**)MLP一夜被干掉！MIT加州理工等革命性KAN破记录，发现数学定理碾压DeepMind  新智元  https://mp.weixin.qq.com/s/vqhTFPbcUQaCsQnARZrn0g \
  全新神经网络架构KAN一夜爆火！200参数顶30万，MIT华人一作，轻松复现Nature封面AI数学研究  量子位  https://mp.weixin.qq.com/s/5WFJMPJvtaofeGDxFQ9aDw \
  无需怀念MLP，新网络KAN基于柯尔莫哥洛夫-阿诺德定理，带着更少的参数、更强的性能、更好的可解释性来了，深度学习架构革新进入新时代！ \
  KAN: Kolmogorov-Arnold Networks \
  论文地址：https://arxiv.org/pdf/2404.19756 \
  项目链接：https://kindxiaoming.github.io/pykan/
* 6.Meta 联合纽约大学和华盛顿大学提出MetaCLIP，带你揭开CLIP的高质量数据之谜  机器之心  https://mp.weixin.qq.com/s/bEhDOBWcGeUZGMGA6lHoCA \
  原文链接：https://arxiv.org/abs/2309.16671 \
  项目链接：https://github.com/facebookresearch/MetaCLIP \
  论文标题：Demystifying CLIP Data
* 7.GitHub 8.9K Star，伯克利大学开源LLM记忆管理框架MemGPT  AI科技大本营  https://mp.weixin.qq.com/s/holcsXlfNQ9ZYBX5xEECNw \
  开源链接：https://github.com/cpacker/MemGPT

# 5.3 Fri
* 8.终于有人调查了小模型过拟合：三分之二都有数据污染，微软Phi-3、Mixtral 8x22B被点名  机器之心  https://mp.weixin.qq.com/s/YRYaCSsaegjBtwevpwlLHQ \
  论文标题：A Careful Examination of Large Language Model Performance on Grade School Arithmetic \
  论文链接：https://arxiv.org/pdf/2405.00332
* 9.小模型性能饱和、表现不佳，根源是因为Softmax?  机器之心  https://mp.weixin.qq.com/s/bvv-frM8bKhkZiqOa9nqDA \
  Why do small language models underperform? Studying LM Saturation via the Softmax Bottleneck \
  论文链接：https://arxiv.org/pdf/2404.07647.pdf
* 10.CVPR 2024 Highlight | 基于单曝光压缩成像，不依赖生成模型也能从单张图像中重建三维场景  机器之心  https://mp.weixin.qq.com/s/8F6Wij7kOkEEFzAHo00j8g \
  原文链接：https://arxiv.org/abs/2403.20018 \
  项目链接：https://github.com/WU-CVGL/SCINeRF \
  论文标题：SCINeRF: Neural Radiance Fields from a Snapshot Compressive Image
* 11.(**meta一次预测多token**)一次预测多个token，Meta新模型推理加速3倍，编程任务提高17%  量子位  https://mp.weixin.qq.com/s/GuIqBdj4MteR9eBlTesdBA \
  对于背后原理，团队认为多token预测缓解了训练时Teacher Forcing和推理时自回归生成之间的分布差异。\
  也就是说，在训练的时候，模型看到的都是标准答案，生成的时候却得靠自己。好比人类在家做练习册时有答案，考试时却啥也没有，就会不适应。\
  而多token预测相当于训练时就逼着模型多想几步，这样到了考场上，才能应对自如。\
  从信息论的角度，团队还给出了一个更精确的论证。\
  传统的下一个Token预测，目标是最小化当前位置的信息熵。而2-Token预测实际上最小化的是当前和下一位置的信息熵之和。\
  数学推导表明，后者其实隐含了更大的互信息权重，也就是更看重当前Token和未来Token的相关性。这就是为什么多Token预测更”有远见”。\
  论文地址：https://arxiv.org/abs/2404.19737 \
  Better & Faster Large Language Models via Multi-token Prediction
* 12.(**多任务学习MTL综述**)释放多任务学习的力量：涵盖传统、深度和预训练基础模型时代的综述  专知  https://mp.weixin.qq.com/s/LjkpH4daIzpSF9FAC6V8-A \
  Unleashing the Power of Multi-Task Learning- A Comprehensive Survey Spanning Traditional, Deep, and Pretrained Foundation Model Eras \
  https://github.com/junfish/AwesomeMultitask-Learning

# 5.4 Sat
* 13.(**Multimodal Pathway**)CVPR‘24：与任务无关的多模态数据也能提升Transformer性能｜港中文&腾讯  量子位  https://mp.weixin.qq.com/s/Y4LV07qNzRa5MA_lygBiaw \
  Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities \
  论文地址：https://arxiv.org/abs/2401.14405 \
  项目网页：https://ailab-cvc.github.io/M2PT/ \
  开源代码：https://github.com/AILab-CVC/M2PT \
  讲解视频：https://www.bilibili.com/video/BV1Sm41127eW/
* 14.AI教母李飞飞首次创业！成立“空间智能”公司，已完成种子轮  量子位  https://mp.weixin.qq.com/s/RPhN_TR3lW990epLE7izmA \
  公司方向定为“空间智能”——旨在让AI能像人类一样对视觉信息进行高级推理。消息人士表示，这将是该技术的一次飞跃 \
  演讲中，李飞飞对“空间智能”的描述是从物体之间的关系中获得预测和洞察力的能力。\
  她表示，AI对空间智能理解的进步，正在催化机器人学习，使我们更接近让AI能与世界互动的目标。

# 5.5 Sun
* 15.(**非常值得看看**)LeCun哈佛演讲PPT放出：唱衰自回归LLM，指明下一代AI方向  机器之心  https://mp.weixin.qq.com/s/-dlh8e7ZLxj8c77iWCEO_g \
  PPT 链接：https://drive.google.com/file/d/1Ymx_LCVzy7vZXalrVHPXjX9qbpd9k_bo/view?pli=1 \
  视频地址 https://www.youtube.com/watch?v=MiqLoAZFRSE \
  LeCun 强调 AI 系统应该朝着能够学习、记忆、推理、规划、有常识、可操纵且安全的方向发展。 \
  LeCun 花了大量篇幅介绍 JEPA 相关技术，最后他给出了简单的总结：放弃生成模型，支持联合嵌入架构；放弃概率模型，支持基于能量的模型（EBM）；放弃对比方法，支持正则化方法；放弃强化学习，支持模型 - 预测控制；仅当规划无法产生结果时才使用强化学习来调整世界模型。\
  高级机器智能（Advanced Machine Intelligence，AMI）:\
  1.从感官输入中学习世界模型的 AI 系统；\
  2.具有持久记忆的系统；\
  3.具有规划行动的系统；\
  4.可控和安全的系统；\
  5.目标驱动的 AI 架构（LeCun 重点强调了这一条）。\
* 16.(**六边形战士JAT**)告别偏科，能玩转多模态、多任务、多领域的强化智能体终于来了  机器之心  https://mp.weixin.qq.com/s/2GBB-w7hBf6equtqD8V0Lg \
  论文名称：《Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent》 \
  论文链接：https://huggingface.co/papers/2402.09844 \
  代码链接：https://github.com/huggingface/jat \
  项目链接：https://huggingface.co/jat-project/jat \
  数据集：https://huggingface.co/datasets/jat-project/jat-dataset \
  要达到全能型智能体，主要需要解决以下问题：（1）如何设计一个能够处理多种数据类型和模态的统一模型结构？（2）如何有效地平衡不同任务的学习进度和优先级？（3）如何确保智能体制定合适的学习目标，以避免不同任务之间的干扰和负向迁移？
* 17.FixAgent：一款自动化debug的多Agent应用，有效提升模型20% debug能力  大语言模型论文追踪  https://mp.weixin.qq.com/s/LZhHg27ce5dWQVzwLQihRg \
  论文原文: https://arxiv.org/abs/2404.17153 \
  https://github.com/HuggingAGI/HuggingArxiv!

# 5.6 Mon
* 18.大骂“深度学习是垃圾”的自由能到底是什么？有什么效果？  CreateAMind  https://mp.weixin.qq.com/s/Jjw1BA1ociiCbAxKmjvU6A 
* 19.强化学习新书-《自适应行为及认知机器人概述》pdf分享  深度学习与NLP  https://mp.weixin.qq.com/s/UFDGNKjlhS9W5DCagjIimA \
  Behavioral and CognitiveRobotics An Adaptive Perspective \
  Stefano Nolfi
* 20.特斯拉Optimus人形机器人进厂打工，娴熟分装电池、自我矫正，还能走更远了  机器之心  https://mp.weixin.qq.com/s/P5pJFKGxxvi-jBuPCmk-RQ \
  Optimus 在机器人的 FSD 计算机上实时运行，而仅仅依靠 2D 摄像头、手部触觉和力传感器。 \
* 21.(**值得试试**)仅用250美元，Hugging Face技术主管手把手教你微调Llama 3  机器之心  https://mp.weixin.qq.com/s/PR4fCky5a6geBdCbxsOURg \
  Efficiently fine-tune Llama 3 with PyTorch FSDP and O-Lora
* 22.今日arXiv最热大模型论文：首个面向AI的python编程框架，提升大模型编程能力新思路  夕小瑶科技说  https://mp.weixin.qq.com/s/PBRfaD3d1PoQG2zt9vBn9g \
  论文标题：AI Coders Are Among Us: Rethinking Programming Language Grammar Towards Efficient Code Generation \
  论文链接：https://arxiv.org/pdf/2404.16333 \
  作者提出并实现了一个面向AI的Python语法，称为Simple Python（SimPy）作为概念验证
* 23.上海AI Lab开源首个可替代GPT-4V的多模态大模型  夕小瑶科技说  https://mp.weixin.qq.com/s/6Y_eFZgBGyIicdgs2zx0FA \
  与开源和闭源模型相比，InternVL 1.5 在 OCR、多模态、数学和多轮对话等 18 个基准测试中的 8 个中取得了最先进的结果。\
  https://arxiv.org/abs/2312.14238 \
  https://github.com/OpenGVLab/InternVL \
  https://internvl.opengvlab.com \
  https://huggingface.co/OpenGVLab/InternVL-Chat-V1-5 
* 24.58行代码把Llama 3扩展到100万上下文，任何微调版都适用  量子位  https://mp.weixin.qq.com/s/gG6qTLIpOcURt5s8GFy96w \
  ???不清楚如何做到的，LLM的上下文长度是怎么定的??? \
  524k版本LoRA：https://huggingface.co/cognitivecomputations/Llama-3-70B-Gradient-524k-adapter \
  1048k版本LoRA：https://huggingface.co/cognitivecomputations/Llama-3-70B-Gradient-1048k-adapter \
  合并代码:https://gist.github.com/ehartford/731e3f7079db234fa1b79a01e09859ac \
  参考链接：https://twitter.com/erhartford/status/1786887884211138784
* 25.(**PhysDreamer**)硬核解决Sora的物理bug！美国四所顶尖高校联合发布：给视频生成器装个物理引擎  新智元  https://mp.weixin.qq.com/s/YZXFVWTi7zJw-eqyJJMVNA \
  PhysDreamer: Physics-Based Interation with 3D Objects via Video Generation \
  论文链接：https://arxiv.org/pdf/2404.13026.pdf
  项目主页：https://physdreamer.github.io/
* 26.(**phi-3**)手机可跑，3.8B参数量超越GPT-3.5！微软发布Phi-3技术报告：秘密武器是洗干净数据  新智元  https://mp.weixin.qq.com/s/_t0jgnqk_WcvEQ37mr5R-A \
  Phi-3 Technical Report:A Highly Capable Language Model Locally on Your Phone \
  论文链接：https://arxiv.org/pdf/2404.14219.pdf \
  模型的训练遵循「Textbooks Are All You Need」的工作序列，利用高质量的训练数据来提升小型语言模型的性能，同时突破了标准的规模法则（scaling-laws）：phi-3-mini仅用3.8B的总参数量，就能达到GPT-3.5或Mixtral等高性能模型的水平（Mixtral的总参数量为45B）\
  在大型语言模型的能力方面，phi-3-mini虽然在语言理解力和推理能力上与更大型的模型旗鼓相当，但由于其规模的限制，在处理某些特定任务时仍然存在一些固有的局限性
* 27.AIXI, FEP-AI, 世界模型:走向智能和意识的统一理解  CreateAMind  https://mp.weixin.qq.com/s/JXwpUUcBJmbdbKBJITgO9A \
  太深奥，看不懂，但是很重要

# 5.7 Tue
* 28.意识的整合世界建模理论：FEP-AI + IIT + GNWT = IWMT  CreateAMind  https://mp.weixin.qq.com/s/rcZzMUyX5Y25L-WWnk49NA
  整合世界模型理论（IWMT）的实现思路  CreateAMind 
 https://mp.weixin.qq.com/s/PlsLVfNZ9Afg9fvrHlgVUw \
  系统工程理论-综合世界建模理论（IWMT）扩展：对意识和人工智能理论的启示  CreatAMind  https://mp.weixin.qq.com/s/tUtDxi8cWfFM7NkJzdaU4A
* 29.斯坦福20亿参数端测多模态AI Agent模型大升级，手机汽车机器人都能用  量子位  https://mp.weixin.qq.com/s/c4Cl4FD16-i6HjwdpmyRgA \
  Octopus v3 \
  论文地址：https://arxiv.org/abs/2404.11459
* 30.LeCun转发，AI让失语者重新说话！纽约大学发布全新「神经-语音」解码器｜Nature子刊  新智元  https://mp.weixin.qq.com/s/IJBebE0CHb-W1fuAp_xpAw \

# 5.8 Wed

# 5.9 Thur
* 31.基础模型视频理解综述  专知  https://mp.weixin.qq.com/s/FZ_qsK_zC0A0oW5NIW6hsQ \
* 32.HuggingFace烧钱做了一大批实验，揭示多模态大模型哪些trick真正有效  夕小瑶科技说  https://mp.weixin.qq.com/s/JnXU8wuyGyWgf7jjMtnFuw  \
  试玩地址: https://huggingface.co/spaces/HuggingFaceM4/idefics2_playground \
  论文标题: What matters when building vision-language models? \
  论文链接：https://arxiv.org/pdf/2405.02246 \
  本文通过详尽的实验，深入探讨了构建多模态大模型时文献中常见trick的有效性，并得出了一系列有价值的结论。不仅如此，作者还亲身实践了这些有用的技巧，成功构建了一个性能卓越的8B参数视觉语言模型——**Idefics2**。在同等规模的模型中，Idefics2展现出了最先进的性能，并具备更高的推理效率，为多模态大模型的研究提供了重要参考
* 33.今日arXiv最热大模型论文：浙江大学：如何减轻视觉大模型中的幻觉问题  夕小瑶科技说  https://mp.weixin.qq.com/s/ptJSDjM80uCZ4hewcyQs9g 
* 34.闭源赶超GPT-4 Turbo、开源击败Llama-3-70B，歪果仁：这中国大模型真香  机器之心  https://mp.weixin.qq.com/s/lwv7OTirD7IoTN8RNWCc5A \
  QWEN1.5
* 35.网传Ilya Sutskever的推荐清单火了，掌握当前AI 90%  机器之心  https://mp.weixin.qq.com/s/AFZoWX8kbk0uWklJwl4M_g \
  推荐清单：https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE
* 36.中山&港大| 提出DQ-LoRe框架，自动选择上下文示例，为LLMs复杂推理开辟新道路！  AINLPer  https://mp.weixin.qq.com/s/Kzh4ZAFwfjBlWzJaXcXflQ \
  DQ-LoRe \
  https://arxiv.org/pdf/2310.02954

# 5.10 Fri
* 37.Sora是世界模拟器吗? 世界模型及其以后的综述  专知  https://mp.weixin.qq.com/s/u9VsQxFEgrwCGSlBqQ3SPQ 
* 38.最详细人脑3D地图登Science！GPT-4参数只相当于人类0.2%  量子位  https://mp.weixin.qq.com/s/-BRNHTHIibMDtGYKJzNe7g 
* 39.14 项任务测下来，GPT4V、Gemini等多模态大模型竟都没什么视觉感知能力？ 
  机器之心  https://mp.weixin.qq.com/s/_-mgdLLJd4ck1UMJmfWTpg \
  **BLINK**将激励社区帮助多模态LLMs达到与人类同等级别的视觉感知能力 \
  BLINK 是一个针对多模态语言模型（Multimodal LLMs）的新基准测试，专注于评估其核心视觉感知能力，这些能力在其他评估中并未涉及。 \
  论文链接：https://zeyofu.github.io/blink
* 40.3倍生成速度还降内存成本，超越Medusa2的高效解码框架终于来了  机器之心  https://mp.weixin.qq.com/s/Aw_bjXIQFdOJvN22UvW9UA \
  抛弃自回归，连接一致性Diffusion和LLM！UCSD上交新作热度紧追AF 3  新智元  https://mp.weixin.qq.com/s/jOmh6g8X67WjXL0iLitD9Q \
  高效解码n -token序列，CLLMs+Jacobi解码框架。\
传统上，大型语言模型（LLMs）被认为是顺序解码器，逐个解码每个token。\
  来自上海交通大学、加利福尼亚大学的研究团队展示了预训练的LLMs可以轻松地被教导成为高效的并行解码器，并介绍了一种新的并行解码器族，称为一致性大语言模型（CLLMs），能够通过在每个推断步骤中高效地解码一个n -token序列来降低推断延迟。\
  在此篇论文中，研究表明：「模仿人类在头脑中形成完整句子后逐字表达的认知过程，可以通过简单地微调预训练的LLMs来有效地学习。」\
  具体而言，CLLMs通过将任何随机初始化的n -token序列映射到尽可能少的步骤中，产生与自回归（AR）解码相同结果，来进行并行解码的训练。\
  论文名称：《CLLMs：Consistency Large Language Models》\
  论文链接：https://arxiv.org/pdf/2403.00835
  
# 5.11 Sat
* 41.30%参数达到92%的表现，大模型稀疏化方法显神通  夕小瑶科技说  https://mp.weixin.qq.com/s/U53JtPQSpxQvHLJ7VLfWxA \
  论文标题: Enabling High-Sparsity Foundational Llama Models With Efficient  Pretraining and Deployment \
  论文链接: https://arxiv.org/pdf/2405.03594.pdf
* 42.微软打破Decoder-Only架构！大幅降低GPU内存需求，网友：把Llama3 70B弄20GB GPU上运行  量子位  https://mp.weixin.qq.com/s/aEi-GAmv_kzct1Pv9fjXMg \
  微软&清华最新研究，打破GPT系列开创的Decoder-Only架构—— \
  提出Decoder-Decoder新型架构，名为YOCO（You Only Cache Once）。\
  **YOCO**仅缓存一次键值对，可大幅降低GPU内存需求，且保留全局注意力能力。\
  论文链接：https://arxiv.org/abs/2405.05254
* 43.人类偏好就是尺！SPPO对齐技术让大语言模型左右互搏、**自我博弈**  机器之心  https://mp.weixin.qq.com/s/ulVGoBkCtFyV_mwSBdzgQg \
  论文标题：Self-Play Preference Optimization for Language Model Alignment \
  论文链接：https://arxiv.org/pdf/2405.00675.pdf

# 5.12 Sun
* 44.(**值得研究**)DiT架构大一统：一个框架集成图像、视频、音频和3D生成，可编辑、能试玩  机器之心  https://mp.weixin.qq.com/s/NwwbaeRujh-02V6LRs5zMg \
  基于 **Diffusion Transformer**（DiT）又迎来一大力作「**Flag-DiT**」，这次要将图像、视频、音频和 3D「一网打尽」\
  **Lumina-T2X** 系列中最大的模型包括具有 70 亿参数的 Flag-DiT 和一个多模态大语言模型 **SPHINX**。SPHINX 是一个文本编码器，它具有 130 亿参数，能够处理 128K tokens。\
  论文地址：https://arxiv.org/pdf/2405.05945 \
  GitHub 地址：https://github.com/Alpha-VLLM/Lumina-T2X \
  模型下载地址：https://huggingface.co/Alpha-VLLM/Lumina-T2I/tree/main \
  论文标题：Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers 

# 5.13 Mon
* 45.美国教授用2岁女儿训AI模型登Science！人类幼崽头戴相机训练全新AI  新智元  https://mp.weixin.qq.com/s/v6xvH1uPq8W5osws_yUzWg 
* 46.大神Karpathy强推，分词领域必读：自动钓鱼让大模型“发疯”的token，来自Transformer作者创业公司  量子位  https://mp.weixin.qq.com/s/UpkgRhZkK45gAPWOOmEwYQ \
  自动检测大模型中那些会导致“故障”的token。
* 47.网友缝合Llama3 120B竟意外能打，轻松击败GPT2-chatbot和GPT-4  量子位  https://mp.weixin.qq.com/s/3LtAKK3E6qC57OWIPAhNuw
* 48.Google和普林斯顿大学联合发表CoRL论文：寻求帮助的机器人-大型语言模型规划者的不确定性对齐   CAAI认知系统与信息处理专委会  https://mp.weixin.qq.com/s/aNeabrcdslgWurqUGL9D0A\
  文章介绍了一种名为KnowNo 的框架，用于测量和对齐基于大型语言模型（LLM）的规划器的不确定性，这样他们就知道什么时候它们不知道，并在需要的时候寻求帮助 \
  Robots That Ask For Help: Uncertainty Alignment for Large Language Model Robots Planners
* 49.(**RAG综述**)一文看懂RAG的各种套路 | 综述：当RAG遇到大语言模型  HuggingAGI 大语言模型论文跟踪  https://mp.weixin.qq.com/s/h8z4eXsemPMeL2oI_8VnvQ \
  A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models
* 50.(**Occupancy感知综述**)最新最全总结！自动驾驶Occupancy感知综述：信息融合视角  3D视觉工坊  https://mp.weixin.qq.com/s/muLuIA00jp1ovFVQBLsfoA

# 5.14 Tue
* 51.OpenAI颠覆世界：GPT-4o完全免费，实时语音视频交互震撼全场，直接进入科幻时代  机器之心  https://mp.weixin.qq.com/s/PfWnlhXh3n3VDfZaMI-ifQ
* 52.微软让MoE长出多个头，大幅提升专家激活率  机器之心  https://mp.weixin.qq.com/s/ZCRyb63M2DL4hOQh7uxxaw \
  多头混合专家  MH-MoE \
  论文标题：Multi-Head Mixture-of-Experts \ 
  论文地址：https://arxiv.org/pdf/2404.15045 \
  代码地址：https://github.com/yushuiwx/MH-MoE
* 53.沉浸式线性代数教材，不懂哪里点哪里，网友：天花板级别  量子位  https://mp.weixin.qq.com/s/g7VDc12v8wG5dTQp4nB0tw \
  传送门：https://immersivemath.com/ila/
* 54.(**值得看看**)思维链不存在了？纽约大学最新研究：推理步骤可「省略」  新智元  https://mp.weixin.qq.com/s/w_Ogu7DhtgdQXMRWrFhvxA \
  思维链技术，可能要被推翻了！来自纽约大学的最新研究表明：大模型并没有利用思维链的推理能力，它只是偷偷加了计算！ \
  研究人员发现，把思维链（Chain-of-Thought，CoT）推理中的具体步骤，替换成毫无意义的「...」，产生的推理结果也大差不差 \
  Let's Think Dot by Dot: Hidden Computation in Transformer Language Models \
  论文地址：https://arxiv.org/pdf/2404.15758
* 55.牛皮吹破？大模型长输入能力不能拿来做上下文学习  夕小瑶科技说  https://mp.weixin.qq.com/s/NI4juWbm9jOjhK2hCM8KQA \
  论文标题: Long-context LLMs Struggle with Long In-context Learning \
  论文链接：https://arxiv.org/pdf/2404.02060.pdf
* 56.【伯克利博士论文】零样本机器人感知的视觉-语言表示，74页pdf  专知  https://mp.weixin.qq.com/s/Ze5x3x4GnQCZExk8jJl1Dg \
  Vision-Language Representations for Zero-Shot Robotic Perception
* 57.RAG 与 LLMs 的结合 - 迈向检索增强的大型语言模型**综述**  专知  https://mp.weixin.qq.com/s/p_sPNF54y1mAoayzWRkBaA \
  
# 5.15 Wed
* 58.博弈论如何让大语言模型更聪明？ | 智能渐近线   追问nextquestion  https://mp.weixin.qq.com/s/kCmkm8litbmAttZwMkHA_A \
  The consensus game: Language model generation via equilibrium search

# 5.16 Thur
* 59.GPT-4o手写板书以假乱真惊呆网友！杀死谷歌翻译，代码建模无所不能  新智元  https://mp.weixin.qq.com/s/mpSSSDqL6qYSvXdtPJbm1A \
* 60.李飞飞解读创业方向「**空间智能**」，让AI真正理解世界  机器之心  https://mp.weixin.qq.com/s/okhjWPp0is0ks3e_RvJO4g \
  李飞飞 TED 演讲链接: https://www.ted.com/talks/fei_fei_li_with_spatial_intelligence_ai_will_understand_the_real_world/transcript \
* 61.无位置编码 (NoPE) 也有长度泛化问题？首个针对NoPE的长度外推方法 
 PaperWeekly  https://mp.weixin.qq.com/s/8Gq2paZSWmzqXRVMRRB-lw \
  论文标题：Length Generalization of Causal Transformers without Position Encoding \
  论文链接：https://arxiv.org/pdf/2404.12224.pdf \
  代码链接：https://github.com/AntNLP/nope_head_scale

# 5.17 Fri
* 62.走向最小统一意识模型  CreateAMind  https://mp.weixin.qq.com/s/MJB1nb9wmwZliJR0HGDSxw \
  意识研究的黄金测试标准，**米田引理**的应用  CreateAMind  https://mp.weixin.qq.com/s/hwfzY0t_cKaP68q9Iofy_A \
  将胡塞尔现象学映射到主动推理  CreateAMind  https://mp.weixin.qq.com/s/Fg-qEKDDdgUxZX0326feCg

# 5.18 Sat
* 63.Transformer是推断还是记忆？初始化大小很重要  PaperWeekly  https://mp.weixin.qq.com/s/hmAUN5GM8AQIxVHFUkip-A \
  通过这项研究，我们发现，Transformer 模型的初始化大小决定了它是像福尔摩斯一样通过推理解谜，还是像我奶奶一样通过记忆菜谱来做饭。小初始化让模型像侦探一样，只需要记住几个关键的线索（运算规则），就能推理出所有结果。而大初始化则像孙悟空，把所有知识吃下去的方式记下来。
* 64.(**可以看看**)我们离AGI有多远？UIUC最新120页论文阐述AGI定义、目标和发展轨迹  专知  https://mp.weixin.qq.com/s/1jXGdt4PjAQBfwy40LvlIA \
  How Far Are We From AGI 
* 65.GPT-4通过图灵测试，胜率高达54%！UCSD新作：人类无法认出GPT-4  新智元  https://mp.weixin.qq.com/s/0_49it464APmy7uwvHH3KQ \
  论文地址：https://arxiv.org/pdf/2405.08007
* 66.(**值得了解**)缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA  PaperWeekly  https://mp.weixin.qq.com/s/yCczYU0po0PvPTa-eh2pfg 

# 5.19 Sun
* 67.Meta首发「变色龙」挑战GPT-4o，34B参数引领多模态革命！10万亿token训练刷新SOTA  新智元  https://mp.weixin.qq.com/s/HQC7F64ZIb-k-K_QLzFegg \
  Meta团队发布了「混合模态」Chameleon，可以在单一神经网络无缝处理文本和图像
* 68.Google | 大模型(LLMs)对齐：为什么在线方法总是优于离线方法？  AINLPer  https://mp.weixin.qq.com/s/RjQxP3itdNrM6yVg2p0RIQ \
  论文标题：Understanding the performance gap between online and offline alignment algorithms \
  论文地址：https://arxiv.org/abs/2405.08448
* 69.学的少，忘的少！UC | LoRA最新研究：总结LoRA最佳实践，实现LLMs高效微调！  AINLPer  https://mp.weixin.qq.com/s/Gt7AlwHAq6Z-KD8d027y8A \
  LoRA Learns Less and Forgets Less \
  https://arxiv.org/pdf/2405.09673 \
  LoRA在大多数情况下性能不如全微调，但作为一种正则化手段，LoRA能够保证在源领域上的性能（遗忘问题），并减少对新任务的学习成本

# 5.20 Mon
* 70.为什么计算机科学存在图灵机和Lambda演算两种世界观，量子力学中却存在着三种世界图景？ 图灵人工智能  https://mp.weixin.qq.com/s/j5yp-NpKRu3N3msXzq79CQ 
* 71.Karpathy称赞，从零实现LLaMa3项目爆火，半天1.5k star  机器之心  https://mp.weixin.qq.com/s/1poG0tEjmym1456mmR66nQ \
  项目地址：https://github.com/naklecha/llama3-from-scratch 
* 72.让大模型理解手机屏幕，苹果多模态Ferret-UI用自然语言操控手机  机器之心  https://mp.weixin.qq.com/s/GPsnp51OaCO0MCRlXTDObQ \
  论文地址：https://arxiv.org/pdf/2404.05719.pdf \
  论文标题：Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs
* 73.150B token从头训练，普林斯顿Meta发布完全可微MoE架构**Lory**  新智元  https://mp.weixin.qq.com/s/UKIXGJTFzSeSZvoTe_c9CQ \
  ???什么是完全可微的MoE \
  论文地址：https://arxiv.org/abs/2405.03133
* 74.今日arXiv最热大模型论文：Agent也疯狂！FoA方法对智能体做树结构搜索，超越ToT   夕小瑶科技说  https://mp.weixin.qq.com/s/3C4OuqPLUp7_psReAMhIOQ \
  论文标题: \
  **Fleet of Agents**: Coordinated Problem Solving with Large Language Models using Genetic Particle Filtering \
  论文链接：https://arxiv.org/pdf/2405.06691
* 75.LoRA数学编程任务不敌全量微调 | 哥大&Databricks新研究  量子位  https://mp.weixin.qq.com/s/hoYYMFH9nSB2tkNmGggquw 

# 5.21 Tue
* 76.李飞飞「空间智能」系列新进展，吴佳俊团队新「BVS」套件评估计算机视觉模型  机器之心  https://mp.weixin.qq.com/s/fZdVrD52db1mE63oHMJ36Q \
  空间智能（Spatial Intelligence）\
  李飞飞曾提到斯坦福团队的一个研究成果 BEHAVIOR，这是他们「创建」的一个用来训练计算机和机器人如何在三维世界中行动的行为和动作数据集。\
  如今，吴佳俊带领团队发表了后续研究——「BEHAVIOR Vision Suite（BVS）」 

# 5.22 Wed
* 77.(**重要**)从Claude 3中提取数百万特征，首次详细理解大模型的「思维」  机器之心  https://mp.weixin.qq.com/s/cZhmvAva6NDLG84kD819Ww \
  Anthropic | 数百万个特征，带你深入理解大模型的「思维」！ AINLPer  https://mp.weixin.qq.com/s/f-_GOiwbXOvsE-UzSh0lSg \
  研究论文：https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html
* 78.(**值得一看**)Hinton万字访谈：用更大模型「预测下一个词」值得全力以赴  机器之心  https://mp.weixin.qq.com/s/OydltjpVwsQ7hNBH6hq_Og \
  视频链接：https://www.youtube.com/watch?v=tP-4njhyGvo&t=660s \
  Hinton 认为，大型语言模型通过寻找不同领域的共同结构来进行编码，这种能力使它们能够压缩信息并形成深层次的理解，发现现实世界中人类尚未发现的万事万物的联系，这是创造力的来源。他还提到，通过预测下一个符号，模型实际上必须执行一定程度的推理，而不是像很多人所说的大模型并不具备推理能力。随着模型规模的增加，这种推理能力也将变得越来越强。这是一个值得全力以赴的方向。
* 79.硬刚 LoRA！北航&微软 | 提出高秩适应LLMs微调法：**MoRA**，填补LoRA低秩缺陷！  AINLPer  https://mp.weixin.qq.com/s/snyzb2Cze6X5zVhQlOpqjw \
  https://arxiv.org/pdf/2405.12130
* 80.开源多模态SOTA再易主，19B模型比肩GPT-4v，16G显存就能跑  量子位  https://mp.weixin.qq.com/s/GWbMmtRJ16RYZEAZFbYC9g \
  Hugging Face开发者大使刚刚把王冠交给了CogVLM2，来自大模型创业公司智谱AI
* 81.(**值得看看**)麻省理工(MIT) | 提出跨层Attention，减少Transformer大模型键值(KV)缓存，加快LLM推理！  AINLPer  https://mp.weixin.qq.com/s/pfSc3Rr8BBo0Lwa2Kb_rzw \
  跨层注意力（Cross-Layer Attention, CLA），即通过在不同层之间共享KV头，减少了KV缓存的大小。对比其它方法，在相同准确性的情况下，可以将KV缓存的大小缩小2倍！\
  Reducing Transformer Key-Value Cache Size with  Cross-Layer Attention \
  https://arxiv.org/pdf/2405.12981
* 82.登顶Top2！MiniCPM-V 8B新版本：GPT-4V水准小钢炮，8G显存，4070轻松推理！  PaperWeekly   https://mp.weixin.qq.com/s/TQVHJlZDExD3nMPRsqa_5w \
  面壁智能 

# 5.23 Thur
* 83.具身智能体三维感知新链条，TeleAI &上海AI Lab提出多视角融合具身模型「SAM-E」  机器之心  https://mp.weixin.qq.com/s/bLqyLHzFoBrRBT0jgkmZMw \
  论文名称：SAM-E: Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation \
  论文链接： https://sam-embodied.github.io/static/SAM-E.pdf \
  项目地址： https://sam-embodied.github.io/
* 84.(**值得看看**)世界模型也扩散！训练出的智能体竟然不错  机器之心  https://mp.weixin.qq.com/s/AWt1Jgvr2aj6sjkGRV9-hg \
  在图像生成领域占据主导地位的扩散模型，开始挑战强化学习智能体 \
  日内瓦大学、爱丁堡大学、微软研究院的研究者联合提出一种在扩散世界模型中训练的强化学习智能体 —— **DIAMOND**（DIffusion As a Model Of eNvironment Dreams） \
  论文地址：https://arxiv.org/abs/2405.12399 \
  项目地址：https://github.com/eloialonso/diamond \
  论文标题：Diffusion for World Modeling: Visual Details Matter in Atari 

# 5.24 Fri
* 85.通用世界模型问世：不学习就能生成新领域视频，可实时控制  机器之心  https://mp.weixin.qq.com/s/Vj2W3BtKITV4mxwVhDJHzg \
  **Pandora** 是一种混合自回归扩散模型，可通过生成视频来模拟世界状态，并允许通过自由文本动作（free-text action）进行实时控制。Pandora 通过大规模预训练和指令调整实现了领域通用性、视频一致性和可控性 \
  论文：Pandora : Towards General World Model with Natural Language Actions and Video States \
  论文地址：https://world-model.maitrix.org/assets/pandora.pdf \
  项目地址：https://github.com/maitrix-org/Pandora \
  项目展示页面：https://world-model.maitrix.org/
* 86.(**重要**)从80个模型中构建Scaling Law：华人博士生新作，思维链提出者力荐  机器之心  https://mp.weixin.qq.com/s/D8yx5Ma38TXjV3Yepa1_Sg \
  论文地址：https://arxiv.org/pdf/2405.10938 \
  论文标题：Observational Scaling Laws and the Predictability of Language Model Performance
* 87.大语言模型的创意"魔法"：召唤隐藏的联想思维  夕小瑶科技说  https://mp.weixin.qq.com/s/1SmShJnpZ4870BZ7Uvfc9A \
  通过激发AI的联想思维，我们有望让机器成为更出色的"创意伙伴"，为人类的创新实践带来启发 \
  什么是联想思维？？？ \
  论文题目：Enhancing Creativity in Large Language Models through Associative Thinking Strategies \
  论文链接：https://arxiv.org/pdf/2405.06715
* 88.(**综述**)大型语言模型遇上自然语言处理：综述  专知  https://mp.weixin.qq.com/s/P1IoUbmBEAgAq9XPNRE35g \
  Large language Models Meet NLP: A Survey 
* 89.李飞飞：大模型不具备知觉，参数再多也不行  量子位  https://mp.weixin.qq.com/s/j7_P2PO4ydPARuG1z8IL4A \

# 5.25 Sat
* 90.(**综述**)《面向具身智能的视觉-语言-动作模型》综述  专知  https://mp.weixin.qq.com/s/5GpChZeS6BYcW_0Q435-aQ \
  A Survey on Vision-Language-Action Models for Embodied AI 
* 91.(**值得看看**)Bengio等人新作：注意力可被视为RNN，新模型媲美Transformer，但超级省内存  机器之心  https://mp.weixin.qq.com/s/mRt2A1n1CmO7uqzuLQHxkw \
  论文地址：https://arxiv.org/pdf/2405.13956 \
  论文标题：Attention as an RNN
* 92.(**值得试试**)只需单卡RTX 3090，低比特量化训练就能实现LLaMA-3 8B全参微调  机器之心  https://mp.weixin.qq.com/s/e19D0ZtAoZXbmmr9KBlYqw 
* 93.(**综述**)今日arXiv最热大模型论文：忘记"也是一门学问：机器如何忘记自己学到的知识？  夕小瑶科技说  https://mp.weixin.qq.com/s/5hxleiSLaaijgbO6dmeK4A \
  论文标题：Machine Unlearning: A Comprehensive Survey \
  论文链接：https://arxiv.org/pdf/2405.07406

# 5.26 Sun
* 94.全面超越DPO：陈丹琦团队提出简单偏好优化SimPO，还炼出最强8B开源模型  机器之心  https://mp.weixin.qq.com/s/wJKiDU8t2RW2DpnqYR1h8w \
  论文标题：SimPO: Simple Preference Optimization with a Reference-Free Reward \
  论文地址：https://arxiv.org/pdf/2405.14734 \
  代码 & 模型：https://github.com/princeton-nlp/SimPO
* 95.ICML 2024 | 脱离LoRA架构，训练参数大幅减少，新型傅立叶微调来了  机器之心  https://mp.weixin.qq.com/s/jaYeIfByJaWU5-4jBmnrzQ \
  Parameter-Efficient Fine-Tuning with Discrete Fourier Transform \
  论文地址：https://arxiv.org/abs/2405.03003 \
  项目地址：https://github.com/Chaos96/fourierft

# 5.27 Mon
* 96.(**重要**)ChatGPT如何「思考」？心理学和神经科学破解AI大模型，Nature发文  机器之心  https://mp.weixin.qq.com/s/4nO4DQE6Llfo3fiFSPSMhQ 
* 97.(**有趣**)GPT-4被证实具有「人类心智」登Nature！AI比人类更好察觉讽刺和暗示  新智元  https://mp.weixin.qq.com/s/3Nu4rrHgv614FFW3CR3GSA \
  Testing theory of mind in large language models and humans \
  论文地址：https://www.nature.com/articles/s41562-024-01882-z
* 98.如何花3400配置一台室内无噪音，48GB显存的深度学习服务器？  PaperWeekly  https://mp.weixin.qq.com/s/KR2jCxTiPM4NIn7o7hNZkg
* 99.全球首台生物计算机开放服务：16个人脑类器官，能耗节省百万倍  机器之心  https://mp.weixin.qq.com/s/EA8HI8kotgH4ot5yw5xtqw

# 5.28 Tue
* 100.多模态CoT思维链架构来了，现已开源｜来自厦大&腾讯优图  量子位  https://mp.weixin.qq.com/s/YCqnAN8vEsP9N7vQ2HQjoA \
  论文地址：https://arxiv.org/abs/2404.16033 \
  项目地址：https://ggg0919.github.io/cantor/
* 101.(**Octo**)适应多形态多任务，最强开源机器人学习系统「八爪鱼」诞生  机器之心  https://mp.weixin.qq.com/s/HPTfOlw25F5JcvlY-Vy9Tw \
  论文标题：Octo: An Open-Source Generalist Robot Policy \
  论文地址：https://arxiv.org/pdf/2405.12213 \
  开源项目：https://octo-models.github.io/
* 102.清华、华为等提出**iVideoGPT**：专攻交互式世界模型  机器之心  https://mp.weixin.qq.com/s/yJdy4NRhMf360Bq3WqRYCQ \
  论文地址：https://arxiv.org/pdf/2405.15223 \
  论文标题：iVideoGPT: Interactive VideoGPTs are Scalable World Models
* 103.人工智能终于敲在了认识论的大门上  图灵人工智能  https://mp.weixin.qq.com/s/OLqe9aeW-d_GwsL761Wkxg \
  现在的人工智能大模型，随着训练的内容越来越丰富，对于不同知识的表示会越来越接近 \
  他们比较了78个计算机视觉的模型，虽然训练数据集、任务目标和算法架构都不一样，训练程度越高的，表征的相似度就越高 \
  https://arxiv.org/abs/2405.07987
* 104.(**LEO已开源**)ICML'24开源 | LEO：首个三维世界中的具身通用智能体  3D视觉工坊  https://mp.weixin.qq.com/s/hU7cevi-TPqjbf1XE9EOPg \
  项目主页：https://embodied-generalist.github.io/ \
  开源代码：https://github.com/embodied-generalist/embodied-generalist \
  个人主页：http://huangjy-pku.github.io/
* 105.(**值得了解**)恐怖如斯！GSU | 提出VB-LoRA，仅需LoRA参数的0.4%，就超越了LoRA微调效果  AINLPer  https://mp.weixin.qq.com/s/yGJ23Nrvd9bTL7WvAizqgQ \
  VB-LoRA，该方法采用“分而共享（divide-and-share）”范式，通过向量库进行全局参数共享，在保证模型性能的同时，实现了极高的参数效率 \
  https://arxiv.org/pdf/2405.15179v1
* 106.(**持续学习SAPT**)哈工大 | 提出共享Attention框架：SAPT，提升LLM持续学习性能  AINLPer  https://mp.weixin.qq.com/s/5_edsqo7uAuKIW1FI8pz9A \
  ACL 2024 | 提升大模型持续学习性能，哈工大、度小满提出共享注意力框架  PaperWeekly  https://mp.weixin.qq.com/s/qLU7ekqSdNUGHFgbJrxOMg \
  论文：SAPT: A Shared Attention Framework for Parameter-Efficient Continual Learning of Large Language Models \
  论文地址：https://arxiv.org/abs/2401.08295
* 107.Karpathy新教程爆火，网友抢着送他H100：从头复现GPT-2训练  量子位  https://mp.weixin.qq.com/s/y3tYldBX9DML4f5XT6EPMw \
  教程：https://github.com/karpathy/llm.c/discussions/481

# 5.29 Wed
* 108.视觉-语言导航模型如何适应更新？ICML2024|基于快-慢测试时自适应的在线视觉-语言导航方法  专知  https://mp.weixin.qq.com/s/Z_x1-xDINDi-Ww8lt4ndFg \
  论文标题：Fast-Slow Test-Time Adaptation for Online Vision-and-Language Navigation \
  论文链接：https://arxiv.org/abs/2311.13209  \
  代码链接：https://github.com/Feliciaxyao/ICML2024-FSTTA
* 109.速度秒掉GPT-4o、22B击败Llama 3 70B，Mistral AI开放首个代码模型  机器之心  https://mp.weixin.qq.com/s/yPLyGyXSkliV2fVz1PxUhw  \
  Codestral 
* 110.(**英特尔Hala Point**)用硅模拟人脑，进度条走到了1/80  量子位  https://mp.weixin.qq.com/s/V5QSdb9fpha-41zX86HNCw  \
  世界上最大的神经拟态系统，英特尔Hala Point
* 111.**MoE门控网络**最新创新！性能对标Llama 3，**源2.0-M32**大幅提升模型算力效率  PaperWeekly  https://mp.weixin.qq.com/s/Z1hK9Xds9XUnmPHqvKrsRw \
  全新发布的大模型“源 2.0-M32”为 MoE 算法结构创新带来了全新思路——创新性地提出和采用了“基于注意力机制的门控网络”技术，构建包含 32 个专家（Expert）的混合专家模型（MoE），大幅提升了模型算力效率。支持以更少的算力消耗，实现更高的模型能力
* 112.(**HippoRAG,非常值得研究**)**长短时记忆RAG**来啦，仿照人脑结构，成本降低20倍，表现提高20%！ 夕小瑶科技说  https://mp.weixin.qq.com/s/iewr5pfd_663U7L_-8ap6Q \
  论文标题：HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models \
  论文链接：https://arxiv.org/pdf/2405.14831 \
  大模型在知识整合和长期记忆方面仍存在明显短板，而这恰恰是人脑的强项。人类的大脑能持续不断地整合新知识，形成强大的长期记忆，为我们的思考和决策提供支持。那么大模型如何才能像人脑一样拥有高效的知识整合和长期记忆呢？ \
  来自俄亥俄州立大学和斯坦福大学的一组科学家们给出了一个有趣的思路：**让人工智能拥有一个类似人类海马体的"记忆大脑"**。他们从神经科学的角度出发，模仿人脑海马体在长期记忆中的作用，设计出一个名为HippoRAG的模型，能够像人脑一样高效地整合和搜索知识。实验表明，这个"记忆大脑"能够在多跳问答等需要知识整合的任务上取得大幅提升。这或许指明了让大模型具备"类人"记忆能力的一个全新方向。
* 113.(**LeCun推荐，重要**)Meta| 提出上下文位置编码：CoPE，解决当前模型「普遍存在的问题」，含GPT-4o！  AINLPer  https://mp.weixin.qq.com/s/xUJXxP6DQGqb6xrmTKKlgQ \
  解决Transformer根本缺陷，CoPE论文爆火：所有大模型都能获得巨大改进  机器之心  https://mp.weixin.qq.com/s/JxB6JU6MxO3709mkg7penw \
  https://arxiv.org/pdf/2405.18719 \
  当前位置编码（PE）主要是通过Token计数来定位，这限制了其泛化能力 \
  针对该问题，本文作者提出了一种新的位置编码方法——上下文位置编码（CoPE），它可以让大模型（LLMs）中的Token基于上下文进行更灵活的定位，降低语言建模和编码任务的困惑度，从而提高模型性能

# 5.30 Thur
* 114.你好世界！LLM开启人形机器人新纪元  新智元  https://mp.weixin.qq.com/s/XbAI-rueAHDxMdB4pxTLyw \
  Do AsICan, Not As I Say: Grounding Language in Robotic Affordances \
  https://arxiv.org/pdf/2204.01691.pdf \
  Generative Expressive Robot Behaviors using Large Language Models \
  https://arxiv.org/pdf/2401.14673v2 \
  OK-Robot \
  https://arxiv.org/pdf/2401.12202.pdf \
  RT-2 \
  https://robotics-transformer2.github.io/assets/rt2.pdf \
  Open X-Embodiment: Robotic Learning Datasets and RT-X Models \
  https://arxiv.org/pdf/2310.08864.pdf
* 115.(**值得看看**)Meta等76页最新《视觉语言模型VLM导论》，详述VLM技术栈  专知  https://mp.weixin.qq.com/s/wBspqWwHVit_Xx1CXq5PYw \
  An Introduction to Vision-Language Modeling \
  https://arxiv.org/abs/2405.17247
* 116.今日arXiv最热大模型论文：13位作者，200篇文献，腾讯最新**综述高效多模态大模型**：性能要强，规模要小  夕小瑶科技说  https://mp.weixin.qq.com/s/oXdj09kRJ3pFwJ0Qpi72_g \
  论文标题:Efficient Multimodal Large Language Models:A Survey  \
  论文链接：https://arxiv.org/pdf/2405.10739v1 \
  GitHub仓库：https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey

# 5.31 Fri
* 117.Yann LeCun：ViT慢且效率低，实时图像处理还得看卷积  机器之心  https://mp.weixin.qq.com/s/VO_AgwBJYrZHOgVXVqG3Ew \
  Yann LeCun 在第二个帖子里总结到：在低级别使用带有步幅或池化的卷积，在高级别使用自注意力循环，并使用特征向量来表征对象。\
  低级别 patch 嵌入上使用 Transformer 完全一种浪费。
* 118.(**有趣**)谷歌DeepMind：GPT-4**高阶心智理论**彻底击败人类！第6阶推理讽刺暗示全懂了  新智元  https://mp.weixin.qq.com/s/Wzb-34VizJFZb8Z6TRwz_g \
  LLMs achieve adult human performances on higher-order theory of mind tasks \
  论文地址：https://arxiv.org/pdf/2405.18870
* 119.(**LLM只是看起来有记忆**)ChatGPT真能记住你的话吗？DeepMind与开源大佬揭示LLM记忆之谜  新智元 
 https://mp.weixin.qq.com/s/8ZjJOXEbE3DRhDlFFYSQDw \
  Django框架的创始人之一、著名开发者Simon Willison最近发表了一篇博客文章，核心观点是——虽然很多LLM看起来有记忆，但本质上是无状态函数 \
  Training is not the same as chatting: ChatGPT and other LLMs don’t remember everything you say \
  文章地址：https://simonwillison.net/2024/May/29/training-not-chatting/ \
