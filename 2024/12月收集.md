# 12.1 Sun
* 1.微软发明全新「LLM语言」，AI智能体交互效率翻倍！  新智元  https://mp.weixin.qq.com/s/suIXm71AoVXgLWtFX3wJwA \
  来自微软、芝加哥大学的研究人员推出了「Droidspeak」，让AI智能体之间可以用自己的语言进行交流 \
  DroidSpeak: Enhancing cross-LLM communication \
  结果表明，在不损失性能的情况下，Droidspeak使模型的通信速度提高了2.78倍 \
  直接传递模型中间的计算结果（缓存），而不需要转换成人类能够理解的自然语言，这就是「Droidspeak」的含义

# 12.2 Mon
* 2.(**可以看看**)AI做数学学会「动脑子」！ UCL等发现LLM「程序性知识」，推理绝不是背答案  新智元  https://mp.weixin.qq.com/s/ShEThew_5sYksIPxbst3KA \
  PROCEDURAL KNOWLEDGE IN PRETRAINING DRIVES REASONING IN LARGE LANGUAGE MODELS \
  LLM在推理任务中进行泛化时，依赖的是文档中的「程序性知识」，使用可概括的策略，来综合推理任务的解决方案 \
  ???具体什么是程序性知识
* 3.清华UCSD提出全新微调方法，8B小模型媲美GPT-4o！科学问题正确率提高28% 
 新智元  https://mp.weixin.qq.com/s/B9aMDNTEbjP8UfoH8jmWsg \
  支来自UCSD和清华的研究团队提出了一种全新的微调方法，让模型「边适应边学习」，学会在使用外部科学工具和依赖内部知识之间做出合理选择 \
  Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation 
* 4.(**可以看看**)DeepMind用语言游戏让大模型学AlphaGo自我博弈，数据限制不存在了  机器之心  https://mp.weixin.qq.com/s/EC5QdHcasev8JpTp-OKLKQ \
  Boundless Socratic Learning with Language Games 

# 12.3 Tue
* 5.(**了解**)李飞飞空间智能首秀：AI靠单图生成3D世界，可探索，遵循基本物理几何规则  量子位  https://mp.weixin.qq.com/s/iU_XQdF-r8AnnXr2dwI89w \
  3个月估值10亿，李飞飞空间智能首个模型诞生！一张图生成3D世界，视频游戏要变天  新智元  https://mp.weixin.qq.com/s/CtmG0pck4fwtBWkypvt0sA \
  https://www.worldlabs.ai/blog \
  交互传送门：https://www.worldlabs.ai/blog#footnote1
* 6.全自动组装家具！ 斯坦福发布IKEA Video Manuals数据集：首次实现「组装指令」真实场景4D对齐  新智元  https://mp.weixin.qq.com/s/a1BX9oLNK9vlfc8dW_50mg \
  IKEA Manuals at Work: 4D Grounding of Assembly Instructions on Internet Videos \
  https://yunongliu1.github.io/ikea-video-manual/ \
  https://github.com/yunongLiu1/IKEA-Manuals-at-Work
* 7.扩散模型、最优传输存在什么关系？法国数学家4页论文引网友围观  机器之心  https://mp.weixin.qq.com/s/MN5MR0KsNGLYEYYfnf9hDA
  THE FLOW MAP OF THE FOKKER-PLANCK EQUATION DOES NOT PROVIDE OPTIMAL TRANSPORT 

# 12.4 Wed
* 8.Lilian Weng博客最新博客《强化学习Reward Hacking》  专知  https://mp.weixin.qq.com/s/QKJPdgajqz6i9dvP3Qxb1Q \
  离职OpenAI后Lilian Weng博客首发！深扒RL训练漏洞，业内狂赞  新智元  https://mp.weixin.qq.com/s/Hf5oKsU3BVd1fOcPhbsugA \
  Reward Hacking in Reinforcement Learning \
  https://lilianweng.github.io/posts/2024-11-28-reward-hacking/ \
  当强化学习（RL）智能体利用奖励函数中的缺陷或歧义来获得高额奖励，而没有真正学习或完成预期任务时，就会发生 Reward Hacking（Reward Hacking in Reinforcement Learning）。Hacking 之所以存在，是因为强化学习（RL）环境通常不完善，而且准确指定奖励函数从根本上具有挑战性

# 12.5 Thur
* 9.(**具有长期记忆能力的WM**)刚刚，DeepMind最强「基础世界模型」诞生！单图生1分钟游戏世界，解锁下一代智能体  新智元  https://mp.weixin.qq.com/s/lUf5_0vnka7OM4jfeAZkeg \
  Genie 2: A large-scale foundation worldmodel \
  https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/ \
  这就意味着，任何人都可以用文字描述自己想要的世界，选择自己喜欢的渲染效果，然后进入这个新创建的世界，并且与之互动（或者，也可以让AI智能体在其中被训练或评估）\
  Genie 2能够记住那些暂时离开画面的场景，并在它们重新进入视野时，精确地还原出来  !!! Genie 2 具有**长期记忆能力**
* 10.推动大模型自我进化，北理工推出「流星雨计划」  机器之心  https://mp.weixin.qq.com/s/_UqhgOpMH6cjYwrsPA0LPg \
  SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation \
  跟随上述自我进化的思想，在 SRA-MCTS（Self-guided MCTS-based data generation for Reasoning Augmentation）方法中，作者无需借助额外的任何监督信号、完全通过模型自身来进行推理路径生成，并进一步迭代大模型的能力。通过这个过程，模型能够自主地生成高质量的推理路径，并将这些路径转化为可执行代码，进而提升在复杂任务上的成功率 \
  代码开源：https://github.com/DIRECT-BIT/SRA-MCTS8B \
  模型的数据开源：https://huggingface.co/datasets/BinXD/SRA-MCTS-Llama-3.1-8B
* 11.清华团队提出HiAR-ICL：基于蒙特卡洛树搜索的全新上下文学习推理范式 
 PaperWeekly  https://mp.weixin.qq.com/s/LcEAbrxS9Rb8IMyyqrSYFA \
  HiAR-ICL: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS

# 12.6 Fri
* 12.Bengio、LeCun再喊话：AGI推理不需要先学语言，LLM路走窄了？  新智元  https://mp.weixin.qq.com/s/BawvPfL3l5GJZNHaPNeHoQ \
  AI can learn to think before it speaks \
  https://www.ft.com/content/894669d6-d69d-4515-a18f-569afbf710e8
* 13.(**可以看看**)NeurIPS 2024 | 哈工深提出新型智能体Optimus-1，横扫Minecraft长序列任务  机器之心  https://mp.weixin.qq.com/s/fqUYuajMH0wNva4HUux8Qw \
  Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks \
  https://cybertronagent.github.io/Optimus-1.github.io/ \
  https://github.com/JiuTian-VL/Optimus-1

# 12.7 Sat
* 14.用LLaVA解读数万神经元，大模型竟然自己打开了多模态智能黑盒  机器之心  https://mp.weixin.qq.com/s/r-MJLNXTDy4WyENl3JjCBw \
  以 GPT4V 为代表的多模态大模型（LMMs）在大语言模型（LLMs）上增加如同视觉的多感官技能，以实现更强的通用智能。虽然 LMMs 让人类更加接近创造智慧，但迄今为止，我们并不能理解自然与人工的多模态智能是如何产生的。\
  像 LLaVA 一样的开源模型是理解多模态智能的一个契机。但这些模型（在未来）可能比人类更加聪明，如何去理解他们的智力呢？来自南洋理工大学的 LMMs-Lab 团队给出的解决方案是：问问 LLaVA 自己是怎么说的。\
  LMMs-Lab 团队使用 LLaVA-OV-72B 对 LLaVA-NeXT-8B 中的神经元进行了自动解读，获得了非常多有趣的结果。\
  Large Multi-modal Models Can Interpret Features in Large Multi-modal Models
* 15.(**语言反馈强化学习，可以看看**)突破！自然语言强化学习(NLRL)：一个可处理语言反馈的强化学习框架  机器之心  https://mp.weixin.qq.com/s/GTkMZTeJBI6ouItMrAjJNw \
  Natural Language Reinforcement Learning 
* 16.(**务必看看**)LeCun团队新作：在世界模型中导航  机器之心  https://mp.weixin.qq.com/s/V5rXxbLYmR8UuiVq-gsi9A \
  Navigation World Models \
  https://www.amirbar.net/nwm/
* 17.新版Llama 3 70B反超405B！Meta开卷后训练，谷歌马斯克都来抢镜  量子位  https://mp.weixin.qq.com/s/6Iv4VzMlYrkmSsAo_IRGTg 
* 18.OpenAI直播第二弹！奥特曼2024年最大惊喜竟来自字节？**强化微调**让o1-mini逆袭o1  新智元 
 https://mp.weixin.qq.com/s/5nO_VZhDttM1Yi7KfFv4zw \
  不过要强调的是，并不是传统的微调，而是强化微调。它真正利用了强化学习算法，把模型从高级中学水平提升到专家博士级别
* 19.Bengio预言o1无法抵达AGI！Nature权威解读AI智能惊人进化，终极边界就在眼前  新智元  https://mp.weixin.qq.com/s/oLhC-OqYbnFV3Gu_4c2uwQ \
  How close is AI to human-level intelligence? \
  此前也有MIT的研究也表明了，大模型内部出现了基本的世界模型: LANGUAGE MODELS REPRESENT SPACE AND TIME
* 20.开源1.6B小模型「小狐狸」，表现超同类模型Qwen和Gemma  夕小瑶科技说  https://mp.weixin.qq.com/s/7xLr-z_KPpU0b7b4nd66oA \
  FOX-1 TECHNICAL REPORT

# 12.8 Sun
* 21.(**MLM综述**)迈向可解释和可理解的多模态大规模语言模型  专知  https://mp.weixin.qq.com/s/Xo1DK3OjeK0goR66VaorTg \
  Towards Explainable and Interpretable Multimodal Large Language Models:A Comprehensive Survey
* 22.《我的世界》搞数学研究，估算欧拉数误差仅0.00766%！数学博士的跨界花活儿火了  量子位  https://mp.weixin.qq.com/s/HBYdtqHHxEWb3EXKINiKhw \
  Approximating Mathematical Constantsusing Minecraft

# 12.9 Mon
* 23.
* 24.
* 25.

# 12.10 Tue

# 12.11 Wed
# 12.12 Thur
# 12.13 Fri
# 12.14 Sat
# 12.15 Sun
# 12.16 Mon
# 12.17 Tue
# 12.18 Wed
# 12.19 Thur
# 12.20 Fri

# 12.21 Sat
# 12.22 Sun
# 12.23 Mon
# 12.24 Tue
# 12.25 Wed
# 12.26 Thur
# 12.27 Fri
# 12.28 Sat
# 12.29 Sun
# 12.30 Mon

# 12.31 Tue
