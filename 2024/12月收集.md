# 12.1 Sun
* 1.微软发明全新「LLM语言」，AI智能体交互效率翻倍！  新智元  https://mp.weixin.qq.com/s/suIXm71AoVXgLWtFX3wJwA \
  来自微软、芝加哥大学的研究人员推出了「Droidspeak」，让AI智能体之间可以用自己的语言进行交流 \
  DroidSpeak: Enhancing cross-LLM communication \
  结果表明，在不损失性能的情况下，Droidspeak使模型的通信速度提高了2.78倍 \
  直接传递模型中间的计算结果（缓存），而不需要转换成人类能够理解的自然语言，这就是「Droidspeak」的含义

# 12.2 Mon
* 2.(**可以看看**)AI做数学学会「动脑子」！ UCL等发现LLM「程序性知识」，推理绝不是背答案  新智元  https://mp.weixin.qq.com/s/ShEThew_5sYksIPxbst3KA \
  PROCEDURAL KNOWLEDGE IN PRETRAINING DRIVES REASONING IN LARGE LANGUAGE MODELS \
  LLM在推理任务中进行泛化时，依赖的是文档中的「程序性知识」，使用可概括的策略，来综合推理任务的解决方案 \
  ???具体什么是程序性知识
* 3.清华UCSD提出全新微调方法，8B小模型媲美GPT-4o！科学问题正确率提高28% 
 新智元  https://mp.weixin.qq.com/s/B9aMDNTEbjP8UfoH8jmWsg \
  支来自UCSD和清华的研究团队提出了一种全新的微调方法，让模型「边适应边学习」，学会在使用外部科学工具和依赖内部知识之间做出合理选择 \
  Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation 
* 4.(**可以看看**)DeepMind用语言游戏让大模型学AlphaGo自我博弈，数据限制不存在了  机器之心  https://mp.weixin.qq.com/s/EC5QdHcasev8JpTp-OKLKQ \
  Boundless Socratic Learning with Language Games 

# 12.3 Tue
* 5.(**了解**)李飞飞空间智能首秀：AI靠单图生成3D世界，可探索，遵循基本物理几何规则  量子位  https://mp.weixin.qq.com/s/iU_XQdF-r8AnnXr2dwI89w \
  3个月估值10亿，李飞飞空间智能首个模型诞生！一张图生成3D世界，视频游戏要变天  新智元  https://mp.weixin.qq.com/s/CtmG0pck4fwtBWkypvt0sA \
  https://www.worldlabs.ai/blog \
  交互传送门：https://www.worldlabs.ai/blog#footnote1
* 6.全自动组装家具！ 斯坦福发布IKEA Video Manuals数据集：首次实现「组装指令」真实场景4D对齐  新智元  https://mp.weixin.qq.com/s/a1BX9oLNK9vlfc8dW_50mg \
  IKEA Manuals at Work: 4D Grounding of Assembly Instructions on Internet Videos \
  https://yunongliu1.github.io/ikea-video-manual/ \
  https://github.com/yunongLiu1/IKEA-Manuals-at-Work
* 7.扩散模型、最优传输存在什么关系？法国数学家4页论文引网友围观  机器之心  https://mp.weixin.qq.com/s/MN5MR0KsNGLYEYYfnf9hDA
  THE FLOW MAP OF THE FOKKER-PLANCK EQUATION DOES NOT PROVIDE OPTIMAL TRANSPORT 

# 12.4 Wed
* 8.Lilian Weng博客最新博客《强化学习Reward Hacking》  专知  https://mp.weixin.qq.com/s/QKJPdgajqz6i9dvP3Qxb1Q \
  离职OpenAI后Lilian Weng博客首发！深扒RL训练漏洞，业内狂赞  新智元  https://mp.weixin.qq.com/s/Hf5oKsU3BVd1fOcPhbsugA \
  Reward Hacking in Reinforcement Learning \
  https://lilianweng.github.io/posts/2024-11-28-reward-hacking/ \
  当强化学习（RL）智能体利用奖励函数中的缺陷或歧义来获得高额奖励，而没有真正学习或完成预期任务时，就会发生 Reward Hacking（Reward Hacking in Reinforcement Learning）。Hacking 之所以存在，是因为强化学习（RL）环境通常不完善，而且准确指定奖励函数从根本上具有挑战性

# 12.5 Thur
* 9.(**具有长期记忆能力的WM**)刚刚，DeepMind最强「基础世界模型」诞生！单图生1分钟游戏世界，解锁下一代智能体  新智元  https://mp.weixin.qq.com/s/lUf5_0vnka7OM4jfeAZkeg \
  Genie 2: A large-scale foundation worldmodel \
  https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/ \
  这就意味着，任何人都可以用文字描述自己想要的世界，选择自己喜欢的渲染效果，然后进入这个新创建的世界，并且与之互动（或者，也可以让AI智能体在其中被训练或评估）\
  Genie 2能够记住那些暂时离开画面的场景，并在它们重新进入视野时，精确地还原出来  !!! Genie 2 具有**长期记忆能力**
* 10.推动大模型自我进化，北理工推出「流星雨计划」  机器之心  https://mp.weixin.qq.com/s/_UqhgOpMH6cjYwrsPA0LPg \
  SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation \
  跟随上述自我进化的思想，在 SRA-MCTS（Self-guided MCTS-based data generation for Reasoning Augmentation）方法中，作者无需借助额外的任何监督信号、完全通过模型自身来进行推理路径生成，并进一步迭代大模型的能力。通过这个过程，模型能够自主地生成高质量的推理路径，并将这些路径转化为可执行代码，进而提升在复杂任务上的成功率 \
  代码开源：https://github.com/DIRECT-BIT/SRA-MCTS8B \
  模型的数据开源：https://huggingface.co/datasets/BinXD/SRA-MCTS-Llama-3.1-8B
* 11.清华团队提出HiAR-ICL：基于蒙特卡洛树搜索的全新上下文学习推理范式 
 PaperWeekly  https://mp.weixin.qq.com/s/LcEAbrxS9Rb8IMyyqrSYFA \
  HiAR-ICL: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS

# 12.6 Fri
* 12.Bengio、LeCun再喊话：AGI推理不需要先学语言，LLM路走窄了？  新智元  https://mp.weixin.qq.com/s/BawvPfL3l5GJZNHaPNeHoQ \
  AI can learn to think before it speaks \
  https://www.ft.com/content/894669d6-d69d-4515-a18f-569afbf710e8
* 13.(**可以看看**)NeurIPS 2024 | 哈工深提出新型智能体Optimus-1，横扫Minecraft长序列任务  机器之心  https://mp.weixin.qq.com/s/fqUYuajMH0wNva4HUux8Qw \
  Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks \
  https://cybertronagent.github.io/Optimus-1.github.io/ \
  https://github.com/JiuTian-VL/Optimus-1

# 12.7 Sat
* 14.用LLaVA解读数万神经元，大模型竟然自己打开了多模态智能黑盒  机器之心  https://mp.weixin.qq.com/s/r-MJLNXTDy4WyENl3JjCBw \
  以 GPT4V 为代表的多模态大模型（LMMs）在大语言模型（LLMs）上增加如同视觉的多感官技能，以实现更强的通用智能。虽然 LMMs 让人类更加接近创造智慧，但迄今为止，我们并不能理解自然与人工的多模态智能是如何产生的。\
  像 LLaVA 一样的开源模型是理解多模态智能的一个契机。但这些模型（在未来）可能比人类更加聪明，如何去理解他们的智力呢？来自南洋理工大学的 LMMs-Lab 团队给出的解决方案是：问问 LLaVA 自己是怎么说的。\
  LMMs-Lab 团队使用 LLaVA-OV-72B 对 LLaVA-NeXT-8B 中的神经元进行了自动解读，获得了非常多有趣的结果。\
  Large Multi-modal Models Can Interpret Features in Large Multi-modal Models
* 15.(**语言反馈强化学习，可以看看**)突破！自然语言强化学习(NLRL)：一个可处理语言反馈的强化学习框架  机器之心  https://mp.weixin.qq.com/s/GTkMZTeJBI6ouItMrAjJNw \
  Natural Language Reinforcement Learning 
* 16.(**务必看看**)LeCun团队新作：在世界模型中导航  机器之心  https://mp.weixin.qq.com/s/V5rXxbLYmR8UuiVq-gsi9A \
  Navigation World Models \
  https://www.amirbar.net/nwm/
* 17.新版Llama 3 70B反超405B！Meta开卷后训练，谷歌马斯克都来抢镜  量子位  https://mp.weixin.qq.com/s/6Iv4VzMlYrkmSsAo_IRGTg 
* 18.OpenAI直播第二弹！奥特曼2024年最大惊喜竟来自字节？**强化微调**让o1-mini逆袭o1  新智元 
 https://mp.weixin.qq.com/s/5nO_VZhDttM1Yi7KfFv4zw \
  不过要强调的是，并不是传统的微调，而是强化微调。它真正利用了强化学习算法，把模型从高级中学水平提升到专家博士级别
* 19.Bengio预言o1无法抵达AGI！Nature权威解读AI智能惊人进化，终极边界就在眼前  新智元  https://mp.weixin.qq.com/s/oLhC-OqYbnFV3Gu_4c2uwQ \
  How close is AI to human-level intelligence? \
  此前也有MIT的研究也表明了，大模型内部出现了基本的世界模型: LANGUAGE MODELS REPRESENT SPACE AND TIME
* 20.开源1.6B小模型「小狐狸」，表现超同类模型Qwen和Gemma  夕小瑶科技说  https://mp.weixin.qq.com/s/7xLr-z_KPpU0b7b4nd66oA \
  FOX-1 TECHNICAL REPORT

# 12.8 Sun
* 21.(**MLM综述**)迈向可解释和可理解的多模态大规模语言模型  专知  https://mp.weixin.qq.com/s/Xo1DK3OjeK0goR66VaorTg \
  Towards Explainable and Interpretable Multimodal Large Language Models:A Comprehensive Survey
* 22.《我的世界》搞数学研究，估算欧拉数误差仅0.00766%！数学博士的跨界花活儿火了  量子位  https://mp.weixin.qq.com/s/HBYdtqHHxEWb3EXKINiKhw \
  Approximating Mathematical Constantsusing Minecraft

# 12.9 Mon
* 23.LLM最大能力密度100天翻一倍！清华刘知远团队提出Densing Law  机器之心  https://mp.weixin.qq.com/s/O_jtO2ZuL11XB9GlaURsWg \
  来自清华大学刘知远教授团队发现并提出大模型的密度定律（Densing Law）—— 模型能力密度随时间呈指数级增长，2023 年以来能力密度约每 3.3 个月（约 100 天) 翻一倍。这意味着每 100 天，我们可以用一半参数量实现当前最优模型相当的性能 \
  Densing Law of LLMs
* 24.3D具身基础模型！北大提出Lift3D赋予2D大模型鲁棒的3D操纵能力  机器之心  https://mp.weixin.qq.com/s/R0Smibgy8NpVJTwj-RjF0A \
  Lift3D Foundation Policy: Lifting 2D Large-Scale Pretrained Models for Robust 3D Robotic Manipulation \
  https://lift3d-web.github.io/ \
  https://github.com/PKU-HMI-Lab/LIFT3D \
  Lift3D 的目标是掩码与任务相关的 Affordance token，并重建深度几何信息，从而增强 2D 基础模型的 3D 空间感知能力
* 25.(**值得看看**)博士论文 | UC Berkeley 2024 | 迈向能够学习和发现一切的机器 147页  图科学实验室Graph Science Lab  https://mp.weixin.qq.com/s/MZz_Xf0NlaKut6SGhq2JUQ \
  Towards A Machine Capable of Learning And Discovering Everything
* 26.18k个视频、专为自动驾驶世界模型设计，DrivingDojo数据集来了  机器之心  https://mp.weixin.qq.com/s/jXVeBRjKPsNtX7bBanW-QQ \
  DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model \
  https://github.com/Robertwyq/Drivingdojo
* 27.(**值得玩玩**)首个VR端3D角色扮演AI发布！南洋理工公开SOLAMI技术报告，端到端VLA模型驱动，唱跳都能陪你玩  新智元  https://mp.weixin.qq.com/s/pecfRQeyACY3zf6Kcb9tvA \
  SOLAMl:Social Vision-Language-Action Modeling for lmmersive Interaction with 3DAutonomous Characters \
  https://solami-ai.github.io/ 
* 28.生成式人工智能的扩散模型概述  专知  https://mp.weixin.qq.com/s/C55_5BLQDQflo7hW7ebdyQ \
  An overview of diffusion models for generative artifcial intelligence \
  https://github.com/deeplearningmethods/diffusion_model

# 12.10 Tue
* 29.(**值得了解**)NeurIPS 2024 | 智能体不够聪明怎么办？清华&蚂蚁团队：让它像学徒一样持续学习  机器之心  https://mp.weixin.qq.com/s/OE5YNcM53ZgipZx06Jno1w \
  AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback \
   AMOR（Adaptable MOdulaR knowledge agent），不仅能低成本地调用专业工具和知识库，更重要的是，它能像人类一样持续学习和成长

# 12.11 Wed
* 30.【新书】《强化学习概述》手册，144页pdf  专知  https://mp.weixin.qq.com/s/pnQ2Z8eZvKc3_DXcPa5fyQ
* 31.DeepMind悄悄发布PaliGemma二代，最易微调「视觉语言全能王」来了，多项任务登顶SOTA  新智元  https://mp.weixin.qq.com/s/XbFGYqIYCj0L6jTUxMCF9Q \
  PaliGemma 2:A Family of Versatile VLMs for Transfer

# 12.12 Thur
* 32.(**非常值得看看**)田渊栋团队论文火了！连续思维链优于CoT，打开LLM推理新范式 
  PaperWeekly  https://mp.weixin.qq.com/s/PzXNblw6I5R1uEywRPwCHw \
  随着 LLM 和 CoT 的兴起，语言已经成为机器推理的默认媒介 —— 但它真的是最佳方法吗？\
  一般而言，LLM 被限制在语言空间（language space）内进行推理，并通过思维链（CoT）来表达推理过程，从而解决复杂的推理问题。 \
  然而，语言空间可能并不总是最适合推理的。例如，很多单词 token 主要用于文本连贯性，而不是推理本身，而一些关键 token 则需要复杂的规划，这种差异给 LLM 带来巨大的挑战。 \
  为了探索 LLM 在不受限制潜在空间中的推理潜力，而非使用自然语言，来自 Meta、加州大学圣地亚哥分校的研究者提出了一种新的范式 ——Coconut（连续思维链，Chain of Continuous Thought），来探索 LLM 在潜在空间中的推理。\
  Training Large Language Models to Reason in a Continuous Latent Space \
  在 Coconut 方法中，LLM 在**语言模式**和**潜在模式**之间切换：在语言模式下，该模型作为标准语言模型运行，自回归生成下一个 token。在潜在模式下，它直接利用最后一个隐藏状态作为下一个输入嵌入。这个最后的隐藏状态代表当前的推理状态，称为连续思维。特殊 token < bot >、< eot > 分别用于标记潜在思维模式的开始和结束。
* 33.谷歌最强大模型Gemini 2.0被抬上来了，网友：好科幻  机器之心  https://mp.weixin.qq.com/s/_JIHTnZgwoFQT18mV9i9-Q \
  谷歌新旗舰模型鲨疯了，免费不限量，网友：我读论文能力提高10倍  量子位  https://mp.weixin.qq.com/s/uVjgCgqBqfSweZgs4rMfeg \
  谷歌“狙击”OpenAI，发布新一代大模型Gemini 2.0！主打Agent+多模态 
  PaperWeekly  https://mp.weixin.qq.com/s/0TzzqwnMC6xmA9V32uD2xA

# 12.13 Fri
* 34.LSTM之父：我也是注意力之父！1991年就发表线性复杂度，遥遥领先Transformer 26年  新智元  https://mp.weixin.qq.com/s/YkYjlynOZcITg18alhyuFg
* 35.ChatGPT「睁眼」了！OpenAI版「Her」满血上线，还有圣诞限定彩蛋  新智元  https://mp.weixin.qq.com/s/wozogt2vtXyWtN_2JtCRww 
* 36.多智能体架构Insight-V来了！突破长链视觉推理瓶颈  机器之心  https://mp.weixin.qq.com/s/-8TvvTDa7zeEUlzcbtuPWg \
  Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models
* 37.扩散模型=流匹配？谷歌DeepMind博客深度详解这种惊人的等价性  机器之心  https://mp.weixin.qq.com/s/BUaE2_VJwJi1VtNI3x-aIA \
  Diffusion Meets FlowMatching: Two Sides of theSame Coin \
  https://diffusionflow.github.io
* 38.李飞飞：World Labs这样实现「空间智能」  机器之心  https://mp.weixin.qq.com/s/3CoXlj8wJpNSaWWysn-_bA \
  World Labs
* 39. 如何做生成更好的视频图像？Meta&MIT最新《 流匹配（Flow Matching, FM） 》指南和代码  专知  https://mp.weixin.qq.com/s/Sx0_MlM7V872r8dyluUjSQ \
  Flow Matching Tutorial \
  流匹配（Flow Matching, FM）是一种新兴的生成建模框架，在图像、视频、音频、语音以及生物结构等多个领域中实现了最先进的性能 \
  https://github.com/facebookresearch/flow_matching \
  流匹配的原理是什么？

# 12.14 Sat
* 40.万字独家爆光，首揭o1 pro架构！惊人反转，Claude 3.5 Opus没失败？  新智元  https://mp.weixin.qq.com/s/LozJEE1sAAYAOrEFDVb6mg \
  外媒SemiAnalysis一篇深度报道再次指明了方向——Scale的维度远不止预训练，Scaling Law仍将继续下去 \
  Scaling Laws-O1 Pro Architecture, Reasoning Training Infrastructure, Orion and Claude 3.5 Opus "Failures" //AI Lab Synthetic Data Infrastructure, Inference Tokenomics of Test Time Compute, The Data Wall Evaluation's are Broken, RLAIF, Inference Time Search, Scale Needed More Than Ever

# 12.15 Sun
* 41.(**了解**)如何增强大模型推理？Meta最新提出《大型概念模型》在句子表示空间中的语言建模  专知  https://mp.weixin.qq.com/s/IevoeuTW6G_3zhGrXN3nug \
  Large Concept Models: Language Modelingin a Sentence Representation Space \
  本文提出了一种尝试，设计了一种在显式更高层次语义表示上操作的架构，我们将其命名为“概念”。概念是语言和模态无关的，表示流中的一个更高层次的思想或动作。因此，我们构建了一个“大型概念模型”（Large Concept Model）
* 42.Phi-4：微软最新的小型语言模型，专注于复杂推理  专知  https://mp.weixin.qq.com/s/OYRwj8WrTbU9G2ziDYAQrA 
* 43.(**了解**)模仿、探索与自我提升：慢思考推理系统的复现之路  专知  https://mp.weixin.qq.com/s/eo_7uunGZHlFMaUKgHoBlg \
  模仿、探索与自我提升：慢思考推理系统的复现之路  PaperWeekly  https://mp.weixin.qq.com/s/0DywDzPJugiOxEnbgzrwKg \
  Imitate, Explore, and Self-Improve: A Reproduction Report on Slow-thinking Reasoning Systems \
  https://github.com/RUCAIBox/Slow_Thinking_with_LLMs
* 44.Ilya NeurIPS 2024报告：预训练即将结束，接下来是超级智能  专知  https://mp.weixin.qq.com/s/LokJBQaewzkquDPb5XNMvA \
  超级智能是未来，还会与意识结合

# 12.16 Mon
* 45.(**非常深刻，值得看看**)量子计算大牛Scott Aaronson：我不理解为什么有人能自信看衰 AI  图灵人工智能  https://mp.weixin.qq.com/s/-JvtA-F1QvzKcc8pQuRS6Q 
* 46.生成式AI仍不可靠，“神经符号AI”是解决之道？  图灵人工智能  https://mp.weixin.qq.com/s/_IO1S3A6VvKHdSuYXjjRig
* 47.从长期记忆的角度谈Agent  关于NLP那些你不知道的事  https://mp.weixin.qq.com/s/d2EEtREDFTGQK-NHnLquGg
* 48.【CMU博士论文】通过课程学习实现鲁棒的强化学习  专知  https://mp.weixin.qq.com/s/t9j0-qdbCmM32VeDWkQrfA \
  Robust Reinforcement Learning via Curricular Learning \
  ???具体什么是课程学习
* 49.【新书】基于RAG的生成式AI：使用LlamaIndex、Deep Lake和Pinecone构建自定义的检索增强生成管道 
 专知  https://mp.weixin.qq.com/s/bLDlf_djd3gssLDAU601bA \
  最小化AI幻觉，构建准确的自定义生成式AI管道，利用嵌入式向量数据库和集成的人类反馈来实现检索增强生成（RAG）
* 50.世界模型进入4D时代！单视角视频构建的自由视角4D世界来了  机器之心  https://mp.weixin.qq.com/s/4TdSQefMdbSjojkUAuUi6g \
  ReconDreamer: Crafting World Models for Driving Scene Reconstruction via Online Restoration \
  https://github.com/GigaAI-research/ReconDreamer \
  https://recondreamer.github.io/

# 12.17 Tue
* 51.Tokenization不存在了？Meta最新研究，无需Tokenizer的架构来了  机器之心  https://mp.weixin.qq.com/s/7ju-PjPZVPrBLQ1qFnFoKw \
  Byte Latent Transformer: Patches Scale Better Than Tokens \
  Meta 刚刚杀死了 TOKENIZATION，他们发布的 BLT 是一种无 tokenizer 的架构，可以动态地将字节编码为 patch，并实现更好的推理效率和稳健性！
* 52.图像领域再次与LLM一拍即合！idea撞车OpenAI强化微调，西湖大学发布图像链CoT  新智元  https://mp.weixin.qq.com/s/k7rfJI8gzzgec_dXqTIVyg \
  MAPLE实验室提出通过强化学习优化图像生成模型的去噪过程，使其能以更少的步骤生成高质量图像，在多个图像生成模型上实现了减少推理步骤，还能提高图像质量 \
  Schedule On the Fly: Diffusion Time Prediction for Faster andBetter lmage Generation
* 53.(**HF官方开源的TTC值得研究**)开源Llama版o1来了，3B小模型反超80B，逆向工程复现OpenAI新Scaling Law  量子位  https://mp.weixin.qq.com/s/IVsbnZZTAsNXwRvr9lqZlg \
  Hugging Face官方发文，开源了扩展测试时计算(TTC)的方法。用在小小小模型Llama 1B上，数学分数直接超过8倍大的模型，也超过了计算机科学博士生的平均分数（40%） \
  https://github.com/huggingface/search-and-learn \
  https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute
* 54.谷歌版Sora来了，**4K**高清暴击OpenAI！视频生图新卷王，更理解物理世界  新智元  https://mp.weixin.qq.com/s/PFeyrX2q9mWd6GIrJ9qdWQ \
  全新发布的Veo 2，实测效果已经被许多人公认「超越Sora」
* 55.(**非常值得看看，Socratic Learning**)语言游戏让AI自我进化，谷歌DeepMind推出苏格拉底式学习  新智元  https://mp.weixin.qq.com/s/dnhNIsEho1APliYW5btTFQ \
  BOUNDLESS SOCRATIC LEARNING WITH LANGUAGE GAMES

# 12.18 Wed
* 56.李飞飞团队统一动作与语言，新的多模态模型不仅超懂指令，还能读懂隐含情  机器之心  https://mp.weixin.qq.com/s/W8wS87YlW_z9rsDfnmtDLQ \
  The Language of Motion: Unifying Verbal and Non-verbal Language of 3D Human Motion \
  https://languageofmotion.github.io/
* 57.Florence-VL来了！使用生成式视觉编码器，重新定义多模态大语言模型视觉信息  机器之心  https://mp.weixin.qq.com/s/sAf-FxUithvgA6noaew4sQ \
  Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion
* 58.沃顿商学院教授发文解析o1：能力仍有短板，「人机协同智能」或成AGI最重要难题  新智元  https://mp.weixin.qq.com/s/yenCtqeAWj5hqXOc47DylA 

# 12.19 Thur
* 59.(**非常值得研究Coconut**)全面超越CoT！Meta田渊栋团队新作：连续思维链  新智元  https://mp.weixin.qq.com/s/fQp3MV5TqPYuiicL5bTMHg \
  Training Large Language Models to Reason in a Continuous Latent Space \
  语言空间可能并不是推理的最佳选择，理想的LLM应该自由进行推理，不受任何语言限制 \
  Coconut不进行隐藏状态和语言之间的映射，这种修改将推理从语言空间内解放出来，并且系统可以通过梯度下降进行端到端优化，因为连续思维是完全可微分的
* 60.《多模态大语言模型时代的数学推理研究：基准、方法与挑战》  专知  https://mp.weixin.qq.com/s/3as-bgQpxD7u5YvonWh7Dg \
  A Survey of Mathematical Reasoning in the Era of Multimoda Large Language Model: Benchmark, Method & Challenges
* 61.(**记忆模型**)【剑桥大学博士论文】深度记忆模型与部分可观察下的高效强化学习  专知  https://mp.weixin.qq.com/s/4nSwOF076IH1Myt1s_fvNw \
  Deep Memory Models and Efficient Reinforcement Learning under Partial Observability \
  在许多现实任务中，感官信息往往是噪声或不完整的，这打破了强化学习的核心假设。解决这一挑战的方案实际上是众所周知的——即使用记忆。记忆是感官信息的存储与回忆，用于决策过程，这类似于人类和许多其他生物体内记忆的功能。记忆使得这些生物体能够建立并更新世界的内部表征，做出合理的猜测，并在不确定性面前取得成功。然而，尚不清楚的是，如何以可靠和可处理的方式建模记忆。本文的目标是让记忆建模变得稍微不那么难以处理，并稍微更具实用性。 \
  首先，我们提出了一种利用我们对任务已有的先验知识的记忆形式。通过使用这些知识，我们动态构建一个记忆图，与标准记忆模型相比，提高了数据和参数的效率。接着，我们讨论了对记忆模型的大规模研究。我们设计了一系列程序化生成的任务，然后在这些任务上实现并评估各种记忆模型。我们采取实践性的方法，确定哪些模型具有潜力，从而为未来的研究人员节省时间和计算资源。然后，我们探讨了计算心理学家所提出的人类记忆模型。基于这些原则，我们开发了一种记忆模型，达到了比标准模型更好的时间和空间效率。我们进一步展示了该方法优于以往的研究，同时还展现了有趣的理论特性。最后，我们发现了一个统一的理论框架，用于高效的记忆建模，涵盖了许多现有的记忆模型。通过这个框架，我们提出了一种新的训练记忆模型的方法，从而提高了时间、空间和数据的效率。
* 62.(**太厉害了，值得研究**)历时2年，华人团队力作，震撼开源生成式物理引擎Genesis，可模拟世界万物  机器之心  https://mp.weixin.qq.com/s/ioYK3YV07f9m0Iu-l6tLsg \
  Genesis，「创世纪」 \
  Genesis: A Generative and Universal Physics Engine for Robotics and Beyond \
  Zhou Xian 表示：「我们的目标是构建一个通用数据引擎，其能利用上层的生成式框架自动创建物理世界，以及各种模式的数据，包括环境、相机运动、机器人任务提议、奖励函数、机器人策略、角色运动、完全交互式 3D 场景、开放世界铰接资产等，从而自动生成用于机器人、物理 AI 和其他应用的数据。」\
  开源地址：https://github.com/Genesis-Embodied-AI/Genesis \
  项目页面：https://genesis-embodied-ai.github.io/ \
  文档地址：https://genesis-world.readthedocs.io/en/latest/
* 63.震惊！Claude伪对齐率竟能高达78％，Anthropic 137页长论文自揭短  机器之心  https://mp.weixin.qq.com/s/UpTjO8ATcYC6-PSnJkZMMg \
  大模型公司 Anthropic 的一篇 137 页长论文火了！该论文探讨了大语言模型中的「伪对齐」，通过一系列实验发现：Claude 在训练过程中经常假装有不同的观点，而实际上却保持了其原始偏好
* 64.CMU把具身智能的机器人给越狱了  机器之心  https://mp.weixin.qq.com/s/UDW38k9Z03-2dCO2oCfOgw \
  https://robopair.org/ \
  Jailbreaking LLM-Controlled Robots
* 65.【NeurIPS2024】在复杂视觉推理场景中学习迭代和并行推理  机器学习研究组订阅  https://mp.weixin.qq.com/s/n6DBtRwyjhpWiO6PbdD5WA \
  https://github.com/shantanuj/IPRM_Iterative_and_Parallel_Reasoning_Mechanism

# 12.20 Fri
* 66.Meta斯坦福全新多模态Apollo，60分钟视频轻松理解！7B性能超越30B  新智元  https://mp.weixin.qq.com/s/sXYmyp2BJKgspql34wtaPw \
  Apollo: An Exploration of Video Understanding in Large Multimodal Models
  https://apollo-lmms.github.io
* 67.出手即王炸？照片级真实度生成式世界模型，还获得皮克斯和Jeff Dean投资  机器之心  https://mp.weixin.qq.com/s/3whlcE6wMkJNBXWAg4PZ1w \
  一家名为 Odyssey 的创业公司也向世界介绍了他们的世界模型 Explorer \
  https://odyssey.systems/learning-from-our-world
* 68.推理最强也最快，谷歌发布Gemini 2.0 Flash Thinking，全面超越o1-preview  机器之心  https://mp.weixin.qq.com/s/NkTP17j6HYIz95sHxCameA 

# 12.21 Sat
* 69.NeurIPS 2024 | 基于信息论，决策模型有了全新预训练范式统一框架  PaperWeekly  https://mp.weixin.qq.com/s/ykCPrXJHOpZnQGOtiXoTnQ \
  Towards an Information Theoretic Framework of Context-Based Offline Meta-Reinforcement Learning \
  https://github.com/betray12138/UNICORN
* 70.人会逆向思维，LLM也可以？DeepMind研究表明还能提升推理能力  机器之心  https://mp.weixin.qq.com/s/Wdexvi1sqNHIyXfijPtr2w \
  Reverse Thinking Makes LLMs Stronger Reasoners \
  人能逆向思维，LLM 也可以吗？北卡罗来纳大学教堂山分校与谷歌最近的一项研究表明，LLM 确实可以，并且逆向思维还能帮助提升 LLM 的正向推理能力！
* 71.统一视觉理解与生成，MetaMorph模型问世，LeCun、谢赛宁、刘壮等参与  机器之心  https://mp.weixin.qq.com/s/Q0obsptFhlZ-R9xH3LCGVw \
  MetaMorph: Multimodal Understanding and Generation via Instruction Tuning \
  https://tsb0601.github.io/metamorph/ \
  在本文中，研究者提出了**视觉预测指令调整**（Visual-Predictive Instruction Tuning，VPiT），它是视觉指令调整的简单扩展，建立在将连续视觉 token 作为输入传递给 LLM 的现有范式之上。VPiT 训练 LLM 以在微调阶段输出连续视觉 token 和离散文本 token。该模型以预训练的视觉编码器嵌入以及文本 token 作为输入，并输出文本 token 和连续视觉 token 的组合
* 72.多模态可解释人工智能综述：过去、现在与未来  专知  https://mp.weixin.qq.com/s/hHQzC1BbrslCz89mKJ4pIw \
  A Review of Multimodal Explainable Artifcial Intelligence: Past, Present and Future

# 12.22 Sun
* 73.正式出版! 新书《多智能体强化学习：基础与现代方法》完整版，爱丁堡Stefano博士编著，395页pdf，附Slides  专知  https://mp.weixin.qq.com/s/7VUEJRQz_usSaGOqJVp7nA 
* 74.o3压轴登场，下一步是领域泛化！ 北交大桑基韬团队发布首个强化微调的技术报告并开源代码：仅用100个样本，领域推理能力提升11%  专知  https://mp.weixin.qq.com/s/BCsc7bw8jj9626OvjzT6hA \
  https://github.com/ADaM-BJTU/OpenRFT
* 75.微软Phi-4封神，14B小模型数学击败GPT-4o！合成数据占比40%，36页技术报告出炉  新智元  https://mp.weixin.qq.com/s/Z1yBY0ZBaqmHllf-fFfEJw \
  Phi-4 Technical Report \
  合成数据构成了Phi-4训练数据的大部分，其通过多种技术生成，包括多智能体提示（multi-agent prompting）、自修订工作流（self-revision workflows）和指令反转（instruction reversal）
* 76.Claude 官方发布《Agent 构建指南》，附 PDF 下载  夕小瑶科技说  https://mp.weixin.qq.com/s/hqNcLv3pKgZdqpGxAPlt2A \
  Anthropic 提出目前市面上已经有很多方法可以实现这些增强功能，但是他们最推荐的还是自家的上下文协议（Model Context Protocol，MCP），该协议允许开发者通过简单的客户端实现与不断增长的第三方工具生态系统集成。\
  Model Context Protocol 介绍：https://www.anthropic.com/news/model-context-protocol

# 12.23 Mon
* 77.李飞飞、谢赛宁等探索MLLM「视觉空间智能」，网友：2025有盼头了  机器之心  https://mp.weixin.qq.com/s/Z4Kv92fukfNTyE1tSpJslA \
  李飞飞谢赛宁：多模态LLM「空间大脑」觉醒，惊现世界模型雏形！  新智元  https://mp.weixin.qq.com/s/HAVxsFmbymgORPBzwpa4RQ \
  Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces \
  https://vision-x-nyu.github.io/thinking-in-space.github.io/ \
  本文还有一些其他发现。\
  发现 1：空间推理是影响 MLLM 在 VSI-Bench 上的主要瓶颈。\
  发现 2：语言提示技术虽然在语言推理和一般视觉任务中有效，但对空间推理有害。\
  发现 3：在记忆空间时，MLLM 会根据给定的视频在模型中形成一系列局部世界模型，而不是统一的全局模型。\
  团队通过提示模型在笛卡尔网格上「可视化」其记忆，来探测它的能力，其中每个被占据的单元格代表一个物体的中心。研究结果表明，在处理空间信息时，MLLM并不是构建一个连贯的全局模型，而是从给定的视频中生成一系列局部化的世界模型。但问题涉及相距较远的对象时，模型的性能会迅速下降，此时这种限制尤为明显。这些观察表明，该领域未来研究的一个关键方向，就是开发更有效的空间记忆机制。\
  MetaMorph: Multimodal Understanding and Generation via Instruction Tuning \
  一种全新的多模态理解与生成模型——MetaMorph
* 78.o3并非独门秘技，谷歌已发背后关键机制，方法更简单、成本更低  量子位  https://mp.weixin.qq.com/s/qdxC_QyJW17gyRfN66D59A \
  来自斯坦福、牛津以及谷歌DeepMind的团队提出通过重复采样来扩展推理计算量——结果在编码任务中将性能最多提高40%。他们发现小模型通过生成多种答案/样本，其任务表现可能比一些大型模型单次尝试还要好。比如，DeepSeek-Coder通过重复采集5个样本，性能优于GPT-4o，而成本却仅为后者的三分之一 \
  Large Language Monkeys: Scaling Inference Compute with Repeated Sampling
* 79.LeCun八年前神预言，大模型路线再颠覆？OpenAI宣告：强化学习取得稳定性突破  新智元  https://mp.weixin.qq.com/s/Twljg_p6utB3cxyGuBiWUg \
  在OpenAI的第二天直播中，宣布即将开放「强化微调」（RFT）的API，开发者只需提供最低「几十个」高质量样本，就能实现领域专家模型的定制，还能根据提供的参考答案对模型的回复进行评分，再次印证了强化学习的重要性！\
  强化微调的重点是「匹配答案」（matching answer），给定查询和正确答案，RFT可以帮助模型「学习」如何获得正确答案 
* 80.主动推理系统中的控制流  CreateAMind  https://mp.weixin.qq.com/s/GeyDMKdHYdgBbgTcrFmSfQ \
  Control flow in active inference systems \
  ???具体什么是控制流???

# 12.24 Tue
* 81.o3曝智商高达157，比肩爱因斯坦碾压99%人类！陶哲轩水平AI或出现  新智元  https://mp.weixin.qq.com/s/fpZeYZ7u6H46brEt7jle0w 
* 82.Meta、斯坦福等：AI的下一个前沿，正是陶哲轩说的形式化数学推理  机器之心  https://mp.weixin.qq.com/s/M0bun7pMXtnDgWcr_u_Bxw \
  Formal Mathematical Reasoning: A New Frontier in AI
* 83.LeCun最新访谈：距离AGI可能不到10年，下一代AI需要情感和视觉训练  量子位  https://mp.weixin.qq.com/s/OV2wm_dUpafnF1GxjgH2bg 
* 84.时隔6年BERT升级！仅编码器架构没被杀死，更快更准确更长上下文  量子位  https://mp.weixin.qq.com/s/MRQO9s5V2CzLLlYFl9Kn_w \
  Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Effcient, and Long Context Finetuning and Inference

# 12.25 Wed
* 85.通往人工超智能的道路：超级对齐的全面综述  专知  https://mp.weixin.qq.com/s/ofxRPRiauEWaraPbgaZ4Ng \
  The Road to Artificial SuperIntelligence: A Comprehensive Survey of Superalignment 
* 86.(**有趣**)首次！大模型自动搜索人工生命，做出AI科学家的Sakana AI又放大招  机器之心  https://mp.weixin.qq.com/s/CVADIa03U2EqpirGbzklrQ \
  MIT、OpenAI等震撼力作：AI首次自主发现人工生命！人类窥见上帝造物  新智元  https://mp.weixin.qq.com/s/ERlCvGuqkYlSQuYB3Yx32g \
  Automating the Search for Artificial Life with Foundation Models
* 87.模拟生命体，智源线虫登上Nature子刊封面，探索AGI的第三条路径  机器之心  https://mp.weixin.qq.com/s/dVZokaecmoYglg1paoejWA \
  BAAIWorm 天宝

# 12.26 Thur
* 88.(**值得看看**)神经网络的物理根源：从自旋玻璃到能量景观｜2024年诺贝尔奖  集智俱乐部  https://mp.weixin.qq.com/s/SuTkV2lOj0EBwYr-AnCJ4w 
* 89.阿里开源首个视觉推理模型，击败GPT-4o，网页一度404  量子位  https://mp.weixin.qq.com/s/dsm1wmUqHaUVCbUteUb-mg \
  “眼睛”模型QVQ \
  https://qwenlm.github.io/blog/qvq-72b-preview/
* 90.15大机构十年研究证明：无约束AI必然超越人类，创造能力也更强！  机器学习研究组订阅  https://mp.weixin.qq.com/s/rkpjtc3Zq6LVu11HJSqPpA 
* 91.机械系统也能自主学习！密歇根大学团队构建了全新数学框架，登上Nature Communications  机器学习研究组订阅  https://mp.weixin.qq.com/s/gPFm6GUrUcfn3agJBXKsmw \
  Training all-mechanical neural networks for task learning through in situ backpropagation

# 12.27 Fri
* 92.DeepMind最新研究：逆向思维训练LLM可大幅提升AI推理能力  夕小瑶科技说  https://mp.weixin.qq.com/s/xERMU0rR4IvSUerO9oAjkw \
  Reverse Thinking Makes LLMs Stronger Reasoners
* 93.首篇「角色扮演AI」综述！复旦等提出大模型三层人格分类框架：群体、角色、个性化 | TMLR  新智元  https://mp.weixin.qq.com/s/NIyDMUuMxVmdr6mT5MGfZw \
  From Persona to Personalization: A Survey on Role-Playing Language Agents
* 94.OpenAI科学家：现有模型+后训练足以产生黎曼猜想的新证明  量子位  https://mp.weixin.qq.com/s/UqQiuuRrojDcaKphKIOAIQ \
  Sparks of Artifcial General Intelligence: Early experiments with GPT-4

# 12.28 Sat

# 12.29 Sun
* 95.可解释人工智能综合指南：从经典模型到大规模语言模型  专知  https://mp.weixin.qq.com/s/cG7BpQTj1OxYBd3nIcItOQ \
  A Comprehensive Guide to Explainable Al: From Classical Models to LLMs
* 96.【伯克利博士论文】在大规模语言模型时代构建自主系统  专知  https://mp.weixin.qq.com/s/ub1MfHMMLZ9A9cutquFcNg \
  Building Agentic Systems in an Era of Large Language Models \
  MemGPT，一个受操作系统启发的框架，使得LLMs能够管理自己的记忆和状态，引入了虚拟上下文管理和自我导向的记忆操作等概念。MemGPT证明了，通过将LLMs视为一种新的计算基本单元——类似于CPU在传统操作系统中的角色——我们能够构建更可靠、更强大的自主智能体
* 97.【AAAI2025】通过多模态思维链得分协作增强多机器人语义导航  专知  https://mp.weixin.qq.com/s/r1upETi1HZgWVZJwoPWrGA \
  Enhancing Multi-Robot Semantic Navigation Through Multimodal Chain-of-Thought Score Collaboration
* 98.(**牛逼，值得看看**)算力直降97%，GPT-3存储只用20MB？！这篇直接在1.58-bit下训练模型的新论文火了  量子位  https://mp.weixin.qq.com/s/G-fpwlK8Z4t9I27yu25MaA \
  提出了一项名为“noise_step”的新技术，允许模型直接在1.58-bit低精度下训练，且无需反向传播或动量（Momentum）加速，从而降低算力和存储消耗 \
  The Era of 1-bit LLMs:All Large Language Models are in 1.58 Bits \
  论文：https://github.com/wbrickner/noise_step?tab=readme-ov-file \
  CPU实现过程：https://colab.research.google.com/drive/1hXzf5xB4INzMUNTlAB8CI1V10-JV7zyg?usp=sharing \
* 99.注意对局部V1视觉脑区的影响解释了选择性V1-V4通信 2023  CreateAMind  https://mp.weixin.qq.com/s/9mCpGuloeJ3ziEhJWbvnJA \
  Attentional effects on local V1 microcircuits explain selective V1-V4 communication

# 12.30 Mon
* 100.

# 12.31 Tue
