# 12.1 Sun
* 1.微软发明全新「LLM语言」，AI智能体交互效率翻倍！  新智元  https://mp.weixin.qq.com/s/suIXm71AoVXgLWtFX3wJwA \
  来自微软、芝加哥大学的研究人员推出了「Droidspeak」，让AI智能体之间可以用自己的语言进行交流 \
  DroidSpeak: Enhancing cross-LLM communication \
  结果表明，在不损失性能的情况下，Droidspeak使模型的通信速度提高了2.78倍 \
  直接传递模型中间的计算结果（缓存），而不需要转换成人类能够理解的自然语言，这就是「Droidspeak」的含义

# 12.2 Mon
* 2.(**可以看看**)AI做数学学会「动脑子」！ UCL等发现LLM「程序性知识」，推理绝不是背答案  新智元  https://mp.weixin.qq.com/s/ShEThew_5sYksIPxbst3KA \
  PROCEDURAL KNOWLEDGE IN PRETRAINING DRIVES REASONING IN LARGE LANGUAGE MODELS \
  LLM在推理任务中进行泛化时，依赖的是文档中的「程序性知识」，使用可概括的策略，来综合推理任务的解决方案 \
  ???具体什么是程序性知识
* 3.清华UCSD提出全新微调方法，8B小模型媲美GPT-4o！科学问题正确率提高28% 
 新智元  https://mp.weixin.qq.com/s/B9aMDNTEbjP8UfoH8jmWsg \
  支来自UCSD和清华的研究团队提出了一种全新的微调方法，让模型「边适应边学习」，学会在使用外部科学工具和依赖内部知识之间做出合理选择 \
  Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation 
* 4.(**可以看看**)DeepMind用语言游戏让大模型学AlphaGo自我博弈，数据限制不存在了  机器之心  https://mp.weixin.qq.com/s/EC5QdHcasev8JpTp-OKLKQ \
  Boundless Socratic Learning with Language Games 

# 12.3 Tue
* 5.(**了解**)李飞飞空间智能首秀：AI靠单图生成3D世界，可探索，遵循基本物理几何规则  量子位  https://mp.weixin.qq.com/s/iU_XQdF-r8AnnXr2dwI89w \
  3个月估值10亿，李飞飞空间智能首个模型诞生！一张图生成3D世界，视频游戏要变天  新智元  https://mp.weixin.qq.com/s/CtmG0pck4fwtBWkypvt0sA \
  https://www.worldlabs.ai/blog \
  交互传送门：https://www.worldlabs.ai/blog#footnote1
* 6.全自动组装家具！ 斯坦福发布IKEA Video Manuals数据集：首次实现「组装指令」真实场景4D对齐  新智元  https://mp.weixin.qq.com/s/a1BX9oLNK9vlfc8dW_50mg \
  IKEA Manuals at Work: 4D Grounding of Assembly Instructions on Internet Videos \
  https://yunongliu1.github.io/ikea-video-manual/ \
  https://github.com/yunongLiu1/IKEA-Manuals-at-Work
* 7.扩散模型、最优传输存在什么关系？法国数学家4页论文引网友围观  机器之心  https://mp.weixin.qq.com/s/MN5MR0KsNGLYEYYfnf9hDA
  THE FLOW MAP OF THE FOKKER-PLANCK EQUATION DOES NOT PROVIDE OPTIMAL TRANSPORT 

# 12.4 Wed
* 8.Lilian Weng博客最新博客《强化学习Reward Hacking》  专知  https://mp.weixin.qq.com/s/QKJPdgajqz6i9dvP3Qxb1Q \
  离职OpenAI后Lilian Weng博客首发！深扒RL训练漏洞，业内狂赞  新智元  https://mp.weixin.qq.com/s/Hf5oKsU3BVd1fOcPhbsugA \
  Reward Hacking in Reinforcement Learning \
  https://lilianweng.github.io/posts/2024-11-28-reward-hacking/ \
  当强化学习（RL）智能体利用奖励函数中的缺陷或歧义来获得高额奖励，而没有真正学习或完成预期任务时，就会发生 Reward Hacking（Reward Hacking in Reinforcement Learning）。Hacking 之所以存在，是因为强化学习（RL）环境通常不完善，而且准确指定奖励函数从根本上具有挑战性

# 12.5 Thur
* 9.(**具有长期记忆能力的WM**)刚刚，DeepMind最强「基础世界模型」诞生！单图生1分钟游戏世界，解锁下一代智能体  新智元  https://mp.weixin.qq.com/s/lUf5_0vnka7OM4jfeAZkeg \
  Genie 2: A large-scale foundation worldmodel \
  https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/ \
  这就意味着，任何人都可以用文字描述自己想要的世界，选择自己喜欢的渲染效果，然后进入这个新创建的世界，并且与之互动（或者，也可以让AI智能体在其中被训练或评估）\
  Genie 2能够记住那些暂时离开画面的场景，并在它们重新进入视野时，精确地还原出来  !!! Genie 2 具有**长期记忆能力**
* 10.推动大模型自我进化，北理工推出「流星雨计划」  机器之心  https://mp.weixin.qq.com/s/_UqhgOpMH6cjYwrsPA0LPg \
  SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation \
  跟随上述自我进化的思想，在 SRA-MCTS（Self-guided MCTS-based data generation for Reasoning Augmentation）方法中，作者无需借助额外的任何监督信号、完全通过模型自身来进行推理路径生成，并进一步迭代大模型的能力。通过这个过程，模型能够自主地生成高质量的推理路径，并将这些路径转化为可执行代码，进而提升在复杂任务上的成功率 \
  代码开源：https://github.com/DIRECT-BIT/SRA-MCTS8B \
  模型的数据开源：https://huggingface.co/datasets/BinXD/SRA-MCTS-Llama-3.1-8B
* 11.清华团队提出HiAR-ICL：基于蒙特卡洛树搜索的全新上下文学习推理范式 
 PaperWeekly  https://mp.weixin.qq.com/s/LcEAbrxS9Rb8IMyyqrSYFA \
  HiAR-ICL: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS

# 12.6 Fri
* 12.Bengio、LeCun再喊话：AGI推理不需要先学语言，LLM路走窄了？  新智元  https://mp.weixin.qq.com/s/BawvPfL3l5GJZNHaPNeHoQ \
  AI can learn to think before it speaks \
  https://www.ft.com/content/894669d6-d69d-4515-a18f-569afbf710e8
* 13.(**可以看看**)NeurIPS 2024 | 哈工深提出新型智能体Optimus-1，横扫Minecraft长序列任务  机器之心  https://mp.weixin.qq.com/s/fqUYuajMH0wNva4HUux8Qw \
  Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks \
  https://cybertronagent.github.io/Optimus-1.github.io/ \
  https://github.com/JiuTian-VL/Optimus-1

# 12.7 Sat
* 14.用LLaVA解读数万神经元，大模型竟然自己打开了多模态智能黑盒  机器之心  https://mp.weixin.qq.com/s/r-MJLNXTDy4WyENl3JjCBw \
  以 GPT4V 为代表的多模态大模型（LMMs）在大语言模型（LLMs）上增加如同视觉的多感官技能，以实现更强的通用智能。虽然 LMMs 让人类更加接近创造智慧，但迄今为止，我们并不能理解自然与人工的多模态智能是如何产生的。\
  像 LLaVA 一样的开源模型是理解多模态智能的一个契机。但这些模型（在未来）可能比人类更加聪明，如何去理解他们的智力呢？来自南洋理工大学的 LMMs-Lab 团队给出的解决方案是：问问 LLaVA 自己是怎么说的。\
  LMMs-Lab 团队使用 LLaVA-OV-72B 对 LLaVA-NeXT-8B 中的神经元进行了自动解读，获得了非常多有趣的结果。\
  Large Multi-modal Models Can Interpret Features in Large Multi-modal Models
* 15.(**语言反馈强化学习，可以看看**)突破！自然语言强化学习(NLRL)：一个可处理语言反馈的强化学习框架  机器之心  https://mp.weixin.qq.com/s/GTkMZTeJBI6ouItMrAjJNw \
  Natural Language Reinforcement Learning 
* 16.(**务必看看**)LeCun团队新作：在世界模型中导航  机器之心  https://mp.weixin.qq.com/s/V5rXxbLYmR8UuiVq-gsi9A \
  Navigation World Models \
  https://www.amirbar.net/nwm/
* 17.新版Llama 3 70B反超405B！Meta开卷后训练，谷歌马斯克都来抢镜  量子位  https://mp.weixin.qq.com/s/6Iv4VzMlYrkmSsAo_IRGTg 
* 18.OpenAI直播第二弹！奥特曼2024年最大惊喜竟来自字节？**强化微调**让o1-mini逆袭o1  新智元 
 https://mp.weixin.qq.com/s/5nO_VZhDttM1Yi7KfFv4zw \
  不过要强调的是，并不是传统的微调，而是强化微调。它真正利用了强化学习算法，把模型从高级中学水平提升到专家博士级别
* 19.Bengio预言o1无法抵达AGI！Nature权威解读AI智能惊人进化，终极边界就在眼前  新智元  https://mp.weixin.qq.com/s/oLhC-OqYbnFV3Gu_4c2uwQ \
  How close is AI to human-level intelligence? \
  此前也有MIT的研究也表明了，大模型内部出现了基本的世界模型: LANGUAGE MODELS REPRESENT SPACE AND TIME
* 20.开源1.6B小模型「小狐狸」，表现超同类模型Qwen和Gemma  夕小瑶科技说  https://mp.weixin.qq.com/s/7xLr-z_KPpU0b7b4nd66oA \
  FOX-1 TECHNICAL REPORT

# 12.8 Sun
* 21.(**MLM综述**)迈向可解释和可理解的多模态大规模语言模型  专知  https://mp.weixin.qq.com/s/Xo1DK3OjeK0goR66VaorTg \
  Towards Explainable and Interpretable Multimodal Large Language Models:A Comprehensive Survey
* 22.《我的世界》搞数学研究，估算欧拉数误差仅0.00766%！数学博士的跨界花活儿火了  量子位  https://mp.weixin.qq.com/s/HBYdtqHHxEWb3EXKINiKhw \
  Approximating Mathematical Constantsusing Minecraft

# 12.9 Mon
* 23.LLM最大能力密度100天翻一倍！清华刘知远团队提出Densing Law  机器之心  https://mp.weixin.qq.com/s/O_jtO2ZuL11XB9GlaURsWg \
  来自清华大学刘知远教授团队发现并提出大模型的密度定律（Densing Law）—— 模型能力密度随时间呈指数级增长，2023 年以来能力密度约每 3.3 个月（约 100 天) 翻一倍。这意味着每 100 天，我们可以用一半参数量实现当前最优模型相当的性能 \
  Densing Law of LLMs
* 24.3D具身基础模型！北大提出Lift3D赋予2D大模型鲁棒的3D操纵能力  机器之心  https://mp.weixin.qq.com/s/R0Smibgy8NpVJTwj-RjF0A \
  Lift3D Foundation Policy: Lifting 2D Large-Scale Pretrained Models for Robust 3D Robotic Manipulation \
  https://lift3d-web.github.io/ \
  https://github.com/PKU-HMI-Lab/LIFT3D \
  Lift3D 的目标是掩码与任务相关的 Affordance token，并重建深度几何信息，从而增强 2D 基础模型的 3D 空间感知能力
* 25.(**值得看看**)博士论文 | UC Berkeley 2024 | 迈向能够学习和发现一切的机器 147页  图科学实验室Graph Science Lab  https://mp.weixin.qq.com/s/MZz_Xf0NlaKut6SGhq2JUQ \
  Towards A Machine Capable of Learning And Discovering Everything
* 26.18k个视频、专为自动驾驶世界模型设计，DrivingDojo数据集来了  机器之心  https://mp.weixin.qq.com/s/jXVeBRjKPsNtX7bBanW-QQ \
  DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model \
  https://github.com/Robertwyq/Drivingdojo
* 27.(**值得玩玩**)首个VR端3D角色扮演AI发布！南洋理工公开SOLAMI技术报告，端到端VLA模型驱动，唱跳都能陪你玩  新智元  https://mp.weixin.qq.com/s/pecfRQeyACY3zf6Kcb9tvA \
  SOLAMl:Social Vision-Language-Action Modeling for lmmersive Interaction with 3DAutonomous Characters \
  https://solami-ai.github.io/ 
* 28.生成式人工智能的扩散模型概述  专知  https://mp.weixin.qq.com/s/C55_5BLQDQflo7hW7ebdyQ \
  An overview of diffusion models for generative artifcial intelligence \
  https://github.com/deeplearningmethods/diffusion_model

# 12.10 Tue
* 29.(**值得了解**)NeurIPS 2024 | 智能体不够聪明怎么办？清华&蚂蚁团队：让它像学徒一样持续学习  机器之心  https://mp.weixin.qq.com/s/OE5YNcM53ZgipZx06Jno1w \
  AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback \
   AMOR（Adaptable MOdulaR knowledge agent），不仅能低成本地调用专业工具和知识库，更重要的是，它能像人类一样持续学习和成长

# 12.11 Wed
* 30.【新书】《强化学习概述》手册，144页pdf  专知  https://mp.weixin.qq.com/s/pnQ2Z8eZvKc3_DXcPa5fyQ
* 31.DeepMind悄悄发布PaliGemma二代，最易微调「视觉语言全能王」来了，多项任务登顶SOTA  新智元  https://mp.weixin.qq.com/s/XbFGYqIYCj0L6jTUxMCF9Q \
  PaliGemma 2:A Family of Versatile VLMs for Transfer

# 12.12 Thur
* 32.(**非常值得看看**)田渊栋团队论文火了！连续思维链优于CoT，打开LLM推理新范式 
  PaperWeekly  https://mp.weixin.qq.com/s/PzXNblw6I5R1uEywRPwCHw \
  随着 LLM 和 CoT 的兴起，语言已经成为机器推理的默认媒介 —— 但它真的是最佳方法吗？\
  一般而言，LLM 被限制在语言空间（language space）内进行推理，并通过思维链（CoT）来表达推理过程，从而解决复杂的推理问题。 \
  然而，语言空间可能并不总是最适合推理的。例如，很多单词 token 主要用于文本连贯性，而不是推理本身，而一些关键 token 则需要复杂的规划，这种差异给 LLM 带来巨大的挑战。 \
  为了探索 LLM 在不受限制潜在空间中的推理潜力，而非使用自然语言，来自 Meta、加州大学圣地亚哥分校的研究者提出了一种新的范式 ——Coconut（连续思维链，Chain of Continuous Thought），来探索 LLM 在潜在空间中的推理。\
  Training Large Language Models to Reason in a Continuous Latent Space \
  在 Coconut 方法中，LLM 在**语言模式**和**潜在模式**之间切换：在语言模式下，该模型作为标准语言模型运行，自回归生成下一个 token。在潜在模式下，它直接利用最后一个隐藏状态作为下一个输入嵌入。这个最后的隐藏状态代表当前的推理状态，称为连续思维。特殊 token < bot >、< eot > 分别用于标记潜在思维模式的开始和结束。
* 33.谷歌最强大模型Gemini 2.0被抬上来了，网友：好科幻  机器之心  https://mp.weixin.qq.com/s/_JIHTnZgwoFQT18mV9i9-Q \
  谷歌新旗舰模型鲨疯了，免费不限量，网友：我读论文能力提高10倍  量子位  https://mp.weixin.qq.com/s/uVjgCgqBqfSweZgs4rMfeg \
  谷歌“狙击”OpenAI，发布新一代大模型Gemini 2.0！主打Agent+多模态 
  PaperWeekly  https://mp.weixin.qq.com/s/0TzzqwnMC6xmA9V32uD2xA

# 12.13 Fri
* 34.LSTM之父：我也是注意力之父！1991年就发表线性复杂度，遥遥领先Transformer 26年  新智元  https://mp.weixin.qq.com/s/YkYjlynOZcITg18alhyuFg
* 35.ChatGPT「睁眼」了！OpenAI版「Her」满血上线，还有圣诞限定彩蛋  新智元  https://mp.weixin.qq.com/s/wozogt2vtXyWtN_2JtCRww 
* 36.多智能体架构Insight-V来了！突破长链视觉推理瓶颈  机器之心  https://mp.weixin.qq.com/s/-8TvvTDa7zeEUlzcbtuPWg \
  Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models
* 37.扩散模型=流匹配？谷歌DeepMind博客深度详解这种惊人的等价性  机器之心  https://mp.weixin.qq.com/s/BUaE2_VJwJi1VtNI3x-aIA \
  Diffusion Meets FlowMatching: Two Sides of theSame Coin \
  https://diffusionflow.github.io
* 38.李飞飞：World Labs这样实现「空间智能」  机器之心  https://mp.weixin.qq.com/s/3CoXlj8wJpNSaWWysn-_bA \
  World Labs
* 39. 如何做生成更好的视频图像？Meta&MIT最新《 流匹配（Flow Matching, FM） 》指南和代码  专知  https://mp.weixin.qq.com/s/Sx0_MlM7V872r8dyluUjSQ \
  Flow Matching Tutorial \
  流匹配（Flow Matching, FM）是一种新兴的生成建模框架，在图像、视频、音频、语音以及生物结构等多个领域中实现了最先进的性能 \
  https://github.com/facebookresearch/flow_matching \
  流匹配的原理是什么？

# 12.14 Sat
* 40.万字独家爆光，首揭o1 pro架构！惊人反转，Claude 3.5 Opus没失败？  新智元  https://mp.weixin.qq.com/s/LozJEE1sAAYAOrEFDVb6mg \
  外媒SemiAnalysis一篇深度报道再次指明了方向——Scale的维度远不止预训练，Scaling Law仍将继续下去 \
  Scaling Laws - O1 Pro Architecture, Reasoning Training Infrastructure, Orion and Claude 3.5 Opus "Failures"
* 41.

# 12.15 Sun
# 12.16 Mon
# 12.17 Tue
# 12.18 Wed
# 12.19 Thur
# 12.20 Fri

# 12.21 Sat
# 12.22 Sun
# 12.23 Mon
# 12.24 Tue
# 12.25 Wed
# 12.26 Thur
# 12.27 Fri
# 12.28 Sat
# 12.29 Sun
# 12.30 Mon

# 12.31 Tue
