# 10.1 Tue
* 1.(**LNN液体神经网络**)给机器人装上「虫脑」？非Transformer液态神经网络终于来了！MIT CSAIL负责人创业成果  机器之心  https://mp.weixin.qq.com/s/oowid3yCpFNTALCvgdSwXg \
  MIT系初创打破Transformer霸权！液体基础模型刷新SOTA，非GPT架构首次显著超越Transformer  机器学习研究组订阅  https://mp.weixin.qq.com/s/Jcyymw4k9YgRkia8mR7zaA \
  Liquid AI 表示他们的目标是「探索构建超越生成式预训练 Transformer (GPT) 基础模型的方法」\
  为了实现这一目标，Liquid AI 推出了其首批多模态 AI 模型：Liquid Foundation Models（LFM）。这是基于第一原理构建的新一代生成式 AI 模型，其 1B、3B 和 40B LFM 在各个规模上均能实现 SOTA 性能，同时保持更小的内存占用和更高效的推理。\
  Liquid 使用了一种混合的计算单元，这些计算单元深深植根于动态系统理论、信号处理和数值线性代数的理论中。结果就是开发出了通用的人工智能模型，这些模型能够用来模拟任何类型的序列数据，包括视频、音频、文本、时间序列和信号，以此来训练其新的 LFM \
  https://www.liquid.ai/blog/liquid-neural-networks-research

# 10.2 Wed
* 2.mini-GPT4o来了? 能看、能听、会说，还情感丰富的多模态全能助手EMOVA  机器之心  https://mp.weixin.qq.com/s/e2KkDjqbWNy7wSv0geCNUg \
  EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotion \
  一个能够同时处理图像、文本和语音模态，能看、能听、会说的多模态全能助手，并通过情感控制，拥有更加人性化的交流能力
* 3.ECCV2024 Oral | 第一视角下的动作图像生成，Meta等提出LEGO模型  机器之心  https://mp.weixin.qq.com/s/ipzFgKN5dROsMuCNblHnhA \
  LEGO:Learning EGOcentric Action FrameGeneration via Visual Instruction Tuning \
  如何基于用户的问题和当前场景的照片，生成同一场景下的第一视角的动作图像，从而更准确地指导用户执行下一步行动？

# 10.3 Thur
* 4.耗资1.3万，ASU团队揭秘o1推理王者！碾压所有LLM成本超高，关键还会PUA  机器学习研究组订阅  https://mp.weixin.qq.com/s/Amki7OB5d_JyK18gOrSnPw \
  OpenAI声称，草莓o1已经突破了自回归LLM常规限制，成为一种新型的「大推理模型」（LRM） \
  LLMS STILL CAN’T PLAN; CAN LRMS? A PRELIMINARY EVALUATION OF OPENAI’S O1 ON PLANBENCH \
  在最新测试中，研究人员发现，o1-preview表现出色，大幅领先其他模型，但也未完全通过PlanBench基准测试
* 5.大模型如何做视频理解？最新《多模态大语言模型在全面长视频理解》综述  专知  https://mp.weixin.qq.com/s/JlCXLuvY2pONSomQwBdGZw \
  From Seconds to Hours: Reviewing MultiModal Large Language Modelson Comprehensive Long Video Understanding
* 6.【牛津大学博士论文】深度具身智能体的空间推理与规划  专知  https://mp.weixin.qq.com/s/dl6DRHlDsj4LwWWr1_YRCQ \
  Spatial Reasoning and Planningfor Deep Embodied Agents

# 10.4 Fri
* 7.(**值得看看**)Noam Brown早已预示o1强大推理能力，演讲深度解析AI推理研究脉络  机器之心  https://mp.weixin.qq.com/s/KRttVeMN4tPw9yb6f4LQgA \
  视频地址：https://www.youtube.com/watch?v=eaAonE58sLU
* 8.《大型语言模型情感认知》最新进展  专知  https://mp.weixin.qq.com/s/x2Z8i4KxdomlHQlnJF6lxw \
  Recent Advancement of Emotion Cognition in Large Language Models

# 10.5 Sat
* 9.号称击败Claude 3.5 Sonnet，媲美GPT-4o，开源多模态模型Molmo挑战Scaling law  机器之心  https://mp.weixin.qq.com/s/9s9sIkP-KDlUuJdlktVT9w \
  Molmo and PixMo: Open Weights and Open Datafor State-of-the-Art Multimodal Models
* 10.ECCV 2024 | 像ChatGPT一样，聊聊天就能实现三维场景编辑  机器之心  https://mp.weixin.qq.com/s/mXin86dhi9A3-VJgsYR0vw \
  Chat Edit 3D: Interactive 3D Scene Editing via Text Prompts
* 11.Meta又给OpenAI一记重击，视频生成Movie Gen震撼登场，甚至可以配音、编辑  机器之心  https://mp.weixin.qq.com/s/c8_sXLRkwEVvg_LKCPQHKw \
  MovieGen: A Cast of Media Foundation Models
* 12.2024年大模型Alignment偏好优化技术：从PPO, SPO到MCTS-DPO  PaperWeekly  https://mp.weixin.qq.com/s/-x2tdJWpi789lfYd0N80XQ \

# 10.6 Sun
* 13.Sebastian Raschka最新博客：从头开始，用Llama 2构建Llama 3.2  机器之心  https://mp.weixin.qq.com/s/RuTRkJPeEP1hqWevxn9h6Q \
  机器学习研究员 Sebastian Raschka 光速发布长篇教程《Converting Llama 2 to Llama 3.2 From Scratch》
* 14.AI博士如何做出有影响力的研究？斯隆奖得主弟子亲身讲述经验  机器之心  https://mp.weixin.qq.com/s/mskAe-kLi1Mrn8zzY_G8ng
* 15.何恺明新作出炉！异构预训练Transformer颠覆本体视觉学习范式，AI性能暴涨超20%  机器学习研究组订阅  https://mp.weixin.qq.com/s/DGVpJHsMsokJSRsn9_rBeA \
  Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers \
  预训练一个大型、可共享的神经网络主干，就能学习与任务和机器人形态无关的共享表示
  
# 10.7 Mon
* 16.ECCV 2024 | 新梦幻场景生成方法，高质量、视角一致、可编辑3D场景  机器之心  https://mp.weixin.qq.com/s/Xv5vDPE8JvDiEqGYG5-UYg \
  DreamScene:3D Gaussian-based ext-to-3DScene Generation via Formation PatternSampling
* 17.设计和构建强大的大语言模型智能体  专知  https://mp.weixin.qq.com/s/YXbEjg9Sf2ZJC0a__64lrA \
  Design and Build PowerfulLLM Agents  PPT
* 18.低比特大语言模型综述：基础、系统与算法  专知  https://mp.weixin.qq.com/s/mSso9ax62LVI6RXP7TSJXA \
  A Survey of Low-bit Large Language Models:Basics, Systems, and Algorithms \
  低比特量化方法

# 10.8 Tue
* 19.《视觉中的Mamba：技术与应用》全面综述  专知  https://mp.weixin.qq.com/s/SW2BplkDIE2YP9dv05R-hQ \
  Mamba in Vision: A Comprehensive Survey of Techniques andApplications
* 20.TPAMI | 安全强化学习方法、理论与应用综述，慕工大、同济、伯克利等深度解析  机器之心  https://mp.weixin.qq.com/s/Ks2EdGstTPngPrnZFcAdSw \
  A Review of Safe Reinforcement Learning: Methods, Theories and Applications
* 21.BAAI：第一原理的脑和认知科学的人工智能，6大角度  CreateAMind  https://mp.weixin.qq.com/s/NSuXbEVnfBw9wrgtHb8w1Q \
  AI of Brain and Cognitive Sciences: From the Perspective of First Principles
* 22.认知架构40年回顾-核心认知能力及其应用 4.5万字  CreateAMind  https://mp.weixin.qq.com/s/mjL5eQd624h4pz4xL6Qf7Q \
  A Review of 40 Years of Cognitive Architecture Research- Core Cognitive Abilities and Practical Applications
* 23.(**值得看看**)Yann LeCun说自回归要完，但DeepMind这篇论文却证明自回归能实现通用计算  机器之心  https://mp.weixin.qq.com/s/NmHlg-6CFcr8aDE8ktdT4A \
  但现在，DeepMind 和阿尔伯塔大学的一篇论文却给出了截然相反的见解，其研究结果表明：无需外部干预或修改模型权重，基于 Transformer 的语言模型的自回归式解码就可以实现通用计算 \
  Autoregressive Large Language Models are Computationally Universal
* 24.重要的事情说两遍！Prompt「复读机」，显著提高LLM推理能力  新智元  https://mp.weixin.qq.com/s/STW6pNFikrmlnIQy0ss42w \
  研究证明，在提问的时候故意重复一遍——也就是复制粘贴，即可显著提高LLM的推理能力 \
  Re-Reading Improves Reasoning in Large Language Models

# 10.9 Wed
* 25.「乘法变加法」！MIT清华校友全新方法优化Transformer：Addition is All You Need  机器学习研究组订阅  https://mp.weixin.qq.com/s/-b16ZrAHROjMhlmqdI46XQ \
  从乘法运算这个更加底层的逻辑出发，两位华人研究者提出，可以用一个整数加法器以高精度近似进行浮点数乘法运算，即L-Mul乘法算法 \
  Addition is All You Need for Energy-efficient Language Models
* 26.(**值得看看**)上交大发布首个OpenAI o1复现项目进展报告，满满的经验洞察  机器之心  https://mp.weixin.qq.com/s/ZO_Rv98OakPuBaZl9Tw5VA \
  https://github.com/GAIR-NLP/O1-Journey#about-the-team \
  "o1 Replication Journey: A Strategic Progress Report (o1 探索之旅：战略进展报告)" 的研究进展报告 \
  技术报告链接：https://github.com/GAIR-NLP/O1-Journey/blob/main/resource/report.pdf \
  Github 链接：https://github.com/GAIR-NLP/O1-Journeyo1 \
  讨论资源：https://github.com/GAIR-NLP/O1-Journey/tree/main/resource
* 27.(**值得看看**)这篇论文非常火！差分Transformer竟能消除注意力噪声，犹如降噪耳机  机器之心  https://mp.weixin.qq.com/s/hG_S85HkyAkTFAI2iQjl6g \
  清华微软最新力作：用物理学革新Transformer注意力，「大海捞针」精度暴涨30%！  机器学习研究组订阅  https://mp.weixin.qq.com/s/GGkpKCBDwemRAvn2rO3L1A \
  Differential Transformer （差分 Transformer，简称 Diff Transformer） \
  ???什么是注意力噪声，有什么危害
* 28.(**可以看看**)综合RLHF、DPO、KTO优势，统一对齐框架UNA来了  机器之心  https://mp.weixin.qq.com/s/8VzRYlHGS0kF1k7A9tJamA \
  UNA: Unifying Alignments of RLHF/PPO, DPO and KTO by a Generalized Implicit Reward Function  \
  来自 Salesforce、厦门大学的研究团队提出了一种名为 UNA 的新方法，它通过一种通用的隐式奖励函数，统一了当前主流的大规模语言模型（LLM）对齐技术。主要包括 RLHF、DPO 和 KTO，这些技术的结合不仅简化了模型的训练流程，还提高了模型对齐的性能，稳定性和效率
* 29.GR-2登场！ByteDance Research提出机器人大模型，具备世界建模和强大泛化能力  机器之心  https://mp.weixin.qq.com/s/h-69PKoCkPtj4_sq9589Tw \
  GR-2 官方项目页面：https://gr2-manipulation.github.io \
  GR-2 的视频生成能力，让它在动作预测方面有着天然的优势。它能够通过输入一帧图片和一句语言指令，预测未来的视频，进而生成相应的动作轨迹
* 30.(**可以看看**)谷歌提出视觉记忆方法，让大模型训练数据更灵活  AIGC开放社区  https://mp.weixin.qq.com/s/Yt6yNFaMMXww7VOatFhEPg \
  Towards flexible perception withvisual memory \
  目前，多数大模型一旦经过预训练，其内部结构便难以改变，就像把知识刻在石头一样。如果你想对模型的数据进行更新，就需要对整个模型重新训练，消耗大量时间和AI算力。为了解决这一难题，谷歌DeepMind的研究人员提出了创新视觉记忆技术，其核心是**将深度学习模型的表示能力与数据库的灵活性相结合，可以灵活地添加或删除数据**。简单来说，和人类的视觉记忆差不多，既能不断学习新的知识，又能对已有的知识进行更新和调整。

# 10.10 Thur
* 31.开源版GPT-4o来了！腾讯开源多模态大模型VITA，支持自然人机交互  PaperWeekly  https://mp.weixin.qq.com/s/wSRoYUgCDfcTnKL8X5JITg \
  VITA:Towards Open-Source InteractiveOmni Multimodal LLM
* 32.细谈大模型监督微调SFT：实战经验技巧和debug分析思路  PaperWeekly  https://mp.weixin.qq.com/s/fbo4j2oYxtuPJ9cn99PMbw \
* 33.NeurIPS 2024｜SparseLLM：突破性全局剪枝技术，大语言模型稀疏化革命  机器之心  https://mp.weixin.qq.com/s/mfdkUFXCsB50iqKgxv7hQQ \
  SparseLLM: Towards Global Pruning of Pre-trained Language Models
* 34.CMU副教授：在多智能体流行的当下，不要忽视单智能体系统  机器之心  https://mp.weixin.qq.com/s/EWnhJTPDmcwXw92H7SHSoA \
  卡内基梅隆大学的副教授 Graham Neubig 在文章《Don't Sleep on Single-agent Systems》中强调了单智能体系统也不可忽视
* 35.唯一答对“strawberry中有几个r”的开源项目，被我找到了！  夕小瑶科技说  https://mp.weixin.qq.com/s/CdhW2XVEdjT9TgpA7kwJlA \
  Open O1，是一个名为@OpenSource-O1 的团队，在github上开源的项目，目的是追齐OpenAI o1 模型的强大功能

# 10.11 Fri
* 36.《多模态持续学习》最新进展综述  专知  https://mp.weixin.qq.com/s/oSsgdFQKvHgKtqLUhJ48Aw \
  Recent Advances of Multimoda Continua.Learning:A Comprehensive Survey \
  https://github.com/LucyDYu/Awesome-Multimodal-Continual-Learning
* 37.(**值得看看**)一文看懂LLM推理，UCL汪军教授解读OpenAI ο1的相关方法  机器之心  https://mp.weixin.qq.com/s/TCWs5TKKXiRbmt-XUd0wfg \
  A Tutorial on LLM Reasoning: Relevant methods behind ChatGPT ol \
  链接：https://github.com/openreasoner/openr/blob/main/reports/Tutorial-LLM-Reasoning-Wang.pdf

# 10.12 Sat
* 38.OpenAI今天Open了一下：开源多智能体框架Swarm  机器之心  https://mp.weixin.qq.com/s/3-iKztrTuRURUGtles4-xA \
  Swarm是一个实验性质的多智能体编排框架，主打特征是工效（ergonomic）与轻量（lightweight）\
  项目地址：https://github.com/openai/swarm
* 39.NeurIPS 2024 | Transformer长度外推，全新位置编码DAPE大幅提升模型性能  机器之心  https://mp.weixin.qq.com/s/-7YsAMYYO92nItRJbqSrpw \
  Transformer 模型在处理长文本时常常遇到性能瓶颈。传统的位置编码方法，如绝对位置编码（APE）和相对位置编码（RPE），虽然在许多任务中表现良好，但其固定性限制了其在处理超长文本时的适应性和灵活性。为了应对这一挑战，提出了一种全新的位置编码方法：Data-Adaptive Positional Encoding（DAPE）。DAPE 通过动态调整位置编码，使其能够根据输入上下文和学习到的固定先验进行自适应调整。\
  DAPE: Data-Adaptive Positional Encoding for LengthExtrapolation \
  https://github.com/chuanyang-Zheng/DAPE 
* 40.虚幻5加持，清华发布首个「真实开放环境具身智能平台」与基准测试集EmbodiedCity！  新智元  https://mp.weixin.qq.com/s/hR-t4NUIF3op7QGEjtS9qA \
  Embodied City: Embodied Agent in Urban Environment

# 10.13 Sun
* 41.【博士论文】自然语言处理中的不确定性，365页pdf  专知  https://mp.weixin.qq.com/s/rM4G6bzIW9MWrFBxJPM66A 
* 42.大模型「强崩溃」！Meta新作：合成数据有「剧毒」，1%即成LLM杀手  新智元  https://mp.weixin.qq.com/s/oIAV4T_-ufTQVUrU2wX40Q \
  Al models collapse when trained on recursively generated data

# 10.14 Mon
* 43.(**值得看看**)昆虫也有意识吗？昆虫脑的复杂性与意识的进化  集智俱乐部  https://mp.weixin.qq.com/s/we5sL46IubfuNyPNSYAUVA \
  《蜂的心智》
* 44.图灵奖得主Yoshua Bengio新作：Were RNNs All We Needed?  机器之心  https://mp.weixin.qq.com/s/ueid-TAw-9OjtKFKA5lqSw \
  Were RNNs All We Needed?
* 45.Evaluation is All You Need！首个开源多模态大模型通用评测器LLaVA-Critic  机器之心  https://mp.weixin.qq.com/s/YweRqZrHJmISVjJWamalQg \
  LLaVA-Critic: Learning to Evaluate Multimodal Models
* 46.(**值得看看REPA**)扩散模型训练方法一直错了！谢赛宁：Representation matters  机器之心  https://mp.weixin.qq.com/s/a725rxzvyQXqNJoL1NsMaA \
  是什么让纽约大学著名研究者谢赛宁三连呼喊「Representation matters」？他表示：「我们可能一直都在用错误的方法训练扩散模型。」即使对生成模型而言，表征也依然有用。基于此，他们提出了 **REPA**，即**表征对齐技术**，其能让「训练扩散 Transformer 变得比你想象的更简单。」 \
  ???什么是REPA，表征对齐技术 \
  Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think
* 47.(**值得看看**)首个o1复现开源RL框架OpenR来了，UCL、上交等高校联合团队发布  机器之心  https://mp.weixin.qq.com/s/Dr9IzbUjiWtZT7bgr58T2g \
  Learning to Reason with LLMs \
  论文：https://github.com/openreasoner/openr/blob/main/reports/OpenR-Wang.pdf \
  代码链接：https://github.com/openreasoner/openr \
  教程链接：https://openreasoner.github.io/
* 48.更快、更强、更经济！港大开源大模型RAG系统LightRAG  新智元  https://mp.weixin.qq.com/s/oMtlTR1bOneohM9RhcX7Xg \
  LIGHTRAG: SIMPLE AND FAST RETRIEVAL-AUGMENTED GENERATION
* 49.李飞飞「数字表兄弟」破解机器人训练难题！零样本sim2real成功率高达90%  新智元  https://mp.weixin.qq.com/s/UHQmxbCpYpAZYWQHzw1kQA \
  Automated Creation of Digital Cousins for Robust Policy Learning

# 10.15 Tue
* 50.NeurIPS 2024 | 突破性全局剪枝技术SparseLLM：大语言模型稀疏化革命 
PaperWeekly  https://mp.weixin.qq.com/s/PJhjCJz5ZIL0HyhakgzOdQ \
  SparseLLM: Towards Global Pruning of Pre-trained Language Models

# 10.16 Wed
* 51.机器人世界模型，TeleAI用少量数据完成训练 | NeurIPS 2024  量子位  https://mp.weixin.qq.com/s/bFVwWpjFQpTTWkbpaEqYCQ \
  Learning an Actionable Discrete Diffusion Policy viaLarge-Scale Actionless Video Pre-Training
* 52.(**有趣，值得看看**)宇宙竟是一个智能体？万物智能演化Ω理论，探索宇宙终极之迷  新智元  https://mp.weixin.qq.com/s/g0k484uR5shKgyJpFpnfnQ \
  From Observer to Agent: On the Unification of Physics and Intelligence Science
* 53.重新定义自监督学习！LeCun团队让MMCR再进一步  新智元  https://mp.weixin.qq.com/s/uO3P37tDwdwjb4_y_066Ow \
  Towards an Improved Understanding and Utilization of Maximum Manifold Capacity Representations \
  ???最大流形容量表示法（MMCR）
* 54.(**值得看看**)补齐Transformer规划短板又不放弃快速思考，田渊栋团队的Dualformer融合System 1和2双重优势  机器之心  https://mp.weixin.qq.com/s/d-MkVjYjyIInRYLhc_01-A \
  来自 Meta FAIR 田渊栋团队从人类认知理论中获得了灵感，提出了一种新型 Transformer 架构：Dualformer \
  用户可以指定在推理过程中使用快速或慢速模式，在未指定时模型也可以自行决定 \
  Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces

# 10.17 Thur
* 55.Yann LeCun最新万字演讲：致力于下一代AI系统，我们基本上不做LLM了  图灵人工智能  https://mp.weixin.qq.com/s/2Bf5J1XR-jLQUY70kD3-EA \
  人类智能有四个基本特征是目前的人工智能系统所不具备的：推理、规划、持久记忆和理解物理世界。一旦我们拥有了具备这些能力的系统，还需要一段时间才能将它们提升到人类的水平
* 56.(**值得看看Dualformer**)Meta版快慢机来了！田渊栋团队整合快慢思考，能走迷宫推箱子  量子位  https://mp.weixin.qq.com/s/_ZgDjxdhj6uUyN72LC8chA \
  通过让模型在推理轨迹和最终答案上进行训练，再基于特定策略丢掉部分轨迹，Dualformer模型可以在模仿慢思考的同时，像快思考一样走捷径
* 57.LeCun最新万字演讲：纯语言模型永远到不了人类水平，我们基本已经放弃了  量子位  https://mp.weixin.qq.com/s/GR0ylZEQqZ7Q7HydjghBiw 
* 58.英伟达开源新王登基！70B刷爆SOTA，击败GPT-4o只服OpenAI o1  新智元  https://mp.weixin.qq.com/s/jWkn_G0ErC2QIKjjENvU0A 
* 59.4090笔记本0.37秒直出大片！英伟达联手MIT清华祭出**Sana**架构，速度秒杀FLUX  新智元  https://mp.weixin.qq.com/s/ZVQBSigc2VoW7qG30SekNQ
* 60.全模态对齐框架align-anything来了：实现跨模态指令跟随  机器之心  https://mp.weixin.qq.com/s/OFOvkp5STkD4n5rllai39A \
  Align-Anything 框架支持文本、图像、音频、视频等多种模态的输入和输出对齐，这在目前开源社区中是独一无二的 \
  框架实现了包括 SFT、DPO、PPO、SimPO 等超过 6 种对齐算法，研究者可以轻易地在任意至任意的模态上扩展新的对齐算法

# 10.18 Fri
* 61.卷起来！让智能体评估智能体，Meta发布Agent-as-a-Judge  机器之心  https://mp.weixin.qq.com/s/YX1cmIMDonUiosSg24boUQ \
  Agent-as-a-Judge: Evaluate Agents with Agents \
  该框架在 LLM-as-a-Judge 的基础上进行了升级，增加了中间反馈功能，确保任务的每个环节都能得到精准评估与优化，同时还能有效模拟并接近人类反馈。
* 62.以图灵机为师：通过微调训练让大语言模型懂执行计算过程  机器之心  https://mp.weixin.qq.com/s/NEOwlcPJuOj30A1GoF2qCw \
  Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines
* 63.(**可以了解**)R-AIF: 超越DreamerV3最强强化学习世界模型  CreateAMind  https://mp.weixin.qq.com/s/qfpKFscP7VFktpN7f6pECQ \
  R-AIF: SOLVING SPARSE-REWARD ROBOTIC TASKS FROMPIXELS WITH ACTIVE INFERENCE AND WORLD MODELS \
  https://github.com/NACLab/robust-active-inference 

# 10.19 Sat
* 64.(**可以看看**)Bengio团队新论文！KL正则化有漏洞，强化学习新策略：不要做我可能不会做的事情 
 新智元  https://mp.weixin.qq.com/s/oKz3QbqKPZCgVbcTkBKbEQ \
  RL, BUT DON'T DO ANYTHING I WOULDN'T DO
* 65.(**值得看看**)苹果一篇论文得罪大模型圈？Transformer不会推理，只是高级模式匹配器！所有LLM都判死刑  新智元  https://mp.weixin.qq.com/s/ecv-c7rlVZGhcSW_MLf1sQ \
  苹果研究员发文质疑道：LLM根本没有不会推理，所谓的推理能力只是复杂的模式匹配罢了。\
  GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models

# 10.20 Sun
* 66.(**值得了解**)视频生成模型变身智能体：斯坦福Percy Liang等提出VideoAgent，竟能自我优化  机器之心  https://mp.weixin.qq.com/s/dbvKbqAvvB9k4HdEvVLbzg \
  VideoAgent: Self-Improving Video Generation
* 67.(**有时间可以看看**)NeurIPS 2024 Oral | 小参数，大作为！揭秘非对称 LoRA 架构的高效性能  机器之心  https://mp.weixin.qq.com/s/M03cU4KSWXWVfNviUbn4yQ \
  HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning \
  HydraLoRA 引入了一种非对称的参数微调架构，能够有效识别并适应数据中的 “内在组件”—— 即子领域或不同任务，这些组件可能难以被领域专家明确界定
* 68.大模型在装傻！谷歌苹果最新发现：LLM知道但不告诉你，掌握知识比表现出来的多  新智元  https://mp.weixin.qq.com/s/WKFSOmpzQ3HdxSEZT4Qd9g \
  LLMS KNOW MORE THAN THEY SHOW: ON THE INTRINSIC REPRESENTATION OF LLM HALLUCINATIONS
  研究揭示了LLM内部编码和外部行为之间的差异：可能编码了正确的答案，却生成了不正确的答案
* 69.英伟达nGPT重塑Transformer，AI训练速度暴增20倍！文本越长，加速越快  新智元  https://mp.weixin.qq.com/s/zCPuR_cj50McBeFkKgTNBA \
  NGPT: NORMALIZED TRANSFORMER WITH REPRESENTATION LEARNING ON THE HYPERSPHERE
* 70.还是原装Transformer好！北大清华团队同时揭示Mamba等推理短板  机器之心  https://mp.weixin.qq.com/s/9QsjiccHtHkrxZApQbVJ3Q \
  最新推出的高效模型（如 Mamba）是否也能像 Transformer 一样具备强大的推理能力？近期，北大和清华的研究团队同时给出了明确的否定答案，揭示了 Mamba 等高效模型在结构上的局限性 \
  Do Efficient Transformers Really Save Computation? \
  RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval \
  近期，来自北大和清华的研究团队从理论角度对上述问题进行了深入探讨。结果令人惊讶：两个团队一致证实包括 Sparse Transformer、Linear Transformer、Mamba 在内的许多架构，即使在这些模型上应用思维链，其理论上的能力上限仍无法解决多种实际推理问题，并与标准 Transformer 有本质差距。这些理论结果为高效结构的实用价值蒙上了一层阴影。\
  Transformer + CoT 依然是最佳选项
* 71.低内存占用也能实现满血训练？！北理北大港中文MMLab推出Fira训练框架  量子位  https://mp.weixin.qq.com/s/gTj3VAhnJOJbl1_Nqfs0Fw \
  FIRA: CAN WE ACHIEVE FULL-RANK TRAINING OFLLMS UNDER LOW-RANK CONSTRAINT?
* 72.(**值得了解**)开源两周4.7k标星，港大LightRAG大幅降低大模型问答成本，全面理解复杂实体依赖关系  量子位  https://mp.weixin.qq.com/s/gxlZUdPiRBRdSVgAeUsmJA

# 10.21 Mon
* 73.(**值得玩玩**)把AI放进《我的世界》服务器：GPT-4o杀牛宰羊，Claude3.5把家拆了｜开源  量子位  https://mp.weixin.qq.com/s/cM6p1uSEwfARPzFRxOLPug \
  https://github.com/kolbytn/mindcraft/tree/main
* 74.Ilya预言成真，下一个token预测直达AGI！智源首发原生多模态世界模型Emu3，不用扩散  机器学习研究组订阅  https://mp.weixin.qq.com/s/Okd4z70seM_WWlTTTJg7dA \
  Emu3: Next-Token Prediction is All You Need
* 75.(**MARL综述**)多代理强化学习综述：原理、算法与挑战  机器学习研究组订阅  https://mp.weixin.qq.com/s/VcWZ3dPuOh2KZXYMqsOJaw

# 10.22 Tue
* 76.​大模型时代的对话分析：阿里最新综述全面解析对话分析的必要性  PaperWeekly  https://mp.weixin.qq.com/s/cEpkU_yb0KtraK-F-OOOfg \
  The Imperative of Conversation Analysis in the Era of LLMs: A Survey of Tasks, Techniques, and Trends
* 77.(**值得看看**)大模型是否有推理能力？DeepMind数月前的论文让AI社区吵起来了  机器之心  https://mp.weixin.qq.com/s/NdRBGFT6systLwn7p2ER7Q \
  Grandmaster-Level Chess Without Search \
  这一结果非常有趣，也很容易激发想象力，因为到目前为止，能达到这个级别的计算机国际象棋系统 —— 无论是否基于机器学习 —— 都使用了搜索组件。而 DeepMind 模型不依赖搜索似乎就能达到如此强大的下棋水平。\
  很多人将其解读为：这表明 Transformer 不是简单的「随机鹦鹉」，而是具有一定的推理和规划能力。就连该论文的作者也在「结论」部分写道：「我们的工作为快速增长的文献增添了新的内容，这些文献表明，复杂而精密的算法可以被蒸馏为前馈 transformer，这意味着一种范式的转变，即从将大型 transformer 视为单纯的统计模式识别器，转变为将其视为通用算法近似的强大技术。」\
  Skepticism About DeepMind's "Grandmaster-Level" Chess Without Search \
  博客链接：https://arjunpanickssery.substack.com/p/skepticism-about-deepminds-grandmaster \
  Grand-master Level Chess without Search: Modeling Choicesand their lmplications \
  博客链接：https://gist.github.com/yoavg/8b98bbd70eb187cf1852b3485b8cda4f#user-content-fnref-3-b6ec0872d32c5df9324eccad8269953b
* 78.(**值得看看**)DeepSeek新作Janus：解耦视觉编码，引领多模态理解与生成统一新范式  机器之心  https://mp.weixin.qq.com/s/Ao5V0ICGX3X2HWfIw23YAQ \
  Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation \
  https://github.com/deepseek-ai/Janus
* 79.人类自身都对不齐，怎么对齐AI？新研究全面审视偏好在AI对齐中的作用  机器之心  https://mp.weixin.qq.com/s/ADyxQQ5B8_Vd1eXBq1gHhg \
  但人类真的能让 AI 与自己对齐吗？近日，来自麻省理工学院、加州大学伯克利分校、伦敦大学学院、剑桥大学的一个四人团队研究发现，人类尚且难以对齐，也就更难以让 AI 与自己对齐了。他们批判性地审视了当前 AI 对齐研究的缺陷，另外他们也展示了一些替代方案。\
  Beyond Preferences in AI Alignment
* 80.(**值得看看**)机器人轻松模仿人类，还能泛化到不同任务和智能体！微软新研究，学习人类和机器人统一动作表示  量子位  https://mp.weixin.qq.com/s/QKA52wWZ8s8fP1l3ma7mvA \
  让机械臂模仿人类动作的新方法来了，不怕缺高质量机器人数据的那种。微软提出图像目标表示（**IGOR**，Image-GOal Representation），“投喂”模型人类与现实世界的交互数据。IGOR能直接为人类和机器人学习一个统一的动作表示空间，实现跨任务和智能体的知识迁移以及下游任务效果的提升。\
  IGOR: Image-GOal Representations \
  Atomic Control Units for Foundation Models in Embodied Al
* 81.你和ChatGPT理解语言的方式一样吗？从表征对齐角度比较人工神经网络与生物大脑  集智俱乐部  https://mp.weixin.qq.com/s/tqUWIXqiy9uzW-ypXCgZIw \
  Can an emerging field called ‘neural systems understanding’ explain the brain?

# 10.23 Wed
* 82.刚刚！Stable Diffusion 3.5最强模型全家桶来了，三个型号  机器之心  https://mp.weixin.qq.com/s/y1tghoFrpWPJllv0bbkdqA \
  https://huggingface.co/stabilityai
* 83.谢赛宁新作：表征学习有多重要？一个操作刷新SOTA，DiT训练速度暴涨18倍  新智元  https://mp.weixin.qq.com/s/qE_gIiWlfN_6gPyg9OGBqw \
  REPRESENTATION ALIGNMENT FOR GENERATION: TRAINING DIFFUSION TRANSFORMERS IS EASIER THAN YOU THINK \
  ???什么是表征学习
* 84.开源版OpenAI再出「神作」，小模型吊打Llama 3！Ministral系列问世，边缘AI革命开启  新智元  https://mp.weixin.qq.com/s/X7NDKBoWwANboZumWV-y3Q
* 85.Claude 3.5深夜觉醒，学会模仿人类用电脑！编程干翻o1，Agent一夜变天  新智元  https://mp.weixin.qq.com/s/dAVfVnzcqvxpocVRhCZqKg 

# 10.24 Thur
* 86.NeurIPS 2024 | 解锁大模型知识记忆编辑的新路径，浙大用「WISE」对抗幻觉  机器之心  https://mp.weixin.qq.com/s/htwBj3PbJR0Ax_40oCvOGA \
  本文借鉴认知科学和人类记忆的机制，探讨了大模型终身知识编辑问题，提出了一种基于双重记忆机制的大模型知识编辑方法 WISE, 旨在持续更新大语言模型的世界知识和纠正其幻觉性输出。此工作结合参数化长期记忆和工作记忆，在保持语言模型通用能力的同时可成功对模型进行数千次连续编辑。\
  WISE: Rethinking the Knowledge Memory for Lifelong 
* 87.他们掰开神经元，终于让大模型9.8大于9.11了：神秘创业公司，开源AI「洗脑」工具 
 机器之心  https://mp.weixin.qq.com/s/pOOBY6cBZUn86xRtO12FtQ \
  刚刚官宣的 AI 研究实验室 Transluce（字面意思是让光线穿过某物以揭示其结构） 就在做这件事情。他们开发了一个名叫 Monitor 的交互界面，以帮助人类观察、理解和引导语言模型的内部计算。
* 88.比扩散模型快50倍！OpenAI发布多模态模型实时生成进展，作者还是清华校友，把休假总裁Greg都炸出来了  量子位  https://mp.weixin.qq.com/s/3h_mxCij5_owicnfsHhp_Q \
  参数15亿模型在单张A100 GPU上无需任何推理优化即可在0.11秒内生成一个样本 \
  SIMPLIFYING, STABILIZING &SCALING CONTINUOUSTIME CONSISTENCY MODELS \
  ???连续时间一致性模型（Continuous-time Consistency Models）
* 89.(**值得看看，空间智能**)空间智能如何构建？牛津大学博士论文《深度具身智能体的空间推理与规划》230页pdf  专知  https://mp.weixin.qq.com/s/FoJVY6XE4HbMi6uUibn_7w \
  Spatial Reasoning and Planningfor Deep Embodied Agents \
  本论文的主要贡献包括四个方面：CALVIN：\
  1.一种微分规划器，能够学习可解释的世界模型用于长期规划。CALVIN成功地在部分可观测的三维环境中（如迷宫和室内房间）导航，通过从专家示范中学习奖励（目标和障碍）以及状态转换（机器人动力学）。\
  2.SOAP：一种强化学习算法，用于无监督地发现长远任务的宏动作（选项）。选项将任务划分为子任务，并实现子任务的稳定执行。SOAP在基于历史条件的走廊任务以及经典基准（如Atari游戏）中表现出稳健的性能。\
  3.LangProp：一个使用大型语言模型（LLM）进行代码优化的框架，通过将代码视为可学习的策略，解决具身智能体问题。该框架在CARLA自动驾驶基准中成功生成了具有可解释性的代码，其性能与人类专家编写的代码相当甚至更优。\
  4.Voggite：一种具有视觉到动作的Transformer后台的具身智能体，它解决了Minecraft中的复杂任务。在MineRL BASALT竞赛中，Voggite通过识别动作触发点，将任务分割成多个阶段，获得了第三名。
* 90.(**值得看看，DuoAttention**)MIT韩松团队**长上下文**LLM推理高效框架DuoAttention：单GPU实现330万Token上下文推理  机器之心  https://mp.weixin.qq.com/s/avM4jketPuNGzx-8tZvxIQ \
  DUOATTENTION: EFFICIENT LONG-CONTEXT LLM INFERENCE WITH RETRIEVAL AND STREAMING HEADS \
  项目主页及代码：https://github.com/mit-han-lab/duo-attention
* 91.7B新王登基！Zamba 2完胜同级模型，推理效率比Llama 3提升20%，内存用量更少  新智元  https://mp.weixin.qq.com/s/6_dQod3hS1IJ_xU09x_jrg 

# 10.25 Fri
* 92.LeCun锐评诺奖：出于压力才颁给AI，但两个成果已经完全无用，玻尔兹曼机和Hopefield网络  量子位  https://mp.weixin.qq.com/s/8krd2Tlb9DzCnexhUKTa0A \
  物理奖颁给Hinton和Hopefield，获奖成果玻尔兹曼机和Hopefield网络现在完全无用
* 93.刚刚，我们感受了一波最「像人」的国产AI，模型还是开源的  机器之心  https://mp.weixin.qq.com/s/Bi7cPZXCmsjSaJu6EglhJA \
  开源地址：https://github.com/THUDM/GLM-4-Voice
* 94.与OpenAI o1技术理念相似，TDPO-R算法有效缓解奖励过优化问题  机器之心  https://mp.weixin.qq.com/s/MYSlYsFtlvZAmusEvrRsjA \
  TDPO-R 在强化学习算法中引入了时间差分奖励机制，对文生图扩散模型的每一步生成过程提供细粒度的反馈，从而有效缓解了在扩散模型对齐时常见的奖励过优化问题。这项研究证实了细粒度奖励机制在扩散模型对齐中的关键性，而 o1 的最新技术同样揭示了这一机制在大模型领域中的广泛应用前景，有望推动生成模型在多样化、复杂任务中的持续发展与优化 \
  由于受奖励目标驱动，这些扩散模型对齐方法常常面临一个核心挑战 —— 奖励过优化（Reward Overoptimization），即经过微调后的模型可能会过度偏向于某一奖励目标，导致生成的图像丧失个性化和多样性、视觉保真度降低，最终偏离人类真实的审美偏 \
  Confronting Reward Overoptimization for Diffusion Models: A Perspective of Inductive and Primacy Biases
* 95.(**幻觉综述**)大型视觉语言模型中幻觉现象的综述  机器学习研究组订阅  https://mp.weixin.qq.com/s/EGL6C_RbwdyFn9EKTQgdlQ \
  A Survey of Hallucination in Large Visual Language Models

# 10.26 Sat
* 96.(**JOWA，值得研究**)一个Agent拿下15款Atari游戏，RL也能实现Pretraining、Scaling和Few-shots微调  PaperWeekly  https://mp.weixin.qq.com/s/aygd_JTarF87TUgCzrddnw \
  Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining \
  https://github.com/CJReinforce/JOWA \
  https://cjreinforce.github.io/JOWA_agents/ 
* 97.端到端优化所有能力，字节跳动提出强化学习LLM Agent框架AGILE  PaperWeekly  https://mp.weixin.qq.com/s/FZdu7gLKXrE3IuU_6GX97w \
  AGILE: A Novel Framework of LLM Agents
* 98.(**值得玩玩OmniParser**)控制电脑手机的智能体人人都能造，微软开源OmniParser  机器之心  https://mp.weixin.qq.com/s/yEC32W-dobHF7pycDSHcPg \
  OmniParser for Pure Vision Based GUI Agent \
  https://github.com/microsoft/OmniParser
* 99.(**值得看看，Unbounded无界**)大模型生成RPG游戏，情节角色全自定义！谷歌出品，一作上海交大校友  量子位  https://mp.weixin.qq.com/s/7xBtIo2x_TbTMNzFxtDXiQ \
  真·开放式游戏，谷歌造出首个无限人生模拟游戏Unbounded  机器之心  https://mp.weixin.qq.com/s/Kau06W56b08W2NQFlHSytQ \
  无界（Unbounded）就是一款完全由生成式模型封装的角色生活模拟游戏。你可以虚拟世界中通过喂养、玩耍和引导角色，与他互动，但需要保证它的健康状态 \
  UNBOUNDED: A GENERATIVE INFINITE GAME OF CHARACTER LIFE SIMULATION \
  https://generative-infinite-game.github.io/ \
  在卡斯的定义中，有限游戏是「以获胜为目的的游戏」，它们有边界条件、固定的规则和明确的终点。而无限游戏的「目标是让游戏继续下去」，没有固定的边界条件，规则也会不断演变。
* 100.LLM等价于众包，只是在输出「网络共识」！哈佛大学最新报告深挖大模型幻觉！  夕小瑶科技说  https://mp.weixin.qq.com/s/jKYCy8fqM2XdeECefBripg 
  
# 10.27 Sun
* 101.(**值得看看，持续学习**)微调失格？持续反向传播算法将解锁新的训练范式吗？  机器之心  https://mp.weixin.qq.com/s/grSl8V_iO1nxepNY6G1m1Q \
  度学习先驱 Richard S。Sutton 近期在 Amii（阿尔伯塔机器学习学院）发表演讲，指出当前的深度学习方法存在根本上的缺陷，进而分享了他对更好的深度学习的愿景，并将新的范式命名为 Dynamic Deep Learning。他在该愿景下提出了反向传播算法，解决了当前持续学习中模型可塑性丧失的问题，并为未来能适应动态环境的深度学习网络指出了可行的方向。\
  Sutton 在演讲的开头就直观地介绍了他对深度学习的愿景，他将其称为 Dynamic Deep Learning（动态深度学习），而这种动态是为了让深度学习适应持续学习的环境。\
  ① Sutton 强调了持续学习的重要性，即学习应该在每个时刻都在进行。持续学习更接近自然学习过程，所有自然系统（如动物和人类）都在持续学习，而不是在特定阶段学习。\
  ② 当前的深度学习是瞬态学习（Transient Learning），其在一个特殊的训练阶段学习，且算法会在持续学习环境中失败，失去可塑性，产生灾难性遗忘，并在强化学习策略中崩溃。\
  Loss of plasticity in deep continual learning
* 102.斯坦福开源学术研究神器STORM再进化，AI智能体像人一样进行圆桌讨论  机器之心  https://mp.weixin.qq.com/s/-NY8Xw8ihIFgUwy4LFLMgA \
  https://github.com/stanford-oval/storm
* 103.谷歌版贾维斯即将问世，最强Gemini 2.0加持！AI自主操控电脑时代来临  新智元  https://mp.weixin.qq.com/s/wl6G0PpX90Kc8S_qcQtjVw \
  谷歌「贾维斯」将由未来版Gemini 2.0驱动，预计在12月亮相
* 104.田渊栋团队新作祭出Agent-as-a-Judge！AI智能体自我审判，成本暴跌97%  新智元  https://mp.weixin.qq.com/s/z48LtC7FhO0T6FgsDvizfw \
  Agent-as-a-Judge: Evaluate Agents with Agents
* 105.(**可以看看**)通用可解释世界模型  CreateAMind  https://mp.weixin.qq.com/s/8oV2X78zDEyB1vcs1RiMww \
  Toward Universal and Interpretable World Models forOpen-ended Learning Agents \
  我们介绍了一类通用、组合式且可解释的生成式世界模型，该类模型支持无界学习代理。这是一类稀疏的贝叶斯网络，能够近似表示各种随机过程，从而使代理能够以既可解释又计算可扩展的方式学习世界模型。这种方法结合了贝叶斯结构学习和内在动机（基于模型的）规划，使代理能够主动开发和优化其世界模型，这可能导致发展性学习以及更稳健、自适应的行为。
* 106.(**可以看看**)探索和学习结构:导航代理中的主动推理方法  CreateAMind  https://mp.weixin.qq.com/s/upBejCRhflwXi8qKep_vDQ \
  Exploring and Learning Structure:Active Inference Approach in Navigational Agents \
  受动物导航策略的启发，我们提出了一种基于生物学原理的新型计算模型，用于导航和绘图。动物通过有效利用记忆、想象力和战略决策，在复杂且存在混淆的环境中展现出卓越的导航能力。基于这些见解，我们将传统的认知绘图方法与主动推理框架（AIF）相结合，只需几步就能学习环境结构。通过整合用于长期记忆的拓扑绘图和用于导航规划及结构学习的主动推理框架，我们的模型能够在探索过程中动态理解环境结构，并根据预测的信念扩展其内部地图。\
  一个功能完善的导航系统必须无缝地完成三个关键功能：自我定位、绘图和路径规划。这既需要一个用于空间感知的传感组件，也需要一个能够延伸这些感知的时间和空间范围的存储能力。动物展现出了快速学习环境结构的惊人能力，通常仅在一次或几次访问中就能实现，这依赖于记忆、想象力和战略决策

# 10.28 Mon
* 107.一种彻底新理论，关于大脑如何表示和计算概率  CreateAMind  https://mp.weixin.qq.com/s/nycq7n66YPJGPccIF1FoZQ \
  A Radically New Theory of how the Brain Represents and Computes with Probabilities
* 108.(**值得看看**)你和ChatGPT理解语言的方式一样吗？从表征对齐角度比较人工神经网络与生物大脑  图灵人工智能  https://mp.weixin.qq.com/s/N3h0B7z_VQL-VHvrlQmCVQ 
* 109.世界模型新突破！极佳科技提出DriveDreamer4D，首次利用世界模型增强4D驾驶场景重建效果  机器之心  https://mp.weixin.qq.com/s/PYh6khHqZqi2PMKKSpf3Ew \
  DriveDreamer4D: World Models Are Effective Data Machinesfor 4D Driving Scene Representation \
  https://github.com/GigaAI-research/DriveDreamer4D
* 110.(**非常值得研究，长期记忆，自进化**)整合长期记忆，AI实现自我进化，探索大模型这一可能性  机器之心  https://mp.weixin.qq.com/s/BwIazafPjpQFtivIXTs5XA \
  Long Term Memory : The Foundation of AI Self-Evolution \
  该团队将 LLM 的模型进化过程分成了三个主要阶段: \
  阶段 1：在物理世界中积累认知。 \
  阶段 2：在数字世界中构建基础模型。 \
  阶段 3：模型自我进化，以实现更强大的智能。
* 111.一块显卡理解一部电影，最新超长视频理解大模型出炉！“大海捞针”准确率近95%，代码已开源  量子位  https://mp.weixin.qq.com/s/kGIGBLH6vpeNwzqBcRREKA \
  Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding
* 112.OpenAI-o1思考替代法火了！焦剑涛高徒一作提出思考偏好优化，不限于推理任务  量子位  https://mp.weixin.qq.com/s/h3o8J2UI_vYySYFAMTtQHA \
  提出了一种称作思考偏好优化（Thought Preference Optimization）的方法，能让模型像OpenAI-o1一样，通过内部“思考”输出更好答案，最终只显示结果，不展示思考过程。\
  思考偏好优化 TPO \
  THINKING LLMS: GENERAL INSTRUCTION FOLLOWING WITH THOUGHT GENERATION
* 113.陶哲轩神预言！Transformer破解百年三体难题，凭数学直觉找到李雅普诺夫函数  机器学习研究组订阅  https://mp.weixin.qq.com/s/XHVY2OCC1CfA7DO0stVvdQ 

# 10.29 Tue
* 114.2mm²芯片点亮盲人黑暗世界！马斯克前搭档出手，失明81%也能阅读了  新智元  https://mp.weixin.qq.com/s/D_kbp_gUtqxI3q2B1SCUiQ \
  前Neuralink总裁创立的脑机接口公司Science Corporation，正在开发一种名为「Prima」的芯片技术。\
* 115.强化学习训练一两个小时，100%自主完成任务：机器人ChatGPT时刻真来了？  机器之心  https://mp.weixin.qq.com/s/5pVajhtp8KSFz4AnV8PVTQ \
  UC 伯克利 BAIR 实验室的 Sergey Levine 研究团队提出了一个强化学习框架 HIL-SERL，可直接在现实世界中训练通用的基于视觉的机器人操作策略。\
  Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning \
  https://hil-serl.github.io/
* 116.新扩散模型OmniGen一统图像生成，架构还高度简化、易用  机器之心  https://mp.weixin.qq.com/s/mzs96Oav3pfj22YoYJPILQ \
  OmniGen: Unifed Image Generation \
  https://github.com/VectorSpaceLab/OmniGen
* 117.超越Transformer，全面升级！MIT等华人团队发布通用时序TimeMixer++架构，8项任务全面领先  新智元  https://mp.weixin.qq.com/s/l_MB11XoShV7vK3BjtEPog 
* 118.免训练大模型知识编辑，吸收新数据更高效｜EMNLP'24  量子位  https://mp.weixin.qq.com/s/aW6Vm2ZTieeyKfHNz9UIow \
  Lifelong Knowledge Editing for LLMs with Retrieval-AugmentedContinuous Prompt Learning \
  名为RECIPE的最新方法，它首先将知识描述转换为简短且信息丰富的连续提示的token表示，作为LLM输入查询嵌入的前缀，有效地细化基于知识的生成过程。它还集成了知识哨兵机制，作为计算动态阈值的媒介，确定检索库是否包含相关知识。
* 119.(**可以看看**)【牛津大学博士论文】迈向具有类人自然语言理解的语言模型  专知  https://mp.weixin.qq.com/s/K7ORYG5DmPBgg3J1xw1BEw \
  探索了基于更符合生物学原理的预测编码训练方法用于语言模型的训练，这种方法可能成为超越反向传播的深度学习未来方向 \
  Towards Human-Like Natural Language Understanding with Language Models
* 120.(**有必要看看**)图灵奖得主 Yann LeCun:《机器如何才能达到人类智能水平？》——Yann LeCun, 附Slides及视频  专知  https://mp.weixin.qq.com/s/luV5AaUtNokDiX4swWMVSA \
  人工与动物能够理解物理世界，具有常识，拥有持久记忆，可以推理，并能规划复杂的子目标和行动序列。这些智能行为的基本特征目前仍超出当前最强大的AI架构（例如自回归大型语言模型，Auto-Regressive LLMs）的能力范围。\
  世界模型采用了一种联合嵌入预测架构（Joint Embedding Predictive Architecture, JEPA），主要通过观察利用自监督学习（self-supervised learning）进行训练。

# 10.30 Wed
* 121.从此不再后训练！NeurIPS2024 & CMU | 提出推理时对齐方法，解码效率最高提升32倍  AINLPer  https://mp.weixin.qq.com/s/U225o19DT6MiyXXv7UJKHQ \
  推理时对齐是指那些完全绕过LLM后训练步骤的程序，并通过改变解码策略直接在推理时进行对齐。\
  Fast Best-of-N Decoding via Speculative Rejection
* 122.如何实现：阿西莫夫机器人三定律  CreateAMind  https://mp.weixin.qq.com/s/2S_TVU-bQ39tKFxdVXQfCA \
  Possible principles for aligned structure learning agents
* 123.小型语言模型综述  专知  https://mp.weixin.qq.com/s/ZkFLwRiTtH1bLfwlp1Yu6w \
  A Survey of Small Language Models
* 124.(**值得研究**)导航、采矿、建造，北大这个新智能体把《我的世界》玩透了  机器之心  https://mp.weixin.qq.com/s/MS9jeZSyHyuXrP4m7lMS1Q \
  ROCKET-1: Master Open-World Interaction with Visual-Temporal Context Prompting \
  https://craftjarvis.github.io/ROCKET-1
* 125.MIT大牛新发现：LLM和人类大脑结构类似，存在脑叶分区！  夕小瑶科技说  https://mp.weixin.qq.com/s/7kxPoraUO746t0e5Ov4LPg \
  AI「长脑子」了？LLM惊现「人类脑叶」结构并有数学代码分区，MIT大牛新作震惊学界！  新智元  https://mp.weixin.qq.com/s/cafpguRWxQuoakyq_V9Y5w \
  Max Tegmark团队又出神作了！他们发现，LLM中居然存在人类大脑结构一样的脑叶分区，分为数学/代码、短文本、长篇科学论文等部分。这项重磅的研究揭示了：大脑构造并非人类独有，硅基生命也从属这一法则。\
  THE GEOMETRY OF CONCEPTS: SPARSE AUTOENCODER FEATURE STRUCTURE

# 10.31 Thur
* 126.(**非常有趣，值得研究**)10秒创造一个世界！吴佳俊团队新作实时交互式3D世界生成，比现有技术快100倍！  计算机视觉Daily  https://mp.weixin.qq.com/s/5QQPzSRMPfbODCLgVuHwBA \
  WonderWorld: Interactive 3D Scene Generation from a Single Image \
  https://kovenyu.com/wonderworld
* 127.大模型已过时，小模型SLM才是未来？苹果正在研究这个  机器之心  https://mp.weixin.qq.com/s/vAa1Tmse-Sn_nhaceWC1lg \
  Computational Bottlenecks of Training Small-scale Large Language Models \
  尽管 SLM 规模很小，但其表现并不一定很差，并且已经展现出了自己的巨大潜力。很多借助剪枝、蒸馏和量化等技术得到的 SLM 的性能并不比大得多的模型差，甚至有时候还能更胜一筹。举个例子，Gemma-2B 的性能就优于大得多的 OPT-175B，这就挑战了大多数人的一个固有观念：模型大小是有效性的主导决定因素。
* 128.全自动打工「人」！波士顿动力Atlas进厂视频火了，不断电不下班  机器之心  https://mp.weixin.qq.com/s/I-6yisQ7dBwVKwsqHDbLWA
* 129.重磅！统一大脑内不同学习的可塑机制  CreateAMind  https://mp.weixin.qq.com/s/AzJKCvLVVDlbHclBUASOng \
  Learning what matters: Synaptic plasticity with invariance to second-order input correlations
* 130.(**有趣，HOVER**)让机器人拥有人一样「潜意识」，英伟达1.5M小模型就能实现通用控制了  机器之心  https://mp.weixin.qq.com/s/u9GQnLlgWZi3TMfWpOoAFQ \
  HOVER 的设计灵感来自人类的潜意识。人类在行走、保持平衡和调整四肢位置时都需要大量潜意识的计算，HOVER 将这种「潜意识」能力融合进了机器人。这个单一模型可以学习协调人形机器人的电机，从而实现运动和操控。\
  HOVER: Versatile Neural Whole-Body Controller for Humanoid Robots \
  https://hover-versatile-humanoid.github.io/
