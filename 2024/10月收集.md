# 10.1 Tue
* 1.(**LNN液体神经网络**)给机器人装上「虫脑」？非Transformer液态神经网络终于来了！MIT CSAIL负责人创业成果  机器之心  https://mp.weixin.qq.com/s/oowid3yCpFNTALCvgdSwXg \
  MIT系初创打破Transformer霸权！液体基础模型刷新SOTA，非GPT架构首次显著超越Transformer  机器学习研究组订阅  https://mp.weixin.qq.com/s/Jcyymw4k9YgRkia8mR7zaA \
  Liquid AI 表示他们的目标是「探索构建超越生成式预训练 Transformer (GPT) 基础模型的方法」\
  为了实现这一目标，Liquid AI 推出了其首批多模态 AI 模型：Liquid Foundation Models（LFM）。这是基于第一原理构建的新一代生成式 AI 模型，其 1B、3B 和 40B LFM 在各个规模上均能实现 SOTA 性能，同时保持更小的内存占用和更高效的推理。\
  Liquid 使用了一种混合的计算单元，这些计算单元深深植根于动态系统理论、信号处理和数值线性代数的理论中。结果就是开发出了通用的人工智能模型，这些模型能够用来模拟任何类型的序列数据，包括视频、音频、文本、时间序列和信号，以此来训练其新的 LFM \
  https://www.liquid.ai/blog/liquid-neural-networks-research

# 10.2 Wed
* 2.mini-GPT4o来了? 能看、能听、会说，还情感丰富的多模态全能助手EMOVA  机器之心  https://mp.weixin.qq.com/s/e2KkDjqbWNy7wSv0geCNUg \
  EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotion \
  一个能够同时处理图像、文本和语音模态，能看、能听、会说的多模态全能助手，并通过情感控制，拥有更加人性化的交流能力
* 3.ECCV2024 Oral | 第一视角下的动作图像生成，Meta等提出LEGO模型  机器之心  https://mp.weixin.qq.com/s/ipzFgKN5dROsMuCNblHnhA \
  LEGO:Learning EGOcentric Action FrameGeneration via Visual Instruction Tuning \
  如何基于用户的问题和当前场景的照片，生成同一场景下的第一视角的动作图像，从而更准确地指导用户执行下一步行动？

# 10.3 Thur
* 4.耗资1.3万，ASU团队揭秘o1推理王者！碾压所有LLM成本超高，关键还会PUA  机器学习研究组订阅  https://mp.weixin.qq.com/s/Amki7OB5d_JyK18gOrSnPw \
  OpenAI声称，草莓o1已经突破了自回归LLM常规限制，成为一种新型的「大推理模型」（LRM） \
  LLMS STILL CAN’T PLAN; CAN LRMS? A PRELIMINARY EVALUATION OF OPENAI’S O1 ON PLANBENCH \
  在最新测试中，研究人员发现，o1-preview表现出色，大幅领先其他模型，但也未完全通过PlanBench基准测试
* 5.大模型如何做视频理解？最新《多模态大语言模型在全面长视频理解》综述  专知  https://mp.weixin.qq.com/s/JlCXLuvY2pONSomQwBdGZw \
  From Seconds to Hours: Reviewing MultiModal Large Language Modelson Comprehensive Long Video Understanding
* 6.【牛津大学博士论文】深度具身智能体的空间推理与规划  专知  https://mp.weixin.qq.com/s/dl6DRHlDsj4LwWWr1_YRCQ \
  Spatial Reasoning and Planningfor Deep Embodied Agents

# 10.4 Fri
* 7.(**值得看看**)Noam Brown早已预示o1强大推理能力，演讲深度解析AI推理研究脉络  机器之心  https://mp.weixin.qq.com/s/KRttVeMN4tPw9yb6f4LQgA \
  视频地址：https://www.youtube.com/watch?v=eaAonE58sLU
* 8.《大型语言模型情感认知》最新进展  专知  https://mp.weixin.qq.com/s/x2Z8i4KxdomlHQlnJF6lxw \
  Recent Advancement of Emotion Cognition in Large Language Models

# 10.5 Sat
* 9.号称击败Claude 3.5 Sonnet，媲美GPT-4o，开源多模态模型Molmo挑战Scaling law  机器之心  https://mp.weixin.qq.com/s/9s9sIkP-KDlUuJdlktVT9w \
  Molmo and PixMo: Open Weights and Open Datafor State-of-the-Art Multimodal Models
* 10.ECCV 2024 | 像ChatGPT一样，聊聊天就能实现三维场景编辑  机器之心  https://mp.weixin.qq.com/s/mXin86dhi9A3-VJgsYR0vw \
  Chat Edit 3D: Interactive 3D Scene Editing via Text Prompts
* 11.Meta又给OpenAI一记重击，视频生成Movie Gen震撼登场，甚至可以配音、编辑  机器之心  https://mp.weixin.qq.com/s/c8_sXLRkwEVvg_LKCPQHKw \
  MovieGen: A Cast of Media Foundation Models
* 12.2024年大模型Alignment偏好优化技术：从PPO, SPO到MCTS-DPO  PaperWeekly  https://mp.weixin.qq.com/s/-x2tdJWpi789lfYd0N80XQ \

# 10.6 Sun
* 13.Sebastian Raschka最新博客：从头开始，用Llama 2构建Llama 3.2  机器之心  https://mp.weixin.qq.com/s/RuTRkJPeEP1hqWevxn9h6Q \
  机器学习研究员 Sebastian Raschka 光速发布长篇教程《Converting Llama 2 to Llama 3.2 From Scratch》
* 14.AI博士如何做出有影响力的研究？斯隆奖得主弟子亲身讲述经验  机器之心  https://mp.weixin.qq.com/s/mskAe-kLi1Mrn8zzY_G8ng
* 15.何恺明新作出炉！异构预训练Transformer颠覆本体视觉学习范式，AI性能暴涨超20%  机器学习研究组订阅  https://mp.weixin.qq.com/s/DGVpJHsMsokJSRsn9_rBeA \
  Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers \
  预训练一个大型、可共享的神经网络主干，就能学习与任务和机器人形态无关的共享表示
  
# 10.7 Mon
* 16.ECCV 2024 | 新梦幻场景生成方法，高质量、视角一致、可编辑3D场景  机器之心  https://mp.weixin.qq.com/s/Xv5vDPE8JvDiEqGYG5-UYg \
  DreamScene:3D Gaussian-based ext-to-3DScene Generation via Formation PatternSampling
* 17.设计和构建强大的大语言模型智能体  专知  https://mp.weixin.qq.com/s/YXbEjg9Sf2ZJC0a__64lrA \
  Design and Build PowerfulLLM Agents  PPT
* 18.低比特大语言模型综述：基础、系统与算法  专知  https://mp.weixin.qq.com/s/mSso9ax62LVI6RXP7TSJXA \
  A Survey of Low-bit Large Language Models:Basics, Systems, and Algorithms \
  低比特量化方法

# 10.8 Tue
* 19.《视觉中的Mamba：技术与应用》全面综述  专知  https://mp.weixin.qq.com/s/SW2BplkDIE2YP9dv05R-hQ \
  Mamba in Vision: A Comprehensive Survey of Techniques andApplications
* 20.TPAMI | 安全强化学习方法、理论与应用综述，慕工大、同济、伯克利等深度解析  机器之心  https://mp.weixin.qq.com/s/Ks2EdGstTPngPrnZFcAdSw \
  A Review of Safe Reinforcement Learning: Methods, Theories and Applications
* 21.BAAI：第一原理的脑和认知科学的人工智能，6大角度  CreateAMind  https://mp.weixin.qq.com/s/NSuXbEVnfBw9wrgtHb8w1Q \
  AI of Brain and Cognitive Sciences: From the Perspective of First Principles
* 22.认知架构40年回顾-核心认知能力及其应用 4.5万字  CreateAMind  https://mp.weixin.qq.com/s/mjL5eQd624h4pz4xL6Qf7Q \
  A Review of 40 Years of Cognitive Architecture Research- Core Cognitive Abilities and Practical Applications
* 23.(**值得看看**)Yann LeCun说自回归要完，但DeepMind这篇论文却证明自回归能实现通用计算  机器之心  https://mp.weixin.qq.com/s/NmHlg-6CFcr8aDE8ktdT4A \
  但现在，DeepMind 和阿尔伯塔大学的一篇论文却给出了截然相反的见解，其研究结果表明：无需外部干预或修改模型权重，基于 Transformer 的语言模型的自回归式解码就可以实现通用计算 \
  Autoregressive Large Language Models are Computationally Universal
* 24.重要的事情说两遍！Prompt「复读机」，显著提高LLM推理能力  新智元  https://mp.weixin.qq.com/s/STW6pNFikrmlnIQy0ss42w \
  研究证明，在提问的时候故意重复一遍——也就是复制粘贴，即可显著提高LLM的推理能力 \
  Re-Reading Improves Reasoning in Large Language Models

# 10.9 Wed
* 25.「乘法变加法」！MIT清华校友全新方法优化Transformer：Addition is All You Need  机器学习研究组订阅  https://mp.weixin.qq.com/s/-b16ZrAHROjMhlmqdI46XQ \
  从乘法运算这个更加底层的逻辑出发，两位华人研究者提出，可以用一个整数加法器以高精度近似进行浮点数乘法运算，即L-Mul乘法算法 \
  Addition is All You Need for Energy-efficient Language Models
* 26.(**值得看看**)上交大发布首个OpenAI o1复现项目进展报告，满满的经验洞察  机器之心  https://mp.weixin.qq.com/s/ZO_Rv98OakPuBaZl9Tw5VA \
  https://github.com/GAIR-NLP/O1-Journey#about-the-team \
  "o1 Replication Journey: A Strategic Progress Report (o1 探索之旅：战略进展报告)" 的研究进展报告 \
  技术报告链接：https://github.com/GAIR-NLP/O1-Journey/blob/main/resource/report.pdf \
  Github 链接：https://github.com/GAIR-NLP/O1-Journeyo1 \
  讨论资源：https://github.com/GAIR-NLP/O1-Journey/tree/main/resource
* 27.(**值得看看**)这篇论文非常火！差分Transformer竟能消除注意力噪声，犹如降噪耳机  机器之心  https://mp.weixin.qq.com/s/hG_S85HkyAkTFAI2iQjl6g \
  清华微软最新力作：用物理学革新Transformer注意力，「大海捞针」精度暴涨30%！  机器学习研究组订阅  https://mp.weixin.qq.com/s/GGkpKCBDwemRAvn2rO3L1A \
  Differential Transformer （差分 Transformer，简称 Diff Transformer） \
  ???什么是注意力噪声，有什么危害
* 28.(**可以看看**)综合RLHF、DPO、KTO优势，统一对齐框架UNA来了  机器之心  https://mp.weixin.qq.com/s/8VzRYlHGS0kF1k7A9tJamA \
  UNA: Unifying Alignments of RLHF/PPO, DPO and KTO by a Generalized Implicit Reward Function  \
  来自 Salesforce、厦门大学的研究团队提出了一种名为 UNA 的新方法，它通过一种通用的隐式奖励函数，统一了当前主流的大规模语言模型（LLM）对齐技术。主要包括 RLHF、DPO 和 KTO，这些技术的结合不仅简化了模型的训练流程，还提高了模型对齐的性能，稳定性和效率
* 29.GR-2登场！ByteDance Research提出机器人大模型，具备世界建模和强大泛化能力  机器之心  https://mp.weixin.qq.com/s/h-69PKoCkPtj4_sq9589Tw \
  GR-2 官方项目页面：https://gr2-manipulation.github.io \
  GR-2 的视频生成能力，让它在动作预测方面有着天然的优势。它能够通过输入一帧图片和一句语言指令，预测未来的视频，进而生成相应的动作轨迹
* 30.(**可以看看**)谷歌提出视觉记忆方法，让大模型训练数据更灵活  AIGC开放社区  https://mp.weixin.qq.com/s/Yt6yNFaMMXww7VOatFhEPg \
  Towards flexible perception withvisual memory \
  目前，多数大模型一旦经过预训练，其内部结构便难以改变，就像把知识刻在石头一样。如果你想对模型的数据进行更新，就需要对整个模型重新训练，消耗大量时间和AI算力。为了解决这一难题，谷歌DeepMind的研究人员提出了创新视觉记忆技术，其核心是**将深度学习模型的表示能力与数据库的灵活性相结合，可以灵活地添加或删除数据**。简单来说，和人类的视觉记忆差不多，既能不断学习新的知识，又能对已有的知识进行更新和调整。

# 10.10 Thur
* 31.开源版GPT-4o来了！腾讯开源多模态大模型VITA，支持自然人机交互  PaperWeekly  https://mp.weixin.qq.com/s/wSRoYUgCDfcTnKL8X5JITg \
  VITA:Towards Open-Source InteractiveOmni Multimodal LLM
* 32.细谈大模型监督微调SFT：实战经验技巧和debug分析思路  PaperWeekly  https://mp.weixin.qq.com/s/fbo4j2oYxtuPJ9cn99PMbw \
* 33.NeurIPS 2024｜SparseLLM：突破性全局剪枝技术，大语言模型稀疏化革命  机器之心  https://mp.weixin.qq.com/s/mfdkUFXCsB50iqKgxv7hQQ \
  SparseLLM: Towards Global Pruning of Pre-trained Language Models
* 34.CMU副教授：在多智能体流行的当下，不要忽视单智能体系统  机器之心  https://mp.weixin.qq.com/s/EWnhJTPDmcwXw92H7SHSoA \
  卡内基梅隆大学的副教授 Graham Neubig 在文章《Don't Sleep on Single-agent Systems》中强调了单智能体系统也不可忽视
* 35.唯一答对“strawberry中有几个r”的开源项目，被我找到了！  夕小瑶科技说  https://mp.weixin.qq.com/s/CdhW2XVEdjT9TgpA7kwJlA \
  Open O1，是一个名为@OpenSource-O1 的团队，在github上开源的项目，目的是追齐OpenAI o1 模型的强大功能

# 10.11 Fri
* 36.《多模态持续学习》最新进展综述  专知  https://mp.weixin.qq.com/s/oSsgdFQKvHgKtqLUhJ48Aw \
  Recent Advances of Multimoda Continua.Learning:A Comprehensive Survey \
  https://github.com/LucyDYu/Awesome-Multimodal-Continual-Learning
* 37.(**值得看看**)一文看懂LLM推理，UCL汪军教授解读OpenAI ο1的相关方法  机器之心  https://mp.weixin.qq.com/s/TCWs5TKKXiRbmt-XUd0wfg \
  A Tutorial on LLM Reasoning: Relevant methods behind ChatGPT ol \
  链接：https://github.com/openreasoner/openr/blob/main/reports/Tutorial-LLM-Reasoning-Wang.pdf

# 10.12 Sat
* 38.OpenAI今天Open了一下：开源多智能体框架Swarm  机器之心  https://mp.weixin.qq.com/s/3-iKztrTuRURUGtles4-xA \
  Swarm是一个实验性质的多智能体编排框架，主打特征是工效（ergonomic）与轻量（lightweight）\
  项目地址：https://github.com/openai/swarm
* 39.NeurIPS 2024 | Transformer长度外推，全新位置编码DAPE大幅提升模型性能  机器之心  https://mp.weixin.qq.com/s/-7YsAMYYO92nItRJbqSrpw \
  Transformer 模型在处理长文本时常常遇到性能瓶颈。传统的位置编码方法，如绝对位置编码（APE）和相对位置编码（RPE），虽然在许多任务中表现良好，但其固定性限制了其在处理超长文本时的适应性和灵活性。为了应对这一挑战，提出了一种全新的位置编码方法：Data-Adaptive Positional Encoding（DAPE）。DAPE 通过动态调整位置编码，使其能够根据输入上下文和学习到的固定先验进行自适应调整。\
  DAPE: Data-Adaptive Positional Encoding for LengthExtrapolation \
  https://github.com/chuanyang-Zheng/DAPE 
* 40.虚幻5加持，清华发布首个「真实开放环境具身智能平台」与基准测试集EmbodiedCity！  新智元  https://mp.weixin.qq.com/s/hR-t4NUIF3op7QGEjtS9qA \
  Embodied City: Embodied Agent in Urban Environment

# 10.13 Sun
* 41.【博士论文】自然语言处理中的不确定性，365页pdf  专知  https://mp.weixin.qq.com/s/rM4G6bzIW9MWrFBxJPM66A 
* 42.大模型「强崩溃」！Meta新作：合成数据有「剧毒」，1%即成LLM杀手  新智元  https://mp.weixin.qq.com/s/oIAV4T_-ufTQVUrU2wX40Q \
  Al models collapse when trained on recursively generated data

# 10.14 Mon
* 43.(**值得看看**)昆虫也有意识吗？昆虫脑的复杂性与意识的进化  集智俱乐部  https://mp.weixin.qq.com/s/we5sL46IubfuNyPNSYAUVA \
  《蜂的心智》
* 44.图灵奖得主Yoshua Bengio新作：Were RNNs All We Needed?  机器之心  https://mp.weixin.qq.com/s/ueid-TAw-9OjtKFKA5lqSw \
  Were RNNs All We Needed?
* 45.Evaluation is All You Need！首个开源多模态大模型通用评测器LLaVA-Critic  机器之心  https://mp.weixin.qq.com/s/YweRqZrHJmISVjJWamalQg \
  LLaVA-Critic: Learning to Evaluate Multimodal Models
* 46.(**值得看看REPA**)扩散模型训练方法一直错了！谢赛宁：Representation matters  机器之心  https://mp.weixin.qq.com/s/a725rxzvyQXqNJoL1NsMaA \
  是什么让纽约大学著名研究者谢赛宁三连呼喊「Representation matters」？他表示：「我们可能一直都在用错误的方法训练扩散模型。」即使对生成模型而言，表征也依然有用。基于此，他们提出了 **REPA**，即**表征对齐技术**，其能让「训练扩散 Transformer 变得比你想象的更简单。」 \
  ???什么是REPA，表征对齐技术 \
  Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think
* 47.(**值得看看**)首个o1复现开源RL框架OpenR来了，UCL、上交等高校联合团队发布  机器之心  https://mp.weixin.qq.com/s/Dr9IzbUjiWtZT7bgr58T2g \
  Learning to Reason with LLMs \
  论文：https://github.com/openreasoner/openr/blob/main/reports/OpenR-Wang.pdf \
  代码链接：https://github.com/openreasoner/openr \
  教程链接：https://openreasoner.github.io/
* 48.更快、更强、更经济！港大开源大模型RAG系统LightRAG  新智元  https://mp.weixin.qq.com/s/oMtlTR1bOneohM9RhcX7Xg \
  LIGHTRAG: SIMPLE AND FAST RETRIEVAL-AUGMENTED GENERATION
* 49.李飞飞「数字表兄弟」破解机器人训练难题！零样本sim2real成功率高达90%  新智元  https://mp.weixin.qq.com/s/UHQmxbCpYpAZYWQHzw1kQA \
  Automated Creation of Digital Cousins for Robust Policy Learning

# 10.15 Tue
* 50.NeurIPS 2024 | 突破性全局剪枝技术SparseLLM：大语言模型稀疏化革命 
PaperWeekly  https://mp.weixin.qq.com/s/PJhjCJz5ZIL0HyhakgzOdQ \
  SparseLLM: Towards Global Pruning of Pre-trained Language Models

# 10.16 Wed
* 51.机器人世界模型，TeleAI用少量数据完成训练 | NeurIPS 2024  量子位  https://mp.weixin.qq.com/s/bFVwWpjFQpTTWkbpaEqYCQ \
  Learning an Actionable Discrete Diffusion Policy viaLarge-Scale Actionless Video Pre-Training
* 52.(**有趣，值得看看**)宇宙竟是一个智能体？万物智能演化Ω理论，探索宇宙终极之迷  新智元  https://mp.weixin.qq.com/s/g0k484uR5shKgyJpFpnfnQ \
  From Observer to Agent: On the Unification of Physics and Intelligence Science
* 53.重新定义自监督学习！LeCun团队让MMCR再进一步  新智元  https://mp.weixin.qq.com/s/uO3P37tDwdwjb4_y_066Ow \
  Towards an Improved Understanding and Utilization of Maximum Manifold Capacity Representations \
  ???最大流形容量表示法（MMCR）
* 54.(**值得看看**)补齐Transformer规划短板又不放弃快速思考，田渊栋团队的Dualformer融合System 1和2双重优势  机器之心  https://mp.weixin.qq.com/s/d-MkVjYjyIInRYLhc_01-A \
  来自 Meta FAIR 田渊栋团队从人类认知理论中获得了灵感，提出了一种新型 Transformer 架构：Dualformer \
  用户可以指定在推理过程中使用快速或慢速模式，在未指定时模型也可以自行决定 \
  Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces

# 10.17 Thur
* 55.
* 56.
* 57.
* 58.
* 59.
* 60.

# 10.18 Fri
# 10.19 Sat
# 10.20 Sun

# 10.21 Mon
# 10.22 Tue
# 10.23 Wed
# 10.24 Thur
# 10.25 Fri
# 10.26 Sat
# 10.27 Sun

# 10.28 Mon
# 10.29 Tue
# 10.30 Wed
# 10.31 Thur
