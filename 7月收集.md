# 7.1 周六
* 1、斯坦福大学吴佳俊：通过自然监督编码理解视觉世界 https://mp.weixin.qq.com/s/R5vyph7RBZOaPW0Tu1BK0A
我们利用自然界中存在的丰富的结构、符号和程序，是为了在视觉世界中更好地感知，更好地理解。因此，有很多丰富的视觉效果，或者场景，你会意识到这不仅仅是像素，尽管这些模型总是以像素为基础，但它们实际上是比像素更丰富的结构。我们是否有可能利用像素之外的某种结构信息，用于智能场景理解和编辑。

# 7.2 周日
* 2、赋予LLM视觉理解能力，360人工智能研究院开源中文多模态对话模型SEEChat https://mp.weixin.qq.com/s/6cPjK5LlP6WFP_XQQ5RRsQ
* 3、大模型与端到端会成为城市自动驾驶新范式吗？ https://mp.weixin.qq.com/s/_Z5ZJV896rPMARkHSflOVA
* 4、首个见证AI重大突破的领域：数学 https://mp.weixin.qq.com/s/jg-Wg9dAW89ALgbT1WeTjw
  项目地址：https://leandojo.org/
  加州理工、英伟达、MIT等机构的学者，构建了一个基于开源LLM的定理证明器。
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9874c22c-f70e-4494-a7be-f08df767f69c)

# 7.4 周二
* 5、理解指向，说出坐标！开源模型“Shikra”开启多模态大模型“参考对话”新模式！ https://mp.weixin.qq.com/s/wIkhAcHgqeQ3LA12J6oBnA
在人类的日常交流中，经常会关注场景中不同的区域或物体，人们可以通过说话并指向这些区域来进行高效的信息交换。这种交互模式被称为参考对话（Referential Dialogue）。
如果 MLLM 擅长这项技能，它将带来许多令人兴奋的应用。例如，将其应用到 Apple Vision Pro 等混合现实 (XR) 眼镜中，用户可以使用视线注视指示任何内容与 AI 对话。同时 AI 也可以通过高亮等形式来指向某些区域，实现与用户的高效交流。
本文提出的 Shikra 模型，就赋予了 MLLM 这样的参考对话能力，既可以理解位置输入，也可以产生位置输出。
论文地址：http://arxiv.org/abs/2306.15195
代码地址：https://github.com/shikras/shikra
![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/99972fa3-d5b0-4877-a886-f87253027564)

# 7.5 周三
* 6、大模型自主智能体爆火，OpenAI也在暗中观察、发力，这是内部人的分析博客 https://mp.weixin.qq.com/s/_IkpIIqeKbAj-shvnCV8rg
  ！！！自主智能体，值得看看
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2b847109-b322-46ec-8559-2954541ac657)

# 7.6 周四
* 7、AI智能体卷爆大模型！AutoGPT等4大Agent打擂，「西部世界」谁将成为软件2.0？ https://mp.weixin.qq.com/s/b04F8oQfRaY2z-FjzA4pMw
  项目1：斯坦福、谷歌「西部世界」  项目2：Camel   项目3：BabyAGI  项目4：AutoGPT
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/63783013-56d1-46ce-a50c-2d64f03429dd)
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/595507ed-f3bf-43a7-b1e5-a53f4a26e1dc)
* 8、OpenAI预言：超级智能10年内降临！正集结算力拯救人类，4年彻底攻克对齐 https://mp.weixin.qq.com/s/X2HfzAxaoSg-28k7BRLvqA
* 9、破解大模型「涌现」之谜：新奇性搜索是AI腾飞的踏脚石 https://mp.weixin.qq.com/s/xPgifx46aZijR_7k-ARE_Q
* 10、Nature：大模型越大越好吗【好文译递】第 8 期 https://mp.weixin.qq.com/s/D1F0fIBP8jDGBD9YF-XmVA 《 In AI, is bigger always better?》
* 11、首个全量化Vision Transformer的方法FQ-ViT，AI大模型落地不远了！  https://mp.weixin.qq.com/s/bipXFZG4lczlqcsMvBMeBA
* 12、【2023新书】决策智能手册：在复杂世界中基于证据做出决策的实用步骤, 376页pdf https://mp.weixin.qq.com/s/V2dbSmOlv3xXq-thMZHDEw
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/a245f9a2-89e9-493b-895f-02f1de8912af)
* 13、大型视觉模型和视觉提示工程 https://mp.weixin.qq.com/s/wFQ3eTXw7SyhBZe80E6gsQ ？？？什么是视觉提示工程
* 14、太牛了！微软最新研究：LONGNET，Transformer序列长度可支持 10亿+ Token https://mp.weixin.qq.com/s/zJE-1xtD49vUiUOqlv3Hpw
  微软研究提出了一种Transformer变体：LONGNET，该架构将序列标记长度扩展到了10亿+，且并不会影响较短序列的性能。LONGNET的核心是扩展注意力，将计算复杂度从二次降低到线性。LONGNET可以用作分布式训练器，「跨多个GPU」设备并行训练序列。

# 7.9 周日
* 15、大模型时代，解析周志华教授的「学件」思想：小模型也可做大事 https://mp.weixin.qq.com/s/mYWSDAXzlx-ZW9fE5eVilQ

# 7.10 周一
* 16、李飞飞「具身智能」新成果！机器人接入大模型直接听懂人话，0预训练就能完成复杂指令 https://mp.weixin.qq.com/s/XleXS_5shzZNiOSxUFZfgQ
  大模型接入机器人，把复杂指令转化成具体行动规划，无需额外数据和训练。  **！！！非常重要**
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2f4526f3-3616-4f4b-b194-11e9d94ccd15)
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b0c67d0d-1f5f-422e-8daa-de480614e393)

# 7.12 周三
* 17、YoloV8与ChatGPT互通，这功能是真的强大！ https://mp.weixin.qq.com/s/ODIFRyvfbZOiEORLdWGc_A
* 18、百川开源最强中英文百亿参数模型！超越LLaMA，中国开源大模型开启商用新纪元 https://mp.weixin.qq.com/s/tVc2zvW3JHJbxln-tCuxIQ
* 19、NLP算法培养计划：跟着大佬一起学，不上岸全额退！ https://mp.weixin.qq.com/s/MN_2st7eU0GEQxUuu8uTWg

# 7.13 周四
* 20、语言大模型的进化轨迹 https://mp.weixin.qq.com/s/NyCawOqtA5mH4Ht5nUFOwg
* 21、Transformer作者：指令型智能体的构建之法 https://mp.weixin.qq.com/s/Vt_TGHKaifKVfDPfmKaqKw

# 7.14 周五
* 22、清华大学&腾讯提出DreamDiffusion：你大脑中的画面，可以高清还原了！ https://mp.weixin.qq.com/s/tC2f2FxPMjZCfVH5k1TOYA
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/c3ec229a-1a03-422a-895b-08e277b3fe52)
  论文地址：https://arxiv.org/pdf/2306.16934
  项目地址：https://github.com/bbaaii/DreamDiffusion

# 7.18 周二
* 21、Transformer后继有模！MSRA提出全新大模型基础架构：推理速度8倍提升，内存占用减少70% https://mp.weixin.qq.com/s/zJsb2vdpEwqXEUgqHmpInA
  Retentive Network（RetNet）：大模型领域Transformer的继任者。RetNet实现了良好的扩展结果、并行训练、低成本部署和高效推理。这些特性使这一基础架构，成为大语言模型中Transformer的有力继承者。
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e48e7352-9344-4e6b-8ae0-8a4d67c40b71)

# 7.19 周三
* 22、Google DeepMind掌舵人Demis Hassabis专访：合并后「超级单元」内幕，以及如何开展下一代模型研究  https://mp.weixin.qq.com/s/xnaGDDArWE4gcfxl6GphqA
  DeepMind 与 Google Brain合并为超级单元（super unit）
* 21、更强的Llama 2开源，可直接商用：一夜之间，大模型格局变了 https://mp.weixin.qq.com/s/klFWFXCbjGaWZ7HO1KFZag
  今日，Meta 终于发布了大家期待已久的免费可商用版本 Llama 2。
  大模型社区再掀波澜，Meta重磅开源LLAMA-2，性能升级可商用 https://mp.weixin.qq.com/s/Eqh-ED4BgiR4BBQQbwXAmA
* 22、AI学语言与人脑极为相似！新研究证明：语言并非人类与生特有的能力，机器也能学丨Nature子刊  https://mp.weixin.qq.com/s/SG0jzmBcu9Ff8NcGmdw1gQ
* 23、类脑智能软硬件协同创新，自动化所团队研发脉冲神经网络加速器“智脉·萤火” https://mp.weixin.qq.com/s/sCELNbxCbbiO2Asgur5Kuw
  一、创新地利用了FPGA器件中的专用运算模块DSP48E2实现脉冲神经网络的高效运算
  二、设计了一个内存系统实现高效的突触权重和膜电压内存访问
  三、运算吞吐率达到了5.53TOP/s，在多个数据集和脉冲神经网络上取得了明显的加速效果

# 7.20 周四
* 24、
  






