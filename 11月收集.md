# 11.1 周三
* 1、(**ControlLLM**)复杂任务也不怕！上海AI Lab提出增强型LLM框架—ControlLLM，大模型可操控多模态工具  夕小瑶科技说  https://mp.weixin.qq.com/s/ycv21NmaHzKpGdjA8RitdA \
  论文题目:ControlLLM: Augment Language Models with Tools by Searching on Graphs \
  论文链接:https://arxiv.org/abs/2310.17796

# 11.2 周四
* 2、(**非常值得研究**)谷歌DeepMind&CMU利用大模型让机器狗像人一样高效使用工具！搭建桥梁、利用杠杆原理搬起重物都不在话下  夕小瑶科技说  https://mp.weixin.qq.com/s/Qetjro4tQwFCduUi0xK3cQ \
  研究人员借助LLM强大的推理、规划能力，建立了一个基于LLM的RoboTool系统，设置四个核心组件分析器、规划器、计算器、编码器，一步一步赋予机器人灵活使用工具的能力。 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/562b998f-2d41-4968-abf5-a0ab049f3e42) \
  论文标题：CREATIVE ROBOT TOOL USE WITH LARGE LANGUAGE MODELS \
  论文链接:https://arxiv.org/pdf/2310.13065.pdf \
  演示地址：https://creative-robotool.github.io/
* 3、(**有趣**)西工大提出全新「群聊式」无人机控制框架！类人对话交互、主动环境感知、自主实体控制  新智元  https://mp.weixin.qq.com/s/JQm1KLKrL5QjJFnHCLk4Zg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/49cbb4c3-e895-4974-8092-0d5982ace3c4)
* 4、(**不太相信，意识的产生可能没有那么简单**)OpenAI首席科学家：ChatGPT已经出现意识，人类未来将与AI融合  新智元  https://mp.weixin.qq.com/s/uWMQpidZpffxNt-JYD3Dog \
  惊~！OpenAI科学家表示：ChatGPT已经出现意识  AINLPer  https://mp.weixin.qq.com/s/vd2RIcoxywRTWu0ksQIqGw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b67b7535-22da-4cfd-b0b5-86b8efcfa1a1) \
  文章地址：https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/
* 5、(**值得看看**)大语言模型的数学之路  PaperWeekly  https://mp.weixin.qq.com/s/BXQVY7rjlwjAkSxWg_dtcQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/427fbc41-e7dd-4d3f-bbba-4a077ef0525e)
* 6、EMNLP2023 | “魔改Transformer”，AWS提出：MASFormer，计算成本降低75%！  AINLPer  https://mp.weixin.qq.com/s/ZkSjiqIfjGt9lqnlHq7LBg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/552ceeac-2362-4845-8697-039ed44517d2) \
  Paper：https://arxiv.org/pdf/2310.12442.pdf

# 11.3 周五
* 7、聊聊我对AI Agents技术的一些看法  夕小瑶科技说  https://mp.weixin.qq.com/s/YI7FX62yRV4-1qA8O3sH4g \
  AI Agent 不断被冠以“大模型下半场”，“**软件 2.0**（ Software 2.0）”等等称号，连 OpenAI 的创始成员 Andrej Karpathy 也在十月份的黑客马拉松演讲中也表示： \
  相比模型训练方法，OpenAI 内部目前更关注 Agent 领域的变化，每当有新的 AI Agents 论文出来的时候，内部都会很兴奋并且认真地讨论。\
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7c45c05f-ae7d-4ffb-9e53-dcfffe105c91) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d8157d83-f565-43dd-9b5b-4be9c3451e9f)
* 8、GPT-4 做「世界模型」，让LLM从「错题」中学习，推理能力显著提升  机器之心  https://mp.weixin.qq.com/s/PUMOWchSPjTglrXzxECxsA \
  通过逆向学习过程（即从 LLM 犯过的错误中学习）进一步提高其推理能力 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d3e25d68-d61b-44f7-b68c-372974943c61) \
  论文地址：https://arxiv.org/pdf/2310.20689.pdf
* 9、纯干货！一文带你了解大模型(LLMs)对齐，非常详细~  AINLPer  https://mp.weixin.qq.com/s/BPpa6e-5YdVo21DLTmoNOw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9381479e-aad1-462a-b2a0-f8fb513980ff) \
  论文（持续更新）：arxiv.org/abs/2310.19852 \
  AI Alignment 纵览网站（持续更新）：www.alignmentsurvey.com \
  GitHub：github.com/PKU-Alignment/AlignmentSurvey \
  Newsletter & Blog（邮件订阅，定期更新）：alignmentsurvey.substack.com

# 11.4 周六
* 10、(**robogen值得看看**)CMU清华MIT引爆全球首个Agent无限流，机器人「007」加班自学停不下来！具身智能被革命  新智元  https://mp.weixin.qq.com/s/2bQTuwE-k6ukp--XHXIzMg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/3b994202-773a-400a-a927-1518f71a29c6) \
  论文地址：https://arxiv.org/abs/2311.01455 \
  项目主页：https://robogen-ai.github.io/ \
  开源地址：https://github.com/Genesis-Embodied-AI

# 11.5 周日
* 11、(**有趣，值得看看ZeroNVS，什么个原理**)AI「脑补」画面太强了！李飞飞团队新作ZeroNVS，单个视图360度全场景生成  新智元  https://mp.weixin.qq.com/s/8OAzkkT0vGsXbLQULHyb6A \
  3D感知扩散模型——ZeroNVS \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f1ac9b27-3f87-4a9a-8352-c24ba277184d) \
  论文地址：https://arxiv.org/pdf/2310.17994.pdf \
  参考资料：https://twitter.com/drfeifei/status/1719778264947016077
* 12、(**有趣，看看具体怎么实现的**)GPT-4V可以用鼠标上网啦？MIT本科生出品  夕小瑶科技说  https://mp.weixin.qq.com/s/kawEec_W_XjrbLKrycykLw \

# 11.6 周一
* 13、GPU推理提速4倍，256K上下文全球最长：无问芯穹刷新大模型优化记录  机器之心  https://mp.weixin.qq.com/s/e9OHATqk88Q9zM3Y5czFQA
* 14、(**为啥，是因为没有意识吗？**)谷歌DeepMind力证：GPT-4终局是人类智慧总和！Transformer模型无法超越训练数据进行泛化  新智元  https://mp.weixin.qq.com/s/Vzsm-0Fk7mEWTO3tnNfhvA \
  Transformer模型是否能够超越预训练数据范围，泛化出新的认知和能力，一直是学界争议已久的问题。最近谷歌DeepMind的3位研究研究人员认为，要求模型在超出预训练数据范围之外泛化出解决新问题的能力，几乎是不可能的。\
  ？？？这到底是为什么呢，难道产生解决新问题的能力是一种超级复杂的计算，图灵机无法完成这个计算，需要量子层面的计算能力才能做到？
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/b5f30675-11f9-41f2-a371-ee9113fe64fd) \
  论文地址：https://arxiv.org/abs/2311.00871
* 15、(**看看演讲，会很有启发的**)宇宙尽头是「计算」！AI大佬Wolfram最新演讲：LLM自主在计算空间探索，奇点降临就是现在  新智元  https://mp.weixin.qq.com/s/cn6atcDNnExXtyN2iQlFFQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/61084bcf-9caa-4158-b23c-db6a5d8e5a7e) 
* 16、多模态物体幻觉下降23%！UNC斯坦福等推出通用修正器LURE：兼容任意LVLM，专攻三大幻觉成因  新智元  https://mp.weixin.qq.com/s/DLbCLorF9M7J8vikfQgNBg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/1b853ddd-cda0-4b48-82e8-01abcedbdbf2) \
  论文地址: https://arxiv.org/abs/2310.00754 \
  代码地址: https://github.com/YiyangZhou/LURE
* 17、(**有趣，看看怎么实现的**)GPT-4V 也会追剧、刷抖音、打游戏、玩手机？微软 MM-VID 充分释放 GPT-4V 潜力！  夕小瑶科技说  https://mp.weixin.qq.com/s/bXkIGXcpJRoJJU1k_OMsog \
  论文题目：《MM-VID : Advancing Video Understanding with GPT-4V(ision)》 \
  论文链接：https://arxiv.org/pdf/2310.19773.pdf
* 18、(**iTransformer**)重新审视Transformer：倒置更有效，真实世界预测的新SOTA出现了  PaperWeekly  https://mp.weixin.qq.com/s/1Azl_8crNLFtpz3gB0eL-g \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/21cc8abe-0b58-4d32-a0b4-7b11a5633b19) \
  论文题目：iTransformer: Inverted Transformers Are Effective for Time Series Forecasting \
  论文链接：https://arxiv.org/pdf/2310.06625.pdf

# 11.7 周二
* 19、(**有趣，看看LLaMA-Rider**)让大模型自主探索开放世界，北大&智源提出训练框架LLaMA-Rider  机器之心  https://mp.weixin.qq.com/s/xQfuuEXVgL8luC6XJ-4ixQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/67458fab-847c-419e-bdd0-9283b6764da0) \
  论文链接：https://arxiv.org/abs/2310.08922 \
  代码链接：https://github.com/PKU-RL/LLaMA-Rider \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/41191022-2806-4029-92e2-5116e1b93490) 
* 20、让大模型忘记哈利波特，微软新研究上演Llama 2记忆消除术，真·用魔法打败魔法（doge）  量子位  https://mp.weixin.qq.com/s/m64cw7wOKBwn7CmXtR0Dtg \
  Llama2失忆啦！微软教你三步抹掉模型的哈利波特记忆  夕小瑶科技说  https://mp.weixin.qq.com/s/wzjp_mHj2Unx3p2mgdH2fg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/713c06de-a4d5-432b-bfdd-37de2441b1bd) \
  参考链接：\
  [1]https://arxiv.org/abs/2310.02238（论文） \
  [2]https://www.microsoft.com/en-us/research/project/physics-of-agi/articles/whos-harry-potter-making-llms-forget-2/
* 21、大模型集体失控！南洋理工新型攻击，主流AI无一幸免  量子位  https://mp.weixin.qq.com/s/Zlsq5kfwPLW6KpbwRyQD_Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/686618cc-0ff5-43dc-a197-2923ebca330b) \
  论文链接：https://arxiv.org/abs/2307.08715
* 22、吴佳俊、李飞飞联合大作！提出全新脑机系统，用大脑操控机器人帮你做家务，要照进现实啦！  夕小瑶科技说  https://mp.weixin.qq.com/s/jEg1DitP9iiwA6r614wIWA \
  论文题目:NOIR: Neural Signal Operated Intelligent Robots for Everyday Activities \
  论文链接:https://openreview.net/pdf?id=eyykI3UIHa \
  项目地址:https://noir-corl.github.io/

# 11.8 周三
* 23、OpenAI大佬甩出「喵喵GPT」调戏黑客！分享ChatGPT成功的秘密：极限压榨GPU资源  新智元  https://mp.weixin.qq.com/s/J1OelO0gz0BKhu4CX9BX1A 
* 24、10分钟定制一个「陈天奇GPT」，OpenAI新品大波实测来袭！Sam Altman降维打击，千家AI初创公司入土  新智元  https://mp.weixin.qq.com/s/5MKmjybE9-6bRNTr8lc5TA \
  用过GPT-4 Turbo以后，我们再也回不去了  机器之心  https://mp.weixin.qq.com/s/1oGfwQFhCsiFKOqPDS6GcQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/de921213-243f-4869-908a-84ca3b4424a4)
* 25、(**可以参考参考**)解说梅西球赛、英雄联盟，OpenAI GPT-4视觉API被开发者玩出新花样  机器之心  https://mp.weixin.qq.com/s/5QIdChH-M4kfHt0c9DzL-w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/88098790-8972-4b74-b3f0-4b2667e060a4) \
  参考链接：\
  https://twitter.com/geepytee/status/1721705524176257296 \
  https://twitter.com/xiaohuggg/status/1721819447516942716 \
  https://twitter.com/sandst1/status/1722008957881876982
* 26、(**可以玩玩该项目用的仿真软件**)北大具身智能团队提出需求驱动导航，对齐人类需求，让机器人更高效  机器之心  https://mp.weixin.qq.com/s/Sj2q02VkY6HMzHDot6X9_w \
  北京大学董豪团队提出了一个新的导航任务 —— 需求驱动导航（Demand-driven Navigation，DDN） \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/17d3257d-8570-4b1c-8965-a98a007c0ddb) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ba0ebd71-16bd-44f5-ac5c-b09f3dfa1375) \
  论文地址：https://arxiv.org/pdf/2309.08138.pdf \
  项目主页：https://sites.google.com/view/demand-driven-navigation/home
* 27、2028年第一个AGI将到来？谷歌DeepMind提6条AGI标准，定义5大AGI等级  新智元  https://mp.weixin.qq.com/s/MUKcHWIFydMrzirlKPNfXQ \
  ChatGPT只算L1阶段，谷歌提出AGI完整路线图  量子位  https://mp.weixin.qq.com/s/7G1Sp4AABEMEuqApxngJ7A \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/5099e871-eb36-41ac-847d-81f7c16bd21c) \
  论文地址：https://arxiv.org/abs/2311.02462 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/eefbe16e-a38c-4147-a5ae-a1e315c3ce01) \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/9cfd202d-d892-46f0-8a40-75363e0dd791) \
  在这个技术之上，作者提出了6种人机互动模式：无AI、AI工具、AI顾问、AI协作者、AI专家、AI智能体。 \
  参考资料：https://huggingface./papers/2311.02462
* 28、姚班天才开发《完蛋！我被大模型包围了》游戏爆火，一日用户过万挤爆服务器  量子位  https://mp.weixin.qq.com/s/FpX0AcHQfQqT5V5-PAp22w

# 11.9 周四
* 29、李飞飞新书《我看到的世界》正式发售！忧心斯坦福没有训练ChatGPT算力，自称不是AI毁灭派  新智元  https://mp.weixin.qq.com/s/QtdOEaDuN-Bwdt6b9ZZmIA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/30495c0f-3536-4c1c-94b1-b12bf9283be4)
* 30、GPT-5明年降临？爆料人泄露多模态Gobi就是GPT-5，已初现自我意识  机器学习研究组订阅  https://mp.weixin.qq.com/s/P_dVhhPm7rcqP-L4pS_tvg
* 31、大模型如何归因？哈工大等《大型语言模型归因》最新综述  专知  https://mp.weixin.qq.com/s/USprVxqzGz181XqkXj61HA \
  大模型如何归因？哈工大等《大型语言模型归因》最新综述  机器学习研究组订阅  https://mp.weixin.qq.com/s/h91QudEmtUjFv9_TpDrZew \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/ebb3ecfc-8e8d-44c5-b678-31a3631bae61)

# 11.10 周五
* 32、(**值得看看**)大语言模型里的Transformer，竟然还可以这么用！？  AINLPer  https://mp.weixin.qq.com/s/O8qeGcGOJrWV7K4B-o6-Zg \
  在语言模型中 Pretrain 的 Transformer 可以用作视觉任务的 Encoder Layer \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/3d902c76-0ada-43ef-b3fc-31b7f032d2b5) \
  论文题目：Frozen Transformers in Language Models Are Effective Visual Encoder Layers \
  论文链接：https://arxiv.org/abs/2310.12973 \
  代码链接：https://github.com/ziqipang/LM4VisualEncoding

# 11.11 周六
* 33、北大&腾讯打造多模态15边形战士！语言作“纽带”，拳打脚踢各模态，超越Imagebind  量子位  https://mp.weixin.qq.com/s/vHgq9MZaiAxoiaZGdydYXA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/01c65baf-1dea-43eb-ae87-4883de24b2b3)

# 11.12 周日
* 34、GPT-4比你更会问问题：让大模型自主复述，打破与人类对话的壁垒  机器之心  https://mp.weixin.qq.com/s/LcTTgxm49isqxxWWuGwSUg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/63ec359d-eeea-44fb-b4bf-58ada2b3aae8) \
  论文地址：https://arxiv.org/pdf/2311.04205.pdf \
  项目地址: https://uclaml.github.io/Rephrase-and-Respond
* 35、斯坦福提出对比偏好学习：无需强化学习即可从人类反馈中学习  机器之心  https://mp.weixin.qq.com/s/XyBxg5lukjNmvkt_oBGrcQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/867271f7-4e6f-48d7-a558-e16aa5c9a15f) \
  论文地址：https://arxiv.org/pdf/2310.13639.pdf \
  代码地址：https://github.com/jhejna/cpl

# 11.13 周一
* 36、视觉分词器统一图文信息，快手提出基座模型 LaVIT 刷榜多模态任务  夕小瑶科技说  https://mp.weixin.qq.com/s/krsX4BA0J7pGLu9O5-wkiw \
  论文题目:Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization \
  论文链接:https://arxiv.org/abs/2309.04669 \
  Github 地址:https://github.com/jy0205/LaVIT
* 37、(值得看看)谷歌DeepMind爆火动画18秒解释LLM原理，网友蒙圈！组团求GPT-4下场分析  新智元  https://mp.weixin.qq.com/s/nMmRu1_oMDk_fUPAbSaHyQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/87f51e35-ff39-4540-93d5-dc2df5edb0ed)
* 38、全新近似注意力机制HyperAttention：对长上下文友好、LLM推理提速50%  机器之心  https://mp.weixin.qq.com/s/RxdX02Z-AoBsQCFrgrWqiA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f21b5502-9d4a-4315-a63a-c491fe569794) \
  论文地址：https://arxiv.org/abs/2310.05869
* 39、破解自注意力推理缺陷的奥秘，蚂蚁自研新一代Transformer或实现无损外推  机器之心  https://mp.weixin.qq.com/s/c6sLSxxZF6Y9IxBtPR9uUQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/6aa784e0-ae30-411f-84e7-8779801abb3c) \
  论文地址：https://arxiv.org/abs/2309.08646 \
  Github仓库：https://github.com/codefuse-ai/Collinear-Constrained-Attention \
  ModelScope：https://modelscope.cn/models/codefuse-ai/Collinear-Constrained-Attention/summary \
  HuggingFace：敬请期待

# 11.14 周二
* 40、终结扩散模型，IGN单步生成逼真图像！UC伯克利谷歌革新LLM，美剧成灵感来源  新智元  https://mp.weixin.qq.com/s/S9YcOrIlZEGrZSomapck8Q \
  终结扩散模型！谷歌&伯克利提出IGN：单步生成逼真图像！  计算机视觉daily  https://mp.weixin.qq.com/s/UKNMPUbjaMVltawpwsLXFw \
  IGN 幂等生成网络 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/75891d64-0d98-4051-a6c1-ec22d287469e) \
  论文地址：https://arxiv.org/abs/2311.01462
* 41、谷歌DeepMind力证：Transformer模型无法超越训练数据进行泛化！GPT-4终局是人类智慧总和！  计算机视觉Daily  https://mp.weixin.qq.com/s/HhILnwk1ZB9wRWs3N0xa9w \
  最近谷歌DeepMind的3位研究研究人员认为，要求模型在超出预训练数据范围之外泛化出解决新问题的能力，几乎是不可能的。\
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4d297afb-2ea7-47b1-b4e3-22fc1a16559b) \
  论文地址：https://arxiv.org/abs/2311.00871 \
  Jim Fan转发论文后评论说，这明确说明了训练数据对于模型性能的重要性，所以数据质量对于LLM来说实在是太重要了。 \
* 42、(**ProAgent值得看看**)被OpenAI带火的Agent如何解放人力？清华等发布ProAgent  机器之心  https://mp.weixin.qq.com/s/eucYZiCvJPxzQ4C98zzT8A \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4945faf9-3819-4eee-9f3d-cb459101bd60) \
  项目地址：https://github.com/OpenBMB/ProAgent \
  论文地址：https://github.com/OpenBMB/ProAgent/blob/main/paper/paper.pdf \
  团队相关研究 \
  目前研究团队已在大模型智能体方向有诸多研究，包括： \
  XAgent：超强大模型智能体应用框架，可自行拆解复杂任务，并高效执行。 \
  项目地址：https://github.com/OpenBMB/XAgent \
  ChatDev：多智能体协作开发框架，让多个不同角色的智能体进行协作，自动化开发软件应用。 \
  项目地址：https://github.com/OpenBMB/ChatDev \
  AgentVerse：大模型驱动的智能体通用平台，招募各种各样的 agent 专家，共同帮助用户解决复杂任务。\
  项目地址：https://github.com/OpenBMB/AgentVerse \
* 43、大模型怎么用知识？哈工大等最新《知识与大型语言模型整合趋势》综述，详述知识编辑与检索增强方法  专知  https://mp.weixin.qq.com/s/WpimyytuYJAwkM2si2Sr5Q \
  
# 11.15 周三

# 11.16 周四
* 44、(**值得研究**)S-LoRA：一个GPU运行数千大模型成为可能  机器之心  https://mp.weixin.qq.com/s/obcrdbf1kpYRDTd5Qqa5sA \
  斯坦福 && UC伯克利 | 提出 S-LoRA大模型微调方法，单个GPU支持上千适配器  AINLPer  https://mp.weixin.qq.com/s/5VOGev2TLQNuT9GR16U2hQ \
  S-LoRA 是专为众多 LoRA 适配程序的可扩展服务而设计的系统，它将所有适配程序存储在主内存中，并将当前运行查询所使用的适配程序取到 GPU 内存中 \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/f874d1bc-6c9c-49a2-9f3b-d8eda2992555) \
  论文地址：https://arxiv.org/pdf/2311.03285.pdf \
  项目地址：https://github.com/S-LoRA/S-LoRA \
  一个LLM的base权重配合多个LoRA适配器权重使用
* 45、(**值得玩玩**)成本2元开发游戏，最快3分钟完成！全程都是AI智能体“打工”，大模型加持的那种  量子位  https://mp.weixin.qq.com/s/7QOEd0ZkumPWnoVxIo5eTA \
* 46、(**不懂，不知是否有用**)通用人工智能（AGI）已经到来？深度解析 ChatGPT 获得智能的数学物理机理  集智俱乐部  https://mp.weixin.qq.com/s/KV1gyu1pdl6ErkX7QD-I1w \
  <img width="272" alt="1701697152709" src="https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/d8fbf162-7095-4777-9ee7-0b343e4b5fa8">

# 11.17 周五
* 47、13B模型全方位碾压GPT-4？这背后有什么猫腻  机器之心  https://mp.weixin.qq.com/s/1eDxT-qCgEsLZoGlhHNADg \
  参数量13B模型全方位碾压GPT-4？这背后有什么猫腻  PaperWeekly  https://mp.weixin.qq.com/s/b0N2OrLl1LhDT7zdX4xMrA \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4429e9b6-177b-476e-85b9-7932c0abc66c) \
  论文地址：https://arxiv.org/pdf/2311.04850.pdf \
  项目地址：https://github.com/lm-sys/llm-decontaminator#detect \
  (数据去污)

# 11.18 周六
  
# 11.19 周日
* 48、(**值得看看**)Nature：大模型只会搞角色扮演，并不真正具有自我意识  量子位  https://mp.weixin.qq.com/s/jTyGU0YI8DkCxbEYurjTsw \
  Nature：大模型只会搞角色扮演，并不真正具有自我意识  脑机接口社区  https://mp.weixin.qq.com/s/tNbxb4TZAaYX54d3giJcrQ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/59c6e582-6f4c-4d0e-8a95-90d82b69286d) \
  论文链接：https://www.nature.com/articles/s41586-023-06647-8 \
  这表明大模型不会通过扮演角色来实现自己的目标，它的本质只是一系列角色的叠加，并在与人们的对话中逐渐明确自己要扮演的身份，并尽力扮演好这个角色。
* 49、(**值得看看**)梅拉妮·米歇尔Science刊文：AI能否自主学习世界模型？  集智俱乐部  https://mp.weixin.qq.com/s/Ml7N8zPCW7O6PvRoU1LxEg \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4925fd40-9280-4d1b-ae68-2ca4fb3128bb) \
  论文题目：AI’s challenge of understanding the world \
  论文地址：https://www.science.org/doi/10.1126/science.adm8175

# 11.20 周一

# 11.21 周二
* 50、NGEL-SLAM：浙大、华为最新SOTA！又快又稳！  3D视觉工坊  https://mp.weixin.qq.com/s/ma83EhC4lZzRsjuwbKGMvw \
* 51、(**可以了解了解**)丢弃99%的参数！阿里团队提出语言模型合体术，性能暴涨且无需重新训练和GPU
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/4d5fdee6-1048-4e20-bd01-9aa987137bd6) \
  论文题目：Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch
  论文链接：https://arxiv.org/abs/2311.03099
  代码链接：https://github.com/yule-BUAA/MergeLM
* 52、(**值得看看**)大规模神经网络优化：神经网络损失空间“长”什么样？  PaperlyWeekly  https://mp.weixin.qq.com/s/5KjW5Xf7i3JgKP5SFP_I_Q \
* 53、(**值得玩玩，值得实践**)用检索增强生成让大模型更强大，这里有个手把手的Python实现  机器学习研究组订阅  https://mp.weixin.qq.com/s/nI-dNv2Rse2oU3R0jXhhmA \
  检索增强生成（RAG）这一概念是指通过外部知识源来为 LLM 提供附加的信息。这让 LLM 可以生成更准确和更符合上下文的答案，同时减少幻觉。 \
  当前最佳的 LLM 都是使用大量数据训练出来的，因此其神经网络权重中存储了大量一般性知识（参数记忆）。但是，如果在通过 prompt 让 LLM 生成结果时需要其训练数据之外的知识（比如新信息、专有数据或特定领域的信息），就可能出现事实不准确的问题（幻觉） \
  因此，将 LLM 的一般性知识与附加上下文整合起来是非常重要的，这有助于 LLM 生成更准确且更符合上下文的结果，同时幻觉也更少。\
  2020 年，Lewis et al. 的论文《Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks》提出了一种更为灵活的技术：检索增强生成（RAG）

# 11.22 周三
* 54、小雪 | 通用的移动操作机器人还有多远？   北京大学前沿计算研究中心  https://mp.weixin.qq.com/s/LUBBEvS95OXNzigiHHJp9Q \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/e5f5b46e-061a-46c3-badb-2230a2627bc2) 
* 55、场景重建——将你看到的通过脑信号重建出来  脑机接口社区  https://mp.weixin.qq.com/s/YtThPuPOm2k2pGNbXNMAqw
* 56、(**值得研究与实践**)教AI Agents学会协作&竞争！首个大模型多智能体框架CAMEL已斩获3.6k星｜NeurIPS 2023  新智元  https://mp.weixin.qq.com/s/zP7DlJEhvHpRDIUel6lNhw \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/12d7b06f-abff-457f-8334-49e66e2b219a) \
  论文链接：https://ghli.org/camel.pdf \
  项目主页：https://www.camel-ai.org/ \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/7d1e1e77-2421-44c0-a330-e341d650ab77)
* 57、PyTorch团队重写「分割一切」模型，比原始实现快8倍  机器学习研究组订阅  https://mp.weixin.qq.com/s/gr-_1gM7A2vH_E_eCoCY6w \
  ![image](https://github.com/shuishenbushui/AICongyin-LLM.github.io/assets/45891944/2635379a-ff6e-428a-ac57-8c32bd7b4de3) \
  博客地址：https://pytorch.org/blog/accelerating-generative-ai/

# 11.23 周四

# 11.24 周五
* 58、0.3%参数推理，实现78倍加速！ETH团队提出UltraFastBERT，构筑语言模型巨人  PaperWeekly  https://mp.weixin.qq.com/s/ZIGS3mV7kcowk4q5loulJQ \
  ![Uploading image.png…]() \
  论文题目：Exponentially Faster Language Modeling
  论文链接：https://arxiv.org/pdf/2311.10770
  代码链接：https://github.com/pbelcak/UltraFastBERT
* 59、被OpenAI带火的Agent如何解放人力？清华NLP实验室发布流程自动化新范式  PaperWeekly  https://mp.weixin.qq.com/s/KpISuu-HPkgvsZtFBYWcnA \
  ![Uploading image.png…]() \
  论文地址：https://github.com/OpenBMB/ProAgent/blob/main/paper/paper.pdf \
  项目地址：https://github.com/OpenBMB/ProAgent
* 60、

# 11.25 周六
# 11.26 周日
# 11.27 周一
# 11.28 周二
# 11.29 周三
# 11.30 周四


